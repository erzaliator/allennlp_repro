{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2003\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "\n",
    "batch_size = 4\n",
    "batches_per_epoch = 541\n",
    "\n",
    "save_path_suffix = '18_refactor_feature_embedding_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_classes_not_in_test(train_df, val_df, test_df):\n",
    "#     test_labels = list(test_df['label'].unique())\n",
    "#     train_df = train_df[train_df['label'].isin(test_labels)]\n",
    "#     val_df = val_df[val_df['label'].isin(test_labels)]\n",
    "#     return train_df, val_df, test_df\n",
    "\n",
    "# train_df, val_df, test_df = remove_classes_not_in_test(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.get_feature_mappings()\n",
    "    self.set_feature_list()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    self.calculate_unique_values()\n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.test_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def get_feature_mappings(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def get_distance(self, d):\n",
    "    if d<-8: return 0.0\n",
    "    elif d>=-8 and d<-2: return 1.0\n",
    "    elif d>=-2 and d<0: return 2.0\n",
    "    elif d>=0 and d<2: return 3.0\n",
    "    elif d>=2 and d<8: return 4.0\n",
    "    elif d>=8: return 3.0\n",
    "    else: raise ValueError()\n",
    "\n",
    "  def get_dep(self, d):\n",
    "    if d=='ROOT': return 0.0\n",
    "    elif d=='RIGHT': return 1.0\n",
    "    elif d=='LEFT': return 2.0\n",
    "    else: raise ValueError()\n",
    "\n",
    "  def get_boolean(self, u):\n",
    "    if u=='False': return 0.0\n",
    "    elif u=='True': return 1.0\n",
    "\n",
    "  def get_u_position(self, u):\n",
    "    if u>=0.0 and u<0.1: return 0.0\n",
    "    elif u>=0.1 and u<0.2: return 1.0\n",
    "    elif u>=0.2 and u<0.3: return 2.0\n",
    "    elif u<=0.3 and u<0.4: return 3.0\n",
    "    elif u<=0.4 and u<0.5: return 4.0\n",
    "    elif u<=0.5 and u<0.6: return 5.0\n",
    "    elif u<=0.6 and u<0.7: return 6.0\n",
    "    elif u<=0.7 and u<0.8: return 7.0\n",
    "    elif u<=0.8 and u<0.9: return 8.0\n",
    "    elif u<=0.9 and u<1.0: return 9.0\n",
    "    elif u<=1.0 and u<1e9: return 10.0\n",
    "    else: raise ValueError()\n",
    "\n",
    "  def get_lex_overlap_length(self,l):\n",
    "    if l>=0.0 and l<2.0: return -1\n",
    "    elif l>=2.0 and l<7.0: return 0\n",
    "    elif l>=7.0 and l<1e9: return 1\n",
    "    else: raise ValueError()\n",
    "\n",
    "\n",
    "  def set_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position']#, 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "\n",
    "    self.feature_unique_values = dict([(feature, set()) for feature in self.feature_list])\n",
    "\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features(self, features, feature_name):\n",
    "    feature_value = None\n",
    "\n",
    "    if feature_name=='distance': feature_value = self.get_distance(float(features[0]))\n",
    "    elif feature_name=='u1_depdir': feature_value = self.get_dep(features[1])\n",
    "    elif feature_name=='u2_depdir': feature_value = self.get_dep(features[2])\n",
    "    elif feature_name=='u2_func': feature_value = self.get_mapping_from_dictionary(column_name='u2_func', dict_val=features[3])\n",
    "    elif feature_name=='u1_position': feature_value = self.get_u_position(float(features[4]))\n",
    "    elif feature_name=='u2_position': feature_value = self.get_u_position(float(features[5]))\n",
    "    elif feature_name=='sat_children': feature_value = float(features[6])\n",
    "    elif feature_name=='nuc_children': feature_value = float(features[7])\n",
    "    elif feature_name=='genre': feature_value = self.get_mapping_from_dictionary(column_name='genre', dict_val=features[8])\n",
    "    elif feature_name=='unit1_case': feature_value = self.get_mapping_from_dictionary(column_name='unit1_case', dict_val=features[9])\n",
    "    elif feature_name=='unit2_case': feature_value = self.get_mapping_from_dictionary(column_name='unit2_case', dict_val=features[10])\n",
    "    elif feature_name=='u1_discontinuous': feature_value = self.get_boolean(features[11])\n",
    "    elif feature_name=='u2_discontinuous': feature_value = self.get_boolean(features[12])\n",
    "    elif feature_name=='same_speaker': feature_value = self.get_boolean(features[13])\n",
    "    elif feature_name=='lex_overlap_length': feature_value = self.get_lex_overlap_length(float(features[14]))\n",
    "    elif feature_name=='u1_func': feature_value = self.get_mapping_from_dictionary(column_name='u1_func', dict_val=features[15])\n",
    "    else:\n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    self.feature_unique_values[feature_name].add(feature_value)\n",
    "    return feature_value\n",
    "\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==16\n",
    "    return list(map(lambda i: self.get_allen_features(features, i), self.feature_list))\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature in self.feature_list:\n",
    "      self.feature_unique_values[feature] = len(self.feature_unique_values[feature])\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      distance = row['distance']\n",
    "      u1_depdir = row['u1_depdir']\n",
    "      u2_depdir = row['u2_depdir']\n",
    "      u2_func = row['u2_func']\n",
    "      u1_position = row['u1_position']\n",
    "      u2_position = row['u2_position']\n",
    "      sat_children = row['sat_children']\n",
    "      nuc_children = row['nuc_children']\n",
    "      genre = row['genre']\n",
    "      unit1_case = row['unit1_case']\n",
    "      unit2_case = row['unit2_case']\n",
    "      u1_discontinuous = row['u1_discontinuous']\n",
    "      u2_discontinuous = row['u2_discontinuous']\n",
    "      same_speaker = row['same_speaker']\n",
    "      lex_overlap_length = row['lex_overlap_length']\n",
    "      u1_func = row['u1_func']\n",
    "      features = [distance, u1_depdir, u2_depdir, u2_func, u1_position, u2_position, sat_children, nuc_children, genre, unit1_case, unit2_case, u1_discontinuous, u2_discontinuous, same_speaker,\n",
    "                  lex_overlap_length, u1_func]\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding='max_length')\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(self.transform_feature(features))\n",
    "\n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "    feats = torch.tensor(feats).type(torch.LongTensor)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,#shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    assert mask_ids.shape[-1]==512\n",
    "    assert seg_ids.shape[-1]==512\n",
    "    assert feat.shape[-1]==len(mnli_dataset.feature_list)\n",
    "    # y.shape==torch.Size([4])\n",
    "    # idx.shape==torch.Size([4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat,\n",
    "                            mnli_dataset=mnli_dataset)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance\n",
      "u1_depdir\n",
      "u2_depdir\n",
      "u2_func\n",
      "u1_position\n",
      "u2_position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from regex import E\n",
    "from transformers import BertModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "from torch import eq\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_modules = nn.ModuleList()\n",
    "        self.dims = 0\n",
    "        for feature in feature_list:\n",
    "            if feature=='distance':\n",
    "                print(feature)\n",
    "                self.feature_modules.append(nn.Embedding(5, 3, padding_idx=0))\n",
    "                self.dims += 3\n",
    "            elif feature=='u1_depdir':\n",
    "                print(feature)\n",
    "                self.feature_modules.append(nn.Embedding(5, 3, padding_idx=0))\n",
    "                self.dims += 3\n",
    "            elif feature=='u2_depdir':\n",
    "                print(feature)\n",
    "                self.feature_modules.append(nn.Embedding(5, 3, padding_idx=0))\n",
    "                self.dims += 3\n",
    "            elif feature=='u2_func':\n",
    "                print(feature)\n",
    "                self.feature_modules.append(nn.Embedding(23, 5, padding_idx=0))\n",
    "                self.dims += 5\n",
    "            elif feature=='u1_position':\n",
    "                print(feature)\n",
    "                self.feature_modules.append(nn.Embedding(12, 4, padding_idx=0))\n",
    "                self.dims += 4\n",
    "            elif feature=='u2_position':\n",
    "                print(feature)\n",
    "                self.feature_modules.append(nn.Embedding(12, 4, padding_idx=0))\n",
    "                self.dims += 4\n",
    "            # elif 'sat_children' in feature_list:        self.modules['sat_children'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'nuc_children' in feature_list:        self.modules['nuc_children'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'genre' in feature_list:               self.modules['genre'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'unit1_case' in feature_list:          self.modules['unit1_case'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'unit2_case' in feature_list:          self.modules['unit2_case'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u1_discontinuous' in feature_list:    self.modules['u1_discontinuous'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u2_discontinuous' in feature_list:    self.modules['u2_discontinuous'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'same_speaker' in feature_list:        self.modules['same_speaker'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'lex_overlap_length' in feature_list:  self.modules['lex_overlap_length'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u1_func' in feature_list:             self.modules['u1_func'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            else: raise ValueError()\n",
    "\n",
    "    def forward(self, features):\n",
    "        feature_output_list = []\n",
    "        for i in range(len(self.feature_modules)):\n",
    "            feature = features[:, i:i+1]\n",
    "            feature_module = self.feature_modules[i]\n",
    "            feature_output = feature_module(feature)\n",
    "            feature_output = torch.squeeze(feature_output)\n",
    "            feature_output_list.append(feature_output)\n",
    "        # print(feature_output_list)\n",
    "        # feature_output_list = torch.cat(feature_output_list, dim=1)\n",
    "        # print(feature_output_list)\n",
    "\n",
    "        print([x.shape for x in feature_output_list])\n",
    "        try: feature_output_list = torch.cat(feature_output_list, dim=1)\n",
    "        except Exception as E:\n",
    "            print(feature_output_list)\n",
    "            print(E)\n",
    "            raise ValueError()\n",
    "        return feature_output_list\n",
    "\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, mnli_dataset):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.num_classes = mnli_dataset.num_labels\n",
    "        self.feature_list = mnli_dataset.feature_list\n",
    "        self.lang = mnli_dataset.lang\n",
    "        print('ASSIGN:', self.num_classes)\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL)\n",
    "        self.module1 = MyModule(self.feature_list)\n",
    "        self.linear1 = nn.Linear(768+self.module1.dims, self.num_classes)\n",
    "        self.act1 = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask, feat, mnli_dataset):\n",
    "        sequence_output, pooled_output = self.bert(input_ids=pair_token_ids, \n",
    "                        token_type_ids=token_type_ids, \n",
    "                        attention_mask=attention_mask).values()\n",
    "        \n",
    "        feat = self.module1(feat)\n",
    "        feat_concat = torch.concat((pooled_output, feat),-1)\n",
    "        assert feat_concat.shape[-1] == 768+feat.shape[-1]\n",
    "\n",
    "        linear1_output = self.linear1(feat_concat) ## extract the 1st token's embeddingsp\n",
    "        # linear1_output = self.linear1(sequence_output[:,0,:].view(-1,768)) ## extract the 1st token's embeddings\n",
    "        linear1_output = self.act1(linear1_output)\n",
    "        assert linear1_output[0].sum()>0.9 and linear1_output[0].sum()<1.1\n",
    "        return linear1_output\n",
    "\n",
    "model = CustomBERTModel(mnli_dataset)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=4e-6, correct_bias=False)#original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7, mode='max', patience=7, min_lr=5e-7, verbose=True)#original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['events.out.tfevents.1666969558.57e5cab0c4d9.9595.11']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat,\n",
    "                            mnli_dataset=mnli_dataset)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 3]), torch.Size([4, 5]), torch.Size([4, 4]), torch.Size([4, 4])]\n",
      "[torch.Size([3]), torch.Size([3]), torch.Size([3]), torch.Size([5]), torch.Size([4]), torch.Size([4])]\n",
      "[tensor([ 1.4125,  1.4461, -0.3154], device='cuda:1'), tensor([0., 0., 0.], device='cuda:1'), tensor([0., 0., 0.], device='cuda:1'), tensor([0., 0., 0., 0., 0.], device='cuda:1'), tensor([0., 0., 0., 0.], device='cuda:1'), tensor([0., 0., 0., 0.], device='cuda:1')]\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb Cell 26\u001b[0m in \u001b[0;36mMyModule.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m([x\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m feature_output_list])\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mtry\u001b[39;00m: feature_output_list \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(feature_output_list, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m E:\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)\n",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb Cell 26\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m train_acc  \u001b[39m=\u001b[39m total_train_acc\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m train_loss \u001b[39m=\u001b[39m total_train_loss\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m val_acc, val_loss, cr, model, optimizer \u001b[39m=\u001b[39m evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mif\u001b[39;00m val_acc\u001b[39m>\u001b[39mbest_val_acc:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m   torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), save_path_suffix\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_best.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb Cell 26\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[0;34m(model, optimizer, data_loader, rev_label_dict, label_dict, is_training)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m labels \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m feat \u001b[39m=\u001b[39m feat\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(pair_token_ids, \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m                       token_type_ids\u001b[39m=\u001b[39;49mseg_ids, \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m                       attention_mask\u001b[39m=\u001b[39;49mmask_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m                       feat\u001b[39m=\u001b[39;49mfeat,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m                       mnli_dataset\u001b[39m=\u001b[39;49mmnli_dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb Cell 26\u001b[0m in \u001b[0;36mCustomBERTModel.forward\u001b[0;34m(self, pair_token_ids, token_type_ids, attention_mask, feat, mnli_dataset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, pair_token_ids, token_type_ids, attention_mask, feat, mnli_dataset):\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m     sequence_output, pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert(input_ids\u001b[39m=\u001b[39mpair_token_ids, \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m                     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids, \n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m                     attention_mask\u001b[39m=\u001b[39mattention_mask)\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m     feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule1(feat)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m     feat_concat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcat((pooled_output, feat),\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m     \u001b[39massert\u001b[39;00m feat_concat\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m768\u001b[39m\u001b[39m+\u001b[39mfeat\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb Cell 26\u001b[0m in \u001b[0;36mMyModule.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mprint\u001b[39m(feature_output_list)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mprint\u001b[39m(E)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/2_prediction_fixes/18refactor_feature_embedding.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mreturn\u001b[39;00m feature_output_list\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.0331 test_acc: 0.2423\n",
      "00:00:03.14\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.00      0.00      0.00        18\n",
      "    background       0.17      0.82      0.29        17\n",
      "         cause       0.00      0.00      0.00         2\n",
      "  circumstance       0.00      0.00      0.00        15\n",
      "    concession       0.38      0.38      0.38        13\n",
      "     condition       0.00      0.00      0.00         9\n",
      "   conjunction       0.33      0.71      0.45         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.00      0.00      0.00        11\n",
      "   elaboration       0.00      0.00      0.00        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.00      0.00      0.00        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.22      0.93      0.36        29\n",
      "          list       0.44      0.31      0.36        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.00      0.00      0.00         4\n",
      "       purpose       0.00      0.00      0.00         3\n",
      "        reason       0.36      0.12      0.18        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.24       260\n",
      "     macro avg       0.08      0.14      0.08       260\n",
      "  weighted avg       0.16      0.24      0.15       260\n",
      "\n",
      "Test Loss: 3.033 |  Test Acc: 24.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#latest\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.0331 test_acc: 0.2423\n",
      "00:00:03.14\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.00      0.00      0.00        18\n",
      "    background       0.17      0.82      0.29        17\n",
      "         cause       0.00      0.00      0.00         2\n",
      "  circumstance       0.00      0.00      0.00        15\n",
      "    concession       0.38      0.38      0.38        13\n",
      "     condition       0.00      0.00      0.00         9\n",
      "   conjunction       0.33      0.71      0.45         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.00      0.00      0.00        11\n",
      "   elaboration       0.00      0.00      0.00        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.00      0.00      0.00        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.22      0.93      0.36        29\n",
      "          list       0.44      0.31      0.36        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.00      0.00      0.00         4\n",
      "       purpose       0.00      0.00      0.00         3\n",
      "        reason       0.36      0.12      0.18        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.24       260\n",
      "     macro avg       0.08      0.14      0.08       260\n",
      "  weighted avg       0.16      0.24      0.15       260\n",
      "\n",
      "Latest Test Loss: 3.033 |  Latest Test Acc: 24.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best earliest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.0331 test_acc: 0.2423\n",
      "00:00:03.14\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.00      0.00      0.00        18\n",
      "    background       0.17      0.82      0.29        17\n",
      "         cause       0.00      0.00      0.00         2\n",
      "  circumstance       0.00      0.00      0.00        15\n",
      "    concession       0.38      0.38      0.38        13\n",
      "     condition       0.00      0.00      0.00         9\n",
      "   conjunction       0.33      0.71      0.45         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.00      0.00      0.00        11\n",
      "   elaboration       0.00      0.00      0.00        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.00      0.00      0.00        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.22      0.93      0.36        29\n",
      "          list       0.44      0.31      0.36        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.00      0.00      0.00         4\n",
      "       purpose       0.00      0.00      0.00         3\n",
      "        reason       0.36      0.12      0.18        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.24       260\n",
      "     macro avg       0.08      0.14      0.08       260\n",
      "  weighted avg       0.16      0.24      0.15       260\n",
      "\n",
      "Best Test Loss: 3.033 |  Best Test Acc: 24.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best lastest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_latest', test_acc, 1)\n",
    "print(f'Best Test Loss: {test_loss:.3f} |  Best Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.0159 test_acc: 0.2417\n",
      "00:00:02.88\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.00      0.00      0.00        11\n",
      "    background       0.19      0.76      0.30        17\n",
      "         cause       0.00      0.00      0.00         7\n",
      "  circumstance       0.00      0.00      0.00        13\n",
      "    concession       0.45      0.82      0.58        11\n",
      "     condition       0.00      0.00      0.00         8\n",
      "   conjunction       0.58      0.88      0.70         8\n",
      "      contrast       0.00      0.00      0.00         3\n",
      " e-elaboration       0.00      0.00      0.00        13\n",
      "   elaboration       0.00      0.00      0.00        28\n",
      "  evaluation-n       0.00      0.00      0.00         8\n",
      "  evaluation-s       0.00      0.00      0.00         5\n",
      "      evidence       0.00      0.00      0.00         8\n",
      "interpretation       0.00      0.00      0.00        13\n",
      "         joint       0.17      0.94      0.28        18\n",
      "          list       0.25      0.28      0.26        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.00      0.00      0.00        11\n",
      "       purpose       0.00      0.00      0.00         5\n",
      "        reason       0.47      0.25      0.33        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.24       238\n",
      "     macro avg       0.09      0.17      0.11       238\n",
      "  weighted avg       0.14      0.24      0.15       238\n",
      "\n",
      "Val Loss: 3.016 |  Val Acc: 24.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best val acc\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
