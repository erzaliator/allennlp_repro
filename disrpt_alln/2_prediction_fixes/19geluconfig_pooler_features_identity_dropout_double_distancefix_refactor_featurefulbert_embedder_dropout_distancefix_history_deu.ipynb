{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2011\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "batch_size = 4\n",
    "batches_per_epoch = 110\n",
    "\n",
    "save_path_suffix = '19geluconfig_pooler_features_identity_dropout_double_refactor_featurefulbertemb_dropout_distancefix_history_deu_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')[:1000]\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'15': 1,\n",
       "         '1': 142,\n",
       "         '2': 41,\n",
       "         '3': 23,\n",
       "         '5': 9,\n",
       "         '6': 4,\n",
       "         '4': 10,\n",
       "         '7': 3,\n",
       "         '9': 3,\n",
       "         '12': 1,\n",
       "         '14': 1,\n",
       "         '8': 1,\n",
       "         '16': 1,\n",
       "         '10': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "Counter(val_df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label',\n",
       "       'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position',\n",
       "       'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case',\n",
       "       'unit2_case', 'u1_discontinuous', 'u2_discontinuous', 'same_speaker',\n",
       "       'lex_overlap_length', 'u1_func'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 08:34:12.092321: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 08:34:12.391205: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-09 08:34:12.391240: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-09 08:34:12.446023: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-09 08:34:13.504935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-09 08:34:13.505083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-09 08:34:13.505095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, ConcatDataset\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate, Vocabulary\n",
    "from features_custom2 import get_vocab_feature_name\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.vocab = Vocabulary(counter=None, max_vocab_size=100000)\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.init_feature_list()\n",
    "    self.init_feature_mappings_and_bins()\n",
    "    self.apply_bins()\n",
    "    self.calculate_unique_values()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    \n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def init_feature_mappings_and_bins(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "    self.bins = {\n",
    "      'distance': [[-1e9, -8], [-8, -2], [-2, 0], [0, 2], [2, 8], [8, 1e9]],\n",
    "      'u1_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'u2_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'lex_overlap_length': [[0, 2], [2, 7], [7, 1e9]]\n",
    "    }   \n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def init_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "    else: \n",
    "      raise ValueError()\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features_list(self, features, feature_name):\n",
    "    if feature_name in ['distance', 'u1_depdir', 'u2_depdir', 'u1_func', 'u2_func', \n",
    "    'u1_position', 'u2_position', 'genre', 'same_speaker', 'unit1_case', 'unit2_case',\n",
    "    'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'dir']: feature_value = self.apply_vocab(features[feature_name], feature_name) #for categorical values\n",
    "    elif feature_name in ['sat_children', 'nuc_children']: feature_value = float(features[feature_name]) #for identiy values\n",
    "    else: \n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    return feature_value\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==17\n",
    "    #after applying the vocab. we need to pass them as int\n",
    "    return {feature_name: torch.tensor(int(self.get_allen_features_list(features, feature_name))).to(device) for feature_name in self.feature_list+['dir']}\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature_name in self.feature_list+['dir']:\n",
    "      vocab_feature_name = get_vocab_feature_name(feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(train_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(val_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "\n",
    "  def apply_bins(self):\n",
    "    for df in [self.train_df, self.test_df, self.val_df]:\n",
    "      for feature_name in self.bins.keys():\n",
    "        df[feature_name] = df[feature_name].apply(lambda x: self.get_mapping_from_bin(feature_name, float(x)))\n",
    "\n",
    "  def get_mapping_from_bin(self, column_name, dict_val):\n",
    "    bins = self.bins[column_name]\n",
    "    for b,i in zip(bins, range(len(bins))):\n",
    "      left = b[0]\n",
    "      right = b[1]\n",
    "      if left<=dict_val and right>=dict_val: return i\n",
    "\n",
    "  def apply_vocab(self, feature_value, feature_name):\n",
    "    return self.vocab.get_token_index(str(feature_value), namespace=get_vocab_feature_name(feature_name))\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      features = {'distance': row['distance'],\n",
    "                'u1_depdir': row['u1_depdir'],\n",
    "                'u2_depdir': row['u2_depdir'],\n",
    "                'u1_func': row['u1_func'],\n",
    "                'u2_func': row['u2_func'],\n",
    "                'u1_position': row['u1_position'],\n",
    "                'u2_position': row['u2_position'],\n",
    "                'sat_children': row['sat_children'],\n",
    "                'nuc_children': row['nuc_children'],\n",
    "                'genre': row['genre'],\n",
    "                'unit1_case': row['unit1_case'],\n",
    "                'unit2_case': row['unit2_case'],\n",
    "                'u1_discontinuous': row['u1_discontinuous'],\n",
    "                'u2_discontinuous': row['u2_discontinuous'],\n",
    "                'same_speaker': row['same_speaker'],\n",
    "                'lex_overlap_length': row['lex_overlap_length'],\n",
    "                'dir': row['dir']}\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding=False) #padding='max_length'\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      features = self.transform_feature(features)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(features)\n",
    "      \n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "      \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "\n",
    "    class featureDataset(Dataset):\n",
    "      def __init__(self, token_ids, mask_ids, seg_ids, feats, y, idx):\n",
    "          self.token_ids = token_ids\n",
    "          self.mask_ids = mask_ids\n",
    "          self.seg_ids = seg_ids\n",
    "          self.feats = feats\n",
    "          self.y = y\n",
    "          self.idx = idx\n",
    "\n",
    "      def __len__(self):\n",
    "          return len(self.feats)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "          return self.token_ids[idx], self.mask_ids[idx], self.seg_ids[idx], self.feats[idx], self.y[idx], self.idx[idx]\n",
    "\n",
    "    dataset = featureDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '3': 2, '4': 3, '5': 4}\n",
      "u1_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_func :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'root': 2, 'conj': 3, 'advcl': 4, 'acl': 5, 'xcomp': 6, 'obl': 7, 'ccomp': 8, 'parataxis': 9, 'advmod': 10, 'dep': 11, 'csubj': 12, 'nmod': 13, 'punct': 14, 'cc': 15, 'appos': 16, 'aux': 17, 'obj': 18, 'iobj': 19, 'nsubj': 20}\n",
      "u1_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '1': 11}\n",
      "u2_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '1': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
      "sat_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '4': 3, '1': 4, '2': 5, '3': 6, '5': 7, '6': 8}\n",
      "nuc_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '4': 2, '3': 3, '1': 4, '2': 5, '5': 6, '6': 7, '7': 8, '8': 9}\n",
      "dir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '1>2': 2, '1<2': 3}\n"
     ]
    }
   ],
   "source": [
    "for feature in mnli_dataset.feature_list:\n",
    "    vocab_feature_name = get_vocab_feature_name(feature)\n",
    "    print(feature, ': ', mnli_dataset.vocab.get_token_to_index_vocabulary(vocab_feature_name))\n",
    "print('dir', ': ', mnli_dataset.vocab.get_token_to_index_vocabulary('dir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    # assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    # assert mask_ids.shape[-1]==512\n",
    "    # assert seg_ids.shape[-1]==512\n",
    "    assert len(feat)==len(mnli_dataset.feature_list)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '@@PADDING@@', 1: '@@UNKNOWN@@'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_dataset.vocab.get_index_to_token_vocabulary('u1_depdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        if i not in idx_map.keys():\n",
    "          print(idx_map)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing FeaturefulBert: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing FeaturefulBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FeaturefulBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, Optional\n",
    "from transformers import BertModel, AutoTokenizer, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from featurefulbertembedder_custom2 import FeaturefulBertEmbedder\n",
    "from featureful_bert_custom2 import get_combined_feature_tensor_2 as get_combined_feature_tensor_forward\n",
    "from featureful_bert_custom2 import get_feature_modules\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class CustomPooler2(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                        requires_grad: bool = True,\n",
    "                        dropout: float = 0.0,\n",
    "                        transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "        super().__init__()\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL) #only used to pass config. BertAttentionClass used in FeatureFulBert\n",
    "        self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.pooler = copy.deepcopy(bert.pooler)\n",
    "        for param in self.pooler.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        self._embedding_dim = bert.config.hidden_size\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "        pooler = self.pooler\n",
    "        \n",
    "        for _ in range(num_wrapping_dims):\n",
    "            pooler = TimeDistributed(pooler)\n",
    "        pooled = pooler(tokens)\n",
    "        pooled = self._dropout(pooled)\n",
    "        return pooled\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list, vocab):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_modules, self._feature_module_size = get_feature_modules(feature_list, vocab)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return get_combined_feature_tensor_forward(features, self.feature_list, self.feature_modules)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels, vocab):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels\n",
    "          self.feature_list = mnli_dataset.feature_list\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "\n",
    "          self.embedder = self.create_featureful_bert()\n",
    "          self.encoder = CustomPooler2()\n",
    "          self.module1 = MyModule(self.feature_list, vocab)\n",
    "          self.dropout1 = nn.Dropout(p=0.0)\n",
    "        #   self.dropout_decoder = nn.Dropout(p=0.5)\n",
    "          self._decoder_input_size = self.encoder._embedding_dim + self.module1._feature_module_size\n",
    "          self.relation_decoder = nn.Linear(self._decoder_input_size, self.num_classes)\n",
    "\n",
    "          self.history_w = {\n",
    "            'cos': [],\n",
    "            # 'l1_linear': [],\n",
    "            # 'l2': []\n",
    "          }\n",
    "          self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "          print(self.pooler_weight)\n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask, feat):\n",
    "        direction_tensor = feat['dir'].to(device)\n",
    "        embedded_sentence = self.embedder(token_ids=pair_token_ids, #featurefulmebedder\n",
    "                        mask=attention_mask, \n",
    "                        type_ids=token_type_ids,\n",
    "                        segment_concat_mask = None,\n",
    "                        direction_tensor = direction_tensor,\n",
    "                        feature_list = self.feature_list,\n",
    "                        features = feat)\n",
    "        mask = token_type_ids\n",
    "        bertpooler_output = self.encoder(tokens=embedded_sentence, mask=mask)\n",
    "        feat = self.convert_to_feature_list(feat)\n",
    "        feat = self.dropout1(feat)\n",
    "        feat = self.module1(feat)\n",
    "        # print(bertpooler_output.shape, self.module1._feature_module_size, feat.shape)\n",
    "        try:\n",
    "            feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "        except:\n",
    "            print(bertpooler_output.shape, feat.shape)\n",
    "            raise ValueError()\n",
    "        assert feat_concat.shape[-1] == self._decoder_input_size\n",
    "        feat_concat = self.dropout1(feat_concat)\n",
    "        # feat_concat = self.dropout_decoder(feat_concat)\n",
    "        linear1_output = self.relation_decoder(feat_concat)\n",
    "        return linear1_output\n",
    "\n",
    "    def compute_pooler_similarity(self):\n",
    "        cur = self.encoder.pooler.dense.weight\n",
    "        pre = self.pooler_weight\n",
    "        print(cur)\n",
    "        print(pre)\n",
    "        assert not torch.all(cur.eq(pre))\n",
    "        for metric in self.history_w.keys():\n",
    "            self.history_w[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "\n",
    "    def similarity(self, cur, pre, metric):\n",
    "        metric = 0\n",
    "        n = 0\n",
    "        for A, B in zip(cur.cpu().detach().numpy(), pre.cpu().detach().numpy()):\n",
    "            cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "            metric+= cosine\n",
    "            n+=1\n",
    "        return float(metric)/float(n), metric\n",
    "\n",
    "    def create_bert_without_activations(self):\n",
    "        config = BertConfig.from_pretrained(BERT_MODEL, hidden_act='gelu')\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "        return bert\n",
    "\n",
    "    def create_featureful_bert(self):\n",
    "        featureful_bert = FeaturefulBertEmbedder(model_name = BERT_MODEL,\n",
    "                                hidden_activation_allen = 'gelu',\n",
    "                                feature_list = self.feature_list, \n",
    "                                vocab=mnli_dataset.vocab)\n",
    "        return featureful_bert\n",
    "\n",
    "    def convert_to_feature_list(self, feat):\n",
    "        feature_linear = [feat[feature_name] for feature_name in self.feature_list]\n",
    "        feature_linear = torch.stack(feature_linear, dim=-1)\n",
    "        return feature_linear\n",
    "        \n",
    "\n",
    "model = CustomBERTModel(mnli_dataset.num_labels, mnli_dataset.vocab)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, correct_bias=False) # original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, mode='max', patience=35, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prinintg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomBERTModel(\n",
      "  (embedder): FeaturefulBertEmbedder(\n",
      "    (transformer_model): FeaturefulBert(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (feature_modules): ModuleDict(\n",
      "        (distance): Embedding(5, 3, padding_idx=0)\n",
      "        (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_func): Embedding(21, 5, padding_idx=0)\n",
      "        (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "        (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "        (sat_children): Identity()\n",
      "        (nuc_children): Identity()\n",
      "      )\n",
      "      (feature_projector): Linear(in_features=25, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): CustomPooler2(\n",
      "    (_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (module1): MyModule(\n",
      "    (feature_modules): ModuleDict(\n",
      "      (distance): Embedding(5, 3, padding_idx=0)\n",
      "      (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_func): Embedding(21, 5, padding_idx=0)\n",
      "      (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "      (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "      (sat_children): Identity()\n",
      "      (nuc_children): Identity()\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (relation_decoder): Linear(in_features=792, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['events.out.tfevents.1670574768.57e5cab0c4d9.22698.0']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n",
    "\n",
    "    model.compute_pooler_similarity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Best val_acc: 0.1721\n",
      "Epoch 1: Best val_acc: 0.1721\n",
      "Epoch 1: train_loss: 2.8933 train_acc: 0.1432 | val_loss: 2.7313 val_acc: 0.1721\n",
      "00:00:10.31\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0090,  0.0129,  ...,  0.0006, -0.0075, -0.0997],\n",
      "        [ 0.0133,  0.0058,  0.0159,  ..., -0.0030,  0.0097, -0.0132],\n",
      "        [-0.0174,  0.0177, -0.0045,  ...,  0.0210, -0.0202, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0160,  0.0058,  ...,  0.0093, -0.0021,  0.0119],\n",
      "        [ 0.0875, -0.0187,  0.0049,  ...,  0.0098, -0.0167,  0.0203],\n",
      "        [ 0.0233,  0.0020, -0.0045,  ...,  0.0064,  0.0224,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 2: Best val_acc: 0.2131\n",
      "Epoch 2: Best val_acc: 0.2131\n",
      "Epoch 2: train_loss: 2.6243 train_acc: 0.1864 | val_loss: 2.5840 val_acc: 0.2131\n",
      "00:00:09.72\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0090,  0.0128,  ...,  0.0003, -0.0072, -0.0995],\n",
      "        [ 0.0134,  0.0057,  0.0158,  ..., -0.0033,  0.0099, -0.0131],\n",
      "        [-0.0176,  0.0176, -0.0044,  ...,  0.0209, -0.0204, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0161,  0.0060,  ...,  0.0096, -0.0021,  0.0119],\n",
      "        [ 0.0878, -0.0186,  0.0048,  ...,  0.0097, -0.0164,  0.0202],\n",
      "        [ 0.0233,  0.0021, -0.0043,  ...,  0.0064,  0.0223,  0.0112]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0090,  0.0129,  ...,  0.0006, -0.0075, -0.0997],\n",
      "        [ 0.0133,  0.0058,  0.0159,  ..., -0.0030,  0.0097, -0.0132],\n",
      "        [-0.0174,  0.0177, -0.0045,  ...,  0.0210, -0.0202, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0160,  0.0058,  ...,  0.0093, -0.0021,  0.0119],\n",
      "        [ 0.0875, -0.0187,  0.0049,  ...,  0.0098, -0.0167,  0.0203],\n",
      "        [ 0.0233,  0.0020, -0.0045,  ...,  0.0064,  0.0224,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 3: Best val_acc: 0.2787\n",
      "Epoch 3: Best val_acc: 0.2787\n",
      "Epoch 3: train_loss: 2.4324 train_acc: 0.3386 | val_loss: 2.4393 val_acc: 0.2787\n",
      "00:00:09.86\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0410,  0.0091,  0.0130,  ...,  0.0001, -0.0070, -0.0998],\n",
      "        [ 0.0135,  0.0056,  0.0157,  ..., -0.0036,  0.0103, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0045,  ...,  0.0207, -0.0205, -0.0041],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0162,  0.0061,  ...,  0.0100, -0.0022,  0.0120],\n",
      "        [ 0.0881, -0.0186,  0.0047,  ...,  0.0094, -0.0161,  0.0201],\n",
      "        [ 0.0230,  0.0021, -0.0044,  ...,  0.0063,  0.0221,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0090,  0.0128,  ...,  0.0003, -0.0072, -0.0995],\n",
      "        [ 0.0134,  0.0057,  0.0158,  ..., -0.0033,  0.0099, -0.0131],\n",
      "        [-0.0176,  0.0176, -0.0044,  ...,  0.0209, -0.0204, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0161,  0.0060,  ...,  0.0096, -0.0021,  0.0119],\n",
      "        [ 0.0878, -0.0186,  0.0048,  ...,  0.0097, -0.0164,  0.0202],\n",
      "        [ 0.0233,  0.0021, -0.0043,  ...,  0.0064,  0.0223,  0.0112]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 4: train_loss: 2.2755 train_acc: 0.3568 | val_loss: 2.3909 val_acc: 0.2664\n",
      "00:00:07.82\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0938e-02,  9.1074e-03,  1.2886e-02,  ...,  8.1624e-05,\n",
      "         -6.9470e-03, -9.9897e-02],\n",
      "        [ 1.3572e-02,  5.5027e-03,  1.5610e-02,  ..., -3.8059e-03,\n",
      "          1.0327e-02, -1.3041e-02],\n",
      "        [-1.7775e-02,  1.7454e-02, -4.4947e-03,  ...,  2.0619e-02,\n",
      "         -2.0653e-02, -4.0779e-03],\n",
      "        ...,\n",
      "        [ 1.4905e-02,  1.6392e-02,  6.2874e-03,  ...,  1.0044e-02,\n",
      "         -2.0464e-03,  1.1860e-02],\n",
      "        [ 8.8209e-02, -1.8679e-02,  4.6373e-03,  ...,  9.4149e-03,\n",
      "         -1.5976e-02,  2.0056e-02],\n",
      "        [ 2.2916e-02,  2.0692e-03, -4.4099e-03,  ...,  6.2970e-03,\n",
      "          2.2129e-02,  1.1451e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0410,  0.0091,  0.0130,  ...,  0.0001, -0.0070, -0.0998],\n",
      "        [ 0.0135,  0.0056,  0.0157,  ..., -0.0036,  0.0103, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0045,  ...,  0.0207, -0.0205, -0.0041],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0162,  0.0061,  ...,  0.0100, -0.0022,  0.0120],\n",
      "        [ 0.0881, -0.0186,  0.0047,  ...,  0.0094, -0.0161,  0.0201],\n",
      "        [ 0.0230,  0.0021, -0.0044,  ...,  0.0063,  0.0221,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 5: train_loss: 2.1144 train_acc: 0.4136 | val_loss: 2.3671 val_acc: 0.2541\n",
      "00:00:07.64\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0409,  0.0090,  0.0129,  ...,  0.0001, -0.0069, -0.0999],\n",
      "        [ 0.0136,  0.0054,  0.0155,  ..., -0.0039,  0.0105, -0.0130],\n",
      "        [-0.0178,  0.0175, -0.0044,  ...,  0.0204, -0.0207, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0164,  0.0064,  ...,  0.0103, -0.0019,  0.0120],\n",
      "        [ 0.0883, -0.0186,  0.0046,  ...,  0.0094, -0.0160,  0.0200],\n",
      "        [ 0.0228,  0.0021, -0.0044,  ...,  0.0064,  0.0221,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0938e-02,  9.1074e-03,  1.2886e-02,  ...,  8.1624e-05,\n",
      "         -6.9470e-03, -9.9897e-02],\n",
      "        [ 1.3572e-02,  5.5027e-03,  1.5610e-02,  ..., -3.8059e-03,\n",
      "          1.0327e-02, -1.3041e-02],\n",
      "        [-1.7775e-02,  1.7454e-02, -4.4947e-03,  ...,  2.0619e-02,\n",
      "         -2.0653e-02, -4.0779e-03],\n",
      "        ...,\n",
      "        [ 1.4905e-02,  1.6392e-02,  6.2874e-03,  ...,  1.0044e-02,\n",
      "         -2.0464e-03,  1.1860e-02],\n",
      "        [ 8.8209e-02, -1.8679e-02,  4.6373e-03,  ...,  9.4149e-03,\n",
      "         -1.5976e-02,  2.0056e-02],\n",
      "        [ 2.2916e-02,  2.0692e-03, -4.4099e-03,  ...,  6.2970e-03,\n",
      "          2.2129e-02,  1.1451e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 6: Best val_acc: 0.2869\n",
      "Epoch 6: Best val_acc: 0.2869\n",
      "Epoch 6: train_loss: 1.9452 train_acc: 0.4886 | val_loss: 2.3177 val_acc: 0.2869\n",
      "00:00:09.66\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0090,  0.0128,  ...,  0.0003, -0.0068, -0.0998],\n",
      "        [ 0.0136,  0.0054,  0.0154,  ..., -0.0040,  0.0106, -0.0130],\n",
      "        [-0.0178,  0.0174, -0.0045,  ...,  0.0202, -0.0208, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0166,  0.0066,  ...,  0.0104, -0.0020,  0.0120],\n",
      "        [ 0.0884, -0.0187,  0.0046,  ...,  0.0094, -0.0160,  0.0199],\n",
      "        [ 0.0226,  0.0021, -0.0044,  ...,  0.0062,  0.0223,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0409,  0.0090,  0.0129,  ...,  0.0001, -0.0069, -0.0999],\n",
      "        [ 0.0136,  0.0054,  0.0155,  ..., -0.0039,  0.0105, -0.0130],\n",
      "        [-0.0178,  0.0175, -0.0044,  ...,  0.0204, -0.0207, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0164,  0.0064,  ...,  0.0103, -0.0019,  0.0120],\n",
      "        [ 0.0883, -0.0186,  0.0046,  ...,  0.0094, -0.0160,  0.0200],\n",
      "        [ 0.0228,  0.0021, -0.0044,  ...,  0.0064,  0.0221,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 7: Best val_acc: 0.3156\n",
      "Epoch 7: Best val_acc: 0.3156\n",
      "Epoch 7: train_loss: 1.7444 train_acc: 0.5591 | val_loss: 2.2613 val_acc: 0.3156\n",
      "00:00:09.97\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0410,  0.0090,  0.0127,  ...,  0.0002, -0.0067, -0.0998],\n",
      "        [ 0.0135,  0.0053,  0.0152,  ..., -0.0042,  0.0107, -0.0129],\n",
      "        [-0.0179,  0.0174, -0.0047,  ...,  0.0199, -0.0207, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0166,  0.0067,  ...,  0.0106, -0.0021,  0.0122],\n",
      "        [ 0.0885, -0.0187,  0.0047,  ...,  0.0094, -0.0161,  0.0197],\n",
      "        [ 0.0226,  0.0021, -0.0044,  ...,  0.0062,  0.0223,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0090,  0.0128,  ...,  0.0003, -0.0068, -0.0998],\n",
      "        [ 0.0136,  0.0054,  0.0154,  ..., -0.0040,  0.0106, -0.0130],\n",
      "        [-0.0178,  0.0174, -0.0045,  ...,  0.0202, -0.0208, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0166,  0.0066,  ...,  0.0104, -0.0020,  0.0120],\n",
      "        [ 0.0884, -0.0187,  0.0046,  ...,  0.0094, -0.0160,  0.0199],\n",
      "        [ 0.0226,  0.0021, -0.0044,  ...,  0.0062,  0.0223,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 8: Best val_acc: 0.3279\n",
      "Epoch 8: Best val_acc: 0.3279\n",
      "Epoch 8: train_loss: 1.7102 train_acc: 0.5432 | val_loss: 2.2491 val_acc: 0.3279\n",
      "00:00:10.28\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0410,  0.0090,  0.0127,  ...,  0.0002, -0.0067, -0.0999],\n",
      "        [ 0.0135,  0.0054,  0.0150,  ..., -0.0043,  0.0109, -0.0129],\n",
      "        [-0.0180,  0.0175, -0.0047,  ...,  0.0199, -0.0208, -0.0046],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0166,  0.0069,  ...,  0.0108, -0.0020,  0.0123],\n",
      "        [ 0.0887, -0.0188,  0.0047,  ...,  0.0094, -0.0160,  0.0197],\n",
      "        [ 0.0224,  0.0022, -0.0044,  ...,  0.0061,  0.0223,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0410,  0.0090,  0.0127,  ...,  0.0002, -0.0067, -0.0998],\n",
      "        [ 0.0135,  0.0053,  0.0152,  ..., -0.0042,  0.0107, -0.0129],\n",
      "        [-0.0179,  0.0174, -0.0047,  ...,  0.0199, -0.0207, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0166,  0.0067,  ...,  0.0106, -0.0021,  0.0122],\n",
      "        [ 0.0885, -0.0187,  0.0047,  ...,  0.0094, -0.0161,  0.0197],\n",
      "        [ 0.0226,  0.0021, -0.0044,  ...,  0.0062,  0.0223,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 9: Best val_acc: 0.3279\n",
      "Epoch 9: train_loss: 1.4643 train_acc: 0.6432 | val_loss: 2.2422 val_acc: 0.3279\n",
      "00:00:08.47\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.1040e-02,  8.9582e-03,  1.2524e-02,  ...,  6.7561e-05,\n",
      "         -6.7118e-03, -9.9820e-02],\n",
      "        [ 1.3490e-02,  5.4320e-03,  1.4883e-02,  ..., -4.4876e-03,\n",
      "          1.1087e-02, -1.2894e-02],\n",
      "        [-1.7939e-02,  1.7495e-02, -4.7320e-03,  ...,  1.9748e-02,\n",
      "         -2.0734e-02, -4.8379e-03],\n",
      "        ...,\n",
      "        [ 1.4920e-02,  1.6694e-02,  7.0821e-03,  ...,  1.0986e-02,\n",
      "         -2.0734e-03,  1.2502e-02],\n",
      "        [ 8.8845e-02, -1.8739e-02,  4.7734e-03,  ...,  9.3938e-03,\n",
      "         -1.6030e-02,  1.9598e-02],\n",
      "        [ 2.2217e-02,  2.0978e-03, -4.3869e-03,  ...,  6.0077e-03,\n",
      "          2.2348e-02,  1.1630e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0410,  0.0090,  0.0127,  ...,  0.0002, -0.0067, -0.0999],\n",
      "        [ 0.0135,  0.0054,  0.0150,  ..., -0.0043,  0.0109, -0.0129],\n",
      "        [-0.0180,  0.0175, -0.0047,  ...,  0.0199, -0.0208, -0.0046],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0166,  0.0069,  ...,  0.0108, -0.0020,  0.0123],\n",
      "        [ 0.0887, -0.0188,  0.0047,  ...,  0.0094, -0.0160,  0.0197],\n",
      "        [ 0.0224,  0.0022, -0.0044,  ...,  0.0061,  0.0223,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 10: train_loss: 1.3944 train_acc: 0.6682 | val_loss: 2.1922 val_acc: 0.3115\n",
      "00:00:08.04\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0980e-02,  8.9323e-03,  1.2416e-02,  ..., -3.9956e-05,\n",
      "         -6.6361e-03, -9.9767e-02],\n",
      "        [ 1.3457e-02,  5.4092e-03,  1.4794e-02,  ..., -4.5874e-03,\n",
      "          1.1106e-02, -1.2815e-02],\n",
      "        [-1.7978e-02,  1.7523e-02, -4.7709e-03,  ...,  1.9544e-02,\n",
      "         -2.0708e-02, -4.9911e-03],\n",
      "        ...,\n",
      "        [ 1.4886e-02,  1.6790e-02,  7.2127e-03,  ...,  1.1179e-02,\n",
      "         -2.0176e-03,  1.2619e-02],\n",
      "        [ 8.9000e-02, -1.8786e-02,  4.8173e-03,  ...,  9.4444e-03,\n",
      "         -1.6139e-02,  1.9480e-02],\n",
      "        [ 2.2094e-02,  2.1829e-03, -4.3428e-03,  ...,  5.9932e-03,\n",
      "          2.2414e-02,  1.1684e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.1040e-02,  8.9582e-03,  1.2524e-02,  ...,  6.7561e-05,\n",
      "         -6.7118e-03, -9.9820e-02],\n",
      "        [ 1.3490e-02,  5.4320e-03,  1.4883e-02,  ..., -4.4876e-03,\n",
      "          1.1087e-02, -1.2894e-02],\n",
      "        [-1.7939e-02,  1.7495e-02, -4.7320e-03,  ...,  1.9748e-02,\n",
      "         -2.0734e-02, -4.8379e-03],\n",
      "        ...,\n",
      "        [ 1.4920e-02,  1.6694e-02,  7.0821e-03,  ...,  1.0986e-02,\n",
      "         -2.0734e-03,  1.2502e-02],\n",
      "        [ 8.8845e-02, -1.8739e-02,  4.7734e-03,  ...,  9.3938e-03,\n",
      "         -1.6030e-02,  1.9598e-02],\n",
      "        [ 2.2217e-02,  2.0978e-03, -4.3869e-03,  ...,  6.0077e-03,\n",
      "          2.2348e-02,  1.1630e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 11: Best val_acc: 0.3443\n",
      "Epoch 11: Best val_acc: 0.3443\n",
      "Epoch 11: train_loss: 1.2121 train_acc: 0.7318 | val_loss: 2.1900 val_acc: 0.3443\n",
      "00:00:09.82\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0995e-02,  8.8589e-03,  1.2244e-02,  ..., -7.0225e-05,\n",
      "         -6.5561e-03, -9.9699e-02],\n",
      "        [ 1.3437e-02,  5.3746e-03,  1.4711e-02,  ..., -4.7109e-03,\n",
      "          1.1219e-02, -1.2750e-02],\n",
      "        [-1.7971e-02,  1.7483e-02, -4.8262e-03,  ...,  1.9371e-02,\n",
      "         -2.0720e-02, -5.0458e-03],\n",
      "        ...,\n",
      "        [ 1.4896e-02,  1.6928e-02,  7.4151e-03,  ...,  1.1331e-02,\n",
      "         -1.9548e-03,  1.2676e-02],\n",
      "        [ 8.9095e-02, -1.8802e-02,  4.9408e-03,  ...,  9.4835e-03,\n",
      "         -1.6288e-02,  1.9448e-02],\n",
      "        [ 2.1966e-02,  2.2479e-03, -4.3607e-03,  ...,  5.9749e-03,\n",
      "          2.2559e-02,  1.1607e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0980e-02,  8.9323e-03,  1.2416e-02,  ..., -3.9956e-05,\n",
      "         -6.6361e-03, -9.9767e-02],\n",
      "        [ 1.3457e-02,  5.4092e-03,  1.4794e-02,  ..., -4.5874e-03,\n",
      "          1.1106e-02, -1.2815e-02],\n",
      "        [-1.7978e-02,  1.7523e-02, -4.7709e-03,  ...,  1.9544e-02,\n",
      "         -2.0708e-02, -4.9911e-03],\n",
      "        ...,\n",
      "        [ 1.4886e-02,  1.6790e-02,  7.2127e-03,  ...,  1.1179e-02,\n",
      "         -2.0176e-03,  1.2619e-02],\n",
      "        [ 8.9000e-02, -1.8786e-02,  4.8173e-03,  ...,  9.4444e-03,\n",
      "         -1.6139e-02,  1.9480e-02],\n",
      "        [ 2.2094e-02,  2.1829e-03, -4.3428e-03,  ...,  5.9932e-03,\n",
      "          2.2414e-02,  1.1684e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 12: train_loss: 1.0921 train_acc: 0.7455 | val_loss: 2.1825 val_acc: 0.3320\n",
      "00:00:07.42\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.1046e-02,  8.7820e-03,  1.2039e-02,  ..., -5.7868e-05,\n",
      "         -6.5067e-03, -9.9605e-02],\n",
      "        [ 1.3465e-02,  5.4445e-03,  1.4537e-02,  ..., -4.7652e-03,\n",
      "          1.1278e-02, -1.2732e-02],\n",
      "        [-1.7966e-02,  1.7531e-02, -4.8758e-03,  ...,  1.9257e-02,\n",
      "         -2.0690e-02, -5.1883e-03],\n",
      "        ...,\n",
      "        [ 1.4826e-02,  1.6989e-02,  7.6155e-03,  ...,  1.1530e-02,\n",
      "         -1.9362e-03,  1.2825e-02],\n",
      "        [ 8.9242e-02, -1.8761e-02,  4.9852e-03,  ...,  9.5181e-03,\n",
      "         -1.6317e-02,  1.9373e-02],\n",
      "        [ 2.1862e-02,  2.2244e-03, -4.3264e-03,  ...,  5.9389e-03,\n",
      "          2.2623e-02,  1.1607e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0995e-02,  8.8589e-03,  1.2244e-02,  ..., -7.0225e-05,\n",
      "         -6.5561e-03, -9.9699e-02],\n",
      "        [ 1.3437e-02,  5.3746e-03,  1.4711e-02,  ..., -4.7109e-03,\n",
      "          1.1219e-02, -1.2750e-02],\n",
      "        [-1.7971e-02,  1.7483e-02, -4.8262e-03,  ...,  1.9371e-02,\n",
      "         -2.0720e-02, -5.0458e-03],\n",
      "        ...,\n",
      "        [ 1.4896e-02,  1.6928e-02,  7.4151e-03,  ...,  1.1331e-02,\n",
      "         -1.9548e-03,  1.2676e-02],\n",
      "        [ 8.9095e-02, -1.8802e-02,  4.9408e-03,  ...,  9.4835e-03,\n",
      "         -1.6288e-02,  1.9448e-02],\n",
      "        [ 2.1966e-02,  2.2479e-03, -4.3607e-03,  ...,  5.9749e-03,\n",
      "          2.2559e-02,  1.1607e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 13: train_loss: 1.0081 train_acc: 0.7773 | val_loss: 2.2171 val_acc: 0.3279\n",
      "00:00:07.51\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.1100e-02,  8.7072e-03,  1.1949e-02,  ..., -5.8527e-05,\n",
      "         -6.3826e-03, -9.9619e-02],\n",
      "        [ 1.3403e-02,  5.4447e-03,  1.4344e-02,  ..., -4.9017e-03,\n",
      "          1.1394e-02, -1.2627e-02],\n",
      "        [-1.7964e-02,  1.7567e-02, -4.9323e-03,  ...,  1.9132e-02,\n",
      "         -2.0690e-02, -5.2157e-03],\n",
      "        ...,\n",
      "        [ 1.4726e-02,  1.7039e-02,  7.7254e-03,  ...,  1.1731e-02,\n",
      "         -1.9416e-03,  1.2923e-02],\n",
      "        [ 8.9306e-02, -1.8687e-02,  5.0222e-03,  ...,  9.5150e-03,\n",
      "         -1.6372e-02,  1.9349e-02],\n",
      "        [ 2.1789e-02,  2.1879e-03, -4.2776e-03,  ...,  5.9677e-03,\n",
      "          2.2671e-02,  1.1588e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.1046e-02,  8.7820e-03,  1.2039e-02,  ..., -5.7868e-05,\n",
      "         -6.5067e-03, -9.9605e-02],\n",
      "        [ 1.3465e-02,  5.4445e-03,  1.4537e-02,  ..., -4.7652e-03,\n",
      "          1.1278e-02, -1.2732e-02],\n",
      "        [-1.7966e-02,  1.7531e-02, -4.8758e-03,  ...,  1.9257e-02,\n",
      "         -2.0690e-02, -5.1883e-03],\n",
      "        ...,\n",
      "        [ 1.4826e-02,  1.6989e-02,  7.6155e-03,  ...,  1.1530e-02,\n",
      "         -1.9362e-03,  1.2825e-02],\n",
      "        [ 8.9242e-02, -1.8761e-02,  4.9852e-03,  ...,  9.5181e-03,\n",
      "         -1.6317e-02,  1.9373e-02],\n",
      "        [ 2.1862e-02,  2.2244e-03, -4.3264e-03,  ...,  5.9389e-03,\n",
      "          2.2623e-02,  1.1607e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 14: Best val_acc: 0.3443\n",
      "Epoch 14: train_loss: 0.8940 train_acc: 0.8159 | val_loss: 2.2004 val_acc: 0.3443\n",
      "00:00:08.90\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.1064e-02,  8.7024e-03,  1.1770e-02,  ..., -9.7381e-05,\n",
      "         -6.2428e-03, -9.9609e-02],\n",
      "        [ 1.3431e-02,  5.5241e-03,  1.4254e-02,  ..., -4.9474e-03,\n",
      "          1.1401e-02, -1.2600e-02],\n",
      "        [-1.7971e-02,  1.7588e-02, -4.9467e-03,  ...,  1.9016e-02,\n",
      "         -2.0680e-02, -5.2979e-03],\n",
      "        ...,\n",
      "        [ 1.4700e-02,  1.7094e-02,  7.9711e-03,  ...,  1.1921e-02,\n",
      "         -1.9227e-03,  1.3010e-02],\n",
      "        [ 8.9379e-02, -1.8621e-02,  5.0552e-03,  ...,  9.5521e-03,\n",
      "         -1.6433e-02,  1.9333e-02],\n",
      "        [ 2.1724e-02,  2.1728e-03, -4.2528e-03,  ...,  5.9140e-03,\n",
      "          2.2760e-02,  1.1563e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.1100e-02,  8.7072e-03,  1.1949e-02,  ..., -5.8527e-05,\n",
      "         -6.3826e-03, -9.9619e-02],\n",
      "        [ 1.3403e-02,  5.4447e-03,  1.4344e-02,  ..., -4.9017e-03,\n",
      "          1.1394e-02, -1.2627e-02],\n",
      "        [-1.7964e-02,  1.7567e-02, -4.9323e-03,  ...,  1.9132e-02,\n",
      "         -2.0690e-02, -5.2157e-03],\n",
      "        ...,\n",
      "        [ 1.4726e-02,  1.7039e-02,  7.7254e-03,  ...,  1.1731e-02,\n",
      "         -1.9416e-03,  1.2923e-02],\n",
      "        [ 8.9306e-02, -1.8687e-02,  5.0222e-03,  ...,  9.5150e-03,\n",
      "         -1.6372e-02,  1.9349e-02],\n",
      "        [ 2.1789e-02,  2.1879e-03, -4.2776e-03,  ...,  5.9677e-03,\n",
      "          2.2671e-02,  1.1588e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 15: Best val_acc: 0.3484\n",
      "Epoch 15: Best val_acc: 0.3484\n",
      "Epoch 15: train_loss: 0.8641 train_acc: 0.8273 | val_loss: 2.1884 val_acc: 0.3484\n",
      "00:00:09.77\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0086,  0.0116,  ..., -0.0002, -0.0062, -0.0996],\n",
      "        [ 0.0134,  0.0055,  0.0141,  ..., -0.0051,  0.0114, -0.0125],\n",
      "        [-0.0180,  0.0177, -0.0050,  ...,  0.0190, -0.0207, -0.0053],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0172,  0.0080,  ...,  0.0120, -0.0019,  0.0131],\n",
      "        [ 0.0894, -0.0186,  0.0051,  ...,  0.0096, -0.0164,  0.0193],\n",
      "        [ 0.0216,  0.0021, -0.0042,  ...,  0.0059,  0.0228,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.1064e-02,  8.7024e-03,  1.1770e-02,  ..., -9.7381e-05,\n",
      "         -6.2428e-03, -9.9609e-02],\n",
      "        [ 1.3431e-02,  5.5241e-03,  1.4254e-02,  ..., -4.9474e-03,\n",
      "          1.1401e-02, -1.2600e-02],\n",
      "        [-1.7971e-02,  1.7588e-02, -4.9467e-03,  ...,  1.9016e-02,\n",
      "         -2.0680e-02, -5.2979e-03],\n",
      "        ...,\n",
      "        [ 1.4700e-02,  1.7094e-02,  7.9711e-03,  ...,  1.1921e-02,\n",
      "         -1.9227e-03,  1.3010e-02],\n",
      "        [ 8.9379e-02, -1.8621e-02,  5.0552e-03,  ...,  9.5521e-03,\n",
      "         -1.6433e-02,  1.9333e-02],\n",
      "        [ 2.1724e-02,  2.1728e-03, -4.2528e-03,  ...,  5.9140e-03,\n",
      "          2.2760e-02,  1.1563e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 16: train_loss: 0.7272 train_acc: 0.8523 | val_loss: 2.2427 val_acc: 0.3279\n",
      "00:00:07.77\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0085,  0.0115,  ..., -0.0002, -0.0062, -0.0995],\n",
      "        [ 0.0134,  0.0054,  0.0140,  ..., -0.0052,  0.0115, -0.0124],\n",
      "        [-0.0179,  0.0177, -0.0050,  ...,  0.0189, -0.0207, -0.0054],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0172,  0.0081,  ...,  0.0121, -0.0018,  0.0131],\n",
      "        [ 0.0895, -0.0185,  0.0052,  ...,  0.0096, -0.0165,  0.0193],\n",
      "        [ 0.0216,  0.0021, -0.0041,  ...,  0.0059,  0.0229,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0086,  0.0116,  ..., -0.0002, -0.0062, -0.0996],\n",
      "        [ 0.0134,  0.0055,  0.0141,  ..., -0.0051,  0.0114, -0.0125],\n",
      "        [-0.0180,  0.0177, -0.0050,  ...,  0.0190, -0.0207, -0.0053],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0172,  0.0080,  ...,  0.0120, -0.0019,  0.0131],\n",
      "        [ 0.0894, -0.0186,  0.0051,  ...,  0.0096, -0.0164,  0.0193],\n",
      "        [ 0.0216,  0.0021, -0.0042,  ...,  0.0059,  0.0228,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 17: train_loss: 0.6569 train_acc: 0.8841 | val_loss: 2.2322 val_acc: 0.3279\n",
      "00:00:07.52\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0084,  0.0113,  ..., -0.0003, -0.0061, -0.0995],\n",
      "        [ 0.0134,  0.0055,  0.0139,  ..., -0.0052,  0.0115, -0.0123],\n",
      "        [-0.0178,  0.0177, -0.0051,  ...,  0.0188, -0.0207, -0.0055],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0172,  0.0083,  ...,  0.0123, -0.0018,  0.0132],\n",
      "        [ 0.0895, -0.0185,  0.0053,  ...,  0.0096, -0.0164,  0.0193],\n",
      "        [ 0.0214,  0.0020, -0.0041,  ...,  0.0058,  0.0229,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0085,  0.0115,  ..., -0.0002, -0.0062, -0.0995],\n",
      "        [ 0.0134,  0.0054,  0.0140,  ..., -0.0052,  0.0115, -0.0124],\n",
      "        [-0.0179,  0.0177, -0.0050,  ...,  0.0189, -0.0207, -0.0054],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0172,  0.0081,  ...,  0.0121, -0.0018,  0.0131],\n",
      "        [ 0.0895, -0.0185,  0.0052,  ...,  0.0096, -0.0165,  0.0193],\n",
      "        [ 0.0216,  0.0021, -0.0041,  ...,  0.0059,  0.0229,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 18: train_loss: 0.5760 train_acc: 0.8886 | val_loss: 2.2881 val_acc: 0.3361\n",
      "00:00:07.80\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0084,  0.0113,  ..., -0.0003, -0.0061, -0.0995],\n",
      "        [ 0.0134,  0.0055,  0.0139,  ..., -0.0053,  0.0115, -0.0122],\n",
      "        [-0.0178,  0.0177, -0.0051,  ...,  0.0187, -0.0206, -0.0055],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0173,  0.0084,  ...,  0.0124, -0.0018,  0.0133],\n",
      "        [ 0.0895, -0.0185,  0.0053,  ...,  0.0096, -0.0165,  0.0194],\n",
      "        [ 0.0214,  0.0020, -0.0040,  ...,  0.0058,  0.0230,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0084,  0.0113,  ..., -0.0003, -0.0061, -0.0995],\n",
      "        [ 0.0134,  0.0055,  0.0139,  ..., -0.0052,  0.0115, -0.0123],\n",
      "        [-0.0178,  0.0177, -0.0051,  ...,  0.0188, -0.0207, -0.0055],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0172,  0.0083,  ...,  0.0123, -0.0018,  0.0132],\n",
      "        [ 0.0895, -0.0185,  0.0053,  ...,  0.0096, -0.0164,  0.0193],\n",
      "        [ 0.0214,  0.0020, -0.0041,  ...,  0.0058,  0.0229,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 19: train_loss: 0.5848 train_acc: 0.8932 | val_loss: 2.2635 val_acc: 0.3443\n",
      "00:00:07.82\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0083,  0.0112,  ..., -0.0004, -0.0061, -0.0995],\n",
      "        [ 0.0135,  0.0055,  0.0138,  ..., -0.0054,  0.0116, -0.0122],\n",
      "        [-0.0178,  0.0177, -0.0052,  ...,  0.0187, -0.0207, -0.0056],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0174,  0.0086,  ...,  0.0125, -0.0017,  0.0132],\n",
      "        [ 0.0895, -0.0184,  0.0054,  ...,  0.0096, -0.0165,  0.0194],\n",
      "        [ 0.0213,  0.0020, -0.0040,  ...,  0.0058,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0084,  0.0113,  ..., -0.0003, -0.0061, -0.0995],\n",
      "        [ 0.0134,  0.0055,  0.0139,  ..., -0.0053,  0.0115, -0.0122],\n",
      "        [-0.0178,  0.0177, -0.0051,  ...,  0.0187, -0.0206, -0.0055],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0173,  0.0084,  ...,  0.0124, -0.0018,  0.0133],\n",
      "        [ 0.0895, -0.0185,  0.0053,  ...,  0.0096, -0.0165,  0.0194],\n",
      "        [ 0.0214,  0.0020, -0.0040,  ...,  0.0058,  0.0230,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 20: train_loss: 0.4361 train_acc: 0.9409 | val_loss: 2.2937 val_acc: 0.3402\n",
      "00:00:07.53\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0083,  0.0111,  ..., -0.0004, -0.0061, -0.0995],\n",
      "        [ 0.0135,  0.0055,  0.0136,  ..., -0.0055,  0.0117, -0.0121],\n",
      "        [-0.0177,  0.0177, -0.0052,  ...,  0.0186, -0.0206, -0.0056],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0174,  0.0088,  ...,  0.0126, -0.0017,  0.0133],\n",
      "        [ 0.0895, -0.0184,  0.0054,  ...,  0.0096, -0.0165,  0.0194],\n",
      "        [ 0.0212,  0.0020, -0.0040,  ...,  0.0058,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0083,  0.0112,  ..., -0.0004, -0.0061, -0.0995],\n",
      "        [ 0.0135,  0.0055,  0.0138,  ..., -0.0054,  0.0116, -0.0122],\n",
      "        [-0.0178,  0.0177, -0.0052,  ...,  0.0187, -0.0207, -0.0056],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0174,  0.0086,  ...,  0.0125, -0.0017,  0.0132],\n",
      "        [ 0.0895, -0.0184,  0.0054,  ...,  0.0096, -0.0165,  0.0194],\n",
      "        [ 0.0213,  0.0020, -0.0040,  ...,  0.0058,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 21: Best val_acc: 0.3525\n",
      "Epoch 21: Best val_acc: 0.3525\n",
      "Epoch 21: train_loss: 0.4704 train_acc: 0.9250 | val_loss: 2.3024 val_acc: 0.3525\n",
      "00:00:10.01\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0082,  0.0110,  ..., -0.0004, -0.0062, -0.0995],\n",
      "        [ 0.0135,  0.0055,  0.0136,  ..., -0.0056,  0.0117, -0.0121],\n",
      "        [-0.0177,  0.0178, -0.0052,  ...,  0.0186, -0.0206, -0.0056],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0175,  0.0089,  ...,  0.0126, -0.0016,  0.0132],\n",
      "        [ 0.0895, -0.0184,  0.0055,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0212,  0.0019, -0.0039,  ...,  0.0058,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0083,  0.0111,  ..., -0.0004, -0.0061, -0.0995],\n",
      "        [ 0.0135,  0.0055,  0.0136,  ..., -0.0055,  0.0117, -0.0121],\n",
      "        [-0.0177,  0.0177, -0.0052,  ...,  0.0186, -0.0206, -0.0056],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0174,  0.0088,  ...,  0.0126, -0.0017,  0.0133],\n",
      "        [ 0.0895, -0.0184,  0.0054,  ...,  0.0096, -0.0165,  0.0194],\n",
      "        [ 0.0212,  0.0020, -0.0040,  ...,  0.0058,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 22: train_loss: 0.3712 train_acc: 0.9591 | val_loss: 2.2980 val_acc: 0.3443\n",
      "00:00:07.88\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0081,  0.0109,  ..., -0.0005, -0.0062, -0.0994],\n",
      "        [ 0.0135,  0.0055,  0.0135,  ..., -0.0057,  0.0118, -0.0120],\n",
      "        [-0.0176,  0.0177, -0.0053,  ...,  0.0185, -0.0207, -0.0057],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0175,  0.0090,  ...,  0.0127, -0.0016,  0.0133],\n",
      "        [ 0.0895, -0.0183,  0.0056,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0211,  0.0020, -0.0038,  ...,  0.0057,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0082,  0.0110,  ..., -0.0004, -0.0062, -0.0995],\n",
      "        [ 0.0135,  0.0055,  0.0136,  ..., -0.0056,  0.0117, -0.0121],\n",
      "        [-0.0177,  0.0178, -0.0052,  ...,  0.0186, -0.0206, -0.0056],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0175,  0.0089,  ...,  0.0126, -0.0016,  0.0132],\n",
      "        [ 0.0895, -0.0184,  0.0055,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0212,  0.0019, -0.0039,  ...,  0.0058,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 23: Best val_acc: 0.3566\n",
      "Epoch 23: Best val_acc: 0.3566\n",
      "Epoch 23: train_loss: 0.3080 train_acc: 0.9705 | val_loss: 2.3339 val_acc: 0.3566\n",
      "00:00:10.43\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0081,  0.0108,  ..., -0.0005, -0.0062, -0.0994],\n",
      "        [ 0.0136,  0.0056,  0.0135,  ..., -0.0058,  0.0118, -0.0120],\n",
      "        [-0.0176,  0.0177, -0.0053,  ...,  0.0185, -0.0206, -0.0057],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0175,  0.0092,  ...,  0.0129, -0.0016,  0.0133],\n",
      "        [ 0.0895, -0.0183,  0.0057,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0210,  0.0020, -0.0038,  ...,  0.0057,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0081,  0.0109,  ..., -0.0005, -0.0062, -0.0994],\n",
      "        [ 0.0135,  0.0055,  0.0135,  ..., -0.0057,  0.0118, -0.0120],\n",
      "        [-0.0176,  0.0177, -0.0053,  ...,  0.0185, -0.0207, -0.0057],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0175,  0.0090,  ...,  0.0127, -0.0016,  0.0133],\n",
      "        [ 0.0895, -0.0183,  0.0056,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0211,  0.0020, -0.0038,  ...,  0.0057,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 24: train_loss: 0.3593 train_acc: 0.9636 | val_loss: 2.3399 val_acc: 0.3156\n",
      "00:00:08.58\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0081,  0.0108,  ..., -0.0005, -0.0062, -0.0994],\n",
      "        [ 0.0136,  0.0056,  0.0134,  ..., -0.0058,  0.0119, -0.0119],\n",
      "        [-0.0176,  0.0177, -0.0054,  ...,  0.0184, -0.0206, -0.0057],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0176,  0.0092,  ...,  0.0130, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0182,  0.0057,  ...,  0.0097, -0.0164,  0.0195],\n",
      "        [ 0.0210,  0.0019, -0.0038,  ...,  0.0057,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0081,  0.0108,  ..., -0.0005, -0.0062, -0.0994],\n",
      "        [ 0.0136,  0.0056,  0.0135,  ..., -0.0058,  0.0118, -0.0120],\n",
      "        [-0.0176,  0.0177, -0.0053,  ...,  0.0185, -0.0206, -0.0057],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0175,  0.0092,  ...,  0.0129, -0.0016,  0.0133],\n",
      "        [ 0.0895, -0.0183,  0.0057,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0210,  0.0020, -0.0038,  ...,  0.0057,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 25: train_loss: 0.2740 train_acc: 0.9750 | val_loss: 2.3763 val_acc: 0.3402\n",
      "00:00:08.19\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0080,  0.0107,  ..., -0.0005, -0.0062, -0.0994],\n",
      "        [ 0.0136,  0.0056,  0.0133,  ..., -0.0059,  0.0119, -0.0118],\n",
      "        [-0.0176,  0.0178, -0.0054,  ...,  0.0184, -0.0206, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0176,  0.0093,  ...,  0.0130, -0.0015,  0.0133],\n",
      "        [ 0.0895, -0.0182,  0.0058,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0210,  0.0019, -0.0037,  ...,  0.0057,  0.0232,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0081,  0.0108,  ..., -0.0005, -0.0062, -0.0994],\n",
      "        [ 0.0136,  0.0056,  0.0134,  ..., -0.0058,  0.0119, -0.0119],\n",
      "        [-0.0176,  0.0177, -0.0054,  ...,  0.0184, -0.0206, -0.0057],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0176,  0.0092,  ...,  0.0130, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0182,  0.0057,  ...,  0.0097, -0.0164,  0.0195],\n",
      "        [ 0.0210,  0.0019, -0.0038,  ...,  0.0057,  0.0231,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 26: train_loss: 0.2636 train_acc: 0.9773 | val_loss: 2.3521 val_acc: 0.3484\n",
      "00:00:07.81\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0079,  0.0106,  ..., -0.0006, -0.0062, -0.0995],\n",
      "        [ 0.0136,  0.0056,  0.0132,  ..., -0.0060,  0.0119, -0.0118],\n",
      "        [-0.0176,  0.0178, -0.0055,  ...,  0.0184, -0.0206, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0177,  0.0094,  ...,  0.0131, -0.0015,  0.0133],\n",
      "        [ 0.0895, -0.0182,  0.0058,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0209,  0.0019, -0.0036,  ...,  0.0056,  0.0232,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0080,  0.0107,  ..., -0.0005, -0.0062, -0.0994],\n",
      "        [ 0.0136,  0.0056,  0.0133,  ..., -0.0059,  0.0119, -0.0118],\n",
      "        [-0.0176,  0.0178, -0.0054,  ...,  0.0184, -0.0206, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0176,  0.0093,  ...,  0.0130, -0.0015,  0.0133],\n",
      "        [ 0.0895, -0.0182,  0.0058,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0210,  0.0019, -0.0037,  ...,  0.0057,  0.0232,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 27: train_loss: 0.2337 train_acc: 0.9932 | val_loss: 2.3791 val_acc: 0.3361\n",
      "00:00:08.11\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0079,  0.0105,  ..., -0.0006, -0.0062, -0.0995],\n",
      "        [ 0.0136,  0.0057,  0.0132,  ..., -0.0060,  0.0119, -0.0117],\n",
      "        [-0.0175,  0.0178, -0.0055,  ...,  0.0183, -0.0206, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0178,  0.0095,  ...,  0.0131, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0182,  0.0059,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0209,  0.0018, -0.0036,  ...,  0.0056,  0.0232,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0079,  0.0106,  ..., -0.0006, -0.0062, -0.0995],\n",
      "        [ 0.0136,  0.0056,  0.0132,  ..., -0.0060,  0.0119, -0.0118],\n",
      "        [-0.0176,  0.0178, -0.0055,  ...,  0.0184, -0.0206, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0177,  0.0094,  ...,  0.0131, -0.0015,  0.0133],\n",
      "        [ 0.0895, -0.0182,  0.0058,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0209,  0.0019, -0.0036,  ...,  0.0056,  0.0232,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 28: Best val_acc: 0.3607\n",
      "Epoch 28: Best val_acc: 0.3607\n",
      "Epoch 28: train_loss: 0.1937 train_acc: 0.9932 | val_loss: 2.3795 val_acc: 0.3607\n",
      "00:00:10.02\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0079,  0.0105,  ..., -0.0006, -0.0063, -0.0995],\n",
      "        [ 0.0137,  0.0057,  0.0131,  ..., -0.0061,  0.0119, -0.0117],\n",
      "        [-0.0175,  0.0178, -0.0055,  ...,  0.0183, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0178,  0.0096,  ...,  0.0132, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0182,  0.0060,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0209,  0.0018, -0.0035,  ...,  0.0056,  0.0232,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0079,  0.0105,  ..., -0.0006, -0.0062, -0.0995],\n",
      "        [ 0.0136,  0.0057,  0.0132,  ..., -0.0060,  0.0119, -0.0117],\n",
      "        [-0.0175,  0.0178, -0.0055,  ...,  0.0183, -0.0206, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0178,  0.0095,  ...,  0.0131, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0182,  0.0059,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0209,  0.0018, -0.0036,  ...,  0.0056,  0.0232,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 29: train_loss: 0.1678 train_acc: 0.9886 | val_loss: 2.4073 val_acc: 0.3484\n",
      "00:00:07.90\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0078,  0.0104,  ..., -0.0006, -0.0063, -0.0994],\n",
      "        [ 0.0137,  0.0057,  0.0131,  ..., -0.0062,  0.0120, -0.0117],\n",
      "        [-0.0175,  0.0177, -0.0056,  ...,  0.0183, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0179,  0.0097,  ...,  0.0132, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0181,  0.0060,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0208,  0.0018, -0.0035,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0079,  0.0105,  ..., -0.0006, -0.0063, -0.0995],\n",
      "        [ 0.0137,  0.0057,  0.0131,  ..., -0.0061,  0.0119, -0.0117],\n",
      "        [-0.0175,  0.0178, -0.0055,  ...,  0.0183, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0178,  0.0096,  ...,  0.0132, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0182,  0.0060,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0209,  0.0018, -0.0035,  ...,  0.0056,  0.0232,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 30: train_loss: 0.1578 train_acc: 0.9909 | val_loss: 2.4767 val_acc: 0.3361\n",
      "00:00:08.02\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0078,  0.0104,  ..., -0.0006, -0.0063, -0.0995],\n",
      "        [ 0.0137,  0.0057,  0.0130,  ..., -0.0063,  0.0120, -0.0116],\n",
      "        [-0.0175,  0.0177, -0.0056,  ...,  0.0182, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0179,  0.0098,  ...,  0.0133, -0.0014,  0.0133],\n",
      "        [ 0.0895, -0.0181,  0.0061,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0034,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0078,  0.0104,  ..., -0.0006, -0.0063, -0.0994],\n",
      "        [ 0.0137,  0.0057,  0.0131,  ..., -0.0062,  0.0120, -0.0117],\n",
      "        [-0.0175,  0.0177, -0.0056,  ...,  0.0183, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0179,  0.0097,  ...,  0.0132, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0181,  0.0060,  ...,  0.0096, -0.0164,  0.0195],\n",
      "        [ 0.0208,  0.0018, -0.0035,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 31: train_loss: 0.1570 train_acc: 0.9886 | val_loss: 2.4926 val_acc: 0.3320\n",
      "00:00:08.08\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0078,  0.0103,  ..., -0.0006, -0.0064, -0.0995],\n",
      "        [ 0.0137,  0.0057,  0.0130,  ..., -0.0063,  0.0120, -0.0116],\n",
      "        [-0.0175,  0.0177, -0.0057,  ...,  0.0181, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0180,  0.0098,  ...,  0.0134, -0.0014,  0.0133],\n",
      "        [ 0.0895, -0.0181,  0.0061,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0034,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0078,  0.0104,  ..., -0.0006, -0.0063, -0.0995],\n",
      "        [ 0.0137,  0.0057,  0.0130,  ..., -0.0063,  0.0120, -0.0116],\n",
      "        [-0.0175,  0.0177, -0.0056,  ...,  0.0182, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0179,  0.0098,  ...,  0.0133, -0.0014,  0.0133],\n",
      "        [ 0.0895, -0.0181,  0.0061,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0034,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 32: train_loss: 0.1462 train_acc: 0.9955 | val_loss: 2.4733 val_acc: 0.3402\n",
      "00:00:07.85\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0078,  0.0103,  ..., -0.0006, -0.0064, -0.0995],\n",
      "        [ 0.0137,  0.0058,  0.0129,  ..., -0.0064,  0.0121, -0.0116],\n",
      "        [-0.0175,  0.0177, -0.0057,  ...,  0.0181, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0180,  0.0099,  ...,  0.0134, -0.0014,  0.0133],\n",
      "        [ 0.0895, -0.0180,  0.0062,  ...,  0.0097, -0.0163,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0033,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0078,  0.0103,  ..., -0.0006, -0.0064, -0.0995],\n",
      "        [ 0.0137,  0.0057,  0.0130,  ..., -0.0063,  0.0120, -0.0116],\n",
      "        [-0.0175,  0.0177, -0.0057,  ...,  0.0181, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0180,  0.0098,  ...,  0.0134, -0.0014,  0.0133],\n",
      "        [ 0.0895, -0.0181,  0.0061,  ...,  0.0096, -0.0164,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0034,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 33: Best val_acc: 0.3689\n",
      "Epoch 33: Best val_acc: 0.3689\n",
      "Epoch 33: train_loss: 0.1355 train_acc: 0.9977 | val_loss: 2.4675 val_acc: 0.3689\n",
      "00:00:10.65\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0077,  0.0102,  ..., -0.0006, -0.0064, -0.0995],\n",
      "        [ 0.0137,  0.0058,  0.0129,  ..., -0.0064,  0.0121, -0.0116],\n",
      "        [-0.0175,  0.0177, -0.0058,  ...,  0.0181, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0181,  0.0100,  ...,  0.0135, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0180,  0.0062,  ...,  0.0097, -0.0163,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0033,  ...,  0.0055,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0078,  0.0103,  ..., -0.0006, -0.0064, -0.0995],\n",
      "        [ 0.0137,  0.0058,  0.0129,  ..., -0.0064,  0.0121, -0.0116],\n",
      "        [-0.0175,  0.0177, -0.0057,  ...,  0.0181, -0.0205, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0180,  0.0099,  ...,  0.0134, -0.0014,  0.0133],\n",
      "        [ 0.0895, -0.0180,  0.0062,  ...,  0.0097, -0.0163,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0033,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 34: train_loss: 0.1139 train_acc: 0.9977 | val_loss: 2.4740 val_acc: 0.3607\n",
      "00:00:08.25\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0077,  0.0102,  ..., -0.0006, -0.0064, -0.0995],\n",
      "        [ 0.0137,  0.0059,  0.0129,  ..., -0.0065,  0.0122, -0.0115],\n",
      "        [-0.0174,  0.0177, -0.0059,  ...,  0.0180, -0.0205, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0181,  0.0101,  ...,  0.0134, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0180,  0.0063,  ...,  0.0097, -0.0163,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0032,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0077,  0.0102,  ..., -0.0006, -0.0064, -0.0995],\n",
      "        [ 0.0137,  0.0058,  0.0129,  ..., -0.0064,  0.0121, -0.0116],\n",
      "        [-0.0175,  0.0177, -0.0058,  ...,  0.0181, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0181,  0.0100,  ...,  0.0135, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0180,  0.0062,  ...,  0.0097, -0.0163,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0033,  ...,  0.0055,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 35: train_loss: 0.1061 train_acc: 0.9955 | val_loss: 2.5781 val_acc: 0.3525\n",
      "00:00:08.23\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0077,  0.0102,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0137,  0.0059,  0.0128,  ..., -0.0066,  0.0122, -0.0115],\n",
      "        [-0.0174,  0.0177, -0.0059,  ...,  0.0180, -0.0205, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0181,  0.0102,  ...,  0.0135, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0180,  0.0063,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0207,  0.0018, -0.0032,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0414,  0.0077,  0.0102,  ..., -0.0006, -0.0064, -0.0995],\n",
      "        [ 0.0137,  0.0059,  0.0129,  ..., -0.0065,  0.0122, -0.0115],\n",
      "        [-0.0174,  0.0177, -0.0059,  ...,  0.0180, -0.0205, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0181,  0.0101,  ...,  0.0134, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0180,  0.0063,  ...,  0.0097, -0.0163,  0.0194],\n",
      "        [ 0.0208,  0.0018, -0.0032,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 36: train_loss: 0.1023 train_acc: 0.9977 | val_loss: 2.5439 val_acc: 0.3279\n",
      "00:00:08.14\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0077,  0.0101,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0137,  0.0059,  0.0128,  ..., -0.0066,  0.0122, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0060,  ...,  0.0179, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0182,  0.0103,  ...,  0.0135, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0063,  ...,  0.0097, -0.0163,  0.0194],\n",
      "        [ 0.0207,  0.0018, -0.0032,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0077,  0.0102,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0137,  0.0059,  0.0128,  ..., -0.0066,  0.0122, -0.0115],\n",
      "        [-0.0174,  0.0177, -0.0059,  ...,  0.0180, -0.0205, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0181,  0.0102,  ...,  0.0135, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0180,  0.0063,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0207,  0.0018, -0.0032,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 00037: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 37: train_loss: 0.0924 train_acc: 0.9955 | val_loss: 2.5009 val_acc: 0.3648\n",
      "00:00:08.18\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0076,  0.0101,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0138,  0.0060,  0.0127,  ..., -0.0067,  0.0122, -0.0115],\n",
      "        [-0.0174,  0.0177, -0.0060,  ...,  0.0179, -0.0204, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0182,  0.0103,  ...,  0.0135, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0064,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0207,  0.0018, -0.0031,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0077,  0.0101,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0137,  0.0059,  0.0128,  ..., -0.0066,  0.0122, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0060,  ...,  0.0179, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0182,  0.0103,  ...,  0.0135, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0063,  ...,  0.0097, -0.0163,  0.0194],\n",
      "        [ 0.0207,  0.0018, -0.0032,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 38: Best val_acc: 0.3730\n",
      "Epoch 38: Best val_acc: 0.3730\n",
      "Epoch 38: train_loss: 0.0773 train_acc: 1.0000 | val_loss: 2.5072 val_acc: 0.3730\n",
      "00:00:10.99\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0076,  0.0101,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0138,  0.0060,  0.0127,  ..., -0.0068,  0.0122, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0060,  ...,  0.0179, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0182,  0.0104,  ...,  0.0136, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0064,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0031,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0076,  0.0101,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0138,  0.0060,  0.0127,  ..., -0.0067,  0.0122, -0.0115],\n",
      "        [-0.0174,  0.0177, -0.0060,  ...,  0.0179, -0.0204, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0182,  0.0103,  ...,  0.0135, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0064,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0207,  0.0018, -0.0031,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 39: train_loss: 0.0763 train_acc: 1.0000 | val_loss: 2.5125 val_acc: 0.3443\n",
      "00:00:07.91\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0076,  0.0100,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0138,  0.0061,  0.0127,  ..., -0.0068,  0.0122, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0061,  ...,  0.0179, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0183,  0.0105,  ...,  0.0136, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0065,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0031,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0076,  0.0101,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0138,  0.0060,  0.0127,  ..., -0.0068,  0.0122, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0060,  ...,  0.0179, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0182,  0.0104,  ...,  0.0136, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0064,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0031,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 40: train_loss: 0.0667 train_acc: 1.0000 | val_loss: 2.5371 val_acc: 0.3607\n",
      "00:00:07.71\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0075,  0.0100,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0061,  0.0126,  ..., -0.0069,  0.0123, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0061,  ...,  0.0178, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0183,  0.0105,  ...,  0.0136, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0065,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0030,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0076,  0.0100,  ..., -0.0006, -0.0065, -0.0995],\n",
      "        [ 0.0138,  0.0061,  0.0127,  ..., -0.0068,  0.0122, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0061,  ...,  0.0179, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0183,  0.0105,  ...,  0.0136, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0065,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0031,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 41: train_loss: 0.0588 train_acc: 1.0000 | val_loss: 2.5820 val_acc: 0.3566\n",
      "00:00:08.15\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0075,  0.0100,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0061,  0.0126,  ..., -0.0069,  0.0123, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0061,  ...,  0.0178, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0183,  0.0106,  ...,  0.0136, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0065,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0030,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0075,  0.0100,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0061,  0.0126,  ..., -0.0069,  0.0123, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0061,  ...,  0.0178, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0183,  0.0105,  ...,  0.0136, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0065,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0030,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 42: train_loss: 0.0632 train_acc: 1.0000 | val_loss: 2.5693 val_acc: 0.3648\n",
      "00:00:07.99\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0075,  0.0099,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0061,  0.0126,  ..., -0.0069,  0.0123, -0.0115],\n",
      "        [-0.0174,  0.0177, -0.0061,  ...,  0.0178, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0184,  0.0106,  ...,  0.0136, -0.0015,  0.0132],\n",
      "        [ 0.0894, -0.0179,  0.0066,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0030,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0075,  0.0100,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0061,  0.0126,  ..., -0.0069,  0.0123, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0061,  ...,  0.0178, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0183,  0.0106,  ...,  0.0136, -0.0014,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0065,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0030,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 43: train_loss: 0.0606 train_acc: 1.0000 | val_loss: 2.6161 val_acc: 0.3607\n",
      "00:00:08.07\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0075,  0.0099,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0062,  0.0126,  ..., -0.0070,  0.0123, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0062,  ...,  0.0177, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0184,  0.0107,  ...,  0.0136, -0.0015,  0.0132],\n",
      "        [ 0.0894, -0.0179,  0.0066,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0030,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0075,  0.0099,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0061,  0.0126,  ..., -0.0069,  0.0123, -0.0115],\n",
      "        [-0.0174,  0.0177, -0.0061,  ...,  0.0178, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0184,  0.0106,  ...,  0.0136, -0.0015,  0.0132],\n",
      "        [ 0.0894, -0.0179,  0.0066,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0030,  ...,  0.0056,  0.0232,  0.0114]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 44: train_loss: 0.0544 train_acc: 1.0000 | val_loss: 2.6259 val_acc: 0.3443\n",
      "00:00:08.27\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0075,  0.0099,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0062,  0.0125,  ..., -0.0071,  0.0123, -0.0114],\n",
      "        [-0.0174,  0.0177, -0.0062,  ...,  0.0177, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0184,  0.0107,  ...,  0.0136, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0066,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0029,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0075,  0.0099,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0062,  0.0126,  ..., -0.0070,  0.0123, -0.0115],\n",
      "        [-0.0175,  0.0177, -0.0062,  ...,  0.0177, -0.0204, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0184,  0.0107,  ...,  0.0136, -0.0015,  0.0132],\n",
      "        [ 0.0894, -0.0179,  0.0066,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0030,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 45: train_loss: 0.0491 train_acc: 1.0000 | val_loss: 2.6564 val_acc: 0.3484\n",
      "00:00:08.36\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0098,  ..., -0.0006, -0.0067, -0.0995],\n",
      "        [ 0.0138,  0.0062,  0.0125,  ..., -0.0071,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0062,  ...,  0.0177, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0185,  0.0108,  ...,  0.0137, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0067,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0029,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0075,  0.0099,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0062,  0.0125,  ..., -0.0071,  0.0123, -0.0114],\n",
      "        [-0.0174,  0.0177, -0.0062,  ...,  0.0177, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0184,  0.0107,  ...,  0.0136, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0066,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0029,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 46: train_loss: 0.0463 train_acc: 1.0000 | val_loss: 2.6775 val_acc: 0.3443\n",
      "00:00:07.74\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0098,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0063,  0.0124,  ..., -0.0071,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0063,  ...,  0.0176, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0185,  0.0108,  ...,  0.0137, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0178,  0.0067,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0029,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0098,  ..., -0.0006, -0.0067, -0.0995],\n",
      "        [ 0.0138,  0.0062,  0.0125,  ..., -0.0071,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0062,  ...,  0.0177, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0185,  0.0108,  ...,  0.0137, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0179,  0.0067,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0208,  0.0017, -0.0029,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 47: train_loss: 0.0459 train_acc: 1.0000 | val_loss: 2.6428 val_acc: 0.3607\n",
      "00:00:08.00\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0098,  ..., -0.0006, -0.0067, -0.0995],\n",
      "        [ 0.0138,  0.0063,  0.0125,  ..., -0.0072,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0063,  ...,  0.0176, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0185,  0.0109,  ...,  0.0137, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0178,  0.0067,  ...,  0.0097, -0.0161,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0028,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0098,  ..., -0.0006, -0.0066, -0.0995],\n",
      "        [ 0.0138,  0.0063,  0.0124,  ..., -0.0071,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0063,  ...,  0.0176, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0185,  0.0108,  ...,  0.0137, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0178,  0.0067,  ...,  0.0097, -0.0162,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0029,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 48: train_loss: 0.0406 train_acc: 1.0000 | val_loss: 2.6389 val_acc: 0.3525\n",
      "00:00:08.23\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0097,  ..., -0.0006, -0.0067, -0.0995],\n",
      "        [ 0.0138,  0.0064,  0.0124,  ..., -0.0073,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0063,  ...,  0.0176, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0186,  0.0109,  ...,  0.0137, -0.0015,  0.0131],\n",
      "        [ 0.0895, -0.0178,  0.0067,  ...,  0.0097, -0.0161,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0028,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0098,  ..., -0.0006, -0.0067, -0.0995],\n",
      "        [ 0.0138,  0.0063,  0.0125,  ..., -0.0072,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0063,  ...,  0.0176, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0185,  0.0109,  ...,  0.0137, -0.0015,  0.0132],\n",
      "        [ 0.0895, -0.0178,  0.0067,  ...,  0.0097, -0.0161,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0028,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 49: train_loss: 0.0444 train_acc: 0.9977 | val_loss: 2.6859 val_acc: 0.3402\n",
      "00:00:07.62\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0097,  ..., -0.0006, -0.0067, -0.0995],\n",
      "        [ 0.0138,  0.0064,  0.0124,  ..., -0.0073,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0063,  ...,  0.0176, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0137,  0.0186,  0.0110,  ...,  0.0137, -0.0015,  0.0131],\n",
      "        [ 0.0895, -0.0178,  0.0068,  ...,  0.0097, -0.0161,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0028,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0074,  0.0097,  ..., -0.0006, -0.0067, -0.0995],\n",
      "        [ 0.0138,  0.0064,  0.0124,  ..., -0.0073,  0.0124, -0.0114],\n",
      "        [-0.0175,  0.0177, -0.0063,  ...,  0.0176, -0.0203, -0.0058],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0186,  0.0109,  ...,  0.0137, -0.0015,  0.0131],\n",
      "        [ 0.0895, -0.0178,  0.0067,  ...,  0.0097, -0.0161,  0.0194],\n",
      "        [ 0.0207,  0.0017, -0.0028,  ...,  0.0056,  0.0232,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9997893110072861, 0.9999573631212115, 0.9999697574724754, 0.9999787900596857, 0.999983424708868, 0.9999857703223825, 0.9999861329173049, 0.9999887152419736, 0.9999878775949279, 0.9999890825711191, 0.9999893431862196, 0.9999902722580979, 0.9999915984614441, 0.9999916415351132, 0.999992899907132, 0.9999934044511368, 0.9999935794621706, 0.9999943363169829, 0.9999943911097944, 0.9999946715154996, 0.999995016027242, 0.9999953436975678, 0.9999962117678175, 0.9999952959672859, 0.9999964259720097, 0.999996134157603, 0.9999962918615589, 0.9999969870162507, 0.9999972893080363, 0.99999751127325, 0.9999972493387759, 0.9999975020376345, 0.9999972952840229, 0.9999978215588877, 0.9999980544671416, 0.9999974614474922, 0.999998154817149, 0.9999988419779887, 0.9999988400377333, 0.9999989641364664, 0.9999990245948235, 0.9999989591694126, 0.9999988257574538, 0.9999989225373914, 0.9999989410862327, 0.9999990171442429, 0.9999989926970253, 0.9999990893993527, 0.9999988914156953]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_w['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Row wise average cos similarity')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule(\n",
      "  (feature_modules): ModuleDict(\n",
      "    (distance): Embedding(5, 3, padding_idx=0)\n",
      "    (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "    (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "    (u2_func): Embedding(21, 5, padding_idx=0)\n",
      "    (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "    (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "    (sat_children): Identity()\n",
      "    (nuc_children): Identity()\n",
      "  )\n",
      ")\n",
      "ModuleDict(\n",
      "  (distance): Embedding(5, 3, padding_idx=0)\n",
      "  (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "  (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "  (u2_func): Embedding(21, 5, padding_idx=0)\n",
      "  (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "  (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "  (sat_children): Identity()\n",
      "  (nuc_children): Identity()\n",
      ")\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(21, 5, padding_idx=0)\n",
      "Embedding(12, 4, padding_idx=0)\n",
      "Embedding(12, 4, padding_idx=0)\n",
      "Identity()\n",
      "Identity()\n"
     ]
    }
   ],
   "source": [
    "for i in model.module1.modules():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.3444 test_acc: 0.2692\n",
      "00:00:01.08\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.50      0.11      0.18        18\n",
      "    background       0.33      0.18      0.23        17\n",
      "         cause       0.00      0.00      0.00         2\n",
      "  circumstance       0.27      0.27      0.27        15\n",
      "    concession       0.47      0.54      0.50        13\n",
      "     condition       0.35      0.78      0.48         9\n",
      "   conjunction       0.27      0.43      0.33         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.67      0.55      0.60        11\n",
      "   elaboration       0.12      0.40      0.18        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.17      0.10      0.12        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.21      0.28      0.24        29\n",
      "          list       0.32      0.23      0.27        26\n",
      "         means       1.00      0.50      0.67         2\n",
      "   preparation       0.33      0.50      0.40         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.32      0.41      0.36        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.27       260\n",
      "     macro avg       0.25      0.24      0.23       260\n",
      "  weighted avg       0.27      0.27      0.25       260\n",
      "\n",
      "Test Loss: 3.344 |  Test Acc: 26.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#latest\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.0875 test_acc: 0.2692\n",
      "00:00:01.07\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.50      0.11      0.18        18\n",
      "    background       0.33      0.29      0.31        17\n",
      "         cause       0.00      0.00      0.00         2\n",
      "  circumstance       0.24      0.27      0.25        15\n",
      "    concession       0.47      0.54      0.50        13\n",
      "     condition       0.37      0.78      0.50         9\n",
      "   conjunction       0.25      0.43      0.32         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.78      0.64      0.70        11\n",
      "   elaboration       0.12      0.40      0.19        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.09      0.10      0.10        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.21      0.21      0.21        29\n",
      "          list       0.32      0.23      0.27        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.33      0.50      0.40         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.39      0.41      0.40        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.27       260\n",
      "     macro avg       0.22      0.22      0.20       260\n",
      "  weighted avg       0.28      0.27      0.26       260\n",
      "\n",
      "Latest Test Loss: 3.087 |  Latest Test Acc: 26.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best earliest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.0875 test_acc: 0.2692\n",
      "00:00:01.13\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.50      0.11      0.18        18\n",
      "    background       0.33      0.29      0.31        17\n",
      "         cause       0.00      0.00      0.00         2\n",
      "  circumstance       0.24      0.27      0.25        15\n",
      "    concession       0.47      0.54      0.50        13\n",
      "     condition       0.37      0.78      0.50         9\n",
      "   conjunction       0.25      0.43      0.32         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.78      0.64      0.70        11\n",
      "   elaboration       0.12      0.40      0.19        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.09      0.10      0.10        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.21      0.21      0.21        29\n",
      "          list       0.32      0.23      0.27        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.33      0.50      0.40         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.39      0.41      0.40        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.27       260\n",
      "     macro avg       0.22      0.22      0.20       260\n",
      "  weighted avg       0.28      0.27      0.26       260\n",
      "\n",
      "Best Test Loss: 3.087 |  Best Test Acc: 26.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best lastest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_latest', test_acc, 1)\n",
    "print(f'Best Test Loss: {test_loss:.3f} |  Best Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.5245 test_acc: 0.3607\n",
      "00:00:01.05\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.14      0.09      0.11        11\n",
      "    background       0.25      0.24      0.24        17\n",
      "         cause       0.17      0.14      0.15         7\n",
      "  circumstance       0.30      0.23      0.26        13\n",
      "    concession       0.36      0.36      0.36        11\n",
      "     condition       0.50      0.88      0.64         8\n",
      "   conjunction       0.70      0.88      0.78         8\n",
      "      contrast       0.00      0.00      0.00         3\n",
      " e-elaboration       0.78      0.54      0.64        13\n",
      "   elaboration       0.32      0.25      0.28        28\n",
      "  evaluation-n       0.00      0.00      0.00         8\n",
      "  evaluation-s       0.17      0.20      0.18         5\n",
      "      evidence       0.17      0.25      0.20         8\n",
      "interpretation       0.08      0.08      0.08        13\n",
      "         joint       0.38      0.44      0.41        18\n",
      "          list       0.45      0.56      0.50        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.80      0.73      0.76        11\n",
      "       purpose       0.75      0.60      0.67         5\n",
      "        reason       0.35      0.50      0.41        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         3\n",
      "      sequence       0.00      0.00      0.00         0\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.37       241\n",
      "     macro avg       0.27      0.28      0.27       241\n",
      "  weighted avg       0.35      0.37      0.35       241\n",
      "\n",
      "Val Loss: 2.524 |  Val Acc: 36.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best val acc\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
