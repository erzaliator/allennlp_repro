{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broken code. Refer only till tokenization step for clarity\n",
    "https://www.analyticsvidhya.com/blog/2021/05/bert-for-natural-language-inference-simplified-in-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jump to section SNLI Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "SEED = 1111\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9211232db27f4a4b90abdbb7da30131a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bc33a2e5084b898d2ce754d408e179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975c23c3e50449bbabb47ff5134f525e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', '##y', 'there', '!', '!', 'see', 'some', 'boys', 'are', 'playing', 'in', 'rain']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Heyy There!! See some boys are playing in rain')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4931, 2100, 2045, 999, 999, 2156, 2070, 3337, 2024, 2652, 1999, 4542]\n"
     ]
    }
   ],
   "source": [
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [SEP] [PAD] [UNK]\n"
     ]
    }
   ],
   "source": [
    "cls_token = tokenizer.cls_token\n",
    "sep_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "print(cls_token, sep_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "cls_token_idx = tokenizer.cls_token_id\n",
    "sep_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "print(cls_token_idx, sep_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_bert(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    return tokens\n",
    "def split_and_cut(sentence):\n",
    "    tokens = sentence.strip().split(\" \")\n",
    "    tokens = tokens[:max_input_length]\n",
    "    return tokens\n",
    "\n",
    "def trim_sentence(sent):\n",
    "    try:\n",
    "        sent = sent.split()\n",
    "        sent = sent[:128]\n",
    "        return \" \".join(sent)\n",
    "    except:\n",
    "        return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper funcs for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of 0s \n",
    "def get_sent1_token_type(sent):\n",
    "    try:\n",
    "        return [0]* len(sent)\n",
    "    except:\n",
    "        return []\n",
    "#Get list of 1s\n",
    "def get_sent2_token_type(sent):\n",
    "    try:\n",
    "        return [1]* len(sent)\n",
    "    except:\n",
    "        return []\n",
    "#combine from lists\n",
    "def combine_seq(seq):\n",
    "    return \" \".join(seq)\n",
    "#combines from lists of int\n",
    "def combine_mask(mask):\n",
    "    mask = [str(m) for m in mask]\n",
    "    return \" \".join(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#load dataset\n",
    "df_train = pd.read_csv('snli/snli_1.0_train.csv')\n",
    "df_dev = pd.read_csv('snli/snli_1.0_dev.csv')\n",
    "df_test = pd.read_csv('snli/snli_1.0_test.csv')\n",
    "\n",
    "#Get neccesary columns\n",
    "df_train = df_train[['gold_label','sentence1','sentence2']]\n",
    "df_dev = df_dev[['gold_label','sentence1','sentence2']]\n",
    "df_test = df_test[['gold_label','sentence1','sentence2']]\n",
    "\n",
    "#Take small dataset\n",
    "df_train = df_train[:80000]\n",
    "df_dev = df_train[:8000]\n",
    "df_test = df_train[:8000]\n",
    "\n",
    "#Trim each sentence upto maximum length\n",
    "df_train['sentence1'] = df_train['sentence1'].apply(trim_sentence)\n",
    "df_train['sentence2'] = df_train['sentence2'].apply(trim_sentence)\n",
    "df_dev['sentence1'] = df_dev['sentence1'].apply(trim_sentence)\n",
    "df_dev['sentence2'] = df_dev['sentence2'].apply(trim_sentence)\n",
    "df_test['sentence1'] = df_test['sentence1'].apply(trim_sentence)\n",
    "df_test['sentence2'] = df_test['sentence2'].apply(trim_sentence)\n",
    "\n",
    "#Add [CLS] and [SEP] tokens\n",
    "df_train['sent1'] = '[CLS] ' + df_train['sentence1'] + ' [SEP] '\n",
    "df_train['sent2'] = df_train['sentence2'] + ' [SEP]'\n",
    "df_dev['sent1'] = '[CLS] ' + df_dev['sentence1'] + ' [SEP] '\n",
    "df_dev['sent2'] = df_dev['sentence2'] + ' [SEP]'\n",
    "df_test['sent1'] = '[CLS] ' + df_test['sentence1'] + ' [SEP] '\n",
    "df_test['sent2'] = df_test['sentence2'] + ' [SEP]'\n",
    "\n",
    "#Apply Bert Tokenizer for tokeinizing\n",
    "df_train['sent1_t'] = df_train['sent1'].apply(tokenize_bert)\n",
    "df_train['sent2_t'] = df_train['sent2'].apply(tokenize_bert)\n",
    "df_dev['sent1_t'] = df_dev['sent1'].apply(tokenize_bert)\n",
    "df_dev['sent2_t'] = df_dev['sent2'].apply(tokenize_bert)\n",
    "df_test['sent1_t'] = df_test['sent1'].apply(tokenize_bert)\n",
    "df_test['sent2_t'] = df_test['sent2'].apply(tokenize_bert)\n",
    "\n",
    "\n",
    "#Get Topen type ids for both sentence\n",
    "df_train['sent1_token_type'] = df_train['sent1_t'].apply(get_sent1_token_type)\n",
    "df_train['sent2_token_type'] = df_train['sent2_t'].apply(get_sent2_token_type)\n",
    "df_dev['sent1_token_type'] = df_dev['sent1_t'].apply(get_sent1_token_type)\n",
    "df_dev['sent2_token_type'] = df_dev['sent2_t'].apply(get_sent2_token_type)\n",
    "df_test['sent1_token_type'] = df_test['sent1_t'].apply(get_sent1_token_type)\n",
    "df_test['sent2_token_type'] = df_test['sent2_t'].apply(get_sent2_token_type)\n",
    "\n",
    "#Combine both sequences\n",
    "df_train['sequence'] = df_train['sent1_t'] + df_train['sent2_t']\n",
    "df_dev['sequence'] = df_dev['sent1_t'] + df_dev['sent2_t']\n",
    "df_test['sequence'] = df_test['sent1_t'] + df_test['sent2_t']\n",
    "\n",
    "\n",
    "#Get attention mask\n",
    "df_train['attention_mask'] = df_train['sequence'].apply(get_sent2_token_type)\n",
    "df_dev['attention_mask'] = df_dev['sequence'].apply(get_sent2_token_type)\n",
    "df_test['attention_mask'] = df_test['sequence'].apply(get_sent2_token_type)\n",
    "\n",
    "#Get combined token type ids for input\n",
    "df_train['token_type'] = df_train['sent1_token_type'] + df_train['sent2_token_type']\n",
    "df_dev['token_type'] = df_dev['sent1_token_type'] + df_dev['sent2_token_type']\n",
    "df_test['token_type'] = df_test['sent1_token_type'] + df_test['sent2_token_type']\n",
    "\n",
    "#Now make all these inputs as sequential data to be easily fed into torchtext Field.\n",
    "df_train['sequence'] = df_train['sequence'].apply(combine_seq)\n",
    "df_dev['sequence'] = df_dev['sequence'].apply(combine_seq)\n",
    "df_test['sequence'] = df_test['sequence'].apply(combine_seq)\n",
    "df_train['attention_mask'] = df_train['attention_mask'].apply(combine_mask)\n",
    "df_dev['attention_mask'] = df_dev['attention_mask'].apply(combine_mask)\n",
    "df_test['attention_mask'] = df_test['attention_mask'].apply(combine_mask)\n",
    "df_train['token_type'] = df_train['token_type'].apply(combine_mask)\n",
    "df_dev['token_type'] = df_dev['token_type'].apply(combine_mask)\n",
    "df_test['token_type'] = df_test['token_type'].apply(combine_mask)\n",
    "df_train = df_train[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
    "df_dev = df_dev[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
    "df_test = df_test[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
    "df_train = df_train.loc[df_train['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
    "df_dev = df_dev.loc[df_dev['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
    "df_test = df_test.loc[df_test['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
    "\n",
    "#Save prepared data as csv file\n",
    "df_train.to_csv('snli/snli_1.0_train_analyticsvidhya.csv', index=False)\n",
    "df_dev.to_csv('snli/snli_1.0_dev_analyticsvidhya.csv', index=False)\n",
    "df_test.to_csv('snli/snli_1.0_test_analyticsvidhya.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sequence</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[CLS] a person on a horse jumps over a broken ...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>[CLS] a person on a horse jumps over a broken ...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>[CLS] a person on a horse jumps over a broken ...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[CLS] children smiling and waving at camera [S...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>0 0 0 0 0 0 0 0 1 1 1 1 1 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>[CLS] children smiling and waving at camera [S...</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1</td>\n",
       "      <td>0 0 0 0 0 0 0 0 1 1 1 1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                           sequence  \\\n",
       "0        neutral  [CLS] a person on a horse jumps over a broken ...   \n",
       "1  contradiction  [CLS] a person on a horse jumps over a broken ...   \n",
       "2     entailment  [CLS] a person on a horse jumps over a broken ...   \n",
       "3        neutral  [CLS] children smiling and waving at camera [S...   \n",
       "4     entailment  [CLS] children smiling and waving at camera [S...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "1  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2    1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "3                      1 1 1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "4                          1 1 1 1 1 1 1 1 1 1 1 1 1   \n",
       "\n",
       "                                          token_type  \n",
       "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1  \n",
       "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 ...  \n",
       "2    0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1  \n",
       "3                      0 0 0 0 0 0 0 0 1 1 1 1 1 1 1  \n",
       "4                          0 0 0 0 0 0 0 0 1 1 1 1 1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36303\n",
      "9831\n",
      "9815\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.base_path = '/content/'\n",
    "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.train_data = self.load_data(self.train_df)\n",
    "    self.val_data = self.load_data(self.val_df)\n",
    "    self.test_data = self.load_data(self.test_df)\n",
    "\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512\n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['sentence1'].to_list()\n",
    "    hypothesis_list = df['sentence2'].to_list()\n",
    "    label_list = df['gold_label'].to_list()\n",
    "\n",
    "    for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
    "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      premise_len = len(premise_id)\n",
    "      hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "    print(len(dataset))\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
    "    train_loader = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_df = pd.read_csv('snli/snli_1.0_train.csv')\n",
    "val_df = pd.read_csv('snli/snli_1.0_dev.csv')\n",
    "test_df = pd.read_csv('snli/snli_1.0_test.csv')\n",
    "\n",
    "# train_df = train_df[:1000]\n",
    "# val_df = val_df[:100]\n",
    "# test_df = test_df[:100]\n",
    "\n",
    "train_df = train_df.loc[train_df['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
    "val_df = val_df.loc[val_df['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
    "test_df = test_df.loc[test_df['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
    "\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'entailment', 1: 'contradiction', 2: 'neutral'},\n",
       " {'entailment': 0, 'contradiction': 1, 'neutral': 2})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = mnli_dataset.label_dict\n",
    "rev_label_dict = {label_dict[k]:k for k in label_dict.keys()}\n",
    "rev_label_dict, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc\n",
    "\n",
    "import time\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer):  \n",
    "  total_step = len(train_loader)\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "\n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "    model.eval()\n",
    "    total_val_acc  = 0\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pair_token_ids = pair_token_ids.to(device)\n",
    "        mask_ids = mask_ids.to(device)\n",
    "        seg_ids = seg_ids.to(device)\n",
    "        labels = y.to(device)\n",
    "        \n",
    "        loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "        \n",
    "        acc = multi_acc(prediction, labels)\n",
    "\n",
    "        total_val_loss += loss.item()\n",
    "        total_val_acc  += acc.item()\n",
    "\n",
    "    val_acc  = total_val_acc/len(val_loader)\n",
    "    val_loss = total_val_loss/len(val_loader)\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.5308 train_acc: 0.7828 | val_loss: 0.4308 val_acc: 0.8371\n",
      "00:04:13.68\n",
      "Epoch 2: train_loss: 0.2874 train_acc: 0.8954 | val_loss: 0.4141 val_acc: 0.8475\n",
      "00:04:13.47\n",
      "Epoch 3: train_loss: 0.1633 train_acc: 0.9441 | val_loss: 0.4863 val_acc: 0.8538\n",
      "00:04:11.44\n",
      "Epoch 4: train_loss: 0.0976 train_acc: 0.9672 | val_loss: 0.5690 val_acc: 0.8483\n",
      "00:04:11.98\n",
      "Epoch 5: train_loss: 0.0663 train_acc: 0.9778 | val_loss: 0.6344 val_acc: 0.8440\n",
      "00:04:12.46\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'bert-nli.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 0.6332 test_acc: 0.8423\n",
      "00:00:13.74\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.85      0.88      0.86      3236\n",
      "   entailment       0.90      0.83      0.86      3364\n",
      "      neutral       0.79      0.82      0.81      3215\n",
      "\n",
      "     accuracy                           0.85      9815\n",
      "    macro avg       0.85      0.85      0.85      9815\n",
      " weighted avg       0.85      0.85      0.85      9815\n",
      "\n",
      "Test Loss: 0.633 |  Test Acc: 84.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "  start = time.time()\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "\n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(iterator):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      \n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            labels=labels).values()\n",
    "      \n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      argmax_predictions = torch.argmax(prediction,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "\n",
    "  val_acc  = total_val_acc/len(val_loader)\n",
    "  val_loss = total_val_loss/len(val_loader)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {val_loss:.4f} test_acc: {val_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "  print(classification_report(y_true, y_pred))\n",
    "  return val_loss, val_acc, y_true, y_pred\n",
    "\n",
    "model.load_state_dict(torch.load('bert-nli.pt'))\n",
    "test_loss, test_acc, y_true, y_pred = evaluate(model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Medium page.\n",
    "# TODO: Make code modular. eg - evaluation called for dev and test adn train. Loss and prediction can become loss and logits. Another wrapper to return basic predictions/log them in it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
