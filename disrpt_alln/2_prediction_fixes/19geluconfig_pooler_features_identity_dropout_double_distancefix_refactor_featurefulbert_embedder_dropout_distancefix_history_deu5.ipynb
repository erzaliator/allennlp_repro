{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2019\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "batch_size = 4\n",
    "batches_per_epoch = 110\n",
    "\n",
    "save_path_suffix = '19geluconfig_pooler_features_identity_dropout_double_refactor_featurefulbertemb_dropout_distancefix_history_deu2019_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label',\n",
       "       'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position',\n",
       "       'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case',\n",
       "       'unit2_case', 'u1_discontinuous', 'u2_discontinuous', 'same_speaker',\n",
       "       'lex_overlap_length', 'u1_func'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 10:15:41.849921: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 10:15:42.149790: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-09 10:15:42.149836: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-09 10:15:42.208327: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-09 10:15:43.133496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-09 10:15:43.133591: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-09 10:15:43.133599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, ConcatDataset\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate, Vocabulary\n",
    "from features_custom2 import get_vocab_feature_name\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.vocab = Vocabulary(counter=None, max_vocab_size=100000)\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.init_feature_list()\n",
    "    self.init_feature_mappings_and_bins()\n",
    "    self.apply_bins()\n",
    "    self.calculate_unique_values()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    \n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def init_feature_mappings_and_bins(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "    self.bins = {\n",
    "      'distance': [[-1e9, -8], [-8, -2], [-2, 0], [0, 2], [2, 8], [8, 1e9]],\n",
    "      'u1_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'u2_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'lex_overlap_length': [[0, 2], [2, 7], [7, 1e9]]\n",
    "    }   \n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def init_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "    else: \n",
    "      raise ValueError()\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features_list(self, features, feature_name):\n",
    "    if feature_name in ['distance', 'u1_depdir', 'u2_depdir', 'u1_func', 'u2_func', \n",
    "    'u1_position', 'u2_position', 'genre', 'same_speaker', 'unit1_case', 'unit2_case',\n",
    "    'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'dir']: feature_value = self.apply_vocab(features[feature_name], feature_name) #for categorical values\n",
    "    elif feature_name in ['sat_children', 'nuc_children']: feature_value = float(features[feature_name]) #for identiy values\n",
    "    else: \n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    return feature_value\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==17\n",
    "    #after applying the vocab. we need to pass them as int\n",
    "    return {feature_name: torch.tensor(int(self.get_allen_features_list(features, feature_name))).to(device) for feature_name in self.feature_list+['dir']}\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature_name in self.feature_list+['dir']:\n",
    "      vocab_feature_name = get_vocab_feature_name(feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(train_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(val_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "\n",
    "  def apply_bins(self):\n",
    "    for df in [self.train_df, self.test_df, self.val_df]:\n",
    "      for feature_name in self.bins.keys():\n",
    "        df[feature_name] = df[feature_name].apply(lambda x: self.get_mapping_from_bin(feature_name, float(x)))\n",
    "\n",
    "  def get_mapping_from_bin(self, column_name, dict_val):\n",
    "    bins = self.bins[column_name]\n",
    "    for b,i in zip(bins, range(len(bins))):\n",
    "      left = b[0]\n",
    "      right = b[1]\n",
    "      if left<=dict_val and right>=dict_val: return i\n",
    "\n",
    "  def apply_vocab(self, feature_value, feature_name):\n",
    "    return self.vocab.get_token_index(str(feature_value), namespace=get_vocab_feature_name(feature_name))\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      features = {'distance': row['distance'],\n",
    "                'u1_depdir': row['u1_depdir'],\n",
    "                'u2_depdir': row['u2_depdir'],\n",
    "                'u1_func': row['u1_func'],\n",
    "                'u2_func': row['u2_func'],\n",
    "                'u1_position': row['u1_position'],\n",
    "                'u2_position': row['u2_position'],\n",
    "                'sat_children': row['sat_children'],\n",
    "                'nuc_children': row['nuc_children'],\n",
    "                'genre': row['genre'],\n",
    "                'unit1_case': row['unit1_case'],\n",
    "                'unit2_case': row['unit2_case'],\n",
    "                'u1_discontinuous': row['u1_discontinuous'],\n",
    "                'u2_discontinuous': row['u2_discontinuous'],\n",
    "                'same_speaker': row['same_speaker'],\n",
    "                'lex_overlap_length': row['lex_overlap_length'],\n",
    "                'dir': row['dir']}\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding=False) #padding='max_length'\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      features = self.transform_feature(features)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(features)\n",
    "      \n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "      \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "\n",
    "    class featureDataset(Dataset):\n",
    "      def __init__(self, token_ids, mask_ids, seg_ids, feats, y, idx):\n",
    "          self.token_ids = token_ids\n",
    "          self.mask_ids = mask_ids\n",
    "          self.seg_ids = seg_ids\n",
    "          self.feats = feats\n",
    "          self.y = y\n",
    "          self.idx = idx\n",
    "\n",
    "      def __len__(self):\n",
    "          return len(self.feats)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "          return self.token_ids[idx], self.mask_ids[idx], self.seg_ids[idx], self.feats[idx], self.y[idx], self.idx[idx]\n",
    "\n",
    "    dataset = featureDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '3': 2, '4': 3, '5': 4}\n",
      "u1_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_func :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'root': 2, 'conj': 3, 'advcl': 4, 'acl': 5, 'xcomp': 6, 'obl': 7, 'ccomp': 8, 'parataxis': 9, 'advmod': 10, 'dep': 11, 'csubj': 12, 'nmod': 13, 'punct': 14, 'cc': 15, 'appos': 16, 'aux': 17, 'obj': 18, 'iobj': 19, 'nsubj': 20}\n",
      "u1_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '1': 11}\n",
      "u2_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '1': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
      "sat_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '4': 3, '1': 4, '2': 5, '3': 6, '5': 7, '6': 8}\n",
      "nuc_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '4': 2, '3': 3, '1': 4, '2': 5, '5': 6, '6': 7, '7': 8, '8': 9}\n",
      "dir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '1>2': 2, '1<2': 3}\n"
     ]
    }
   ],
   "source": [
    "for feature in mnli_dataset.feature_list:\n",
    "    vocab_feature_name = get_vocab_feature_name(feature)\n",
    "    print(feature, ': ', mnli_dataset.vocab.get_token_to_index_vocabulary(vocab_feature_name))\n",
    "print('dir', ': ', mnli_dataset.vocab.get_token_to_index_vocabulary('dir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    # assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    # assert mask_ids.shape[-1]==512\n",
    "    # assert seg_ids.shape[-1]==512\n",
    "    assert len(feat)==len(mnli_dataset.feature_list)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '@@PADDING@@', 1: '@@UNKNOWN@@'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_dataset.vocab.get_index_to_token_vocabulary('u1_depdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        if i not in idx_map.keys():\n",
    "          print(idx_map)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing FeaturefulBert: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing FeaturefulBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FeaturefulBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, Optional\n",
    "from transformers import BertModel, AutoTokenizer, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from featurefulbertembedder_custom2 import FeaturefulBertEmbedder\n",
    "from featureful_bert_custom2 import get_combined_feature_tensor_2 as get_combined_feature_tensor_forward\n",
    "from featureful_bert_custom2 import get_feature_modules\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class CustomPooler2(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                        requires_grad: bool = True,\n",
    "                        dropout: float = 0.0,\n",
    "                        transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "        super().__init__()\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL) #only used to pass config. BertAttentionClass used in FeatureFulBert\n",
    "        self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.pooler = copy.deepcopy(bert.pooler)\n",
    "        for param in self.pooler.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        self._embedding_dim = bert.config.hidden_size\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "        pooler = self.pooler\n",
    "        \n",
    "        for _ in range(num_wrapping_dims):\n",
    "            pooler = TimeDistributed(pooler)\n",
    "        pooled = pooler(tokens)\n",
    "        pooled = self._dropout(pooled)\n",
    "        return pooled\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list, vocab):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_modules, self._feature_module_size = get_feature_modules(feature_list, vocab)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return get_combined_feature_tensor_forward(features, self.feature_list, self.feature_modules)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels, vocab):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels\n",
    "          self.feature_list = mnli_dataset.feature_list\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "\n",
    "          self.embedder = self.create_featureful_bert()\n",
    "          self.encoder = CustomPooler2()\n",
    "          self.module1 = MyModule(self.feature_list, vocab)\n",
    "          self.dropout1 = nn.Dropout(p=0.0)\n",
    "        #   self.dropout_decoder = nn.Dropout(p=0.5)\n",
    "          self._decoder_input_size = self.encoder._embedding_dim + self.module1._feature_module_size\n",
    "          self.relation_decoder = nn.Linear(self._decoder_input_size, self.num_classes)\n",
    "\n",
    "          self.history_w = {\n",
    "            'cos': [],\n",
    "            # 'l1_linear': [],\n",
    "            # 'l2': []\n",
    "          }\n",
    "          self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "          print(self.pooler_weight)\n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask, feat):\n",
    "        direction_tensor = feat['dir'].to(device)\n",
    "        embedded_sentence = self.embedder(token_ids=pair_token_ids, #featurefulmebedder\n",
    "                        mask=attention_mask, \n",
    "                        type_ids=token_type_ids,\n",
    "                        segment_concat_mask = None,\n",
    "                        direction_tensor = direction_tensor,\n",
    "                        feature_list = self.feature_list,\n",
    "                        features = feat)\n",
    "        mask = token_type_ids\n",
    "        bertpooler_output = self.encoder(tokens=embedded_sentence, mask=mask)\n",
    "        feat = self.convert_to_feature_list(feat)\n",
    "        feat = self.dropout1(feat)\n",
    "        feat = self.module1(feat)\n",
    "        # print(bertpooler_output.shape, self.module1._feature_module_size, feat.shape)\n",
    "        try:\n",
    "            feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "        except:\n",
    "            print(bertpooler_output.shape, feat.shape)\n",
    "            raise ValueError()\n",
    "        assert feat_concat.shape[-1] == self._decoder_input_size\n",
    "        feat_concat = self.dropout1(feat_concat)\n",
    "        # feat_concat = self.dropout_decoder(feat_concat)\n",
    "        linear1_output = self.relation_decoder(feat_concat)\n",
    "        return linear1_output\n",
    "\n",
    "    def compute_pooler_similarity(self):\n",
    "        cur = self.encoder.pooler.dense.weight\n",
    "        pre = self.pooler_weight\n",
    "        print(cur)\n",
    "        print(pre)\n",
    "        assert not torch.all(cur.eq(pre))\n",
    "        for metric in self.history_w.keys():\n",
    "            self.history_w[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "\n",
    "    def similarity(self, cur, pre, metric):\n",
    "        metric = 0\n",
    "        n = 0\n",
    "        for A, B in zip(cur.cpu().detach().numpy(), pre.cpu().detach().numpy()):\n",
    "            cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "            metric+= cosine\n",
    "            n+=1\n",
    "        return float(metric)/float(n), metric\n",
    "\n",
    "    def create_bert_without_activations(self):\n",
    "        config = BertConfig.from_pretrained(BERT_MODEL, hidden_act='gelu')\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "        return bert\n",
    "\n",
    "    def create_featureful_bert(self):\n",
    "        featureful_bert = FeaturefulBertEmbedder(model_name = BERT_MODEL,\n",
    "                                hidden_activation_allen = 'gelu',\n",
    "                                feature_list = self.feature_list, \n",
    "                                vocab=mnli_dataset.vocab)\n",
    "                                # .... FeatureBert() .... model(**parameters)\n",
    "        return featureful_bert\n",
    "\n",
    "    def convert_to_feature_list(self, feat):\n",
    "        feature_linear = [feat[feature_name] for feature_name in self.feature_list]\n",
    "        feature_linear = torch.stack(feature_linear, dim=-1)\n",
    "        return feature_linear\n",
    "        \n",
    "\n",
    "model = CustomBERTModel(mnli_dataset.num_labels, mnli_dataset.vocab)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, correct_bias=False) # original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, mode='max', patience=35, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prinintg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomBERTModel(\n",
      "  (embedder): FeaturefulBertEmbedder(\n",
      "    (transformer_model): FeaturefulBert(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (feature_modules): ModuleDict(\n",
      "        (distance): Embedding(5, 3, padding_idx=0)\n",
      "        (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_func): Embedding(21, 5, padding_idx=0)\n",
      "        (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "        (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "        (sat_children): Identity()\n",
      "        (nuc_children): Identity()\n",
      "      )\n",
      "      (feature_projector): Linear(in_features=25, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): CustomPooler2(\n",
      "    (_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (module1): MyModule(\n",
      "    (feature_modules): ModuleDict(\n",
      "      (distance): Embedding(5, 3, padding_idx=0)\n",
      "      (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_func): Embedding(21, 5, padding_idx=0)\n",
      "      (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "      (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "      (sat_children): Identity()\n",
      "      (nuc_children): Identity()\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (relation_decoder): Linear(in_features=792, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3376364234.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [21]\u001b[0;36m\u001b[0m\n\u001b[0;31m    feat=feat)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n",
    "\n",
    "    model.compute_pooler_similarity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Best val_acc: 0.1475\n",
      "Epoch 1: Best val_acc: 0.1475\n",
      "Epoch 1: train_loss: 2.9537 train_acc: 0.1568 | val_loss: 2.7046 val_acc: 0.1475\n",
      "00:00:20.33\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0419,  0.0082,  0.0122,  ...,  0.0006, -0.0076, -0.0988],\n",
      "        [ 0.0135,  0.0063,  0.0166,  ..., -0.0025,  0.0091, -0.0130],\n",
      "        [-0.0180,  0.0178, -0.0042,  ...,  0.0210, -0.0207, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0161,  0.0057,  ...,  0.0090, -0.0010,  0.0117],\n",
      "        [ 0.0870, -0.0188,  0.0049,  ...,  0.0100, -0.0164,  0.0203],\n",
      "        [ 0.0235,  0.0022, -0.0043,  ...,  0.0064,  0.0227,  0.0112]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 2: Best val_acc: 0.2090\n",
      "Epoch 2: Best val_acc: 0.2090\n",
      "Epoch 2: train_loss: 2.5628 train_acc: 0.2364 | val_loss: 2.5139 val_acc: 0.2090\n",
      "00:00:21.95\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2312e-02,  7.6115e-03,  1.1716e-02,  ...,  8.5486e-05,\n",
      "         -7.2836e-03, -9.8239e-02],\n",
      "        [ 1.3693e-02,  6.3788e-03,  1.6918e-02,  ..., -2.1408e-03,\n",
      "          8.9769e-03, -1.3329e-02],\n",
      "        [-1.7953e-02,  1.7610e-02, -4.4659e-03,  ...,  2.0963e-02,\n",
      "         -2.0820e-02, -3.9661e-03],\n",
      "        ...,\n",
      "        [ 1.4490e-02,  1.6164e-02,  5.6012e-03,  ...,  9.1533e-03,\n",
      "         -8.3126e-04,  1.1684e-02],\n",
      "        [ 8.6938e-02, -1.8479e-02,  4.8035e-03,  ...,  1.0129e-02,\n",
      "         -1.6396e-02,  2.0073e-02],\n",
      "        [ 2.3430e-02,  2.2654e-03, -4.3080e-03,  ...,  6.5375e-03,\n",
      "          2.2794e-02,  1.1247e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0419,  0.0082,  0.0122,  ...,  0.0006, -0.0076, -0.0988],\n",
      "        [ 0.0135,  0.0063,  0.0166,  ..., -0.0025,  0.0091, -0.0130],\n",
      "        [-0.0180,  0.0178, -0.0042,  ...,  0.0210, -0.0207, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0161,  0.0057,  ...,  0.0090, -0.0010,  0.0117],\n",
      "        [ 0.0870, -0.0188,  0.0049,  ...,  0.0100, -0.0164,  0.0203],\n",
      "        [ 0.0235,  0.0022, -0.0043,  ...,  0.0064,  0.0227,  0.0112]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 3: Best val_acc: 0.2623\n",
      "Epoch 3: Best val_acc: 0.2623\n",
      "Epoch 3: train_loss: 2.3878 train_acc: 0.3114 | val_loss: 2.4179 val_acc: 0.2623\n",
      "00:00:18.24\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0425,  0.0073,  0.0114,  ..., -0.0002, -0.0072, -0.0980],\n",
      "        [ 0.0140,  0.0065,  0.0171,  ..., -0.0020,  0.0089, -0.0135],\n",
      "        [-0.0180,  0.0177, -0.0045,  ...,  0.0209, -0.0208, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0162,  0.0056,  ...,  0.0093, -0.0007,  0.0117],\n",
      "        [ 0.0869, -0.0185,  0.0047,  ...,  0.0101, -0.0165,  0.0201],\n",
      "        [ 0.0233,  0.0023, -0.0043,  ...,  0.0066,  0.0227,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2312e-02,  7.6115e-03,  1.1716e-02,  ...,  8.5486e-05,\n",
      "         -7.2836e-03, -9.8239e-02],\n",
      "        [ 1.3693e-02,  6.3788e-03,  1.6918e-02,  ..., -2.1408e-03,\n",
      "          8.9769e-03, -1.3329e-02],\n",
      "        [-1.7953e-02,  1.7610e-02, -4.4659e-03,  ...,  2.0963e-02,\n",
      "         -2.0820e-02, -3.9661e-03],\n",
      "        ...,\n",
      "        [ 1.4490e-02,  1.6164e-02,  5.6012e-03,  ...,  9.1533e-03,\n",
      "         -8.3126e-04,  1.1684e-02],\n",
      "        [ 8.6938e-02, -1.8479e-02,  4.8035e-03,  ...,  1.0129e-02,\n",
      "         -1.6396e-02,  2.0073e-02],\n",
      "        [ 2.3430e-02,  2.2654e-03, -4.3080e-03,  ...,  6.5375e-03,\n",
      "          2.2794e-02,  1.1247e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 4: Best val_acc: 0.2746\n",
      "Epoch 4: Best val_acc: 0.2746\n",
      "Epoch 4: train_loss: 2.1924 train_acc: 0.4091 | val_loss: 2.3650 val_acc: 0.2746\n",
      "00:00:20.43\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0426,  0.0072,  0.0113,  ..., -0.0005, -0.0074, -0.0979],\n",
      "        [ 0.0142,  0.0067,  0.0173,  ..., -0.0018,  0.0089, -0.0135],\n",
      "        [-0.0181,  0.0178, -0.0047,  ...,  0.0207, -0.0209, -0.0035],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0163,  0.0057,  ...,  0.0095, -0.0006,  0.0117],\n",
      "        [ 0.0868, -0.0186,  0.0046,  ...,  0.0101, -0.0164,  0.0202],\n",
      "        [ 0.0233,  0.0024, -0.0043,  ...,  0.0066,  0.0228,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0425,  0.0073,  0.0114,  ..., -0.0002, -0.0072, -0.0980],\n",
      "        [ 0.0140,  0.0065,  0.0171,  ..., -0.0020,  0.0089, -0.0135],\n",
      "        [-0.0180,  0.0177, -0.0045,  ...,  0.0209, -0.0208, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0162,  0.0056,  ...,  0.0093, -0.0007,  0.0117],\n",
      "        [ 0.0869, -0.0185,  0.0047,  ...,  0.0101, -0.0165,  0.0201],\n",
      "        [ 0.0233,  0.0023, -0.0043,  ...,  0.0066,  0.0227,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 5: Best val_acc: 0.2951\n",
      "Epoch 5: Best val_acc: 0.2951\n",
      "Epoch 5: train_loss: 2.0177 train_acc: 0.4636 | val_loss: 2.3129 val_acc: 0.2951\n",
      "00:00:18.87\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0428,  0.0070,  0.0109,  ..., -0.0008, -0.0074, -0.0978],\n",
      "        [ 0.0143,  0.0067,  0.0173,  ..., -0.0016,  0.0090, -0.0135],\n",
      "        [-0.0182,  0.0178, -0.0047,  ...,  0.0207, -0.0209, -0.0033],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0163,  0.0056,  ...,  0.0095, -0.0005,  0.0118],\n",
      "        [ 0.0867, -0.0185,  0.0046,  ...,  0.0103, -0.0164,  0.0202],\n",
      "        [ 0.0232,  0.0024, -0.0045,  ...,  0.0065,  0.0227,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0426,  0.0072,  0.0113,  ..., -0.0005, -0.0074, -0.0979],\n",
      "        [ 0.0142,  0.0067,  0.0173,  ..., -0.0018,  0.0089, -0.0135],\n",
      "        [-0.0181,  0.0178, -0.0047,  ...,  0.0207, -0.0209, -0.0035],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0163,  0.0057,  ...,  0.0095, -0.0006,  0.0117],\n",
      "        [ 0.0868, -0.0186,  0.0046,  ...,  0.0101, -0.0164,  0.0202],\n",
      "        [ 0.0233,  0.0024, -0.0043,  ...,  0.0066,  0.0228,  0.0113]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 6: Best val_acc: 0.3156\n",
      "Epoch 6: Best val_acc: 0.3156\n",
      "Epoch 6: train_loss: 1.9040 train_acc: 0.5091 | val_loss: 2.2581 val_acc: 0.3156\n",
      "00:00:17.52\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0070,  0.0108,  ..., -0.0009, -0.0073, -0.0977],\n",
      "        [ 0.0144,  0.0068,  0.0173,  ..., -0.0015,  0.0090, -0.0135],\n",
      "        [-0.0182,  0.0179, -0.0048,  ...,  0.0206, -0.0210, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0163,  0.0056,  ...,  0.0096, -0.0004,  0.0119],\n",
      "        [ 0.0867, -0.0184,  0.0047,  ...,  0.0103, -0.0163,  0.0201],\n",
      "        [ 0.0230,  0.0024, -0.0046,  ...,  0.0065,  0.0227,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0428,  0.0070,  0.0109,  ..., -0.0008, -0.0074, -0.0978],\n",
      "        [ 0.0143,  0.0067,  0.0173,  ..., -0.0016,  0.0090, -0.0135],\n",
      "        [-0.0182,  0.0178, -0.0047,  ...,  0.0207, -0.0209, -0.0033],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0163,  0.0056,  ...,  0.0095, -0.0005,  0.0118],\n",
      "        [ 0.0867, -0.0185,  0.0046,  ...,  0.0103, -0.0164,  0.0202],\n",
      "        [ 0.0232,  0.0024, -0.0045,  ...,  0.0065,  0.0227,  0.0115]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 7: train_loss: 1.6868 train_acc: 0.6114 | val_loss: 2.2268 val_acc: 0.2951\n",
      "00:00:15.09\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0068,  0.0106,  ..., -0.0012, -0.0073, -0.0975],\n",
      "        [ 0.0146,  0.0068,  0.0174,  ..., -0.0015,  0.0091, -0.0135],\n",
      "        [-0.0184,  0.0179, -0.0048,  ...,  0.0204, -0.0211, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0163,  0.0055,  ...,  0.0096, -0.0004,  0.0121],\n",
      "        [ 0.0867, -0.0184,  0.0047,  ...,  0.0105, -0.0164,  0.0201],\n",
      "        [ 0.0228,  0.0024, -0.0048,  ...,  0.0064,  0.0228,  0.0117]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0070,  0.0108,  ..., -0.0009, -0.0073, -0.0977],\n",
      "        [ 0.0144,  0.0068,  0.0173,  ..., -0.0015,  0.0090, -0.0135],\n",
      "        [-0.0182,  0.0179, -0.0048,  ...,  0.0206, -0.0210, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0163,  0.0056,  ...,  0.0096, -0.0004,  0.0119],\n",
      "        [ 0.0867, -0.0184,  0.0047,  ...,  0.0103, -0.0163,  0.0201],\n",
      "        [ 0.0230,  0.0024, -0.0046,  ...,  0.0065,  0.0227,  0.0116]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 8: train_loss: 1.6269 train_acc: 0.5773 | val_loss: 2.2233 val_acc: 0.3033\n",
      "00:00:13.90\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0067,  0.0105,  ..., -0.0013, -0.0073, -0.0974],\n",
      "        [ 0.0146,  0.0069,  0.0175,  ..., -0.0014,  0.0090, -0.0135],\n",
      "        [-0.0183,  0.0178, -0.0049,  ...,  0.0204, -0.0212, -0.0029],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0164,  0.0055,  ...,  0.0097, -0.0003,  0.0122],\n",
      "        [ 0.0865, -0.0184,  0.0048,  ...,  0.0105, -0.0162,  0.0201],\n",
      "        [ 0.0226,  0.0025, -0.0048,  ...,  0.0063,  0.0228,  0.0119]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0068,  0.0106,  ..., -0.0012, -0.0073, -0.0975],\n",
      "        [ 0.0146,  0.0068,  0.0174,  ..., -0.0015,  0.0091, -0.0135],\n",
      "        [-0.0184,  0.0179, -0.0048,  ...,  0.0204, -0.0211, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0163,  0.0055,  ...,  0.0096, -0.0004,  0.0121],\n",
      "        [ 0.0867, -0.0184,  0.0047,  ...,  0.0105, -0.0164,  0.0201],\n",
      "        [ 0.0228,  0.0024, -0.0048,  ...,  0.0064,  0.0228,  0.0117]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 9: train_loss: 1.3751 train_acc: 0.6841 | val_loss: 2.2375 val_acc: 0.3033\n",
      "00:00:16.87\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0066,  0.0103,  ..., -0.0014, -0.0072, -0.0972],\n",
      "        [ 0.0147,  0.0069,  0.0175,  ..., -0.0013,  0.0091, -0.0135],\n",
      "        [-0.0183,  0.0178, -0.0049,  ...,  0.0203, -0.0212, -0.0028],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0164,  0.0054,  ...,  0.0097, -0.0001,  0.0123],\n",
      "        [ 0.0865, -0.0184,  0.0048,  ...,  0.0105, -0.0162,  0.0200],\n",
      "        [ 0.0224,  0.0026, -0.0050,  ...,  0.0063,  0.0229,  0.0120]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0067,  0.0105,  ..., -0.0013, -0.0073, -0.0974],\n",
      "        [ 0.0146,  0.0069,  0.0175,  ..., -0.0014,  0.0090, -0.0135],\n",
      "        [-0.0183,  0.0178, -0.0049,  ...,  0.0204, -0.0212, -0.0029],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0164,  0.0055,  ...,  0.0097, -0.0003,  0.0122],\n",
      "        [ 0.0865, -0.0184,  0.0048,  ...,  0.0105, -0.0162,  0.0201],\n",
      "        [ 0.0226,  0.0025, -0.0048,  ...,  0.0063,  0.0228,  0.0119]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 10: Best val_acc: 0.3484\n",
      "Epoch 10: Best val_acc: 0.3484\n",
      "Epoch 10: train_loss: 1.3591 train_acc: 0.6682 | val_loss: 2.1493 val_acc: 0.3484\n",
      "00:00:15.10\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0064,  0.0101,  ..., -0.0016, -0.0071, -0.0972],\n",
      "        [ 0.0148,  0.0070,  0.0175,  ..., -0.0013,  0.0091, -0.0136],\n",
      "        [-0.0184,  0.0179, -0.0050,  ...,  0.0203, -0.0213, -0.0027],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0164,  0.0054,  ...,  0.0098, -0.0002,  0.0126],\n",
      "        [ 0.0865, -0.0184,  0.0048,  ...,  0.0106, -0.0162,  0.0200],\n",
      "        [ 0.0223,  0.0026, -0.0051,  ...,  0.0063,  0.0227,  0.0122]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0066,  0.0103,  ..., -0.0014, -0.0072, -0.0972],\n",
      "        [ 0.0147,  0.0069,  0.0175,  ..., -0.0013,  0.0091, -0.0135],\n",
      "        [-0.0183,  0.0178, -0.0049,  ...,  0.0203, -0.0212, -0.0028],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0164,  0.0054,  ...,  0.0097, -0.0001,  0.0123],\n",
      "        [ 0.0865, -0.0184,  0.0048,  ...,  0.0105, -0.0162,  0.0200],\n",
      "        [ 0.0224,  0.0026, -0.0050,  ...,  0.0063,  0.0229,  0.0120]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 11: train_loss: 1.1381 train_acc: 0.7659 | val_loss: 2.2027 val_acc: 0.2910\n",
      "00:00:10.72\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0063,  0.0100,  ..., -0.0017, -0.0071, -0.0970],\n",
      "        [ 0.0149,  0.0071,  0.0176,  ..., -0.0011,  0.0091, -0.0136],\n",
      "        [-0.0185,  0.0179, -0.0051,  ...,  0.0203, -0.0213, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0164,  0.0053,  ...,  0.0098, -0.0002,  0.0127],\n",
      "        [ 0.0864, -0.0184,  0.0047,  ...,  0.0107, -0.0162,  0.0200],\n",
      "        [ 0.0222,  0.0027, -0.0051,  ...,  0.0063,  0.0228,  0.0124]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0064,  0.0101,  ..., -0.0016, -0.0071, -0.0972],\n",
      "        [ 0.0148,  0.0070,  0.0175,  ..., -0.0013,  0.0091, -0.0136],\n",
      "        [-0.0184,  0.0179, -0.0050,  ...,  0.0203, -0.0213, -0.0027],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0164,  0.0054,  ...,  0.0098, -0.0002,  0.0126],\n",
      "        [ 0.0865, -0.0184,  0.0048,  ...,  0.0106, -0.0162,  0.0200],\n",
      "        [ 0.0223,  0.0026, -0.0051,  ...,  0.0063,  0.0227,  0.0122]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 12: Best val_acc: 0.3484\n",
      "Epoch 12: train_loss: 1.0232 train_acc: 0.7750 | val_loss: 2.1789 val_acc: 0.3484\n",
      "00:00:09.34\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0061,  0.0100,  ..., -0.0018, -0.0071, -0.0970],\n",
      "        [ 0.0149,  0.0072,  0.0177,  ..., -0.0011,  0.0091, -0.0136],\n",
      "        [-0.0186,  0.0179, -0.0051,  ...,  0.0202, -0.0214, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0164,  0.0052,  ...,  0.0098, -0.0002,  0.0129],\n",
      "        [ 0.0864, -0.0184,  0.0048,  ...,  0.0107, -0.0161,  0.0200],\n",
      "        [ 0.0221,  0.0027, -0.0052,  ...,  0.0063,  0.0228,  0.0126]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0063,  0.0100,  ..., -0.0017, -0.0071, -0.0970],\n",
      "        [ 0.0149,  0.0071,  0.0176,  ..., -0.0011,  0.0091, -0.0136],\n",
      "        [-0.0185,  0.0179, -0.0051,  ...,  0.0203, -0.0213, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0139,  0.0164,  0.0053,  ...,  0.0098, -0.0002,  0.0127],\n",
      "        [ 0.0864, -0.0184,  0.0047,  ...,  0.0107, -0.0162,  0.0200],\n",
      "        [ 0.0222,  0.0027, -0.0051,  ...,  0.0063,  0.0228,  0.0124]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 13: Best val_acc: 0.3607\n",
      "Epoch 13: Best val_acc: 0.3607\n",
      "Epoch 13: train_loss: 0.9636 train_acc: 0.8227 | val_loss: 2.1776 val_acc: 0.3607\n",
      "00:00:10.99\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2862e-02,  6.0363e-03,  9.8878e-03,  ..., -1.9685e-03,\n",
      "         -7.0363e-03, -9.6899e-02],\n",
      "        [ 1.4974e-02,  7.2376e-03,  1.7637e-02,  ..., -1.0444e-03,\n",
      "          9.1279e-03, -1.3558e-02],\n",
      "        [-1.8622e-02,  1.7903e-02, -5.1818e-03,  ...,  2.0122e-02,\n",
      "         -2.1474e-02, -2.4709e-03],\n",
      "        ...,\n",
      "        [ 1.3709e-02,  1.6398e-02,  5.2018e-03,  ...,  9.9104e-03,\n",
      "         -6.7117e-05,  1.3108e-02],\n",
      "        [ 8.6341e-02, -1.8459e-02,  4.7410e-03,  ...,  1.0571e-02,\n",
      "         -1.6147e-02,  2.0062e-02],\n",
      "        [ 2.2028e-02,  2.7249e-03, -5.2698e-03,  ...,  6.2378e-03,\n",
      "          2.2953e-02,  1.2753e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0061,  0.0100,  ..., -0.0018, -0.0071, -0.0970],\n",
      "        [ 0.0149,  0.0072,  0.0177,  ..., -0.0011,  0.0091, -0.0136],\n",
      "        [-0.0186,  0.0179, -0.0051,  ...,  0.0202, -0.0214, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0138,  0.0164,  0.0052,  ...,  0.0098, -0.0002,  0.0129],\n",
      "        [ 0.0864, -0.0184,  0.0048,  ...,  0.0107, -0.0161,  0.0200],\n",
      "        [ 0.0221,  0.0027, -0.0052,  ...,  0.0063,  0.0228,  0.0126]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 14: train_loss: 0.7942 train_acc: 0.8523 | val_loss: 2.2647 val_acc: 0.3484\n",
      "00:00:10.19\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2903e-02,  5.8926e-03,  9.7495e-03,  ..., -2.1209e-03,\n",
      "         -7.0115e-03, -9.6837e-02],\n",
      "        [ 1.4990e-02,  7.3409e-03,  1.7633e-02,  ..., -9.8287e-04,\n",
      "          9.1363e-03, -1.3494e-02],\n",
      "        [-1.8702e-02,  1.7903e-02, -5.1950e-03,  ...,  2.0122e-02,\n",
      "         -2.1506e-02, -2.3933e-03],\n",
      "        ...,\n",
      "        [ 1.3661e-02,  1.6425e-02,  5.1122e-03,  ...,  9.8961e-03,\n",
      "         -5.9113e-05,  1.3305e-02],\n",
      "        [ 8.6340e-02, -1.8466e-02,  4.8004e-03,  ...,  1.0566e-02,\n",
      "         -1.6155e-02,  2.0059e-02],\n",
      "        [ 2.1923e-02,  2.7827e-03, -5.4226e-03,  ...,  6.1814e-03,\n",
      "          2.3021e-02,  1.2956e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2862e-02,  6.0363e-03,  9.8878e-03,  ..., -1.9685e-03,\n",
      "         -7.0363e-03, -9.6899e-02],\n",
      "        [ 1.4974e-02,  7.2376e-03,  1.7637e-02,  ..., -1.0444e-03,\n",
      "          9.1279e-03, -1.3558e-02],\n",
      "        [-1.8622e-02,  1.7903e-02, -5.1818e-03,  ...,  2.0122e-02,\n",
      "         -2.1474e-02, -2.4709e-03],\n",
      "        ...,\n",
      "        [ 1.3709e-02,  1.6398e-02,  5.2018e-03,  ...,  9.9104e-03,\n",
      "         -6.7117e-05,  1.3108e-02],\n",
      "        [ 8.6341e-02, -1.8459e-02,  4.7410e-03,  ...,  1.0571e-02,\n",
      "         -1.6147e-02,  2.0062e-02],\n",
      "        [ 2.2028e-02,  2.7249e-03, -5.2698e-03,  ...,  6.2378e-03,\n",
      "          2.2953e-02,  1.2753e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 15: train_loss: 0.8755 train_acc: 0.8182 | val_loss: 2.2169 val_acc: 0.3525\n",
      "00:00:09.32\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2875e-02,  5.8288e-03,  9.7330e-03,  ..., -2.1031e-03,\n",
      "         -6.9575e-03, -9.6814e-02],\n",
      "        [ 1.5043e-02,  7.4215e-03,  1.7664e-02,  ..., -9.0691e-04,\n",
      "          9.1056e-03, -1.3551e-02],\n",
      "        [-1.8699e-02,  1.8001e-02, -5.1754e-03,  ...,  2.0146e-02,\n",
      "         -2.1484e-02, -2.4400e-03],\n",
      "        ...,\n",
      "        [ 1.3621e-02,  1.6411e-02,  5.0761e-03,  ...,  9.9486e-03,\n",
      "         -8.6852e-05,  1.3409e-02],\n",
      "        [ 8.6244e-02, -1.8492e-02,  4.7434e-03,  ...,  1.0469e-02,\n",
      "         -1.6200e-02,  2.0060e-02],\n",
      "        [ 2.1878e-02,  2.7855e-03, -5.4592e-03,  ...,  6.2032e-03,\n",
      "          2.3081e-02,  1.3101e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2903e-02,  5.8926e-03,  9.7495e-03,  ..., -2.1209e-03,\n",
      "         -7.0115e-03, -9.6837e-02],\n",
      "        [ 1.4990e-02,  7.3409e-03,  1.7633e-02,  ..., -9.8287e-04,\n",
      "          9.1363e-03, -1.3494e-02],\n",
      "        [-1.8702e-02,  1.7903e-02, -5.1950e-03,  ...,  2.0122e-02,\n",
      "         -2.1506e-02, -2.3933e-03],\n",
      "        ...,\n",
      "        [ 1.3661e-02,  1.6425e-02,  5.1122e-03,  ...,  9.8961e-03,\n",
      "         -5.9113e-05,  1.3305e-02],\n",
      "        [ 8.6340e-02, -1.8466e-02,  4.8004e-03,  ...,  1.0566e-02,\n",
      "         -1.6155e-02,  2.0059e-02],\n",
      "        [ 2.1923e-02,  2.7827e-03, -5.4226e-03,  ...,  6.1814e-03,\n",
      "          2.3021e-02,  1.2956e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 16: train_loss: 0.6265 train_acc: 0.8932 | val_loss: 2.2843 val_acc: 0.3443\n",
      "00:00:09.11\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2877e-02,  5.7490e-03,  9.6206e-03,  ..., -2.1939e-03,\n",
      "         -6.9208e-03, -9.6739e-02],\n",
      "        [ 1.5049e-02,  7.4471e-03,  1.7607e-02,  ..., -8.8666e-04,\n",
      "          9.1092e-03, -1.3570e-02],\n",
      "        [-1.8788e-02,  1.7983e-02, -5.2144e-03,  ...,  2.0076e-02,\n",
      "         -2.1490e-02, -2.3604e-03],\n",
      "        ...,\n",
      "        [ 1.3592e-02,  1.6419e-02,  5.0299e-03,  ...,  9.9782e-03,\n",
      "         -7.8993e-05,  1.3544e-02],\n",
      "        [ 8.6161e-02, -1.8516e-02,  4.7652e-03,  ...,  1.0464e-02,\n",
      "         -1.6249e-02,  1.9985e-02],\n",
      "        [ 2.1842e-02,  2.8207e-03, -5.5495e-03,  ...,  6.1742e-03,\n",
      "          2.3113e-02,  1.3259e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2875e-02,  5.8288e-03,  9.7330e-03,  ..., -2.1031e-03,\n",
      "         -6.9575e-03, -9.6814e-02],\n",
      "        [ 1.5043e-02,  7.4215e-03,  1.7664e-02,  ..., -9.0691e-04,\n",
      "          9.1056e-03, -1.3551e-02],\n",
      "        [-1.8699e-02,  1.8001e-02, -5.1754e-03,  ...,  2.0146e-02,\n",
      "         -2.1484e-02, -2.4400e-03],\n",
      "        ...,\n",
      "        [ 1.3621e-02,  1.6411e-02,  5.0761e-03,  ...,  9.9486e-03,\n",
      "         -8.6852e-05,  1.3409e-02],\n",
      "        [ 8.6244e-02, -1.8492e-02,  4.7434e-03,  ...,  1.0469e-02,\n",
      "         -1.6200e-02,  2.0060e-02],\n",
      "        [ 2.1878e-02,  2.7855e-03, -5.4592e-03,  ...,  6.2032e-03,\n",
      "          2.3081e-02,  1.3101e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 17: train_loss: 0.6773 train_acc: 0.8727 | val_loss: 2.2101 val_acc: 0.3484\n",
      "00:00:09.21\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2876e-02,  5.6607e-03,  9.5817e-03,  ..., -2.2605e-03,\n",
      "         -6.8328e-03, -9.6684e-02],\n",
      "        [ 1.5016e-02,  7.5095e-03,  1.7591e-02,  ..., -8.9331e-04,\n",
      "          9.1353e-03, -1.3540e-02],\n",
      "        [-1.8842e-02,  1.8028e-02, -5.2296e-03,  ...,  2.0112e-02,\n",
      "         -2.1506e-02, -2.3325e-03],\n",
      "        ...,\n",
      "        [ 1.3480e-02,  1.6401e-02,  4.9241e-03,  ...,  9.8988e-03,\n",
      "         -4.9078e-05,  1.3708e-02],\n",
      "        [ 8.6075e-02, -1.8639e-02,  4.7432e-03,  ...,  1.0458e-02,\n",
      "         -1.6252e-02,  1.9984e-02],\n",
      "        [ 2.1741e-02,  2.8527e-03, -5.6528e-03,  ...,  6.0991e-03,\n",
      "          2.3196e-02,  1.3412e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2877e-02,  5.7490e-03,  9.6206e-03,  ..., -2.1939e-03,\n",
      "         -6.9208e-03, -9.6739e-02],\n",
      "        [ 1.5049e-02,  7.4471e-03,  1.7607e-02,  ..., -8.8666e-04,\n",
      "          9.1092e-03, -1.3570e-02],\n",
      "        [-1.8788e-02,  1.7983e-02, -5.2144e-03,  ...,  2.0076e-02,\n",
      "         -2.1490e-02, -2.3604e-03],\n",
      "        ...,\n",
      "        [ 1.3592e-02,  1.6419e-02,  5.0299e-03,  ...,  9.9782e-03,\n",
      "         -7.8993e-05,  1.3544e-02],\n",
      "        [ 8.6161e-02, -1.8516e-02,  4.7652e-03,  ...,  1.0464e-02,\n",
      "         -1.6249e-02,  1.9985e-02],\n",
      "        [ 2.1842e-02,  2.8207e-03, -5.5495e-03,  ...,  6.1742e-03,\n",
      "          2.3113e-02,  1.3259e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 18: Best val_acc: 0.3607\n",
      "Epoch 18: train_loss: 0.5455 train_acc: 0.9045 | val_loss: 2.2378 val_acc: 0.3607\n",
      "00:00:09.75\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0056,  0.0095,  ..., -0.0024, -0.0068, -0.0966],\n",
      "        [ 0.0150,  0.0076,  0.0176,  ..., -0.0009,  0.0091, -0.0136],\n",
      "        [-0.0189,  0.0181, -0.0053,  ...,  0.0201, -0.0216, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0134,  0.0164,  0.0049,  ...,  0.0099, -0.0001,  0.0139],\n",
      "        [ 0.0861, -0.0187,  0.0047,  ...,  0.0104, -0.0163,  0.0200],\n",
      "        [ 0.0217,  0.0029, -0.0057,  ...,  0.0061,  0.0232,  0.0136]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2876e-02,  5.6607e-03,  9.5817e-03,  ..., -2.2605e-03,\n",
      "         -6.8328e-03, -9.6684e-02],\n",
      "        [ 1.5016e-02,  7.5095e-03,  1.7591e-02,  ..., -8.9331e-04,\n",
      "          9.1353e-03, -1.3540e-02],\n",
      "        [-1.8842e-02,  1.8028e-02, -5.2296e-03,  ...,  2.0112e-02,\n",
      "         -2.1506e-02, -2.3325e-03],\n",
      "        ...,\n",
      "        [ 1.3480e-02,  1.6401e-02,  4.9241e-03,  ...,  9.8988e-03,\n",
      "         -4.9078e-05,  1.3708e-02],\n",
      "        [ 8.6075e-02, -1.8639e-02,  4.7432e-03,  ...,  1.0458e-02,\n",
      "         -1.6252e-02,  1.9984e-02],\n",
      "        [ 2.1741e-02,  2.8527e-03, -5.6528e-03,  ...,  6.0991e-03,\n",
      "          2.3196e-02,  1.3412e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 19: Best val_acc: 0.3607\n",
      "Epoch 19: train_loss: 0.5010 train_acc: 0.9250 | val_loss: 2.2445 val_acc: 0.3607\n",
      "00:00:10.71\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2874e-02,  5.5298e-03,  9.4696e-03,  ..., -2.4852e-03,\n",
      "         -6.7284e-03, -9.6623e-02],\n",
      "        [ 1.5061e-02,  7.6722e-03,  1.7586e-02,  ..., -9.1800e-04,\n",
      "          9.1492e-03, -1.3563e-02],\n",
      "        [-1.8938e-02,  1.8149e-02, -5.2765e-03,  ...,  2.0054e-02,\n",
      "         -2.1644e-02, -2.2390e-03],\n",
      "        ...,\n",
      "        [ 1.3364e-02,  1.6388e-02,  4.8522e-03,  ...,  9.9357e-03,\n",
      "         -9.8986e-05,  1.4015e-02],\n",
      "        [ 8.6045e-02, -1.8658e-02,  4.7765e-03,  ...,  1.0367e-02,\n",
      "         -1.6241e-02,  2.0002e-02],\n",
      "        [ 2.1628e-02,  2.9494e-03, -5.7569e-03,  ...,  6.0724e-03,\n",
      "          2.3259e-02,  1.3725e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0056,  0.0095,  ..., -0.0024, -0.0068, -0.0966],\n",
      "        [ 0.0150,  0.0076,  0.0176,  ..., -0.0009,  0.0091, -0.0136],\n",
      "        [-0.0189,  0.0181, -0.0053,  ...,  0.0201, -0.0216, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0134,  0.0164,  0.0049,  ...,  0.0099, -0.0001,  0.0139],\n",
      "        [ 0.0861, -0.0187,  0.0047,  ...,  0.0104, -0.0163,  0.0200],\n",
      "        [ 0.0217,  0.0029, -0.0057,  ...,  0.0061,  0.0232,  0.0136]],\n",
      "       device='cuda:6', requires_grad=True)\n",
      "Epoch 20: train_loss: 0.4679 train_acc: 0.9159 | val_loss: 2.2784 val_acc: 0.3402\n",
      "00:00:09.37\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2813e-02,  5.4757e-03,  9.4454e-03,  ..., -2.6440e-03,\n",
      "         -6.7475e-03, -9.6618e-02],\n",
      "        [ 1.5049e-02,  7.7113e-03,  1.7472e-02,  ..., -9.1641e-04,\n",
      "          9.1699e-03, -1.3608e-02],\n",
      "        [-1.9017e-02,  1.8169e-02, -5.3499e-03,  ...,  2.0068e-02,\n",
      "         -2.1705e-02, -2.1936e-03],\n",
      "        ...,\n",
      "        [ 1.3315e-02,  1.6353e-02,  4.7725e-03,  ...,  9.9022e-03,\n",
      "         -9.3417e-05,  1.4090e-02],\n",
      "        [ 8.5985e-02, -1.8706e-02,  4.7650e-03,  ...,  1.0329e-02,\n",
      "         -1.6273e-02,  2.0044e-02],\n",
      "        [ 2.1581e-02,  2.9322e-03, -5.8759e-03,  ...,  6.0190e-03,\n",
      "          2.3302e-02,  1.3815e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2874e-02,  5.5298e-03,  9.4696e-03,  ..., -2.4852e-03,\n",
      "         -6.7284e-03, -9.6623e-02],\n",
      "        [ 1.5061e-02,  7.6722e-03,  1.7586e-02,  ..., -9.1800e-04,\n",
      "          9.1492e-03, -1.3563e-02],\n",
      "        [-1.8938e-02,  1.8149e-02, -5.2765e-03,  ...,  2.0054e-02,\n",
      "         -2.1644e-02, -2.2390e-03],\n",
      "        ...,\n",
      "        [ 1.3364e-02,  1.6388e-02,  4.8522e-03,  ...,  9.9357e-03,\n",
      "         -9.8986e-05,  1.4015e-02],\n",
      "        [ 8.6045e-02, -1.8658e-02,  4.7765e-03,  ...,  1.0367e-02,\n",
      "         -1.6241e-02,  2.0002e-02],\n",
      "        [ 2.1628e-02,  2.9494e-03, -5.7569e-03,  ...,  6.0724e-03,\n",
      "          2.3259e-02,  1.3725e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 21: train_loss: 0.4211 train_acc: 0.9364 | val_loss: 2.3199 val_acc: 0.3402\n",
      "00:00:10.28\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2818e-02,  5.3966e-03,  9.3970e-03,  ..., -2.6767e-03,\n",
      "         -6.6310e-03, -9.6629e-02],\n",
      "        [ 1.5099e-02,  7.7958e-03,  1.7449e-02,  ..., -8.5044e-04,\n",
      "          9.2327e-03, -1.3650e-02],\n",
      "        [-1.9118e-02,  1.8256e-02, -5.3625e-03,  ...,  2.0061e-02,\n",
      "         -2.1750e-02, -2.2051e-03],\n",
      "        ...,\n",
      "        [ 1.3299e-02,  1.6349e-02,  4.7348e-03,  ...,  9.9395e-03,\n",
      "         -3.4064e-05,  1.4202e-02],\n",
      "        [ 8.5976e-02, -1.8717e-02,  4.7679e-03,  ...,  1.0361e-02,\n",
      "         -1.6309e-02,  2.0064e-02],\n",
      "        [ 2.1591e-02,  2.9779e-03, -5.9370e-03,  ...,  6.0431e-03,\n",
      "          2.3340e-02,  1.3973e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2813e-02,  5.4757e-03,  9.4454e-03,  ..., -2.6440e-03,\n",
      "         -6.7475e-03, -9.6618e-02],\n",
      "        [ 1.5049e-02,  7.7113e-03,  1.7472e-02,  ..., -9.1641e-04,\n",
      "          9.1699e-03, -1.3608e-02],\n",
      "        [-1.9017e-02,  1.8169e-02, -5.3499e-03,  ...,  2.0068e-02,\n",
      "         -2.1705e-02, -2.1936e-03],\n",
      "        ...,\n",
      "        [ 1.3315e-02,  1.6353e-02,  4.7725e-03,  ...,  9.9022e-03,\n",
      "         -9.3417e-05,  1.4090e-02],\n",
      "        [ 8.5985e-02, -1.8706e-02,  4.7650e-03,  ...,  1.0329e-02,\n",
      "         -1.6273e-02,  2.0044e-02],\n",
      "        [ 2.1581e-02,  2.9322e-03, -5.8759e-03,  ...,  6.0190e-03,\n",
      "          2.3302e-02,  1.3815e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 22: train_loss: 0.3613 train_acc: 0.9523 | val_loss: 2.3614 val_acc: 0.3443\n",
      "00:00:08.41\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2797e-02,  5.3763e-03,  9.3746e-03,  ..., -2.7302e-03,\n",
      "         -6.5997e-03, -9.6619e-02],\n",
      "        [ 1.5081e-02,  7.8713e-03,  1.7451e-02,  ..., -8.6980e-04,\n",
      "          9.2408e-03, -1.3656e-02],\n",
      "        [-1.9208e-02,  1.8300e-02, -5.3791e-03,  ...,  2.0022e-02,\n",
      "         -2.1843e-02, -2.1836e-03],\n",
      "        ...,\n",
      "        [ 1.3275e-02,  1.6403e-02,  4.6961e-03,  ...,  9.9243e-03,\n",
      "         -4.5112e-05,  1.4301e-02],\n",
      "        [ 8.5831e-02, -1.8839e-02,  4.7375e-03,  ...,  1.0343e-02,\n",
      "         -1.6320e-02,  2.0094e-02],\n",
      "        [ 2.1541e-02,  3.0030e-03, -6.0077e-03,  ...,  6.0117e-03,\n",
      "          2.3402e-02,  1.4121e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2818e-02,  5.3966e-03,  9.3970e-03,  ..., -2.6767e-03,\n",
      "         -6.6310e-03, -9.6629e-02],\n",
      "        [ 1.5099e-02,  7.7958e-03,  1.7449e-02,  ..., -8.5044e-04,\n",
      "          9.2327e-03, -1.3650e-02],\n",
      "        [-1.9118e-02,  1.8256e-02, -5.3625e-03,  ...,  2.0061e-02,\n",
      "         -2.1750e-02, -2.2051e-03],\n",
      "        ...,\n",
      "        [ 1.3299e-02,  1.6349e-02,  4.7348e-03,  ...,  9.9395e-03,\n",
      "         -3.4064e-05,  1.4202e-02],\n",
      "        [ 8.5976e-02, -1.8717e-02,  4.7679e-03,  ...,  1.0361e-02,\n",
      "         -1.6309e-02,  2.0064e-02],\n",
      "        [ 2.1591e-02,  2.9779e-03, -5.9370e-03,  ...,  6.0431e-03,\n",
      "          2.3340e-02,  1.3973e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 23: Best val_acc: 0.3730\n",
      "Epoch 23: Best val_acc: 0.3730\n",
      "Epoch 23: train_loss: 0.3488 train_acc: 0.9477 | val_loss: 2.3259 val_acc: 0.3730\n",
      "00:00:10.86\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2783e-02,  5.3333e-03,  9.3501e-03,  ..., -2.8129e-03,\n",
      "         -6.5867e-03, -9.6587e-02],\n",
      "        [ 1.5070e-02,  7.9122e-03,  1.7407e-02,  ..., -8.6038e-04,\n",
      "          9.2703e-03, -1.3641e-02],\n",
      "        [-1.9262e-02,  1.8299e-02, -5.4312e-03,  ...,  2.0011e-02,\n",
      "         -2.1826e-02, -2.1402e-03],\n",
      "        ...,\n",
      "        [ 1.3250e-02,  1.6470e-02,  4.6818e-03,  ...,  9.9405e-03,\n",
      "         -3.3636e-05,  1.4393e-02],\n",
      "        [ 8.5780e-02, -1.8874e-02,  4.7827e-03,  ...,  1.0283e-02,\n",
      "         -1.6343e-02,  2.0085e-02],\n",
      "        [ 2.1491e-02,  3.0809e-03, -6.0260e-03,  ...,  6.0103e-03,\n",
      "          2.3400e-02,  1.4259e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2797e-02,  5.3763e-03,  9.3746e-03,  ..., -2.7302e-03,\n",
      "         -6.5997e-03, -9.6619e-02],\n",
      "        [ 1.5081e-02,  7.8713e-03,  1.7451e-02,  ..., -8.6980e-04,\n",
      "          9.2408e-03, -1.3656e-02],\n",
      "        [-1.9208e-02,  1.8300e-02, -5.3791e-03,  ...,  2.0022e-02,\n",
      "         -2.1843e-02, -2.1836e-03],\n",
      "        ...,\n",
      "        [ 1.3275e-02,  1.6403e-02,  4.6961e-03,  ...,  9.9243e-03,\n",
      "         -4.5112e-05,  1.4301e-02],\n",
      "        [ 8.5831e-02, -1.8839e-02,  4.7375e-03,  ...,  1.0343e-02,\n",
      "         -1.6320e-02,  2.0094e-02],\n",
      "        [ 2.1541e-02,  3.0030e-03, -6.0077e-03,  ...,  6.0117e-03,\n",
      "          2.3402e-02,  1.4121e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 24: train_loss: 0.2863 train_acc: 0.9727 | val_loss: 2.3786 val_acc: 0.3484\n",
      "00:00:08.55\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2744e-02,  5.2553e-03,  9.3358e-03,  ..., -2.8138e-03,\n",
      "         -6.5379e-03, -9.6599e-02],\n",
      "        [ 1.5085e-02,  7.9575e-03,  1.7400e-02,  ..., -8.1603e-04,\n",
      "          9.2796e-03, -1.3653e-02],\n",
      "        [-1.9309e-02,  1.8345e-02, -5.4564e-03,  ...,  2.0013e-02,\n",
      "         -2.1888e-02, -2.1318e-03],\n",
      "        ...,\n",
      "        [ 1.3192e-02,  1.6500e-02,  4.6375e-03,  ...,  9.9808e-03,\n",
      "         -4.5368e-05,  1.4514e-02],\n",
      "        [ 8.5789e-02, -1.8881e-02,  4.8030e-03,  ...,  1.0244e-02,\n",
      "         -1.6336e-02,  2.0132e-02],\n",
      "        [ 2.1430e-02,  3.1341e-03, -6.0705e-03,  ...,  6.0376e-03,\n",
      "          2.3435e-02,  1.4414e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2783e-02,  5.3333e-03,  9.3501e-03,  ..., -2.8129e-03,\n",
      "         -6.5867e-03, -9.6587e-02],\n",
      "        [ 1.5070e-02,  7.9122e-03,  1.7407e-02,  ..., -8.6038e-04,\n",
      "          9.2703e-03, -1.3641e-02],\n",
      "        [-1.9262e-02,  1.8299e-02, -5.4312e-03,  ...,  2.0011e-02,\n",
      "         -2.1826e-02, -2.1402e-03],\n",
      "        ...,\n",
      "        [ 1.3250e-02,  1.6470e-02,  4.6818e-03,  ...,  9.9405e-03,\n",
      "         -3.3636e-05,  1.4393e-02],\n",
      "        [ 8.5780e-02, -1.8874e-02,  4.7827e-03,  ...,  1.0283e-02,\n",
      "         -1.6343e-02,  2.0085e-02],\n",
      "        [ 2.1491e-02,  3.0809e-03, -6.0260e-03,  ...,  6.0103e-03,\n",
      "          2.3400e-02,  1.4259e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 25: train_loss: 0.2620 train_acc: 0.9727 | val_loss: 2.3869 val_acc: 0.3648\n",
      "00:00:10.18\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2671e-02,  5.2731e-03,  9.4100e-03,  ..., -2.8679e-03,\n",
      "         -6.5353e-03, -9.6628e-02],\n",
      "        [ 1.5047e-02,  8.0220e-03,  1.7356e-02,  ..., -8.4739e-04,\n",
      "          9.2874e-03, -1.3628e-02],\n",
      "        [-1.9390e-02,  1.8387e-02, -5.4508e-03,  ...,  2.0032e-02,\n",
      "         -2.1935e-02, -2.1000e-03],\n",
      "        ...,\n",
      "        [ 1.3178e-02,  1.6537e-02,  4.6058e-03,  ...,  9.9293e-03,\n",
      "         -5.9337e-05,  1.4614e-02],\n",
      "        [ 8.5736e-02, -1.8963e-02,  4.7878e-03,  ...,  1.0270e-02,\n",
      "         -1.6381e-02,  2.0176e-02],\n",
      "        [ 2.1401e-02,  3.1951e-03, -6.0986e-03,  ...,  5.9960e-03,\n",
      "          2.3492e-02,  1.4531e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2744e-02,  5.2553e-03,  9.3358e-03,  ..., -2.8138e-03,\n",
      "         -6.5379e-03, -9.6599e-02],\n",
      "        [ 1.5085e-02,  7.9575e-03,  1.7400e-02,  ..., -8.1603e-04,\n",
      "          9.2796e-03, -1.3653e-02],\n",
      "        [-1.9309e-02,  1.8345e-02, -5.4564e-03,  ...,  2.0013e-02,\n",
      "         -2.1888e-02, -2.1318e-03],\n",
      "        ...,\n",
      "        [ 1.3192e-02,  1.6500e-02,  4.6375e-03,  ...,  9.9808e-03,\n",
      "         -4.5368e-05,  1.4514e-02],\n",
      "        [ 8.5789e-02, -1.8881e-02,  4.8030e-03,  ...,  1.0244e-02,\n",
      "         -1.6336e-02,  2.0132e-02],\n",
      "        [ 2.1430e-02,  3.1341e-03, -6.0705e-03,  ...,  6.0376e-03,\n",
      "          2.3435e-02,  1.4414e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 26: train_loss: 0.2441 train_acc: 0.9818 | val_loss: 2.4845 val_acc: 0.3361\n",
      "00:00:08.82\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2624e-02,  5.2076e-03,  9.3094e-03,  ..., -2.9058e-03,\n",
      "         -6.5191e-03, -9.6636e-02],\n",
      "        [ 1.5071e-02,  8.0434e-03,  1.7319e-02,  ..., -8.4438e-04,\n",
      "          9.3525e-03, -1.3664e-02],\n",
      "        [-1.9409e-02,  1.8396e-02, -5.4659e-03,  ...,  1.9972e-02,\n",
      "         -2.1975e-02, -2.0533e-03],\n",
      "        ...,\n",
      "        [ 1.3182e-02,  1.6557e-02,  4.5679e-03,  ...,  9.9393e-03,\n",
      "         -4.4503e-05,  1.4723e-02],\n",
      "        [ 8.5687e-02, -1.9028e-02,  4.7925e-03,  ...,  1.0190e-02,\n",
      "         -1.6381e-02,  2.0170e-02],\n",
      "        [ 2.1359e-02,  3.2371e-03, -6.1154e-03,  ...,  6.0050e-03,\n",
      "          2.3509e-02,  1.4642e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2671e-02,  5.2731e-03,  9.4100e-03,  ..., -2.8679e-03,\n",
      "         -6.5353e-03, -9.6628e-02],\n",
      "        [ 1.5047e-02,  8.0220e-03,  1.7356e-02,  ..., -8.4739e-04,\n",
      "          9.2874e-03, -1.3628e-02],\n",
      "        [-1.9390e-02,  1.8387e-02, -5.4508e-03,  ...,  2.0032e-02,\n",
      "         -2.1935e-02, -2.1000e-03],\n",
      "        ...,\n",
      "        [ 1.3178e-02,  1.6537e-02,  4.6058e-03,  ...,  9.9293e-03,\n",
      "         -5.9337e-05,  1.4614e-02],\n",
      "        [ 8.5736e-02, -1.8963e-02,  4.7878e-03,  ...,  1.0270e-02,\n",
      "         -1.6381e-02,  2.0176e-02],\n",
      "        [ 2.1401e-02,  3.1951e-03, -6.0986e-03,  ...,  5.9960e-03,\n",
      "          2.3492e-02,  1.4531e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 27: Best val_acc: 0.3811\n",
      "Epoch 27: Best val_acc: 0.3811\n",
      "Epoch 27: train_loss: 0.2296 train_acc: 0.9750 | val_loss: 2.3996 val_acc: 0.3811\n",
      "00:00:10.81\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2587e-02,  5.1939e-03,  9.2876e-03,  ..., -2.9849e-03,\n",
      "         -6.4396e-03, -9.6641e-02],\n",
      "        [ 1.5052e-02,  8.0968e-03,  1.7306e-02,  ..., -8.2605e-04,\n",
      "          9.3406e-03, -1.3687e-02],\n",
      "        [-1.9465e-02,  1.8387e-02, -5.5169e-03,  ...,  1.9971e-02,\n",
      "         -2.1995e-02, -2.0372e-03],\n",
      "        ...,\n",
      "        [ 1.3129e-02,  1.6589e-02,  4.5038e-03,  ...,  9.9631e-03,\n",
      "         -7.3707e-05,  1.4829e-02],\n",
      "        [ 8.5609e-02, -1.9092e-02,  4.7776e-03,  ...,  1.0205e-02,\n",
      "         -1.6410e-02,  2.0205e-02],\n",
      "        [ 2.1290e-02,  3.2782e-03, -6.1392e-03,  ...,  6.0215e-03,\n",
      "          2.3516e-02,  1.4752e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2624e-02,  5.2076e-03,  9.3094e-03,  ..., -2.9058e-03,\n",
      "         -6.5191e-03, -9.6636e-02],\n",
      "        [ 1.5071e-02,  8.0434e-03,  1.7319e-02,  ..., -8.4438e-04,\n",
      "          9.3525e-03, -1.3664e-02],\n",
      "        [-1.9409e-02,  1.8396e-02, -5.4659e-03,  ...,  1.9972e-02,\n",
      "         -2.1975e-02, -2.0533e-03],\n",
      "        ...,\n",
      "        [ 1.3182e-02,  1.6557e-02,  4.5679e-03,  ...,  9.9393e-03,\n",
      "         -4.4503e-05,  1.4723e-02],\n",
      "        [ 8.5687e-02, -1.9028e-02,  4.7925e-03,  ...,  1.0190e-02,\n",
      "         -1.6381e-02,  2.0170e-02],\n",
      "        [ 2.1359e-02,  3.2371e-03, -6.1154e-03,  ...,  6.0050e-03,\n",
      "          2.3509e-02,  1.4642e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 28: train_loss: 0.2060 train_acc: 0.9864 | val_loss: 2.4684 val_acc: 0.3648\n",
      "00:00:09.60\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2521e-02,  5.1502e-03,  9.2631e-03,  ..., -3.0018e-03,\n",
      "         -6.4508e-03, -9.6607e-02],\n",
      "        [ 1.5059e-02,  8.1559e-03,  1.7263e-02,  ..., -8.2037e-04,\n",
      "          9.3792e-03, -1.3723e-02],\n",
      "        [-1.9528e-02,  1.8394e-02, -5.5757e-03,  ...,  1.9945e-02,\n",
      "         -2.2052e-02, -2.0024e-03],\n",
      "        ...,\n",
      "        [ 1.3101e-02,  1.6572e-02,  4.4417e-03,  ...,  9.9598e-03,\n",
      "         -6.2332e-05,  1.4910e-02],\n",
      "        [ 8.5603e-02, -1.9081e-02,  4.7767e-03,  ...,  1.0185e-02,\n",
      "         -1.6460e-02,  2.0183e-02],\n",
      "        [ 2.1240e-02,  3.3200e-03, -6.1769e-03,  ...,  6.0107e-03,\n",
      "          2.3578e-02,  1.4849e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2587e-02,  5.1939e-03,  9.2876e-03,  ..., -2.9849e-03,\n",
      "         -6.4396e-03, -9.6641e-02],\n",
      "        [ 1.5052e-02,  8.0968e-03,  1.7306e-02,  ..., -8.2605e-04,\n",
      "          9.3406e-03, -1.3687e-02],\n",
      "        [-1.9465e-02,  1.8387e-02, -5.5169e-03,  ...,  1.9971e-02,\n",
      "         -2.1995e-02, -2.0372e-03],\n",
      "        ...,\n",
      "        [ 1.3129e-02,  1.6589e-02,  4.5038e-03,  ...,  9.9631e-03,\n",
      "         -7.3707e-05,  1.4829e-02],\n",
      "        [ 8.5609e-02, -1.9092e-02,  4.7776e-03,  ...,  1.0205e-02,\n",
      "         -1.6410e-02,  2.0205e-02],\n",
      "        [ 2.1290e-02,  3.2782e-03, -6.1392e-03,  ...,  6.0215e-03,\n",
      "          2.3516e-02,  1.4752e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 29: train_loss: 0.1787 train_acc: 0.9864 | val_loss: 2.4934 val_acc: 0.3566\n",
      "00:00:08.50\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2507e-02,  5.1803e-03,  9.3120e-03,  ..., -3.0455e-03,\n",
      "         -6.4413e-03, -9.6641e-02],\n",
      "        [ 1.5069e-02,  8.2212e-03,  1.7236e-02,  ..., -7.5984e-04,\n",
      "          9.4123e-03, -1.3734e-02],\n",
      "        [-1.9580e-02,  1.8430e-02, -5.5659e-03,  ...,  1.9937e-02,\n",
      "         -2.2076e-02, -1.9581e-03],\n",
      "        ...,\n",
      "        [ 1.3087e-02,  1.6599e-02,  4.4317e-03,  ...,  9.9711e-03,\n",
      "         -4.2462e-05,  1.4970e-02],\n",
      "        [ 8.5619e-02, -1.9122e-02,  4.7723e-03,  ...,  1.0182e-02,\n",
      "         -1.6496e-02,  2.0176e-02],\n",
      "        [ 2.1210e-02,  3.3308e-03, -6.2175e-03,  ...,  6.0263e-03,\n",
      "          2.3646e-02,  1.4906e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2521e-02,  5.1502e-03,  9.2631e-03,  ..., -3.0018e-03,\n",
      "         -6.4508e-03, -9.6607e-02],\n",
      "        [ 1.5059e-02,  8.1559e-03,  1.7263e-02,  ..., -8.2037e-04,\n",
      "          9.3792e-03, -1.3723e-02],\n",
      "        [-1.9528e-02,  1.8394e-02, -5.5757e-03,  ...,  1.9945e-02,\n",
      "         -2.2052e-02, -2.0024e-03],\n",
      "        ...,\n",
      "        [ 1.3101e-02,  1.6572e-02,  4.4417e-03,  ...,  9.9598e-03,\n",
      "         -6.2332e-05,  1.4910e-02],\n",
      "        [ 8.5603e-02, -1.9081e-02,  4.7767e-03,  ...,  1.0185e-02,\n",
      "         -1.6460e-02,  2.0183e-02],\n",
      "        [ 2.1240e-02,  3.3200e-03, -6.1769e-03,  ...,  6.0107e-03,\n",
      "          2.3578e-02,  1.4849e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 30: train_loss: 0.1582 train_acc: 0.9932 | val_loss: 2.4812 val_acc: 0.3525\n",
      "00:00:08.20\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2470e-02,  5.1103e-03,  9.2784e-03,  ..., -3.0868e-03,\n",
      "         -6.4202e-03, -9.6634e-02],\n",
      "        [ 1.5094e-02,  8.2368e-03,  1.7226e-02,  ..., -7.6463e-04,\n",
      "          9.4373e-03, -1.3782e-02],\n",
      "        [-1.9616e-02,  1.8438e-02, -5.5731e-03,  ...,  1.9904e-02,\n",
      "         -2.2102e-02, -1.9518e-03],\n",
      "        ...,\n",
      "        [ 1.3046e-02,  1.6634e-02,  4.4101e-03,  ...,  9.9689e-03,\n",
      "         -5.3975e-05,  1.5041e-02],\n",
      "        [ 8.5617e-02, -1.9107e-02,  4.7770e-03,  ...,  1.0194e-02,\n",
      "         -1.6482e-02,  2.0177e-02],\n",
      "        [ 2.1149e-02,  3.3828e-03, -6.2300e-03,  ...,  6.0583e-03,\n",
      "          2.3674e-02,  1.4985e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2507e-02,  5.1803e-03,  9.3120e-03,  ..., -3.0455e-03,\n",
      "         -6.4413e-03, -9.6641e-02],\n",
      "        [ 1.5069e-02,  8.2212e-03,  1.7236e-02,  ..., -7.5984e-04,\n",
      "          9.4123e-03, -1.3734e-02],\n",
      "        [-1.9580e-02,  1.8430e-02, -5.5659e-03,  ...,  1.9937e-02,\n",
      "         -2.2076e-02, -1.9581e-03],\n",
      "        ...,\n",
      "        [ 1.3087e-02,  1.6599e-02,  4.4317e-03,  ...,  9.9711e-03,\n",
      "         -4.2462e-05,  1.4970e-02],\n",
      "        [ 8.5619e-02, -1.9122e-02,  4.7723e-03,  ...,  1.0182e-02,\n",
      "         -1.6496e-02,  2.0176e-02],\n",
      "        [ 2.1210e-02,  3.3308e-03, -6.2175e-03,  ...,  6.0263e-03,\n",
      "          2.3646e-02,  1.4906e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 31: Best val_acc: 0.3811\n",
      "Epoch 31: train_loss: 0.1479 train_acc: 0.9955 | val_loss: 2.4666 val_acc: 0.3811\n",
      "00:00:09.80\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2435e-02,  5.1026e-03,  9.2538e-03,  ..., -3.1505e-03,\n",
      "         -6.4205e-03, -9.6711e-02],\n",
      "        [ 1.5121e-02,  8.3003e-03,  1.7214e-02,  ..., -7.8210e-04,\n",
      "          9.4684e-03, -1.3810e-02],\n",
      "        [-1.9644e-02,  1.8432e-02, -5.5973e-03,  ...,  1.9871e-02,\n",
      "         -2.2130e-02, -1.9557e-03],\n",
      "        ...,\n",
      "        [ 1.3040e-02,  1.6648e-02,  4.3607e-03,  ...,  1.0004e-02,\n",
      "         -4.2646e-05,  1.5128e-02],\n",
      "        [ 8.5632e-02, -1.9074e-02,  4.7939e-03,  ...,  1.0194e-02,\n",
      "         -1.6537e-02,  2.0209e-02],\n",
      "        [ 2.1142e-02,  3.4067e-03, -6.2347e-03,  ...,  6.0925e-03,\n",
      "          2.3707e-02,  1.5123e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2470e-02,  5.1103e-03,  9.2784e-03,  ..., -3.0868e-03,\n",
      "         -6.4202e-03, -9.6634e-02],\n",
      "        [ 1.5094e-02,  8.2368e-03,  1.7226e-02,  ..., -7.6463e-04,\n",
      "          9.4373e-03, -1.3782e-02],\n",
      "        [-1.9616e-02,  1.8438e-02, -5.5731e-03,  ...,  1.9904e-02,\n",
      "         -2.2102e-02, -1.9518e-03],\n",
      "        ...,\n",
      "        [ 1.3046e-02,  1.6634e-02,  4.4101e-03,  ...,  9.9689e-03,\n",
      "         -5.3975e-05,  1.5041e-02],\n",
      "        [ 8.5617e-02, -1.9107e-02,  4.7770e-03,  ...,  1.0194e-02,\n",
      "         -1.6482e-02,  2.0177e-02],\n",
      "        [ 2.1149e-02,  3.3828e-03, -6.2300e-03,  ...,  6.0583e-03,\n",
      "          2.3674e-02,  1.4985e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 32: train_loss: 0.1378 train_acc: 0.9932 | val_loss: 2.4913 val_acc: 0.3730\n",
      "00:00:10.23\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2412e-02,  5.0963e-03,  9.2751e-03,  ..., -3.1893e-03,\n",
      "         -6.3923e-03, -9.6755e-02],\n",
      "        [ 1.5103e-02,  8.3289e-03,  1.7156e-02,  ..., -8.1002e-04,\n",
      "          9.4450e-03, -1.3816e-02],\n",
      "        [-1.9696e-02,  1.8396e-02, -5.6492e-03,  ...,  1.9844e-02,\n",
      "         -2.2190e-02, -1.9348e-03],\n",
      "        ...,\n",
      "        [ 1.3039e-02,  1.6718e-02,  4.3613e-03,  ...,  9.9924e-03,\n",
      "         -2.3797e-05,  1.5197e-02],\n",
      "        [ 8.5647e-02, -1.9116e-02,  4.7573e-03,  ...,  1.0194e-02,\n",
      "         -1.6600e-02,  2.0197e-02],\n",
      "        [ 2.1102e-02,  3.4814e-03, -6.2568e-03,  ...,  6.0781e-03,\n",
      "          2.3740e-02,  1.5237e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2435e-02,  5.1026e-03,  9.2538e-03,  ..., -3.1505e-03,\n",
      "         -6.4205e-03, -9.6711e-02],\n",
      "        [ 1.5121e-02,  8.3003e-03,  1.7214e-02,  ..., -7.8210e-04,\n",
      "          9.4684e-03, -1.3810e-02],\n",
      "        [-1.9644e-02,  1.8432e-02, -5.5973e-03,  ...,  1.9871e-02,\n",
      "         -2.2130e-02, -1.9557e-03],\n",
      "        ...,\n",
      "        [ 1.3040e-02,  1.6648e-02,  4.3607e-03,  ...,  1.0004e-02,\n",
      "         -4.2646e-05,  1.5128e-02],\n",
      "        [ 8.5632e-02, -1.9074e-02,  4.7939e-03,  ...,  1.0194e-02,\n",
      "         -1.6537e-02,  2.0209e-02],\n",
      "        [ 2.1142e-02,  3.4067e-03, -6.2347e-03,  ...,  6.0925e-03,\n",
      "          2.3707e-02,  1.5123e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 33: train_loss: 0.1397 train_acc: 0.9955 | val_loss: 2.5488 val_acc: 0.3443\n",
      "00:00:09.75\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2376e-02,  5.0714e-03,  9.2761e-03,  ..., -3.2411e-03,\n",
      "         -6.3360e-03, -9.6748e-02],\n",
      "        [ 1.5089e-02,  8.3881e-03,  1.7151e-02,  ..., -8.0332e-04,\n",
      "          9.5047e-03, -1.3844e-02],\n",
      "        [-1.9779e-02,  1.8418e-02, -5.6894e-03,  ...,  1.9780e-02,\n",
      "         -2.2192e-02, -1.9041e-03],\n",
      "        ...,\n",
      "        [ 1.3021e-02,  1.6748e-02,  4.3596e-03,  ...,  1.0021e-02,\n",
      "         -1.6213e-05,  1.5250e-02],\n",
      "        [ 8.5641e-02, -1.9145e-02,  4.7906e-03,  ...,  1.0206e-02,\n",
      "         -1.6621e-02,  2.0203e-02],\n",
      "        [ 2.1108e-02,  3.5001e-03, -6.2326e-03,  ...,  6.1205e-03,\n",
      "          2.3756e-02,  1.5280e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2412e-02,  5.0963e-03,  9.2751e-03,  ..., -3.1893e-03,\n",
      "         -6.3923e-03, -9.6755e-02],\n",
      "        [ 1.5103e-02,  8.3289e-03,  1.7156e-02,  ..., -8.1002e-04,\n",
      "          9.4450e-03, -1.3816e-02],\n",
      "        [-1.9696e-02,  1.8396e-02, -5.6492e-03,  ...,  1.9844e-02,\n",
      "         -2.2190e-02, -1.9348e-03],\n",
      "        ...,\n",
      "        [ 1.3039e-02,  1.6718e-02,  4.3613e-03,  ...,  9.9924e-03,\n",
      "         -2.3797e-05,  1.5197e-02],\n",
      "        [ 8.5647e-02, -1.9116e-02,  4.7573e-03,  ...,  1.0194e-02,\n",
      "         -1.6600e-02,  2.0197e-02],\n",
      "        [ 2.1102e-02,  3.4814e-03, -6.2568e-03,  ...,  6.0781e-03,\n",
      "          2.3740e-02,  1.5237e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 34: train_loss: 0.1061 train_acc: 0.9977 | val_loss: 2.5878 val_acc: 0.3525\n",
      "00:00:09.12\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2350e-02,  5.0046e-03,  9.2393e-03,  ..., -3.2873e-03,\n",
      "         -6.3173e-03, -9.6746e-02],\n",
      "        [ 1.5139e-02,  8.4524e-03,  1.7136e-02,  ..., -7.8320e-04,\n",
      "          9.5244e-03, -1.3849e-02],\n",
      "        [-1.9831e-02,  1.8407e-02, -5.7159e-03,  ...,  1.9718e-02,\n",
      "         -2.2217e-02, -1.8354e-03],\n",
      "        ...,\n",
      "        [ 1.3004e-02,  1.6784e-02,  4.3121e-03,  ...,  1.0042e-02,\n",
      "         -1.3271e-05,  1.5321e-02],\n",
      "        [ 8.5654e-02, -1.9147e-02,  4.7822e-03,  ...,  1.0166e-02,\n",
      "         -1.6647e-02,  2.0189e-02],\n",
      "        [ 2.1092e-02,  3.5640e-03, -6.2459e-03,  ...,  6.1432e-03,\n",
      "          2.3774e-02,  1.5365e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2376e-02,  5.0714e-03,  9.2761e-03,  ..., -3.2411e-03,\n",
      "         -6.3360e-03, -9.6748e-02],\n",
      "        [ 1.5089e-02,  8.3881e-03,  1.7151e-02,  ..., -8.0332e-04,\n",
      "          9.5047e-03, -1.3844e-02],\n",
      "        [-1.9779e-02,  1.8418e-02, -5.6894e-03,  ...,  1.9780e-02,\n",
      "         -2.2192e-02, -1.9041e-03],\n",
      "        ...,\n",
      "        [ 1.3021e-02,  1.6748e-02,  4.3596e-03,  ...,  1.0021e-02,\n",
      "         -1.6213e-05,  1.5250e-02],\n",
      "        [ 8.5641e-02, -1.9145e-02,  4.7906e-03,  ...,  1.0206e-02,\n",
      "         -1.6621e-02,  2.0203e-02],\n",
      "        [ 2.1108e-02,  3.5001e-03, -6.2326e-03,  ...,  6.1205e-03,\n",
      "          2.3756e-02,  1.5280e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 35: train_loss: 0.1132 train_acc: 0.9932 | val_loss: 2.5542 val_acc: 0.3607\n",
      "00:00:08.93\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2285e-02,  5.0308e-03,  9.2808e-03,  ..., -3.3298e-03,\n",
      "         -6.3010e-03, -9.6783e-02],\n",
      "        [ 1.5162e-02,  8.5032e-03,  1.7115e-02,  ..., -7.8211e-04,\n",
      "          9.5348e-03, -1.3881e-02],\n",
      "        [-1.9874e-02,  1.8415e-02, -5.7387e-03,  ...,  1.9684e-02,\n",
      "         -2.2263e-02, -1.8143e-03],\n",
      "        ...,\n",
      "        [ 1.2984e-02,  1.6855e-02,  4.3166e-03,  ...,  1.0036e-02,\n",
      "          8.2675e-06,  1.5344e-02],\n",
      "        [ 8.5603e-02, -1.9245e-02,  4.7297e-03,  ...,  1.0176e-02,\n",
      "         -1.6658e-02,  2.0215e-02],\n",
      "        [ 2.1098e-02,  3.6547e-03, -6.2443e-03,  ...,  6.1795e-03,\n",
      "          2.3826e-02,  1.5422e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2350e-02,  5.0046e-03,  9.2393e-03,  ..., -3.2873e-03,\n",
      "         -6.3173e-03, -9.6746e-02],\n",
      "        [ 1.5139e-02,  8.4524e-03,  1.7136e-02,  ..., -7.8320e-04,\n",
      "          9.5244e-03, -1.3849e-02],\n",
      "        [-1.9831e-02,  1.8407e-02, -5.7159e-03,  ...,  1.9718e-02,\n",
      "         -2.2217e-02, -1.8354e-03],\n",
      "        ...,\n",
      "        [ 1.3004e-02,  1.6784e-02,  4.3121e-03,  ...,  1.0042e-02,\n",
      "         -1.3271e-05,  1.5321e-02],\n",
      "        [ 8.5654e-02, -1.9147e-02,  4.7822e-03,  ...,  1.0166e-02,\n",
      "         -1.6647e-02,  2.0189e-02],\n",
      "        [ 2.1092e-02,  3.5640e-03, -6.2459e-03,  ...,  6.1432e-03,\n",
      "          2.3774e-02,  1.5365e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 36: train_loss: 0.0913 train_acc: 1.0000 | val_loss: 2.5893 val_acc: 0.3484\n",
      "00:00:08.66\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2292e-02,  5.0289e-03,  9.3059e-03,  ..., -3.3861e-03,\n",
      "         -6.2690e-03, -9.6810e-02],\n",
      "        [ 1.5141e-02,  8.5531e-03,  1.7139e-02,  ..., -7.5291e-04,\n",
      "          9.5230e-03, -1.3877e-02],\n",
      "        [-1.9912e-02,  1.8415e-02, -5.7362e-03,  ...,  1.9680e-02,\n",
      "         -2.2283e-02, -1.7690e-03],\n",
      "        ...,\n",
      "        [ 1.2964e-02,  1.6861e-02,  4.2929e-03,  ...,  1.0057e-02,\n",
      "         -2.6380e-05,  1.5399e-02],\n",
      "        [ 8.5594e-02, -1.9274e-02,  4.7339e-03,  ...,  1.0179e-02,\n",
      "         -1.6705e-02,  2.0233e-02],\n",
      "        [ 2.1077e-02,  3.6963e-03, -6.2631e-03,  ...,  6.2227e-03,\n",
      "          2.3816e-02,  1.5490e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2285e-02,  5.0308e-03,  9.2808e-03,  ..., -3.3298e-03,\n",
      "         -6.3010e-03, -9.6783e-02],\n",
      "        [ 1.5162e-02,  8.5032e-03,  1.7115e-02,  ..., -7.8211e-04,\n",
      "          9.5348e-03, -1.3881e-02],\n",
      "        [-1.9874e-02,  1.8415e-02, -5.7387e-03,  ...,  1.9684e-02,\n",
      "         -2.2263e-02, -1.8143e-03],\n",
      "        ...,\n",
      "        [ 1.2984e-02,  1.6855e-02,  4.3166e-03,  ...,  1.0036e-02,\n",
      "          8.2675e-06,  1.5344e-02],\n",
      "        [ 8.5603e-02, -1.9245e-02,  4.7297e-03,  ...,  1.0176e-02,\n",
      "         -1.6658e-02,  2.0215e-02],\n",
      "        [ 2.1098e-02,  3.6547e-03, -6.2443e-03,  ...,  6.1795e-03,\n",
      "          2.3826e-02,  1.5422e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 00037: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 37: train_loss: 0.0852 train_acc: 1.0000 | val_loss: 2.6456 val_acc: 0.3525\n",
      "00:00:08.92\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2247e-02,  5.0133e-03,  9.3382e-03,  ..., -3.4036e-03,\n",
      "         -6.2228e-03, -9.6855e-02],\n",
      "        [ 1.5136e-02,  8.5777e-03,  1.7102e-02,  ..., -7.7175e-04,\n",
      "          9.5208e-03, -1.3906e-02],\n",
      "        [-1.9972e-02,  1.8401e-02, -5.7823e-03,  ...,  1.9612e-02,\n",
      "         -2.2320e-02, -1.7537e-03],\n",
      "        ...,\n",
      "        [ 1.2962e-02,  1.6917e-02,  4.2751e-03,  ...,  1.0066e-02,\n",
      "         -3.8939e-05,  1.5464e-02],\n",
      "        [ 8.5578e-02, -1.9297e-02,  4.7265e-03,  ...,  1.0171e-02,\n",
      "         -1.6708e-02,  2.0217e-02],\n",
      "        [ 2.1086e-02,  3.7768e-03, -6.2654e-03,  ...,  6.2386e-03,\n",
      "          2.3818e-02,  1.5559e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2292e-02,  5.0289e-03,  9.3059e-03,  ..., -3.3861e-03,\n",
      "         -6.2690e-03, -9.6810e-02],\n",
      "        [ 1.5141e-02,  8.5531e-03,  1.7139e-02,  ..., -7.5291e-04,\n",
      "          9.5230e-03, -1.3877e-02],\n",
      "        [-1.9912e-02,  1.8415e-02, -5.7362e-03,  ...,  1.9680e-02,\n",
      "         -2.2283e-02, -1.7690e-03],\n",
      "        ...,\n",
      "        [ 1.2964e-02,  1.6861e-02,  4.2929e-03,  ...,  1.0057e-02,\n",
      "         -2.6380e-05,  1.5399e-02],\n",
      "        [ 8.5594e-02, -1.9274e-02,  4.7339e-03,  ...,  1.0179e-02,\n",
      "         -1.6705e-02,  2.0233e-02],\n",
      "        [ 2.1077e-02,  3.6963e-03, -6.2631e-03,  ...,  6.2227e-03,\n",
      "          2.3816e-02,  1.5490e-02]], device='cuda:6', requires_grad=True)\n",
      "Epoch 38: train_loss: 0.0823 train_acc: 1.0000 | val_loss: 2.6570 val_acc: 0.3525\n",
      "00:00:08.79\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2225e-02,  5.0236e-03,  9.3276e-03,  ..., -3.4460e-03,\n",
      "         -6.2178e-03, -9.6842e-02],\n",
      "        [ 1.5151e-02,  8.5992e-03,  1.7081e-02,  ..., -7.7178e-04,\n",
      "          9.5093e-03, -1.3904e-02],\n",
      "        [-2.0024e-02,  1.8388e-02, -5.7941e-03,  ...,  1.9622e-02,\n",
      "         -2.2379e-02, -1.7134e-03],\n",
      "        ...,\n",
      "        [ 1.2959e-02,  1.6950e-02,  4.2358e-03,  ...,  1.0055e-02,\n",
      "         -6.8824e-05,  1.5509e-02],\n",
      "        [ 8.5592e-02, -1.9335e-02,  4.7333e-03,  ...,  1.0181e-02,\n",
      "         -1.6723e-02,  2.0198e-02],\n",
      "        [ 2.1062e-02,  3.7971e-03, -6.2796e-03,  ...,  6.2357e-03,\n",
      "          2.3807e-02,  1.5614e-02]], device='cuda:6', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2247e-02,  5.0133e-03,  9.3382e-03,  ..., -3.4036e-03,\n",
      "         -6.2228e-03, -9.6855e-02],\n",
      "        [ 1.5136e-02,  8.5777e-03,  1.7102e-02,  ..., -7.7175e-04,\n",
      "          9.5208e-03, -1.3906e-02],\n",
      "        [-1.9972e-02,  1.8401e-02, -5.7823e-03,  ...,  1.9612e-02,\n",
      "         -2.2320e-02, -1.7537e-03],\n",
      "        ...,\n",
      "        [ 1.2962e-02,  1.6917e-02,  4.2751e-03,  ...,  1.0066e-02,\n",
      "         -3.8939e-05,  1.5464e-02],\n",
      "        [ 8.5578e-02, -1.9297e-02,  4.7265e-03,  ...,  1.0171e-02,\n",
      "         -1.6708e-02,  2.0217e-02],\n",
      "        [ 2.1086e-02,  3.7768e-03, -6.2654e-03,  ...,  6.2386e-03,\n",
      "          2.3818e-02,  1.5559e-02]], device='cuda:6', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.999797705716143, 0.9999458546905468, 0.9999697094317526, 0.9999795210702965, 0.9999822820536792, 0.99998559577701, 0.999986259965226, 0.9999874168230841, 0.9999880392570049, 0.9999902488198131, 0.9999893998416761, 0.9999907095140467, 0.9999918181759616, 0.9999920200401297, 0.9999925174439946, 0.9999933905589083, 0.999993761225293, 0.9999945524614304, 0.9999945658103874, 0.9999948087303588, 0.9999952007395526, 0.9999952930957079, 0.9999957035761327, 0.9999960662486652, 0.9999967129745831, 0.9999961846042424, 0.9999967499946555, 0.999996825431784, 0.9999972022293756, 0.9999973858551433, 0.9999974094486485, 0.9999977088688562, 0.9999973439456274, 0.9999980208619187, 0.9999978615281483, 0.9999979339384785, 0.9999982084458073, 0.999998783149446]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_w['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Row wise average cos similarity')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule(\n",
      "  (feature_modules): ModuleDict(\n",
      "    (distance): Embedding(5, 3, padding_idx=0)\n",
      "    (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "    (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "    (u2_func): Embedding(21, 5, padding_idx=0)\n",
      "    (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "    (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "    (sat_children): Identity()\n",
      "    (nuc_children): Identity()\n",
      "  )\n",
      ")\n",
      "ModuleDict(\n",
      "  (distance): Embedding(5, 3, padding_idx=0)\n",
      "  (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "  (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "  (u2_func): Embedding(21, 5, padding_idx=0)\n",
      "  (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "  (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "  (sat_children): Identity()\n",
      "  (nuc_children): Identity()\n",
      ")\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(21, 5, padding_idx=0)\n",
      "Embedding(12, 4, padding_idx=0)\n",
      "Embedding(12, 4, padding_idx=0)\n",
      "Identity()\n",
      "Identity()\n"
     ]
    }
   ],
   "source": [
    "for i in model.module1.modules():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.0753 test_acc: 0.2846\n",
      "00:00:01.26\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.25      0.11      0.15        18\n",
      "    background       0.29      0.24      0.26        17\n",
      "         cause       0.25      1.00      0.40         2\n",
      "  circumstance       0.30      0.20      0.24        15\n",
      "    concession       0.29      0.54      0.38        13\n",
      "     condition       0.41      0.78      0.54         9\n",
      "   conjunction       0.33      0.57      0.42         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.57      0.73      0.64        11\n",
      "   elaboration       0.18      0.60      0.27        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.25      0.06      0.10        17\n",
      "      evidence       0.10      0.10      0.10        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.40      0.28      0.33        29\n",
      "          list       0.35      0.27      0.30        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.80      1.00      0.89         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.35      0.24      0.28        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.28       260\n",
      "     macro avg       0.24      0.29      0.24       260\n",
      "  weighted avg       0.29      0.28      0.27       260\n",
      "\n",
      "Test Loss: 3.075 |  Test Acc: 28.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#latest\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.7966 test_acc: 0.2808\n",
      "00:00:00.94\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.29      0.11      0.16        18\n",
      "    background       0.27      0.24      0.25        17\n",
      "         cause       0.25      1.00      0.40         2\n",
      "  circumstance       0.30      0.20      0.24        15\n",
      "    concession       0.33      0.54      0.41        13\n",
      "     condition       0.47      0.78      0.58         9\n",
      "   conjunction       0.31      0.57      0.40         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.67      0.73      0.70        11\n",
      "   elaboration       0.17      0.60      0.26        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.17      0.10      0.12        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.31      0.28      0.29        29\n",
      "          list       0.30      0.23      0.26        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.57      1.00      0.73         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.35      0.26      0.30        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.28       260\n",
      "     macro avg       0.23      0.29      0.24       260\n",
      "  weighted avg       0.27      0.28      0.26       260\n",
      "\n",
      "Latest Test Loss: 2.797 |  Latest Test Acc: 28.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best earliest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.9412 test_acc: 0.2846\n",
      "00:00:00.96\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.29      0.11      0.16        18\n",
      "    background       0.36      0.29      0.32        17\n",
      "         cause       0.25      1.00      0.40         2\n",
      "  circumstance       0.30      0.20      0.24        15\n",
      "    concession       0.28      0.54      0.37        13\n",
      "     condition       0.40      0.67      0.50         9\n",
      "   conjunction       0.33      0.57      0.42         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.67      0.73      0.70        11\n",
      "   elaboration       0.16      0.60      0.26        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.14      0.10      0.12        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.40      0.28      0.33        29\n",
      "          list       0.36      0.31      0.33        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.44      1.00      0.62         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.35      0.24      0.28        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.28       260\n",
      "     macro avg       0.23      0.29      0.23       260\n",
      "  weighted avg       0.28      0.28      0.27       260\n",
      "\n",
      "Best Test Loss: 2.941 |  Best Test Acc: 28.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best lastest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_latest', test_acc, 1)\n",
    "print(f'Best Test Loss: {test_loss:.3f} |  Best Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.4690 test_acc: 0.3811\n",
      "00:00:01.18\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.20      0.18      0.19        11\n",
      "    background       0.20      0.18      0.19        17\n",
      "         cause       0.20      0.14      0.17         7\n",
      "  circumstance       0.22      0.15      0.18        13\n",
      "    concession       0.30      0.55      0.39        11\n",
      "     condition       0.54      0.88      0.67         8\n",
      "   conjunction       0.60      0.75      0.67         8\n",
      "      contrast       1.00      0.67      0.80         3\n",
      " e-elaboration       0.78      0.54      0.64        13\n",
      "   elaboration       0.18      0.11      0.13        28\n",
      "  evaluation-n       1.00      0.12      0.22         8\n",
      "  evaluation-s       0.00      0.00      0.00         5\n",
      "      evidence       0.24      0.50      0.32         8\n",
      "interpretation       0.26      0.54      0.35        13\n",
      "         joint       0.21      0.17      0.19        18\n",
      "          list       0.48      0.67      0.56        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.64      0.64      0.64        11\n",
      "       purpose       0.75      0.60      0.67         5\n",
      "        reason       0.47      0.50      0.48        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         3\n",
      "      sequence       0.00      0.00      0.00         0\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.37       241\n",
      "     macro avg       0.33      0.31      0.30       241\n",
      "  weighted avg       0.37      0.37      0.35       241\n",
      "\n",
      "Val Loss: 2.469 |  Val Acc: 38.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best val acc\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
