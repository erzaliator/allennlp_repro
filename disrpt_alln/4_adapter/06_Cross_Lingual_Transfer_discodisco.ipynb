{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI6aVBQRy6LC"
   },
   "source": [
    "# 4️⃣ Zero-Shot Cross-Lingual Transfer using Adapters\n",
    "\n",
    "Beyond AdapterFusion, which we trained in [the previous notebook](https://github.com/Adapter-Hub/adapter-transformers/blob/master/notebooks/04_Cross_Lingual_Transfer.ipynb), we can compose adapters for zero-shot cross-lingual transfer between tasks. We will use the stacked adapter setup presented in **MAD-X** ([Pfeiffer et al., 2020](https://arxiv.org/pdf/2005.00052.pdf)) for this purpose.\n",
    "\n",
    "In this example, the base model is a pre-trained multilingual **XLM-R** (`xlm-roberta-base`) ([Conneau et al., 2019](https://arxiv.org/pdf/1911.02116.pdf)) model. Additionally, two types of adapters, language adapters and task adapters, are used. Here's how the MAD-X process works in detail:\n",
    "\n",
    "1. Train language adapters for the source and target language on a language modeling task. In this notebook, we won't train them ourselves but use [pre-trained language adapters from the Hub](https://adapterhub.ml/explore/text_lang/).\n",
    "2. Train a task adapter on the target task dataset. This task adapter is **stacked** upon the previously trained language adapter. During this step, only the weights of the task adapter are updated.\n",
    "3. Perform zero-shot cross-lingual transfer. In this last step, we simply replace the source language adapter with the target language adapter while keeping the stacked task adapter.\n",
    "\n",
    "Now to our concrete example: we select **XCOPA** ([Ponti et al., 2020](https://ducdauge.github.io/files/xcopa.pdf)), a multilingual extension of the **COPA** commonsence reasoning dataset ([Roemmele et al., 2011](https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF)) as our target task. The setup is trained on the original **English** dataset and then transferred to **Chinese**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L9gYpCV28OA"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Besides `adapter-transformers`, we use HuggingFace's `datasets` library for loading the data. So let's install both first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qL3Sq1HQynCq",
    "outputId": "1a53add7-208d-4767-a6f7-c51fad93787e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BERT_MODEL = 'bert-base-multilingual-cased'#'bert-base-german-cased'\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'AdapterAlphaDisco'\n",
    "lr = 'lr=AdafactorDefault'\n",
    "model_name = 'plm='+BERT_MODEL\n",
    "additional_info = 'Info=v3_lrtest1'\n",
    "name = '_'.join([experiment_name, lr, model_name, additional_info])\n",
    "\n",
    "MODEL_DIR = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merzaliator\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/wandb/run-20230109_181544-2p0bylbf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/erzaliator/allennlp_repro-disrpt_alln_4_adapter/runs/2p0bylbf\" target=\"_blank\">dark-durian-38</a></strong> to <a href=\"https://wandb.ai/erzaliator/allennlp_repro-disrpt_alln_4_adapter\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#WANDB\n",
    "wandb.init(reinit=True)\n",
    "wandb.run.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with params: BERT_MODEL=bert-base-multilingual-cased lr=lr=AdafactorDefault\n"
     ]
    }
   ],
   "source": [
    "# LOGGING\n",
    "from utils.logger import Logger\n",
    "logger = Logger(MODEL_DIR, wandb, wandb_flag=True)\n",
    "print('Running with params: BERT_MODEL='+ BERT_MODEL+ ' lr='+ str(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP9OMSUT-FtL"
   },
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "We need the English COPA dataset for training our task adapter. It is part of the SuperGLUE benchmark and can be loaded via `datasets` using one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2155, 1621)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "en_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_train_enriched.rels')[:100])\n",
    "en_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_test_enriched.rels'))\n",
    "en_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_dev_enriched.rels'))\n",
    "\n",
    "de_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')[:100])\n",
    "de_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels'))\n",
    "de_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels'))\n",
    "\n",
    "len(en_train_dataset_df), len(en_test_dataset_df), len(en_valid_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit1_txt': Value(dtype='string', id=None),\n",
       " 'unit1_sent': Value(dtype='string', id=None),\n",
       " 'unit2_txt': Value(dtype='string', id=None),\n",
       " 'unit2_sent': Value(dtype='string', id=None),\n",
       " 'dir': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='string', id=None),\n",
       " 'distance': Value(dtype='string', id=None),\n",
       " 'u1_depdir': Value(dtype='string', id=None),\n",
       " 'u2_depdir': Value(dtype='string', id=None),\n",
       " 'u2_func': Value(dtype='string', id=None),\n",
       " 'u1_position': Value(dtype='string', id=None),\n",
       " 'u2_position': Value(dtype='string', id=None),\n",
       " 'sat_children': Value(dtype='string', id=None),\n",
       " 'nuc_children': Value(dtype='string', id=None),\n",
       " 'genre': Value(dtype='string', id=None),\n",
       " 'unit1_case': Value(dtype='string', id=None),\n",
       " 'unit2_case': Value(dtype='string', id=None),\n",
       " 'u1_discontinuous': Value(dtype='string', id=None),\n",
       " 'u2_discontinuous': Value(dtype='string', id=None),\n",
       " 'same_speaker': Value(dtype='string', id=None),\n",
       " 'lex_overlap_length': Value(dtype='string', id=None),\n",
       " 'u1_func': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train_dataset_df.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVa3Vk0QdNYI"
   },
   "source": [
    "In this example, we model COPA as a multiple-choice task with two choices. Thus, we encode the premise and question as well as both choices as one input to our `xlm-roberta-base` model. Using `dataset.map()`, we can pass the full dataset through the tokenizer in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 100 examples\n",
      "read 1621 examples\n",
      "read 2155 examples\n",
      "read 100 examples\n",
      "read 241 examples\n",
      "read 260 examples\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from datasets import ClassLabel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the SNLI dataset.\"\"\"\n",
    "    def __init__(self, dataset, labels, raw_text=False):\n",
    "        self.text = []\n",
    "        self.raw_text = []\n",
    "        self.raw_label = []\n",
    "        self.raw_text_flag = raw_text\n",
    "        self.num_rows = len(dataset)\n",
    "        for premise, hypothesis in zip(dataset['unit1_txt'], dataset['unit2_txt']):\n",
    "            self.text.append(tokenizer.encode_plus(premise, hypothesis, padding=\"max_length\", truncation=True, max_length=512, return_token_type_ids=True))\n",
    "            if raw_text: self.raw_text.append([premise, hypothesis])\n",
    "        # self.labels = torch.tensor(labels.str2int(dataset['label'])).to(device)\n",
    "        self.labels = labels.str2int(dataset['label'])\n",
    "        if raw_text: self.raw_label = dataset['label']\n",
    "        print('read ' + str(len(self.text)) + ' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.raw_text_flag:  \n",
    "            return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'raw_text': self.raw_text[idx],\n",
    "                'label':self.labels[idx],\n",
    "                'raw_label': self.raw_label[idx]}\n",
    "\n",
    "        return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'label':self.labels[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def combine_with_another_dataset(self, dataset2):\n",
    "        print('Adding datasets of sizes ', self.num_rows, ', ', dataset2.num_rows)\n",
    "        self.text = self.text + dataset2.text\n",
    "        self.raw_text = self.raw_text + dataset2.raw_text\n",
    "        self.raw_label = self.raw_label + dataset2.raw_label\n",
    "        self.num_rows = len(self.text) #update texts is now longer\n",
    "        assert self.raw_text_flag == dataset2.raw_text_flag\n",
    "        print('To new dataset size: ', self.num_rows)\n",
    "\n",
    "\n",
    "def load_data_snli(batch_size, train_dataset_df, valid_dataset_df, test_dataset_df, labels):\n",
    "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
    "    train_data = train_dataset_df\n",
    "    valid_data = valid_dataset_df\n",
    "    test_data = test_dataset_df\n",
    "    train_set = SNLIDataset(train_data, labels, raw_text=False)\n",
    "    valid_set = SNLIDataset(valid_data, labels, raw_text=False)\n",
    "    test_set = SNLIDataset(test_data, labels, raw_text=False)\n",
    "    return train_set, valid_set, test_set #TODO: MAKE INTO DICT\n",
    "\n",
    "en_labels = ClassLabel(names=list(set(en_train_dataset_df['label'])|set(en_test_dataset_df['label'])|set(en_valid_dataset_df['label'])))\n",
    "en_train_dataset, en_valid_dataset, en_test_dataset = load_data_snli(BATCH_SIZE, en_train_dataset_df, en_valid_dataset_df, en_test_dataset_df, en_labels)\n",
    "de_labels = ClassLabel(names=list(set(de_train_dataset_df['label'])|set(de_test_dataset_df['label'])|set(de_valid_dataset_df['label'])))\n",
    "de_train_dataset, de_valid_dataset, de_test_dataset = load_data_snli(BATCH_SIZE, de_train_dataset_df, de_valid_dataset_df, de_test_dataset_df, de_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs21MzEQ_0v4"
   },
   "source": [
    "## Task Adapter Training\n",
    "\n",
    "In this section, we will train the task adapter on the English COPA dataset. We use a pre-trained XLM-R model from HuggingFace and instantiate our model using `AutoAdapterModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# from typing import Any, Dict, Optional\n",
    "# from transformers import BertModel, AutoTokenizer, BertConfig\n",
    "# from transformers.models.bert.modeling_bert import BertPooler\n",
    "# import torch.nn as nn\n",
    "# from tensorflow.keras.layers import TimeDistributed\n",
    "# from featurefulbertembedder_custom2 import FeaturefulBertEmbedder\n",
    "# from featureful_bert_custom2 import get_combined_feature_tensor_2 as get_combined_feature_tensor_forward\n",
    "# from featureful_bert_custom2 import get_feature_modules\n",
    "\n",
    "# class CustomPooler2(nn.Module):\n",
    "#     def __init__(self, *,\n",
    "#                         requires_grad: bool = True,\n",
    "#                         dropout: float = 0.0,\n",
    "#                         transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "#         super().__init__()\n",
    "#         bert = BertModel.from_pretrained(BERT_MODEL) #only used to pass config. BertAttentionClass used in FeatureFulBert\n",
    "#         self._dropout = torch.nn.Dropout(p=dropout)\n",
    "#         self.pooler = copy.deepcopy(bert.pooler)\n",
    "#         for param in self.pooler.parameters():\n",
    "#             param.requires_grad = requires_grad\n",
    "#         self._embedding_dim = bert.config.hidden_size\n",
    "\n",
    "#     def get_input_dim(self) -> int:\n",
    "#         return self._embedding_dim\n",
    "\n",
    "#     def get_output_dim(self) -> int:\n",
    "#         return self._embedding_dim\n",
    "\n",
    "#     def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "#         pooler = self.pooler\n",
    "        \n",
    "#         for _ in range(num_wrapping_dims):\n",
    "#             pooler = TimeDistributed(pooler)\n",
    "#         pooled = pooler(tokens)\n",
    "#         pooled = self._dropout(pooled)\n",
    "#         return pooled\n",
    "\n",
    "# class MyModule(nn.Module):    \n",
    "#     def __init__(self, feature_list, vocab):\n",
    "#         super(MyModule, self).__init__()\n",
    "#         self.feature_list = feature_list\n",
    "#         self.feature_modules, self._feature_module_size = get_feature_modules(feature_list, vocab)\n",
    "\n",
    "#     def forward(self, features):\n",
    "#         return get_combined_feature_tensor_forward(features, self.feature_list, self.feature_modules)\n",
    "\n",
    "# class CustomBERTModel(nn.Module):\n",
    "#     def __init__(self, num_labels, vocab):\n",
    "#           super(CustomBERTModel, self).__init__()\n",
    "#           self.num_classes = num_labels\n",
    "#           self.feature_list = mnli_dataset.feature_list\n",
    "#           print('ASSIGN:', self.num_classes)\n",
    "\n",
    "#           self.embedder = self.create_featureful_bert()\n",
    "#           self.encoder = CustomPooler2()\n",
    "#           self.module1 = MyModule(self.feature_list, vocab)\n",
    "#           self.dropout1 = nn.Dropout(p=0.0)\n",
    "#         #   self.dropout_decoder = nn.Dropout(p=0.5)\n",
    "#           self._decoder_input_size = self.encoder._embedding_dim + self.module1._feature_module_size\n",
    "#           self.relation_decoder = nn.Linear(self._decoder_input_size, self.num_classes)\n",
    "\n",
    "#     def forward(self, pair_token_ids, token_type_ids, attention_mask, feat):\n",
    "#         direction_tensor = feat['dir'].to(device)\n",
    "#         embedded_sentence = self.embedder(token_ids=pair_token_ids, #featurefulmebedder\n",
    "#                         mask=attention_mask, \n",
    "#                         type_ids=token_type_ids,\n",
    "#                         segment_concat_mask = None,\n",
    "#                         direction_tensor = direction_tensor,\n",
    "#                         feature_list = self.feature_list,\n",
    "#                         features = feat)\n",
    "#         mask = token_type_ids\n",
    "#         bertpooler_output = self.encoder(tokens=embedded_sentence, mask=mask)\n",
    "#         feat = self.convert_to_feature_list(feat)\n",
    "#         feat = self.dropout1(feat)\n",
    "#         feat = self.module1(feat)\n",
    "#         # print(bertpooler_output.shape, self.module1._feature_module_size, feat.shape)\n",
    "#         try:\n",
    "#             feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "#         except:\n",
    "#             print(bertpooler_output.shape, feat.shape)\n",
    "#             raise ValueError()\n",
    "#         assert feat_concat.shape[-1] == self._decoder_input_size\n",
    "#         feat_concat = self.dropout1(feat_concat)\n",
    "#         # feat_concat = self.dropout_decoder(feat_concat)\n",
    "#         linear1_output = self.relation_decoder(feat_concat)\n",
    "#         return linear1_output\n",
    "\n",
    "\n",
    "#     def create_bert_without_activations(self):\n",
    "#         config = BertConfig.from_pretrained(BERT_MODEL, hidden_act='gelu')\n",
    "#         bert = BertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "#         return bert\n",
    "\n",
    "#     def create_featureful_bert(self):\n",
    "#         featureful_bert = FeaturefulBertEmbedder(model_name = BERT_MODEL,\n",
    "#                                 hidden_activation_allen = 'gelu',\n",
    "#                                 feature_list = self.feature_list, \n",
    "#                                 vocab=mnli_dataset.vocab)\n",
    "#         return featureful_bert\n",
    "\n",
    "#     def convert_to_feature_list(self, feat):\n",
    "#         feature_linear = [feat[feature_name] for feature_name in self.feature_list]\n",
    "#         feature_linear = torch.stack(feature_linear, dim=-1)\n",
    "#         return feature_linear\n",
    "        \n",
    "\n",
    "# model = CustomBERTModel(mnli_dataset.num_labels, mnli_dataset.vocab)\n",
    "# model.to(device)\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-6, correct_bias=False) # original 2e-5\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, mode='max', patience=35, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnq8n_KP_3aX",
    "outputId": "590b1cae-a454-4110-c9fb-f76f4dff423a"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.adapters.models.bert.adapter_model because of the following error (look up to see its traceback):\nname 'BERT_START_DOCSTRING' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/utils/import_utils.py:1002\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1002\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1003\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/adapters/models/bert/adapter_model.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_mixin\u001b[39;00m \u001b[39mimport\u001b[39;00m EmbeddingAdaptersWrapperMixin\n\u001b[1;32m     20\u001b[0m \u001b[39m@add_start_docstrings\u001b[39m(\n\u001b[1;32m     21\u001b[0m     \u001b[39m\"\"\"Bert Model transformer with the option to add multiple flexible heads on top.\"\"\"\u001b[39;00m,\n\u001b[0;32m---> 22\u001b[0m     BERT_START_DOCSTRING,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBertAdapterModel\u001b[39;00m(EmbeddingAdaptersWrapperMixin, ModelWithFlexibleHeadsAdaptersMixin, BertPreTrainedModel):\n\u001b[1;32m     25\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BERT_START_DOCSTRING' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoConfig, AutoAdapterModel\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     BERT_MODEL,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m AutoAdapterModel\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     BERT_MODEL,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:445\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m--> 445\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_model_mapping)\n\u001b[1;32m    446\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    447\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m )\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:359\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 359\u001b[0m     supported_models \u001b[39m=\u001b[39m model_mapping[\u001b[39mtype\u001b[39;49m(config)]\n\u001b[1;32m    360\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(supported_models, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    361\u001b[0m         \u001b[39mreturn\u001b[39;00m supported_models\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_mapping:\n\u001b[1;32m    563\u001b[0m     model_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_attr_from_module(model_type, model_name)\n\u001b[1;32m    566\u001b[0m \u001b[39m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m model_types \u001b[39m=\u001b[39m [k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config_mapping\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39m==\u001b[39m key\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m]\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:578\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules:\n\u001b[1;32m    577\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules[module_name] \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtransformers.models\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 578\u001b[0m \u001b[39mreturn\u001b[39;00m getattribute_from_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modules[module_name], attr)\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:539\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39m# object at the top level.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m transformers_module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39mtransformers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 539\u001b[0m \u001b[39mreturn\u001b[39;00m getattribute_from_module(transformers_module, attr)\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:534\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(attr, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m attr)\n\u001b[0;32m--> 534\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(module, attr):\n\u001b[1;32m    535\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    536\u001b[0m \u001b[39m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39m# object at the top level.\u001b[39;00m\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/utils/import_utils.py:993\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    992\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module[name])\n\u001b[0;32m--> 993\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(module, name)\n\u001b[1;32m    994\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/utils/import_utils.py:993\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    992\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module[name])\n\u001b[0;32m--> 993\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(module, name)\n\u001b[1;32m    994\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/utils/import_utils.py:992\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    990\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m    991\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m--> 992\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m    993\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m    994\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/utils/import_utils.py:1004\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1002\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1003\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1004\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1005\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.adapters.models.bert.adapter_model because of the following error (look up to see its traceback):\nname 'BERT_START_DOCSTRING' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoAdapterModel\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    BERT_MODEL,\n",
    ")\n",
    "model = AutoAdapterModel.from_pretrained(\n",
    "    BERT_MODEL,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertAdapterModel(\n",
      "  (shared_parameters): ModuleDict()\n",
      "  (bert): BertModel(\n",
      "    (shared_parameters): ModuleDict()\n",
      "    (invertible_adapters): ModuleDict()\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict()\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "    (prefix_tuning): PrefixTuningPool(\n",
      "      (prefix_tunings): ModuleDict()\n",
      "    )\n",
      "  )\n",
      "  (heads): ModuleDict()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/06_Cross_Lingual_Transfer_discodisco.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base AutoModel. If you print model before adding the adapters, you can see that the embeddings+12 transformer layers will be shared by En and Zh adapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDCNJzTXezcn"
   },
   "source": [
    "Now we only need to set up the adapters. As described, we need two language adapters (which are assumed to be pre-trained in this example) and a task adapter (which will be trained in a few moments).\n",
    "\n",
    "First, we load both the language adapters for our source language English (`\"en\"`) and our target language Chinese (`\"zh\"`) from the Hub. Then we add a new task adapter (`\"copa\"`) for our target task.\n",
    "\n",
    "Finally, we add a multiple-choice head with the same name as our task adapter on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRqbBgS0BoHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdapterConfig\n",
    "\n",
    "# Load the language adapters\n",
    "lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "model.load_adapter(\"en/wiki@ukp\", config=lang_adapter_config)\n",
    "model.load_adapter(\"de/wiki@ukp\", config=lang_adapter_config)\n",
    "\n",
    "# Add a new task adapter\n",
    "# model.add_adapter_task(\"disrpt\", labels=[1,0,0,0,0,0,0])\n",
    "model.add_adapter(\"disrpt\")\n",
    "\n",
    "# Add a classification head for our target task\n",
    "num_labels=de_labels.num_classes\n",
    "print([num_labels])\n",
    "# model.add_multiple_choice_head(\"disrpt\", num_choices=num_labels)\n",
    "model.add_classification_head(\"disrpt\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `train_adapter()`, we tell our model to only train the task adapter in the following. This call will freeze the weights of the pre-trained model and the weights of the language adapters to prevent them from further finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wBpjGWZ4v7O"
   },
   "outputs": [],
   "source": [
    "model.train_adapter([\"disrpt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60qIas8-il92"
   },
   "source": [
    "We want the task adapter to be stacked on top of the language adapter, so we have to tell our model to use this setup via the `active_adapters` property.\n",
    "\n",
    "A stack of adapters is represented by the `Stack` class, which takes the names of the adapters to be stacked as arguments.\n",
    "Of course, there are various other possibilities to compose adapters beyonde stacking. Learn more about those [in our documentation](https://docs.adapterhub.ml/adapter_composition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgGqHJQbijgg"
   },
   "outputs": [],
   "source": [
    "# Unfreeze and activate stack setup\n",
    "from transformers.adapters.composition import Stack\n",
    "\n",
    "lang = 'en'\n",
    "model.active_adapters = Stack(lang, \"disrpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBDvwmUf_-mc"
   },
   "source": [
    "Great! Now, the input will be passed through the English language adapter first and the COPA task adapter second in every forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb8BY5RAmzkd"
   },
   "source": [
    "For training, we make use of the `Trainer` class built-in into `transformers`. We configure the training process using a `TrainingArguments` object.\n",
    "\n",
    "As the dataset splits of English COPA in the SuperGLUE are slightly different, we train on both the train and validation split of the dataset. Later, we will evaluate on the test split of XCOPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SHUFFLE print smples: https://discuss.huggingface.co/t/how-to-print-a-few-examples-at-the-beginning-of-training-when-using-trainer/7597/2\n",
    "# https://github.com/huggingface/datasets/blob/cd3169f3f35afcf73a36a8276113e1881d92e5e0/src/datasets/iterable_dataset.py#L223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 14:35:34.770274: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 14:35:35.069295: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-05 14:35:35.069340: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-05 14:35:35.131767: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-05 14:35:36.133893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-05 14:35:36.133994: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-05 14:35:36.134003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train@\"+lang)\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, log_loss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    global num_labels\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    logits = torch.tensor(pred.predictions)\n",
    "    labels = torch.tensor(labels)\n",
    "    loss = loss_fct(logits.view(-1, num_labels), labels.view(-1))\n",
    "    return {\n",
    "        'accuracy@'+lang: acc,\n",
    "        'f1@'+lang: f1,\n",
    "        'precision@'+lang: precision,\n",
    "        'recall@'+lang: recall,\n",
    "        'loss@'+lang: loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0gFxQRdDkQ6"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer\n",
    "# from datasets import concatenate_datasets\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def concatenate_datasets(dataset1, dataset2, shuffle=True):\n",
    "    y_iter = chain(dataset1, dataset2)\n",
    "    return y_iter\n",
    "    # tmp = list(yielding(y_iter))\n",
    "    # random.shuffle(tmp)\n",
    "    # for i in tmp:\n",
    "    #     print i\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    output_dir=MODEL_DIR+'_EN',\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "# train_dataset.combine_with_another_dataset(valid_dataset)\n",
    "# train_dataset = concatenate_datasets([dataset_en[\"train\"], dataset_en[\"validation\"]])\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=en_train_dataset,\n",
    "    eval_dataset=en_valid_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.add_callback(CustomCallback(trainer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKlYjA9rm2Kp"
   },
   "source": [
    "Start the training 🚀 (this will take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "vSUs2FjXDmsx",
    "outputId": "2b8bb989-f6ca-4702-c222-15eea9823bbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 03:10, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy@en</th>\n",
       "      <th>F1@en</th>\n",
       "      <th>Precision@en</th>\n",
       "      <th>Recall@en</th>\n",
       "      <th>Loss@en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.964214</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.066789</td>\n",
       "      <td>0.051959</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>2.964214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.159000</td>\n",
       "      <td>2.994197</td>\n",
       "      <td>0.354719</td>\n",
       "      <td>0.041642</td>\n",
       "      <td>0.031404</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>2.994197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.159000</td>\n",
       "      <td>2.678128</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>2.678128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.839300</td>\n",
       "      <td>2.735241</td>\n",
       "      <td>0.394818</td>\n",
       "      <td>0.039306</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.060830</td>\n",
       "      <td>2.735240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.839300</td>\n",
       "      <td>2.424406</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>2.424406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.604200</td>\n",
       "      <td>2.500849</td>\n",
       "      <td>0.395435</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.034664</td>\n",
       "      <td>0.060375</td>\n",
       "      <td>2.500849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.604200</td>\n",
       "      <td>2.294416</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.059576</td>\n",
       "      <td>0.052827</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>2.294416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.466900</td>\n",
       "      <td>2.398073</td>\n",
       "      <td>0.389883</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>0.034010</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>2.398073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.466900</td>\n",
       "      <td>2.237481</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.059766</td>\n",
       "      <td>0.047286</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>2.237482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.311300</td>\n",
       "      <td>2.386429</td>\n",
       "      <td>0.368908</td>\n",
       "      <td>0.042550</td>\n",
       "      <td>0.032873</td>\n",
       "      <td>0.062763</td>\n",
       "      <td>2.386429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.311300</td>\n",
       "      <td>2.199067</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.056375</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>2.199067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>2.376349</td>\n",
       "      <td>0.357804</td>\n",
       "      <td>0.041941</td>\n",
       "      <td>0.031828</td>\n",
       "      <td>0.062227</td>\n",
       "      <td>2.376349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>2.175109</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>2.175109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.344400</td>\n",
       "      <td>2.363405</td>\n",
       "      <td>0.356570</td>\n",
       "      <td>0.042547</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>0.063137</td>\n",
       "      <td>2.363405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.344400</td>\n",
       "      <td>2.166503</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>2.166503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.220200</td>\n",
       "      <td>2.360330</td>\n",
       "      <td>0.356570</td>\n",
       "      <td>0.042722</td>\n",
       "      <td>0.032314</td>\n",
       "      <td>0.063410</td>\n",
       "      <td>2.360330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train_log metrics *****\n",
      "  epoch                    =        8.0\n",
      "  total_flos               =   233292GF\n",
      "  train_loss               =     2.5238\n",
      "  train_runtime            = 0:03:11.30\n",
      "  train_samples_per_second =      4.182\n",
      "  train_steps_per_second   =      0.293\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train_log\", metrics)\n",
    "trainer.save_metrics(\"train_log\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2155\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_en_loss': 2.4515175819396973,\n",
       " 'test_en_accuracy@en': 0.33178654292343385,\n",
       " 'test_en_f1@en': 0.04071513997224092,\n",
       " 'test_en_precision@en': 0.030522834978779965,\n",
       " 'test_en_recall@en': 0.06247606318035189,\n",
       " 'test_en_loss@en': 2.451517343521118,\n",
       " 'test_en_runtime': 26.5909,\n",
       " 'test_en_samples_per_second': 81.043,\n",
       " 'test_en_steps_per_second': 5.077,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval_trainer = AdapterTrainer(\n",
    "#     model=model,\n",
    "#     args=TrainingArguments(output_dir=\"./eval_output_en\", remove_unused_columns=False,),\n",
    "#     eval_dataset=en_test_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "trainer.evaluate(metric_key_prefix='test_en',\n",
    "                eval_dataset=en_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axvDsmnJnGUG"
   },
   "source": [
    "## Cross-lingual transfer\n",
    "\n",
    "With the model and all adapters trained and ready, we can come to the cross-lingual transfer step here. We will evaluate our setup on the Chinese split of the XCOPA dataset.\n",
    "Therefore, we'll first download the data and preprocess it using the same method as the English dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0w3ofGZC4Oi"
   },
   "source": [
    "Next, let's adapt our setup to the new language. We simply replace the English language adapter with the Chinese language adapter we already loaded previously. The task adapter we just trained is kept. Again, we set this architecture using `active_adapters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V04UntKfeK_z"
   },
   "outputs": [],
   "source": [
    "lang = 'de'\n",
    "model.active_adapters = Stack(lang, \"disrpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9RAmZLzDk-j"
   },
   "source": [
    "Finally, let's see how well our adapter setup performs on the new language. We measure the zero-shot accuracy on the test split of the target language dataset. Evaluation is also performed using the built-in `Trainer` class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set training args for de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir=MODEL_DIR+'_DE',\n",
    "    overwrite_output_dir=False,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=1,\n",
    "    # resume_from_checkpoint=MODEL_DIR+'/last-checkpoint',\n",
    ")\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=de_train_dataset,\n",
    "    eval_dataset=de_valid_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.add_callback(CustomCallback(trainer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 104\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [104/104 01:00, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy@de</th>\n",
       "      <th>F1@de</th>\n",
       "      <th>Precision@de</th>\n",
       "      <th>Recall@de</th>\n",
       "      <th>Loss@de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.982893</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>2.982893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.257700</td>\n",
       "      <td>3.243593</td>\n",
       "      <td>0.053942</td>\n",
       "      <td>0.004265</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>3.243592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.257700</td>\n",
       "      <td>2.869488</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.036840</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>2.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.937400</td>\n",
       "      <td>3.129823</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.011176</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.040408</td>\n",
       "      <td>3.129823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.937400</td>\n",
       "      <td>2.757950</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>2.757949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.879800</td>\n",
       "      <td>3.132065</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>0.010923</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>3.132065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.879800</td>\n",
       "      <td>2.691318</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.073370</td>\n",
       "      <td>2.691318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>3.114051</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.038919</td>\n",
       "      <td>3.114051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.745600</td>\n",
       "      <td>2.631517</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.037826</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.073370</td>\n",
       "      <td>2.631517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.687200</td>\n",
       "      <td>3.108267</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.040408</td>\n",
       "      <td>3.108267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.687200</td>\n",
       "      <td>2.587355</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.034928</td>\n",
       "      <td>0.023309</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>2.587355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.676700</td>\n",
       "      <td>3.112995</td>\n",
       "      <td>0.120332</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.051740</td>\n",
       "      <td>3.112995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.676700</td>\n",
       "      <td>2.560259</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.034928</td>\n",
       "      <td>0.023309</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>2.560259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.570500</td>\n",
       "      <td>3.103766</td>\n",
       "      <td>0.116183</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.048535</td>\n",
       "      <td>3.103766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.570500</td>\n",
       "      <td>2.551108</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.036430</td>\n",
       "      <td>0.024426</td>\n",
       "      <td>0.073370</td>\n",
       "      <td>2.551109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.612800</td>\n",
       "      <td>3.101262</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>0.042125</td>\n",
       "      <td>3.101262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train_logger metrics *****\n",
      "  epoch                    =        8.0\n",
      "  total_flos               =   233292GF\n",
      "  train_loss               =     2.5238\n",
      "  train_runtime            = 0:03:11.30\n",
      "  train_samples_per_second =      4.182\n",
      "  train_steps_per_second   =      0.293\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train_logger\", metrics)\n",
    "trainer.save_metrics(\"train_logger\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "CrW1cJyaeMox",
    "outputId": "f3f504c1-9518-4c21-e10f-b5202ae1c39f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 260\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='303' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_de_loss': 3.1481635570526123,\n",
       " 'test_de_accuracy@de': 0.1076923076923077,\n",
       " 'test_de_f1@de': 0.01305642759397891,\n",
       " 'test_de_precision@de': 0.0077206123924042315,\n",
       " 'test_de_recall@de': 0.04330065359477125,\n",
       " 'test_de_loss@de': 3.1481635570526123,\n",
       " 'test_de_runtime': 3.4364,\n",
       " 'test_de_samples_per_second': 75.66,\n",
       " 'test_de_steps_per_second': 9.603,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(metric_key_prefix='test_de',\n",
    "                eval_dataset=de_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "CrW1cJyaeMox",
    "outputId": "f3f504c1-9518-4c21-e10f-b5202ae1c39f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2155\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_en(de)_loss': 2.8030734062194824,\n",
       " 'test_en(de)_accuracy@en(de)': 0.362877030162413,\n",
       " 'test_en(de)_f1@en(de)': 0.03016975308641975,\n",
       " 'test_en(de)_precision@en(de)': 0.020846662401364895,\n",
       " 'test_en(de)_recall@en(de)': 0.054578447794528195,\n",
       " 'test_en(de)_loss@en(de)': 2.8030736446380615,\n",
       " 'test_en(de)_runtime': 28.3676,\n",
       " 'test_en(de)_samples_per_second': 75.967,\n",
       " 'test_en(de)_steps_per_second': 9.518,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = 'en(de)'\n",
    "\n",
    "trainer.evaluate(metric_key_prefix='test_en(de)',\n",
    "                eval_dataset=en_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op8M7AfYnWhs"
   },
   "source": [
    "You should get an overall accuracy of about 56 which is on-par with full finetuning on COPA only but below the state-of-the-art which is sequentially finetuned on an additional dataset before finetuning on COPA.\n",
    "\n",
    "For results on different languages and a sequential finetuning setup which yields better results, make sure to check out [the MAD-X paper](https://arxiv.org/pdf/2005.00052.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you mean to say that even the SOTAs struggle to match randomized baseline for Zh."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_Cross_Lingual_Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cb7dbc5b67469b8643c0ea3e6b3921": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f3bac44e13246ab9f9c8564a44e1fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e45676711b477e9a1ce2cf4ac8f3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "11b4409af40748e0b760e91c3d91ede7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28b184f13a948d5995ee04720748871",
      "placeholder": "​",
      "style": "IPY_MODEL_2393e906e07e4e8ba661b0eafd2268e8",
      "value": " 100/0 [00:00&lt;00:00, 1191.08 examples/s]"
     }
    },
    "12ec755bb33c4ff894644e291ce33040": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13829992bf994ec5bbec71684cc824e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ccbb12bb5a548488c9b646159f893d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e70f23ca6f94a2099c2cca1eaf875d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8348929b740242d3bdc73ea2c8bcd9c8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c82fa83594a349c991626ee55b8edfa4",
      "value": 1
     }
    },
    "21bd77c2c70040548a696c5a40d81a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac8b24c5d6214716a409ca95580306f5",
      "placeholder": "​",
      "style": "IPY_MODEL_932d3ee3c9d74761bfc4bcf5c003d205",
      "value": " 1/1 [00:10&lt;00:00, 10.75s/ba]"
     }
    },
    "2393e906e07e4e8ba661b0eafd2268e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "249abcb1904c4d1ca4116b677011b017": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12ec755bb33c4ff894644e291ce33040",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df292d721c1748c485f281aa2162b9a9",
      "value": 1
     }
    },
    "2a76413cb9cd4a6f901a8bef7dc70220": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c154bfdf049147638c67d2844d25f9e6",
       "IPY_MODEL_4fe615dff7104a018c48491fd711ed45"
      ],
      "layout": "IPY_MODEL_13829992bf994ec5bbec71684cc824e6"
     }
    },
    "2d964df49d71456093b427af2a3ac6cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "315cd377eae94488b258460f06e5cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02cb7dbc5b67469b8643c0ea3e6b3921",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a8c7ea6d7ec4ec691525f6e3ca88d48",
      "value": 1
     }
    },
    "342e98cd2d99438d861d5c1cf54b573d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d85845466e5a4ffd8370ef4c8b965684",
       "IPY_MODEL_5b84c1bb95354f939bc1918b5478cf08"
      ],
      "layout": "IPY_MODEL_e3e3c18ef96e48999e14be0c60ad9f04"
     }
    },
    "3bc11633e20c460eb9058cc4b480b224": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3ccf15d7bea44e9bb91b9b3d32b3c691": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a0b61f58dfd4b2c88e7fe818c4de4b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfc579b1c3354bcd9a0be2fde370954c",
       "IPY_MODEL_ed22b18a21c943f291c6326030cb2753"
      ],
      "layout": "IPY_MODEL_bc7b5cd3163b4b60877d80be43598436"
     }
    },
    "4a23a9bdd091425cbda38222f2e4c3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58b17e932dd74756b62fb7f6ed0d37ba",
      "placeholder": "​",
      "style": "IPY_MODEL_77583bbefaf849eea83d3ae327e4070e",
      "value": " 1/1 [00:00&lt;00:00,  2.51ba/s]"
     }
    },
    "4eac0e183d8047e498d3a576f3c3a1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fe615dff7104a018c48491fd711ed45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2423ca88827446aa5b5c78ccc36a263",
      "placeholder": "​",
      "style": "IPY_MODEL_527ea785de0a47f0ba5b0d0aea72cc97",
      "value": " 500/0 [00:00&lt;00:00, 2888.43 examples/s]"
     }
    },
    "525a5c1a8ba04c8e89fc514064539d73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527ea785de0a47f0ba5b0d0aea72cc97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5321f4576a6c4fe69de0c97b43269d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "568fedab4a4e44d9baa8213d54d60d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f512c5cdfaa64005bb987f032957e530",
      "placeholder": "​",
      "style": "IPY_MODEL_87c546c1a23c402f8a6de964828dc035",
      "value": " 28.2k/? [00:00&lt;00:00, 297kB/s]"
     }
    },
    "58b17e932dd74756b62fb7f6ed0d37ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b2e4c980b6a4e15bef86d1907b20f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d964df49d71456093b427af2a3ac6cc",
      "placeholder": "​",
      "style": "IPY_MODEL_3ccf15d7bea44e9bb91b9b3d32b3c691",
      "value": " 642k/? [00:00&lt;00:00, 3.06MB/s]"
     }
    },
    "5b84c1bb95354f939bc1918b5478cf08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fec9b3f47668416f8709fd7ab80a9730",
      "placeholder": "​",
      "style": "IPY_MODEL_5d95a7e842dc43d995b3ad5f0b61ae8f",
      "value": " 1/1 [00:00&lt;00:00,  2.28ba/s]"
     }
    },
    "5d95a7e842dc43d995b3ad5f0b61ae8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5df3d17d64e24faeab6cc644d333536a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f708ccdb4f941918696d583ad9bd9c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6025f45ce1af4c8caab09042992f2094": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "630597c0e70d4792b58c8942296692a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff7c6d1bfc654c2db63e40bad4e3eb33",
       "IPY_MODEL_f964d3d5333948e0b14117555b82275b"
      ],
      "layout": "IPY_MODEL_64e51ced10004147b21e51db1343cac8"
     }
    },
    "64e51ced10004147b21e51db1343cac8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67bde4b1393e48a1a5c1b00969317131": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71b51022c34247929dcb8f11c74a2de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e70f23ca6f94a2099c2cca1eaf875d8",
       "IPY_MODEL_11b4409af40748e0b760e91c3d91ede7"
      ],
      "layout": "IPY_MODEL_8119426c8705459fb9df8b2c711d3c36"
     }
    },
    "77583bbefaf849eea83d3ae327e4070e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a31bf9dedde47188efdfaf6a262b730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a718fb0db5640fd8eb04ef18fe1e339": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8119426c8705459fb9df8b2c711d3c36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8348929b740242d3bdc73ea2c8bcd9c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c546c1a23c402f8a6de964828dc035": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89f8555b95ec48b7b3282cb365b1cfdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb6e0c49bd040b7bd5f266c4608dd31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d88b67069074ee6bc937b46cc10418a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "932d3ee3c9d74761bfc4bcf5c003d205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9380ff7e78f846babb16740cfc9cf7f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f45f9a16f75e4d07abe5dcaf2fb300f4",
       "IPY_MODEL_21bd77c2c70040548a696c5a40d81a00"
      ],
      "layout": "IPY_MODEL_7a31bf9dedde47188efdfaf6a262b730"
     }
    },
    "949971635f1f498e86e04b9d4e28d353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9a8c7ea6d7ec4ec691525f6e3ca88d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9c8548e2e4c54bf88e678c571c537867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a3da9679c78640c3be6e7cbbd5bcccae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f3bac44e13246ab9f9c8564a44e1fa3",
      "placeholder": "​",
      "style": "IPY_MODEL_7a718fb0db5640fd8eb04ef18fe1e339",
      "value": " 1/1 [00:13&lt;00:00, 13.12s/ba]"
     }
    },
    "ac8b24c5d6214716a409ca95580306f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb9523d3e594c3d84036ad2348a7a64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e71f76432d5e469d8cf742bbed6e0f1c",
       "IPY_MODEL_a3da9679c78640c3be6e7cbbd5bcccae"
      ],
      "layout": "IPY_MODEL_8d88b67069074ee6bc937b46cc10418a"
     }
    },
    "aebd284cd0ba4dfbafce1f0b99cd5213": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28b184f13a948d5995ee04720748871": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2b6f74edcdb465e94d9f07287fa506d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bc7b5cd3163b4b60877d80be43598436": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfc579b1c3354bcd9a0be2fde370954c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efbd298ec8f0461ba89793855901330b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67bde4b1393e48a1a5c1b00969317131",
      "value": 1
     }
    },
    "c154bfdf049147638c67d2844d25f9e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f708ccdb4f941918696d583ad9bd9c9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bc11633e20c460eb9058cc4b480b224",
      "value": 1
     }
    },
    "c21fa18f6c4b4bdd9621ef29180646db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_249abcb1904c4d1ca4116b677011b017",
       "IPY_MODEL_4a23a9bdd091425cbda38222f2e4c3a9"
      ],
      "layout": "IPY_MODEL_fa8da5adaacd4534b60e51ba4dce6c4a"
     }
    },
    "c2423ca88827446aa5b5c78ccc36a263": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b64289fc4445f59a94d6c51a288834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ccbb12bb5a548488c9b646159f893d3",
      "max": 1750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6025f45ce1af4c8caab09042992f2094",
      "value": 1750
     }
    },
    "c515e4e9f5b7470e8a17e4a4247878f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4b64289fc4445f59a94d6c51a288834",
       "IPY_MODEL_568fedab4a4e44d9baa8213d54d60d38"
      ],
      "layout": "IPY_MODEL_89f8555b95ec48b7b3282cb365b1cfdd"
     }
    },
    "c6ae198ebaf2467bba3f0a49f3aab196": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82fa83594a349c991626ee55b8edfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d85845466e5a4ffd8370ef4c8b965684": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6ae198ebaf2467bba3f0a49f3aab196",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2b6f74edcdb465e94d9f07287fa506d",
      "value": 1
     }
    },
    "df292d721c1748c485f281aa2162b9a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e3e3c18ef96e48999e14be0c60ad9f04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6bdcb09b73d4aa3844076829cf43f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e71f76432d5e469d8cf742bbed6e0f1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cb6e0c49bd040b7bd5f266c4608dd31",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10e45676711b477e9a1ce2cf4ac8f3a9",
      "value": 1
     }
    },
    "ea780b89e28a4348abfac40ef8fd140a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_315cd377eae94488b258460f06e5cc10",
       "IPY_MODEL_5b2e4c980b6a4e15bef86d1907b20f40"
      ],
      "layout": "IPY_MODEL_4eac0e183d8047e498d3a576f3c3a1f4"
     }
    },
    "ecac341937124f21b04479a50a05c688": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed22b18a21c943f291c6326030cb2753": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecac341937124f21b04479a50a05c688",
      "placeholder": "​",
      "style": "IPY_MODEL_e6bdcb09b73d4aa3844076829cf43f8a",
      "value": " 1/1 [04:39&lt;00:00, 279.14s/ba]"
     }
    },
    "efbd298ec8f0461ba89793855901330b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f45f9a16f75e4d07abe5dcaf2fb300f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5321f4576a6c4fe69de0c97b43269d3b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c8548e2e4c54bf88e678c571c537867",
      "value": 1
     }
    },
    "f512c5cdfaa64005bb987f032957e530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f964d3d5333948e0b14117555b82275b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_525a5c1a8ba04c8e89fc514064539d73",
      "placeholder": "​",
      "style": "IPY_MODEL_5df3d17d64e24faeab6cc644d333536a",
      "value": " 4.89k/? [00:01&lt;00:00, 3.05kB/s]"
     }
    },
    "fa8da5adaacd4534b60e51ba4dce6c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fec9b3f47668416f8709fd7ab80a9730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7c6d1bfc654c2db63e40bad4e3eb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aebd284cd0ba4dfbafce1f0b99cd5213",
      "max": 1935,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_949971635f1f498e86e04b9d4e28d353",
      "value": 1935
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
