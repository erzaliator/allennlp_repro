{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "SEED = 1111\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'GroNLP/bert-base-dutch-cased' #'bert-base-uncased'\n",
    "MAX_SEQ_LENGTH = 100 # we dont need to enforce this now because snli is a relatively sanitized dataset where sentence lenghts are reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1608"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label'])\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label']:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "# we only need specific columns\n",
    "train_df = read_df_custom('./processed/nld.rst.nldt_train_enriched.rels')\n",
    "test_df = read_df_custom('./processed/nld.rst.nldt_test_enriched.rels')\n",
    "val_df = read_df_custom('./processed/nld.rst.nldt_dev_enriched.rels')\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# train_df = train_df[:500]\n",
    "# val_df = val_df[:50]\n",
    "# test_df = test_df[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.num_labels = -1\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.train_data = self.load_data(self.train_df)\n",
    "    self.val_data = self.load_data(self.val_df)\n",
    "    self.test_data = self.load_data(self.test_df)\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels# {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "  \n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "    \n",
    "\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 256 # dont need to enforce this now because snli is a sanitized dataset where sentence lenghts are reasonable. otherwise the beert model doesn't have enough parameters to handle long length sentences\n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['unit1_txt'].to_list()\n",
    "    hypothesis_list = df['unit2_txt'].to_list()\n",
    "    label_list = df['label'].to_list()\n",
    "    dir_list = df['dir'].to_list()\n",
    "    \n",
    "    self.num_labels = max(self.num_labels, len(df['label'].unique()))\n",
    "\n",
    "    for (premise, hypothesis, label, dir) in zip(premise_list, hypothesis_list, label_list, dir_list):\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False, max_length=MAX_LEN, truncation=True)\n",
    "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False, max_length=MAX_LEN, truncation=True)\n",
    "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      premise_len = len(premise_id)\n",
    "      hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=16, shuffle=True):\n",
    "    train_loader = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e39e856e384b96ae904acc85c19d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/236k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ef246e2fc74e29a25bdb17ea85ab5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66dc3ac664b438ba77642f09beb436e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/254 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abfbf627a8b414295e3ad22f4c86164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=64)\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'restatement-mn': 0, 'background': 1, 'purpose': 2, 'sequence': 3, 'nonvolitional-cause': 4, 'enablement': 5, 'joint': 6, 'concession': 7, 'volitional-cause': 8, 'motivation': 9, 'unconditional': 10, 'elaboration': 11, 'unless': 12, 'evidence': 13, 'restatement': 14, 'antithesis': 15, 'preparation': 16, 'conjunction': 17, 'justify': 18, 'contrast': 19, 'span': 20, 'volitional-result': 21, 'list': 22, 'evaluation': 23, 'solutionhood': 24, 'condition': 25, 'nonvolitional-result': 26, 'otherwise': 27, 'interpretation': 28, 'circumstance': 29, 'disjunction': 30, 'summary': 31, 'means': 32}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999aaf585e374a32bc8fefc320092d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/417M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=len(label_dict)).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.6, mode='max', patience=2, min_lr=5e-7, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      \n",
    "      # loss, prediction = model(pair_token_ids, \n",
    "      #                       token_type_ids=seg_ids, \n",
    "      #                       attention_mask=mask_ids, \n",
    "      #                       labels=labels).values()\n",
    "      # acc = multi_acc(prediction, labels)\n",
    "\n",
    "      ############new code#####################\n",
    "\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids)\n",
    "      # probs = F.softmax(outputs, dim=1)\n",
    "      # max_idx = torch.max(outputs, 1).indices\n",
    "      # one_hot = F.one_hot(max_idx, outputs.shape[1])\n",
    "\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      ########################################\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = torch.tensor([[1.0890e-04, 5.2673e-05, 1.2360e-04, 1.0418e-04, 1.2566e-04, 9.8514e-01,\n",
    "#          5.3395e-05, 1.2905e-04, 4.4259e-05, 6.8244e-05, 7.6694e-05, 1.9960e-05,\n",
    "#          1.2552e-03, 4.4366e-04, 5.7364e-05, 3.5897e-05, 1.8665e-04, 1.4762e-04,\n",
    "#          2.0718e-04, 3.6333e-04, 1.4289e-04, 7.9607e-04, 1.4576e-04, 9.2251e-05,\n",
    "#          8.8410e-05, 6.9524e-05, 6.2618e-03, 1.7346e-04, 3.2187e-03, 2.6895e-04], \n",
    "#          [1.1661e-03, 5.0136e-04, 6.6534e-03, 2.9997e-04, 1.7821e-02, 4.7819e-04,\n",
    "#          3.6546e-04, 9.7448e-04, 1.7562e-03, 6.0838e-03, 3.8355e-04, 1.9341e-03,\n",
    "#          4.0050e-04, 2.3111e-04, 9.4716e-04, 4.5940e-04, 9.0194e-01, 5.8271e-03,\n",
    "#          3.8972e-04, 2.8722e-03, 5.6120e-04, 5.8885e-03, 2.2553e-04, 3.2046e-04,\n",
    "#          2.2358e-02, 5.4926e-03, 5.0868e-03, 6.9310e-04, 3.8507e-03, 4.0405e-03]])\n",
    "# max_idx = torch.max(probs, 1).indices\n",
    "# F.one_hot(max_idx, probs.shape[1])\n",
    "# one_hot = torch.FloatTensor(probs.shape)\n",
    "# one_hot.zero_()\n",
    "# one_hot.scatter_(0, max_idx, 1)\n",
    "# one_hot\n",
    "# assert sum(one_hot)==1\n",
    "# max_idx\n",
    "\n",
    "# [1.8954e-03, 2.5696e-04, 8.2484e-04, 2.2843e-04, 1.0369e-03, 4.5720e-01,\n",
    "#          1.2688e-03, 1.1442e-03, 1.2277e-03, 1.5966e-03, 1.7590e-02, 2.4132e-04,\n",
    "#          3.7562e-01, 7.7780e-04, 9.8553e-05, 5.1157e-04, 6.1281e-05, 2.0767e-03,\n",
    "#          8.3567e-04, 2.0880e-03, 1.1388e-01, 4.5953e-03, 5.4112e-03, 2.9414e-04,\n",
    "#          3.7741e-04, 6.8984e-04, 2.0752e-04, 5.5542e-03, 3.4503e-04, 2.0683e-03]\n",
    "        # [1.0890e-04, 5.2673e-05, 1.2360e-04, 1.0418e-04, 1.2566e-04, 9.8514e-01,\n",
    "        #  5.3395e-05, 1.2905e-04, 4.4259e-05, 6.8244e-05, 7.6694e-05, 1.9960e-05,\n",
    "        #  1.2552e-03, 4.4366e-04, 5.7364e-05, 3.5897e-05, 1.8665e-04, 1.4762e-04,\n",
    "        #  2.0718e-04, 3.6333e-04, 1.4289e-04, 7.9607e-04, 1.4576e-04, 9.2251e-05,\n",
    "        #  8.8410e-05, 6.9524e-05, 6.2618e-03, 1.7346e-04, 3.2187e-03, 2.6895e-04]\n",
    "        # [1.1661e-03, 5.0136e-04, 6.6534e-03, 2.9997e-04, 1.7821e-02, 4.7819e-04,\n",
    "        #  3.6546e-04, 9.7448e-04, 1.7562e-03, 6.0838e-03, 3.8355e-04, 1.9341e-03,\n",
    "        #  4.0050e-04, 2.3111e-04, 9.4716e-04, 4.5940e-04, 9.0194e-01, 5.8271e-03,\n",
    "        #  3.8972e-04, 2.8722e-03, 5.6120e-04, 5.8885e-03, 2.2553e-04, 3.2046e-04,\n",
    "        #  2.2358e-02, 5.4926e-03, 5.0868e-03, 6.9310e-04, 3.8507e-03, 4.0405e-03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define bert custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "class CustomBERTModel(nn.Module):\n",
    "    #https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
    "    def __init__(self, num_labels):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels+1 # zero indexed classes\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "          self.bert = BertModel.from_pretrained(BERT_MODEL)\n",
    "          ### New layers:\n",
    "          self.linear1 = nn.Linear(768, 512)\n",
    "          self.linear2 = nn.Linear(512, 256)\n",
    "          self.linear3 = nn.Linear(256, 128)\n",
    "          self.linear4 = nn.Linear(128, self.num_classes)\n",
    "          self.act1 = nn.ReLU() # can i use the same activation object everywhere?\n",
    "          self.act2 = nn.ReLU()\n",
    "          self.act3 = nn.ReLU()\n",
    "          self.drop = nn.Dropout(0.1) \n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask):\n",
    "        sequence_output, pooled_output = self.bert(input_ids=pair_token_ids, \n",
    "                        token_type_ids=token_type_ids, \n",
    "                        attention_mask=attention_mask).values()\n",
    "\n",
    "        # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
    "        linear1_output = self.linear1(sequence_output[:,0,:].view(-1,768)) ## extract the 1st token's embeddings\n",
    "        linear1_output = self.act1(linear1_output)\n",
    "        linear2_output = self.linear2(linear1_output)\n",
    "        linear2_output = self.act2(linear2_output)\n",
    "        linear3_output = self.linear3(linear2_output)\n",
    "        linear3_output = self.act3(linear3_output)\n",
    "        linear4_output = self.linear4(linear3_output)\n",
    "        drop_output = self.drop(linear4_output)\n",
    "        return drop_output# loss, outputs\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "model = CustomBERTModel(mnli_dataset.num_labels) # You can pass the parameters if required to have more flexible model\n",
    "model.to(device) ## can be gpu\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class EarlyStoppingCallbackCustom:\n",
    "  def __init__(self, validation_metric='accuracy', patience=12):\n",
    "    self.validation_metric = validation_metric\n",
    "    self.patience = patience\n",
    "    self.trigger_times = 0\n",
    "    self.prev_loss = 1000 if self.validation_metric=='loss' else -1000\n",
    "    \n",
    "  def compare_and_trigger(self, current, previous):\n",
    "    if self.validation_metric=='loss': return current > previous\n",
    "    else: return current <= previous\n",
    "\n",
    "  def callback_to_stop(self, val_loss):\n",
    "    if self.compare_and_trigger(val_loss, self.prev_loss):\n",
    "      self.trigger_times += 1\n",
    "      print('trigger times:', self.trigger_times)\n",
    "      if self.trigger_times >= self.patience:\n",
    "          print('Early stopping!\\nStart to test process.')\n",
    "          return True\n",
    "    else:\n",
    "      if self.trigger_times!=0: print('Resetting trigertime:', self.trigger_times)\n",
    "      print('trigger times: 0')\n",
    "      self.trigger_times = 0\n",
    "    self.prev_loss = val_loss\n",
    "    return False\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  # EarlyStopper = EarlyStoppingCallbackCustom(validation_metric='accuracy')\n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "\n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "\n",
    "      ############new code#####################\n",
    "\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids)\n",
    "      # outputs = F.log_softmax(outputs, dim=1) # log prob\n",
    "      # outputs = np.argmax(prob, axis=1) # preds\n",
    "      # https://stackoverflow.com/questions/43672047/convert-probability-vector-into-target-vector-in-python\n",
    "      # https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      ################old code#################\n",
    "\n",
    "      # loss, prediction = model(pair_token_ids, \n",
    "      #                       token_type_ids=seg_ids, \n",
    "      #                       attention_mask=mask_ids, \n",
    "      #                       labels=labels).values()\n",
    "\n",
    "      # acc = multi_acc(prediction, labels)\n",
    "      # loss.backward()\n",
    "      # optimizer.step()\n",
    "\n",
    "      ########################################\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      # log losses for scheduler\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      mean_loss = sum(losses)/len(losses)\n",
    "      scheduler.step(mean_loss)\n",
    "\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict)\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "    # if EarlyStopper.callback_to_stop(val_acc): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### WORKING CODE 2\n",
    "# import time\n",
    "# import traceback\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# def EarlyStoppingCallbackCustomBasedOnLoss(val_loss, prev_loss, trigger_times, patience, model):\n",
    "#   # https://clay-atlas.com/us/blog/2021/08/25/pytorch-en-early-stopping/\n",
    "#   if val_loss > prev_loss:\n",
    "#     trigger_times += 1\n",
    "#     print('trigger times:', trigger_times)\n",
    "#     if trigger_times >= patience:\n",
    "#         print('Early stopping!\\nStart to test process.')\n",
    "#         return model\n",
    "#   else:\n",
    "#     print('trigger times: 0')\n",
    "#     trigger_times = 0\n",
    "#   prev_loss = val_loss\n",
    "#   return prev_loss\n",
    "\n",
    "# EPOCHS = 100\n",
    "\n",
    "# def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "#   for epoch in range(EPOCHS):\n",
    "#     start = time.time()\n",
    "#     model.train()\n",
    "#     total_train_loss = 0\n",
    "#     total_train_acc  = 0\n",
    "\n",
    "#     # logging for scheduler\n",
    "#     losses = []\n",
    "#     accuracies= []\n",
    "\n",
    "#     # Early stopping\n",
    "#     prev_loss = 100\n",
    "#     patience = 12\n",
    "#     trigger_times = 0\n",
    "\n",
    "#     for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "#       optimizer.zero_grad()\n",
    "#       pair_token_ids = pair_token_ids.to(device)\n",
    "#       mask_ids = mask_ids.to(device)\n",
    "#       seg_ids = seg_ids.to(device)\n",
    "#       labels = y.to(device)\n",
    "\n",
    "#       try:\n",
    "#         loss, prediction = model(pair_token_ids, \n",
    "#                               token_type_ids=seg_ids, \n",
    "#                               attention_mask=mask_ids, \n",
    "#                               labels=labels).values()\n",
    "\n",
    "#         acc = multi_acc(prediction, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_train_loss += loss.item()\n",
    "#         total_train_acc  += acc.item()\n",
    "\n",
    "#         # log losses for scheduler\n",
    "#         losses.append(loss)\n",
    "#         accuracies.append(acc)\n",
    "#         mean_loss = sum(losses)/len(losses)\n",
    "#         scheduler.step(mean_loss)\n",
    "\n",
    "       \n",
    "        \n",
    "#       except Exception as e:\n",
    "#         print(traceback.format_exc())\n",
    "#         print('helpp')\n",
    "#         break\n",
    "\n",
    "#     train_acc  = total_train_acc/len(train_loader)\n",
    "#     train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "#     val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict)\n",
    "#     prev_loss = EarlyStoppingCallbackCustomBasedOnLoss(val_loss, prev_loss, trigger_times, patience, model)\n",
    "\n",
    "#     end = time.time()\n",
    "#     hours, rem = divmod(end-start, 3600)\n",
    "#     minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "#     print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "#     print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### WORKING CODE\n",
    "# import time\n",
    "# import traceback\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# EPOCHS = 1\n",
    "\n",
    "# def train(model, train_loader, val_loader, optimizer, rev_label_dict):  \n",
    "#   for epoch in range(EPOCHS):\n",
    "#     start = time.time()\n",
    "#     model.train()\n",
    "#     total_train_loss = 0\n",
    "#     total_train_acc  = 0\n",
    "#     for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "#       optimizer.zero_grad()\n",
    "#       pair_token_ids = pair_token_ids.to(device)\n",
    "#       mask_ids = mask_ids.to(device)\n",
    "#       seg_ids = seg_ids.to(device)\n",
    "#       labels = y.to(device)\n",
    "\n",
    "#       try:\n",
    "#         loss, prediction = model(pair_token_ids, \n",
    "#                               token_type_ids=seg_ids, \n",
    "#                               attention_mask=mask_ids, \n",
    "#                               labels=labels).values()\n",
    "\n",
    "#         acc = multi_acc(prediction, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_train_loss += loss.item()\n",
    "#         total_train_acc  += acc.item()\n",
    "#         # print(seg_ids.shape, pair_token_ids.shape, mask_ids.shape)\n",
    "#       except Exception as e:\n",
    "#         print(labels)\n",
    "#         print(seg_ids.shape, pair_token_ids.shape, mask_ids.shape)\n",
    "#         print(pair_token_ids)\n",
    "#         print(traceback.format_exc())\n",
    "#         print('helpp')\n",
    "#         break\n",
    "\n",
    "#     train_acc  = total_train_acc/len(train_loader)\n",
    "#     train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "#     val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict)\n",
    "#     end = time.time()\n",
    "#     hours, rem = divmod(end-start, 3600)\n",
    "#     minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "#     print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "#     print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: reducing learning rate of group 0 to 1.2000e-05.\n",
      "Epoch 00007: reducing learning rate of group 0 to 7.2000e-06.\n",
      "Epoch 00010: reducing learning rate of group 0 to 4.3200e-06.\n",
      "Epoch 00013: reducing learning rate of group 0 to 2.5920e-06.\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.5552e-06.\n",
      "Epoch 00019: reducing learning rate of group 0 to 9.3312e-07.\n",
      "Epoch 00022: reducing learning rate of group 0 to 5.5987e-07.\n",
      "Epoch 00025: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch 1: train_loss: 3.2038 train_acc: 0.2308 | val_loss: 2.8509 val_acc: 0.2898\n",
      "00:00:08.25\n",
      "Epoch 2: train_loss: 2.8869 train_acc: 0.2476 | val_loss: 2.6128 val_acc: 0.3575\n",
      "00:00:08.25\n",
      "Epoch 3: train_loss: 2.6171 train_acc: 0.3215 | val_loss: 2.3724 val_acc: 0.4039\n",
      "00:00:08.26\n",
      "Epoch 4: train_loss: 2.2378 train_acc: 0.4038 | val_loss: 2.2289 val_acc: 0.4283\n",
      "00:00:08.25\n",
      "Epoch 5: train_loss: 1.9646 train_acc: 0.4712 | val_loss: 2.1999 val_acc: 0.4638\n",
      "00:00:08.30\n",
      "Epoch 6: train_loss: 1.7497 train_acc: 0.5288 | val_loss: 1.9784 val_acc: 0.5331\n",
      "00:00:08.31\n",
      "Epoch 7: train_loss: 1.4943 train_acc: 0.6196 | val_loss: 1.9408 val_acc: 0.5028\n",
      "00:00:08.26\n",
      "Epoch 8: train_loss: 1.3161 train_acc: 0.6677 | val_loss: 2.2437 val_acc: 0.4768\n",
      "00:00:08.28\n",
      "Epoch 9: train_loss: 1.1337 train_acc: 0.7157 | val_loss: 2.1363 val_acc: 0.5107\n",
      "00:00:08.32\n",
      "Epoch 10: train_loss: 0.9914 train_acc: 0.7572 | val_loss: 2.2093 val_acc: 0.4621\n",
      "00:00:08.27\n",
      "Epoch 11: train_loss: 0.8336 train_acc: 0.8011 | val_loss: 2.3250 val_acc: 0.4768\n",
      "00:00:08.27\n",
      "Epoch 12: train_loss: 0.7176 train_acc: 0.8323 | val_loss: 2.1515 val_acc: 0.4924\n",
      "00:00:08.25\n",
      "Epoch 13: train_loss: 0.6386 train_acc: 0.8444 | val_loss: 2.2811 val_acc: 0.4841\n",
      "00:00:08.30\n",
      "Epoch 14: train_loss: 0.5662 train_acc: 0.8660 | val_loss: 2.1243 val_acc: 0.5019\n",
      "00:00:08.30\n",
      "Epoch 15: train_loss: 0.4965 train_acc: 0.8750 | val_loss: 2.3712 val_acc: 0.4877\n",
      "00:00:08.35\n",
      "Epoch 16: train_loss: 0.4304 train_acc: 0.8894 | val_loss: 2.1643 val_acc: 0.5123\n",
      "00:00:08.35\n",
      "Epoch 17: train_loss: 0.3957 train_acc: 0.8906 | val_loss: 2.3719 val_acc: 0.4946\n",
      "00:00:08.32\n",
      "Allen NLP Early Stopping\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'bert-disrpt_nld.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.8523 test_acc: 0.4306\n",
      "00:00:00.48\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          antithesis       0.00      0.00      0.00         2\n",
      "          background       0.00      0.00      0.00         3\n",
      "        circumstance       0.24      0.44      0.31        16\n",
      "          concession       0.58      0.58      0.58        12\n",
      "           condition       0.62      0.62      0.62         8\n",
      "         conjunction       0.50      0.42      0.46        19\n",
      "            contrast       0.33      0.14      0.20         7\n",
      "         disjunction       0.67      0.50      0.57         4\n",
      "         elaboration       0.60      0.68      0.64        95\n",
      "          enablement       0.25      0.25      0.25         4\n",
      "          evaluation       0.00      0.00      0.00         2\n",
      "            evidence       0.20      0.17      0.18         6\n",
      "      interpretation       0.11      0.20      0.14        10\n",
      "               joint       0.00      0.00      0.00         3\n",
      "             justify       0.33      0.50      0.40        10\n",
      "                list       0.43      0.25      0.32        12\n",
      "               means       0.25      0.25      0.25         4\n",
      "          motivation       0.56      0.52      0.54        29\n",
      " nonvolitional-cause       0.54      0.54      0.54        13\n",
      "nonvolitional-result       0.33      0.36      0.34        14\n",
      "           otherwise       0.00      0.00      0.00         1\n",
      "         preparation       0.43      0.16      0.23        19\n",
      "             purpose       0.75      0.50      0.60         6\n",
      "         restatement       0.00      0.00      0.00         2\n",
      "            sequence       0.67      0.20      0.31        10\n",
      "        solutionhood       0.25      0.38      0.30         8\n",
      "                span       0.00      0.00      0.00         1\n",
      "             summary       0.00      0.00      0.00         4\n",
      "    volitional-cause       0.00      0.00      0.00         2\n",
      "\n",
      "            accuracy                           0.45       326\n",
      "           macro avg       0.30      0.26      0.27       326\n",
      "        weighted avg       0.46      0.45      0.44       326\n",
      "\n",
      "Test Loss: 2.852 |  Test Acc: 43.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def validate(model, test_loader, optimizer, rev_label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load('bert-nli.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Another wrapper to return basic predictions/log them in it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
