{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/discodapter/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2017\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "batch_size = 4\n",
    "batches_per_epoch = 541\n",
    "\n",
    "save_path_suffix = 'baseline_de_batchfix_patience=10_multilingual_roberta_modelfix_hyperparam3_testing_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label',\n",
       "       'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position',\n",
       "       'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case',\n",
       "       'unit2_case', 'u1_discontinuous', 'u2_discontinuous', 'same_speaker',\n",
       "       'lex_overlap_length', 'u1_func'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 16:40:34.388046: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-18 16:40:34.510254: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-18 16:40:34.510272: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-18 16:40:35.166928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-18 16:40:35.166999: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-18 16:40:35.167006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, ConcatDataset\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate, Vocabulary\n",
    "from features_custom2 import get_vocab_feature_name\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer, BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.vocab = Vocabulary(counter=None, max_vocab_size=100000)\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.init_feature_list()\n",
    "    self.init_feature_mappings_and_bins()\n",
    "    self.apply_bins()\n",
    "    self.calculate_unique_values()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    \n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def init_feature_mappings_and_bins(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "    self.bins = {\n",
    "      'distance': [[-1e9, -8], [-8, -2], [-2, 0], [0, 2], [2, 8], [8, 1e9]],\n",
    "      'u1_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'u2_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'lex_overlap_length': [[0, 2], [2, 7], [7, 1e9]]\n",
    "    }   \n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def init_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "    else: \n",
    "      raise ValueError()\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features_list(self, features, feature_name):\n",
    "    if feature_name in ['distance', 'u1_depdir', 'u2_depdir', 'u1_func', 'u2_func', \n",
    "    'u1_position', 'u2_position', 'genre', 'same_speaker', 'unit1_case', 'unit2_case',\n",
    "    'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'dir']: feature_value = self.apply_vocab(features[feature_name], feature_name) #for categorical values\n",
    "    elif feature_name in ['sat_children', 'nuc_children']: feature_value = float(features[feature_name]) #for identiy values\n",
    "    else: \n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    return feature_value\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==17\n",
    "    #after applying the vocab. we need to pass them as int\n",
    "    return {feature_name: torch.tensor(int(self.get_allen_features_list(features, feature_name))).to(device) for feature_name in self.feature_list+['dir']}\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature_name in self.feature_list+['dir']:\n",
    "      vocab_feature_name = get_vocab_feature_name(feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(train_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(val_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "\n",
    "  def apply_bins(self):\n",
    "    for df in [self.train_df, self.test_df, self.val_df]:\n",
    "      for feature_name in self.bins.keys():\n",
    "        df[feature_name] = df[feature_name].apply(lambda x: self.get_mapping_from_bin(feature_name, float(x)))\n",
    "\n",
    "  def get_mapping_from_bin(self, column_name, dict_val):\n",
    "    bins = self.bins[column_name]\n",
    "    for b,i in zip(bins, range(len(bins))):\n",
    "      left = b[0]\n",
    "      right = b[1]\n",
    "      if left<=dict_val and right>=dict_val: return i\n",
    "\n",
    "  def apply_vocab(self, feature_value, feature_name):\n",
    "    return self.vocab.get_token_index(str(feature_value), namespace=get_vocab_feature_name(feature_name))\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    # seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      features = {'distance': row['distance'],\n",
    "                'u1_depdir': row['u1_depdir'],\n",
    "                'u2_depdir': row['u2_depdir'],\n",
    "                'u1_func': row['u1_func'],\n",
    "                'u2_func': row['u2_func'],\n",
    "                'u1_position': row['u1_position'],\n",
    "                'u2_position': row['u2_position'],\n",
    "                'sat_children': row['sat_children'],\n",
    "                'nuc_children': row['nuc_children'],\n",
    "                'genre': row['genre'],\n",
    "                'unit1_case': row['unit1_case'],\n",
    "                'unit2_case': row['unit2_case'],\n",
    "                'u1_discontinuous': row['u1_discontinuous'],\n",
    "                'u2_discontinuous': row['u2_discontinuous'],\n",
    "                'same_speaker': row['same_speaker'],\n",
    "                'lex_overlap_length': row['lex_overlap_length'],\n",
    "                'dir': row['dir']}\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding=False) #padding='max_length'\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      # segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      features = self.transform_feature(features)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      # seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(features)\n",
    "      \n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "      \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    # seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "\n",
    "    class featureDataset(Dataset):\n",
    "      def __init__(self, token_ids, mask_ids, feats, y, idx):\n",
    "          self.token_ids = token_ids\n",
    "          self.mask_ids = mask_ids\n",
    "          # self.seg_ids = seg_ids\n",
    "          self.feats = feats\n",
    "          self.y = y\n",
    "          self.idx = idx\n",
    "\n",
    "      def __len__(self):\n",
    "          return len(self.feats)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "          return self.token_ids[idx], self.mask_ids[idx], self.feats[idx], self.y[idx], self.idx[idx]\n",
    "          # return self.token_ids[idx], self.mask_ids[idx], self.seg_ids[idx], self.feats[idx], self.y[idx], self.idx[idx]\n",
    "\n",
    "    # dataset = featureDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    dataset = featureDataset(token_ids, mask_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '3': 2, '4': 3, '5': 4}\n",
      "u1_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_func :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'root': 2, 'conj': 3, 'advcl': 4, 'acl': 5, 'xcomp': 6, 'obl': 7, 'ccomp': 8, 'parataxis': 9, 'advmod': 10, 'dep': 11, 'csubj': 12, 'nmod': 13, 'punct': 14, 'cc': 15, 'appos': 16, 'aux': 17, 'obj': 18, 'iobj': 19, 'nsubj': 20, 'nsubj:pass': 21, 'csubj:pass': 22}\n",
      "u1_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '1': 11}\n",
      "u2_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '1': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
      "sat_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '4': 3, '1': 4, '2': 5, '3': 6, '5': 7, '6': 8}\n",
      "nuc_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '4': 2, '3': 3, '1': 4, '2': 5, '5': 6, '6': 7, '7': 8, '8': 9}\n",
      "dir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '1>2': 2, '1<2': 3}\n"
     ]
    }
   ],
   "source": [
    "for feature in mnli_dataset.feature_list:\n",
    "    vocab_feature_name = get_vocab_feature_name(feature)\n",
    "    print(feature, ': ', mnli_dataset.vocab.get_token_to_index_vocabulary(vocab_feature_name))\n",
    "print('dir', ': ', mnli_dataset.vocab.get_token_to_index_vocabulary('dir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (pair_token_ids, mask_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    # assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    # assert mask_ids.shape[-1]==512\n",
    "    # assert seg_ids.shape[-1]==512\n",
    "    assert len(feat)==len(mnli_dataset.feature_list)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '@@PADDING@@', 1: '@@UNKNOWN@@'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_dataset.vocab.get_index_to_token_vocabulary('u1_depdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      # seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            # token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 26\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parameter config in `FeaturefulBert(config)` should be an instance of class `PretrainedConfig`. To create a model from a pretrained model use `model = FeaturefulBert.from_pretrained(PRETRAINED_MODEL_NAME)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 136\u001b[0m\n\u001b[1;32m    132\u001b[0m         feature_linear \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(feature_linear, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    133\u001b[0m         \u001b[39mreturn\u001b[39;00m feature_linear\n\u001b[0;32m--> 136\u001b[0m model \u001b[39m=\u001b[39m CustomBERTModel(mnli_dataset\u001b[39m.\u001b[39;49mnum_labels)\n\u001b[1;32m    137\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    138\u001b[0m optimizer \u001b[39m=\u001b[39m AdamW(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m2e-6\u001b[39m, correct_bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m# original 2e-5\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 89\u001b[0m, in \u001b[0;36mCustomBERTModel.__init__\u001b[0;34m(self, num_labels)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_list \u001b[39m=\u001b[39m mnli_dataset\u001b[39m.\u001b[39mfeature_list\n\u001b[1;32m     87\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mASSIGN:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m---> 89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_featureful_bert()\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m CustomPooler2()\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule1 \u001b[39m=\u001b[39m MyModule(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_list)\n",
      "Cell \u001b[0;32mIn[16], line 124\u001b[0m, in \u001b[0;36mCustomBERTModel.create_featureful_bert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_featureful_bert\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m     featureful_bert \u001b[39m=\u001b[39m FeaturefulBertEmbedder(model_name \u001b[39m=\u001b[39;49m BERT_MODEL,\n\u001b[1;32m    125\u001b[0m                             hidden_activation_allen \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mgelu\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    126\u001b[0m                             feature_list \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_list, \n\u001b[1;32m    127\u001b[0m                             vocab\u001b[39m=\u001b[39;49mmnli_dataset\u001b[39m.\u001b[39;49mvocab)\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m featureful_bert\n",
      "File \u001b[0;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/featurefulbertembedder_custom2.py:98\u001b[0m, in \u001b[0;36mFeaturefulBertEmbedder.__init__\u001b[0;34m(self, model_name, hidden_activation_allen, feature_list, vocab, max_length, sub_module, train_parameters, eval_mode, last_layer_only, gradient_checkpointing, tokenizer_kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AdapterConfig\n\u001b[1;32m     97\u001b[0m lang_adapter_config \u001b[39m=\u001b[39m AdapterConfig\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mpfeiffer\u001b[39m\u001b[39m\"\u001b[39m, reduction_factor\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_model \u001b[39m=\u001b[39m FeaturefulBert(config\u001b[39m=\u001b[39;49mlang_adapter_config)\n\u001b[1;32m     99\u001b[0m \u001b[39m# self.transformer_model = FeaturefulBert.from_pretrained(pretrained_model_name_or_path=model_name, hidden_act=hidden_activation_allen)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m# Unfreeze and activate stack setup\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39madapters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m Stack\n",
      "File \u001b[0;32m/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/featureful_bert_custom2.py:65\u001b[0m, in \u001b[0;36mFeaturefulBert.__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config: BertConfig, add_pooling_layer\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 65\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config)\n\u001b[1;32m     66\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m config\n\u001b[1;32m     68\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoConfig\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/discodapter/lib/python3.10/site-packages/transformers/modeling_utils.py:920\u001b[0m, in \u001b[0;36mPreTrainedModel.__init__\u001b[0;34m(self, config, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m    919\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 920\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    921\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter config in `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m(config)` should be an instance of class \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`PretrainedConfig`. To create a model from a pretrained model use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    923\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`model = \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.from_pretrained(PRETRAINED_MODEL_NAME)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    924\u001b[0m     )\n\u001b[1;32m    925\u001b[0m \u001b[39m# Save config and origin of the pretrained weights if given in model\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m config\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter config in `FeaturefulBert(config)` should be an instance of class `PretrainedConfig`. To create a model from a pretrained model use `model = FeaturefulBert.from_pretrained(PRETRAINED_MODEL_NAME)`"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, Optional\n",
    "from transformers import BertModel, BertConfig\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from featurefulbertembedder_custom2 import FeaturefulBertEmbedder\n",
    "from featureful_bert_custom2 import get_combined_feature_tensor_2 as get_combined_feature_tensor_forward\n",
    "\n",
    "class CustomPooler2(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                        requires_grad: bool = True,\n",
    "                        dropout: float = 0.0,\n",
    "                        transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "        super().__init__()\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL) #only used to pass config. BertAttentionClass used in FeatureFulBert\n",
    "        self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.pooler = copy.deepcopy(bert.pooler)\n",
    "        for param in self.pooler.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        self._embedding_dim = bert.config.hidden_size\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "        pooler = self.pooler\n",
    "        \n",
    "        for _ in range(num_wrapping_dims):\n",
    "            pooler = TimeDistributed(pooler)\n",
    "        pooled = pooler(tokens)\n",
    "        pooled = self._dropout(pooled)\n",
    "        return pooled\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_modules = nn.ModuleDict()\n",
    "        self.dims = 0\n",
    "        for feature in feature_list:\n",
    "            print(feature)\n",
    "            if feature=='distance':\n",
    "                self.feature_modules[feature] = nn.Embedding(5, 3, padding_idx=0)\n",
    "                self.dims += 3\n",
    "            elif feature=='u1_depdir':\n",
    "                self.feature_modules[feature] = nn.Embedding(5, 3, padding_idx=0)\n",
    "                self.dims += 3\n",
    "            elif feature=='u2_depdir':\n",
    "                self.feature_modules[feature] = nn.Embedding(5, 3, padding_idx=0)\n",
    "                self.dims += 3\n",
    "            elif feature=='u2_func':\n",
    "                self.feature_modules[feature] = nn.Embedding(23, 5, padding_idx=0)\n",
    "                self.dims += 5\n",
    "            elif feature=='u1_position':\n",
    "                self.feature_modules[feature] = nn.Embedding(12, 4, padding_idx=0)\n",
    "                self.dims += 4\n",
    "            elif feature=='u2_position':\n",
    "                self.feature_modules[feature] = nn.Embedding(12, 4, padding_idx=0)\n",
    "                self.dims += 4\n",
    "            elif 'sat_children' in feature_list:        \n",
    "                self.feature_modules[feature] = nn.Identity()\n",
    "                self.dims += 1\n",
    "            elif 'nuc_children' in feature_list:\n",
    "                self.feature_modules[feature] = nn.Identity()\n",
    "                self.dims += 1\n",
    "            # elif 'genre' in feature_list:               self.modules['genre'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'unit1_case' in feature_list:          self.modules['unit1_case'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'unit2_case' in feature_list:          self.modules['unit2_case'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u1_discontinuous' in feature_list:    self.modules['u1_discontinuous'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u2_discontinuous' in feature_list:    self.modules['u2_discontinuous'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'same_speaker' in feature_list:        self.modules['same_speaker'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'lex_overlap_length' in feature_list:  self.modules['lex_overlap_length'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u1_func' in feature_list:             self.modules['u1_func'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            else: raise ValueError()\n",
    "\n",
    "    def forward(self, features):\n",
    "        return get_combined_feature_tensor_forward(features, self.feature_list, self.feature_modules)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels\n",
    "          self.feature_list = mnli_dataset.feature_list\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "\n",
    "          self.embedder = self.create_featureful_bert()\n",
    "          self.encoder = CustomPooler2()\n",
    "          self.module1 = MyModule(self.feature_list)\n",
    "          self.dropout1 = nn.Dropout(p=0.0)\n",
    "        #   self.dropout_decoder = nn.Dropout(p=0.5)\n",
    "          self.relation_decoder = nn.Linear(792, self.num_classes)\n",
    "\n",
    "    def forward(self, pair_token_ids, attention_mask, feat):\n",
    "        direction_tensor = feat['dir'].to(device)\n",
    "        embedded_sentence = self.embedder(token_ids=pair_token_ids, #featurefulmebedder\n",
    "                        mask=attention_mask, \n",
    "                        # type_ids=token_type_ids,\n",
    "                        segment_concat_mask = None,\n",
    "                        direction_tensor = direction_tensor,\n",
    "                        feature_list = self.feature_list,\n",
    "                        features = feat)\n",
    "        # mask = token_type_ids\n",
    "        bertpooler_output = self.encoder(tokens=embedded_sentence, mask=None)\n",
    "        feat = self.convert_to_feature_list(feat)\n",
    "        feat = self.dropout1(feat)\n",
    "        feat = self.module1(feat)\n",
    "        try:\n",
    "            feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "        except:\n",
    "            print(bertpooler_output.shape, feat.shape)\n",
    "            raise ValueError()\n",
    "        if feat_concat.shape[-1]!=792: print(feat_concat.shape)\n",
    "        assert feat_concat.shape[-1] == 792\n",
    "        feat_concat = self.dropout1(feat_concat)\n",
    "        # feat_concat = self.dropout_decoder(feat_concat)\n",
    "        linear1_output = self.relation_decoder(feat_concat)\n",
    "        return linear1_output\n",
    "\n",
    "\n",
    "    def create_featureful_bert(self):\n",
    "        featureful_bert = FeaturefulBertEmbedder(model_name = BERT_MODEL,\n",
    "                                hidden_activation_allen = 'gelu',\n",
    "                                feature_list = self.feature_list, \n",
    "                                vocab=mnli_dataset.vocab)\n",
    "        return featureful_bert\n",
    "\n",
    "    def convert_to_feature_list(self, feat):\n",
    "        feature_linear = [feat[feature_name] for feature_name in self.feature_list]\n",
    "        feature_linear = torch.stack(feature_linear, dim=-1)\n",
    "        return feature_linear\n",
    "        \n",
    "\n",
    "model = CustomBERTModel(mnli_dataset.num_labels)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False) # original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, mode='max', patience=35, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prinintg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomBERTModel(\n",
      "  (embedder): FeaturefulBertEmbedder(\n",
      "    (transformer_model): FeaturefulBert(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoderDouble(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (value): Linear(\n",
      "                  in_features=768, out_features=768, bias=True\n",
      "                  (loras): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (prefix_tuning): PrefixTuningShim(\n",
      "                  (prefix_gates): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (adapters): ModuleDict()\n",
      "                (adapter_fusion_layer): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(\n",
      "                in_features=768, out_features=3072, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(\n",
      "                in_features=3072, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (feature_modules): ModuleDict(\n",
      "        (distance): Embedding(5, 3, padding_idx=0)\n",
      "        (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "        (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "        (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "        (sat_children): Identity()\n",
      "        (nuc_children): Identity()\n",
      "      )\n",
      "      (feature_projector): Linear(in_features=25, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): CustomPooler2(\n",
      "    (_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (module1): MyModule(\n",
      "    (feature_modules): ModuleDict(\n",
      "      (distance): Embedding(5, 3, padding_idx=0)\n",
      "      (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "      (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "      (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "      (sat_children): Identity()\n",
      "      (nuc_children): Identity()\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (relation_decoder): Linear(in_features=792, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['events.out.tfevents.1673958129.57e5cab0c4d9.8527.0']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=20, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      # seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids = pair_token_ids, \n",
    "                            # token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), 'run1/'+save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), 'run1/'+save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Best val_acc: 0.0943\n",
      "Epoch 1: Best val_acc: 0.0943\n",
      "Epoch 1: train_loss: 3.0429 train_acc: 0.0883 | val_loss: 2.9058 val_acc: 0.0943\n",
      "00:01:15.90\n",
      "train_size: 541\n",
      "Epoch 2: Best val_acc: 0.1025\n",
      "Epoch 2: Best val_acc: 0.1025\n",
      "Epoch 2: train_loss: 2.8602 train_acc: 0.1229 | val_loss: 2.7287 val_acc: 0.1025\n",
      "00:01:51.72\n",
      "train_size: 541\n",
      "Epoch 3: Best val_acc: 0.1516\n",
      "Epoch 3: Best val_acc: 0.1516\n",
      "Epoch 3: train_loss: 2.7400 train_acc: 0.1419 | val_loss: 2.6345 val_acc: 0.1516\n",
      "00:02:13.10\n",
      "train_size: 541\n",
      "Epoch 4: Best val_acc: 0.1516\n",
      "Epoch 4: train_loss: 2.6693 train_acc: 0.1604 | val_loss: 2.5761 val_acc: 0.1516\n",
      "00:02:04.70\n",
      "train_size: 541\n",
      "Epoch 5: Best val_acc: 0.1598\n",
      "Epoch 5: Best val_acc: 0.1598\n",
      "Epoch 5: train_loss: 2.6277 train_acc: 0.1617 | val_loss: 2.5373 val_acc: 0.1598\n",
      "00:02:09.47\n",
      "train_size: 541\n",
      "Epoch 6: Best val_acc: 0.1721\n",
      "Epoch 6: Best val_acc: 0.1721\n",
      "Epoch 6: train_loss: 2.5872 train_acc: 0.1807 | val_loss: 2.5212 val_acc: 0.1721\n",
      "00:02:02.05\n",
      "train_size: 541\n",
      "Epoch 7: Best val_acc: 0.1844\n",
      "Epoch 7: Best val_acc: 0.1844\n",
      "Epoch 7: train_loss: 2.5280 train_acc: 0.2001 | val_loss: 2.4407 val_acc: 0.1844\n",
      "00:02:02.07\n",
      "train_size: 541\n",
      "Epoch 8: Best val_acc: 0.2008\n",
      "Epoch 8: Best val_acc: 0.2008\n",
      "Epoch 8: train_loss: 2.4623 train_acc: 0.2366 | val_loss: 2.4061 val_acc: 0.2008\n",
      "00:02:02.23\n",
      "train_size: 541\n",
      "Epoch 9: Best val_acc: 0.2254\n",
      "Epoch 9: Best val_acc: 0.2254\n",
      "Epoch 9: train_loss: 2.3986 train_acc: 0.2495 | val_loss: 2.4030 val_acc: 0.2254\n",
      "00:02:01.08\n",
      "train_size: 541\n",
      "Epoch 10: Best val_acc: 0.2541\n",
      "Epoch 10: Best val_acc: 0.2541\n",
      "Epoch 10: train_loss: 2.3367 train_acc: 0.2750 | val_loss: 2.3170 val_acc: 0.2541\n",
      "00:02:01.89\n",
      "train_size: 541\n",
      "Epoch 11: Best val_acc: 0.2746\n",
      "Epoch 11: Best val_acc: 0.2746\n",
      "Epoch 11: train_loss: 2.2888 train_acc: 0.2985 | val_loss: 2.2976 val_acc: 0.2746\n",
      "00:02:02.15\n",
      "train_size: 541\n",
      "Epoch 12: Best val_acc: 0.2746\n",
      "Epoch 12: train_loss: 2.2497 train_acc: 0.3073 | val_loss: 2.2800 val_acc: 0.2746\n",
      "00:02:11.94\n",
      "train_size: 541\n",
      "Epoch 13: train_loss: 2.1781 train_acc: 0.3392 | val_loss: 2.2549 val_acc: 0.2664\n",
      "00:02:07.70\n",
      "train_size: 541\n",
      "Epoch 14: Best val_acc: 0.2951\n",
      "Epoch 14: Best val_acc: 0.2951\n",
      "Epoch 14: train_loss: 2.1322 train_acc: 0.3549 | val_loss: 2.1943 val_acc: 0.2951\n",
      "00:02:02.49\n",
      "train_size: 541\n",
      "Epoch 15: Best val_acc: 0.3074\n",
      "Epoch 15: Best val_acc: 0.3074\n",
      "Epoch 15: train_loss: 2.0611 train_acc: 0.3706 | val_loss: 2.2406 val_acc: 0.3074\n",
      "00:02:03.48\n",
      "train_size: 541\n",
      "Epoch 16: Best val_acc: 0.3156\n",
      "Epoch 16: Best val_acc: 0.3156\n",
      "Epoch 16: train_loss: 2.0050 train_acc: 0.3854 | val_loss: 2.1928 val_acc: 0.3156\n",
      "00:02:11.32\n",
      "train_size: 541\n",
      "Epoch 17: Best val_acc: 0.3197\n",
      "Epoch 17: Best val_acc: 0.3197\n",
      "Epoch 17: train_loss: 1.9422 train_acc: 0.4191 | val_loss: 2.1965 val_acc: 0.3197\n",
      "00:02:11.74\n",
      "train_size: 541\n",
      "Epoch 18: Best val_acc: 0.3320\n",
      "Epoch 18: Best val_acc: 0.3320\n",
      "Epoch 18: train_loss: 1.8926 train_acc: 0.4395 | val_loss: 2.2145 val_acc: 0.3320\n",
      "00:02:12.42\n",
      "train_size: 541\n",
      "Epoch 19: train_loss: 1.8458 train_acc: 0.4584 | val_loss: 2.2199 val_acc: 0.3238\n",
      "00:02:09.29\n",
      "train_size: 541\n",
      "Epoch 20: Best val_acc: 0.3361\n",
      "Epoch 20: Best val_acc: 0.3361\n",
      "Epoch 20: train_loss: 1.7696 train_acc: 0.4820 | val_loss: 2.2508 val_acc: 0.3361\n",
      "00:02:12.85\n",
      "train_size: 541\n",
      "Epoch 21: train_loss: 1.7193 train_acc: 0.4884 | val_loss: 2.2562 val_acc: 0.3197\n",
      "00:02:09.20\n",
      "train_size: 541\n",
      "Epoch 22: train_loss: 1.6621 train_acc: 0.5079 | val_loss: 2.3029 val_acc: 0.3156\n",
      "00:02:05.87\n",
      "train_size: 541\n",
      "Epoch 23: Best val_acc: 0.3525\n",
      "Epoch 23: Best val_acc: 0.3525\n",
      "Epoch 23: train_loss: 1.5940 train_acc: 0.5351 | val_loss: 2.2220 val_acc: 0.3525\n",
      "00:02:13.53\n",
      "train_size: 541\n",
      "Epoch 24: train_loss: 1.5198 train_acc: 0.5684 | val_loss: 2.2256 val_acc: 0.3320\n",
      "00:02:06.02\n",
      "train_size: 541\n",
      "Epoch 25: train_loss: 1.4848 train_acc: 0.5767 | val_loss: 2.2544 val_acc: 0.3156\n",
      "00:02:06.23\n",
      "train_size: 541\n",
      "Epoch 26: train_loss: 1.4084 train_acc: 0.6044 | val_loss: 2.2339 val_acc: 0.3320\n",
      "00:02:09.33\n",
      "train_size: 541\n",
      "Epoch 27: Best val_acc: 0.3607\n",
      "Epoch 27: Best val_acc: 0.3607\n",
      "Epoch 27: train_loss: 1.3593 train_acc: 0.6211 | val_loss: 2.2605 val_acc: 0.3607\n",
      "00:02:15.40\n",
      "train_size: 541\n",
      "Epoch 28: train_loss: 1.3051 train_acc: 0.6335 | val_loss: 2.2606 val_acc: 0.3484\n",
      "00:02:09.61\n",
      "train_size: 541\n",
      "Epoch 29: Best val_acc: 0.3607\n",
      "Epoch 29: train_loss: 1.2366 train_acc: 0.6622 | val_loss: 2.2535 val_acc: 0.3607\n",
      "00:02:09.01\n",
      "train_size: 541\n",
      "Epoch 30: train_loss: 1.1790 train_acc: 0.6774 | val_loss: 2.3007 val_acc: 0.3525\n",
      "00:02:09.15\n",
      "train_size: 541\n",
      "Epoch 31: Best val_acc: 0.3648\n",
      "Epoch 31: Best val_acc: 0.3648\n",
      "Epoch 31: train_loss: 1.1161 train_acc: 0.6955 | val_loss: 2.2839 val_acc: 0.3648\n",
      "00:02:16.38\n",
      "train_size: 541\n",
      "Epoch 32: train_loss: 1.0628 train_acc: 0.7107 | val_loss: 2.3278 val_acc: 0.3320\n",
      "00:02:09.25\n",
      "train_size: 541\n",
      "Epoch 33: Best val_acc: 0.3770\n",
      "Epoch 33: Best val_acc: 0.3770\n",
      "Epoch 33: train_loss: 0.9963 train_acc: 0.7227 | val_loss: 2.3477 val_acc: 0.3770\n",
      "00:02:15.57\n",
      "train_size: 541\n",
      "Epoch 34: Best val_acc: 0.3934\n",
      "Epoch 34: Best val_acc: 0.3934\n",
      "Epoch 34: train_loss: 0.9343 train_acc: 0.7458 | val_loss: 2.4154 val_acc: 0.3934\n",
      "00:02:12.41\n",
      "train_size: 541\n",
      "Epoch 35: train_loss: 0.8847 train_acc: 0.7625 | val_loss: 2.4753 val_acc: 0.3566\n",
      "00:02:09.27\n",
      "train_size: 541\n",
      "Epoch 36: train_loss: 0.8289 train_acc: 0.7731 | val_loss: 2.4405 val_acc: 0.3689\n",
      "00:02:09.17\n",
      "train_size: 541\n",
      "Epoch 00037: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 37: train_loss: 0.7952 train_acc: 0.7842 | val_loss: 2.4402 val_acc: 0.3893\n",
      "00:02:09.14\n",
      "train_size: 541\n",
      "Epoch 38: train_loss: 0.7504 train_acc: 0.7981 | val_loss: 2.4983 val_acc: 0.3730\n",
      "00:02:09.16\n",
      "train_size: 541\n",
      "Epoch 39: Best val_acc: 0.3975\n",
      "Epoch 39: Best val_acc: 0.3975\n",
      "Epoch 39: train_loss: 0.7099 train_acc: 0.8138 | val_loss: 2.4213 val_acc: 0.3975\n",
      "00:02:15.77\n",
      "train_size: 541\n",
      "Epoch 40: train_loss: 0.6623 train_acc: 0.8313 | val_loss: 2.5163 val_acc: 0.3811\n",
      "00:02:09.26\n",
      "train_size: 541\n",
      "Epoch 41: Best val_acc: 0.4057\n",
      "Epoch 41: Best val_acc: 0.4057\n",
      "Epoch 41: train_loss: 0.6351 train_acc: 0.8253 | val_loss: 2.5439 val_acc: 0.4057\n",
      "00:02:15.91\n",
      "train_size: 541\n",
      "Epoch 42: train_loss: 0.6119 train_acc: 0.8336 | val_loss: 2.5792 val_acc: 0.3770\n",
      "00:02:09.35\n",
      "train_size: 541\n",
      "Epoch 43: train_loss: 0.5874 train_acc: 0.8466 | val_loss: 2.5491 val_acc: 0.3811\n",
      "00:02:09.12\n",
      "train_size: 541\n",
      "Epoch 44: Best val_acc: 0.4057\n",
      "Epoch 44: train_loss: 0.5528 train_acc: 0.8549 | val_loss: 2.6124 val_acc: 0.4057\n",
      "00:02:12.14\n",
      "train_size: 541\n",
      "Epoch 45: train_loss: 0.5074 train_acc: 0.8706 | val_loss: 2.7386 val_acc: 0.3648\n",
      "00:02:07.59\n",
      "train_size: 541\n",
      "Epoch 46: train_loss: 0.4895 train_acc: 0.8729 | val_loss: 2.5926 val_acc: 0.3730\n",
      "00:02:09.24\n",
      "train_size: 541\n",
      "Epoch 47: train_loss: 0.4688 train_acc: 0.8826 | val_loss: 2.7189 val_acc: 0.3525\n",
      "00:02:09.35\n",
      "train_size: 541\n",
      "Epoch 48: train_loss: 0.4286 train_acc: 0.8891 | val_loss: 2.8336 val_acc: 0.3770\n",
      "00:02:09.30\n",
      "train_size: 541\n",
      "Epoch 49: train_loss: 0.4184 train_acc: 0.8905 | val_loss: 2.8563 val_acc: 0.3361\n",
      "00:01:36.76\n",
      "train_size: 541\n",
      "Epoch 50: train_loss: 0.3849 train_acc: 0.9053 | val_loss: 2.8555 val_acc: 0.3934\n",
      "00:01:26.00\n",
      "train_size: 541\n",
      "Epoch 51: train_loss: 0.3689 train_acc: 0.9094 | val_loss: 2.9166 val_acc: 0.3279\n",
      "00:01:25.98\n",
      "train_size: 541\n",
      "Epoch 52: train_loss: 0.3486 train_acc: 0.9145 | val_loss: 2.7907 val_acc: 0.3852\n",
      "00:01:25.99\n",
      "train_size: 541\n",
      "Epoch 53: train_loss: 0.3358 train_acc: 0.9154 | val_loss: 3.0005 val_acc: 0.3770\n",
      "00:01:26.01\n",
      "train_size: 541\n",
      "Epoch 54: train_loss: 0.3076 train_acc: 0.9256 | val_loss: 2.8847 val_acc: 0.3770\n",
      "00:01:12.78\n",
      "train_size: 541\n",
      "Epoch 55: train_loss: 0.2902 train_acc: 0.9348 | val_loss: 2.9698 val_acc: 0.3730\n",
      "00:00:38.95\n",
      "train_size: 541\n",
      "Epoch 56: train_loss: 0.2834 train_acc: 0.9311 | val_loss: 2.9722 val_acc: 0.3730\n",
      "00:00:39.28\n",
      "train_size: 541\n",
      "Epoch 57: train_loss: 0.2755 train_acc: 0.9376 | val_loss: 2.9344 val_acc: 0.3648\n",
      "00:00:39.12\n",
      "train_size: 541\n",
      "Epoch 58: train_loss: 0.2532 train_acc: 0.9390 | val_loss: 3.0925 val_acc: 0.3566\n",
      "00:00:39.28\n",
      "train_size: 541\n",
      "Epoch 59: train_loss: 0.2280 train_acc: 0.9524 | val_loss: 3.0750 val_acc: 0.3770\n",
      "00:00:39.38\n",
      "train_size: 541\n",
      "Epoch 60: train_loss: 0.2095 train_acc: 0.9552 | val_loss: 3.1657 val_acc: 0.3852\n",
      "00:00:39.09\n",
      "train_size: 541\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:768: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 3.4316 test_acc: 0.3038\n",
      "00:00:00.78\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.36      0.28      0.31        18\n",
      "    background       0.30      0.41      0.35        17\n",
      "         cause       0.12      0.50      0.20         2\n",
      "  circumstance       0.36      0.53      0.43        15\n",
      "    concession       0.36      0.31      0.33        13\n",
      "     condition       0.60      0.67      0.63         9\n",
      "   conjunction       0.27      0.57      0.36         7\n",
      "      contrast       0.20      0.12      0.15         8\n",
      " e-elaboration       0.55      0.55      0.55        11\n",
      "   elaboration       0.10      0.40      0.16        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.40      0.24      0.30        17\n",
      "      evidence       0.17      0.30      0.21        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.30      0.28      0.29        29\n",
      "          list       0.50      0.46      0.48        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.50      0.75      0.60         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.33      0.03      0.05        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.30       260\n",
      "     macro avg       0.26      0.28      0.25       260\n",
      "  weighted avg       0.32      0.30      0.29       260\n",
      "\n",
      "Test Loss: 3.432 |  Test Acc: 30.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best earliest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:768: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.8820 test_acc: 0.3000\n",
      "00:00:00.77\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.38      0.33      0.35        18\n",
      "    background       0.19      0.18      0.18        17\n",
      "         cause       0.14      0.50      0.22         2\n",
      "  circumstance       0.35      0.47      0.40        15\n",
      "    concession       0.42      0.38      0.40        13\n",
      "     condition       0.58      0.78      0.67         9\n",
      "   conjunction       0.25      0.57      0.35         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.50      0.55      0.52        11\n",
      "   elaboration       0.05      0.20      0.09        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.33      0.06      0.10        17\n",
      "      evidence       0.33      0.10      0.15        10\n",
      "interpretation       0.06      0.08      0.07        12\n",
      "         joint       0.31      0.52      0.39        29\n",
      "          list       0.44      0.42      0.43        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.30      0.75      0.43         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.60      0.09      0.15        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.30       260\n",
      "     macro avg       0.26      0.28      0.24       260\n",
      "  weighted avg       0.34      0.30      0.28       260\n",
      "\n",
      "Latest Test Loss: 2.882 |  Latest Test Acc: 30.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('run1/'+save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best lastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:768: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.8430 test_acc: 0.3038\n",
      "00:00:00.77\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.41      0.39      0.40        18\n",
      "    background       0.24      0.24      0.24        17\n",
      "         cause       0.12      0.50      0.20         2\n",
      "  circumstance       0.36      0.33      0.34        15\n",
      "    concession       0.36      0.38      0.37        13\n",
      "     condition       0.50      0.78      0.61         9\n",
      "   conjunction       0.29      0.57      0.38         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.50      0.55      0.52        11\n",
      "   elaboration       0.06      0.20      0.09        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.25      0.06      0.10        17\n",
      "      evidence       0.36      0.40      0.38        10\n",
      "interpretation       0.06      0.08      0.07        12\n",
      "         joint       0.30      0.45      0.36        29\n",
      "          list       0.48      0.38      0.43        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.43      0.75      0.55         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.57      0.12      0.20        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.30       260\n",
      "     macro avg       0.26      0.29      0.25       260\n",
      "  weighted avg       0.34      0.30      0.29       260\n",
      "\n",
      "Best Test Loss: 2.843 |  Best Test Acc: 30.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('run1/'+save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_latest', test_acc, 1)\n",
    "print(f'Best Test Loss: {test_loss:.3f} |  Best Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:768: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.6310 test_acc: 0.3934\n",
      "00:00:00.75\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.50      0.36      0.42        11\n",
      "    background       0.32      0.35      0.33        17\n",
      "         cause       0.00      0.00      0.00         7\n",
      "  circumstance       0.31      0.38      0.34        13\n",
      "    concession       0.32      0.73      0.44        11\n",
      "     condition       0.73      1.00      0.84         8\n",
      "   conjunction       0.67      0.75      0.71         8\n",
      "      contrast       0.00      0.00      0.00         3\n",
      " e-elaboration       0.73      0.62      0.67        13\n",
      "   elaboration       0.44      0.39      0.42        28\n",
      "  evaluation-n       0.00      0.00      0.00         8\n",
      "  evaluation-s       0.00      0.00      0.00         5\n",
      "      evidence       0.38      0.38      0.38         8\n",
      "interpretation       0.00      0.00      0.00        13\n",
      "         joint       0.14      0.33      0.20        18\n",
      "          list       0.56      0.56      0.56        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.89      0.73      0.80        11\n",
      "       purpose       1.00      0.40      0.57         5\n",
      "        reason       0.61      0.39      0.48        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         3\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.40       241\n",
      "     macro avg       0.32      0.31      0.30       241\n",
      "  weighted avg       0.41      0.40      0.39       241\n",
      "\n",
      "Val Loss: 2.631 |  Val Acc: 39.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('run1/'+save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discodapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d8a2a8a5b9abc71c133cb1f832a117b3c491b0de04eda931ac6db8a0de0367f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
