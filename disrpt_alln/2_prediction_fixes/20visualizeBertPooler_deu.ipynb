{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2011\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "batch_size = 4\n",
    "batches_per_epoch = 110\n",
    "\n",
    "save_path_suffix = '20visualizeBertPooler_rand_deu_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'15': 1,\n",
       "         '1': 142,\n",
       "         '2': 41,\n",
       "         '3': 23,\n",
       "         '5': 9,\n",
       "         '6': 4,\n",
       "         '4': 10,\n",
       "         '7': 3,\n",
       "         '9': 3,\n",
       "         '12': 1,\n",
       "         '14': 1,\n",
       "         '8': 1,\n",
       "         '16': 1,\n",
       "         '10': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "Counter(val_df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label',\n",
       "       'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position',\n",
       "       'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case',\n",
       "       'unit2_case', 'u1_discontinuous', 'u2_discontinuous', 'same_speaker',\n",
       "       'lex_overlap_length', 'u1_func'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 12:56:04.619005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 12:56:04.860618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-12 12:56:04.860660: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 12:56:04.905572: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-12 12:56:06.032985: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-12 12:56:06.033093: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-12 12:56:06.033101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, ConcatDataset\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate, Vocabulary\n",
    "from features_custom2 import get_vocab_feature_name\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.vocab = Vocabulary(counter=None, max_vocab_size=100000)\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.init_feature_list()\n",
    "    self.init_feature_mappings_and_bins()\n",
    "    self.apply_bins()\n",
    "    self.calculate_unique_values()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    \n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def init_feature_mappings_and_bins(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "    self.bins = {\n",
    "      'distance': [[-1e9, -8], [-8, -2], [-2, 0], [0, 2], [2, 8], [8, 1e9]],\n",
    "      'u1_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'u2_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'lex_overlap_length': [[0, 2], [2, 7], [7, 1e9]]\n",
    "    }   \n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def init_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "    else: \n",
    "      raise ValueError()\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features_list(self, features, feature_name):\n",
    "    if feature_name in ['distance', 'u1_depdir', 'u2_depdir', 'u1_func', 'u2_func', \n",
    "    'u1_position', 'u2_position', 'genre', 'same_speaker', 'unit1_case', 'unit2_case',\n",
    "    'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'dir']: feature_value = self.apply_vocab(features[feature_name], feature_name) #for categorical values\n",
    "    elif feature_name in ['sat_children', 'nuc_children']: feature_value = float(features[feature_name]) #for identiy values\n",
    "    else: \n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    return feature_value\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==17\n",
    "    #after applying the vocab. we need to pass them as int\n",
    "    return {feature_name: torch.tensor(int(self.get_allen_features_list(features, feature_name))).to(device) for feature_name in self.feature_list+['dir']}\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature_name in self.feature_list+['dir']:\n",
    "      vocab_feature_name = get_vocab_feature_name(feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(train_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(val_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "\n",
    "  def apply_bins(self):\n",
    "    for df in [self.train_df, self.test_df, self.val_df]:\n",
    "      for feature_name in self.bins.keys():\n",
    "        df[feature_name] = df[feature_name].apply(lambda x: self.get_mapping_from_bin(feature_name, float(x)))\n",
    "\n",
    "  def get_mapping_from_bin(self, column_name, dict_val):\n",
    "    bins = self.bins[column_name]\n",
    "    for b,i in zip(bins, range(len(bins))):\n",
    "      left = b[0]\n",
    "      right = b[1]\n",
    "      if left<=dict_val and right>=dict_val: return i\n",
    "\n",
    "  def apply_vocab(self, feature_value, feature_name):\n",
    "    return self.vocab.get_token_index(str(feature_value), namespace=get_vocab_feature_name(feature_name))\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      features = {'distance': row['distance'],\n",
    "                'u1_depdir': row['u1_depdir'],\n",
    "                'u2_depdir': row['u2_depdir'],\n",
    "                'u1_func': row['u1_func'],\n",
    "                'u2_func': row['u2_func'],\n",
    "                'u1_position': row['u1_position'],\n",
    "                'u2_position': row['u2_position'],\n",
    "                'sat_children': row['sat_children'],\n",
    "                'nuc_children': row['nuc_children'],\n",
    "                'genre': row['genre'],\n",
    "                'unit1_case': row['unit1_case'],\n",
    "                'unit2_case': row['unit2_case'],\n",
    "                'u1_discontinuous': row['u1_discontinuous'],\n",
    "                'u2_discontinuous': row['u2_discontinuous'],\n",
    "                'same_speaker': row['same_speaker'],\n",
    "                'lex_overlap_length': row['lex_overlap_length'],\n",
    "                'dir': row['dir']}\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding=False) #padding='max_length'\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      features = self.transform_feature(features)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(features)\n",
    "      \n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "      \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "\n",
    "    class featureDataset(Dataset):\n",
    "      def __init__(self, token_ids, mask_ids, seg_ids, feats, y, idx):\n",
    "          self.token_ids = token_ids\n",
    "          self.mask_ids = mask_ids\n",
    "          self.seg_ids = seg_ids\n",
    "          self.feats = feats\n",
    "          self.y = y\n",
    "          self.idx = idx\n",
    "\n",
    "      def __len__(self):\n",
    "          return len(self.feats)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "          return self.token_ids[idx], self.mask_ids[idx], self.seg_ids[idx], self.feats[idx], self.y[idx], self.idx[idx]\n",
    "\n",
    "    dataset = featureDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '3': 2, '4': 3, '5': 4}\n",
      "u1_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_func :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'root': 2, 'conj': 3, 'advcl': 4, 'acl': 5, 'xcomp': 6, 'obl': 7, 'ccomp': 8, 'parataxis': 9, 'advmod': 10, 'dep': 11, 'csubj': 12, 'nmod': 13, 'punct': 14, 'cc': 15, 'appos': 16, 'aux': 17, 'obj': 18, 'iobj': 19, 'nsubj': 20, 'nsubj:pass': 21, 'csubj:pass': 22}\n",
      "u1_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '1': 11}\n",
      "u2_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '1': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
      "sat_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '4': 3, '1': 4, '2': 5, '3': 6, '5': 7, '6': 8}\n",
      "nuc_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '4': 2, '3': 3, '1': 4, '2': 5, '5': 6, '6': 7, '7': 8, '8': 9}\n",
      "dir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '1>2': 2, '1<2': 3}\n"
     ]
    }
   ],
   "source": [
    "for feature in mnli_dataset.feature_list:\n",
    "    vocab_feature_name = get_vocab_feature_name(feature)\n",
    "    print(feature, ': ', mnli_dataset.vocab.get_token_to_index_vocabulary(vocab_feature_name))\n",
    "print('dir', ': ', mnli_dataset.vocab.get_token_to_index_vocabulary('dir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    # assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    # assert mask_ids.shape[-1]==512\n",
    "    # assert seg_ids.shape[-1]==512\n",
    "    assert len(feat)==len(mnli_dataset.feature_list)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '@@PADDING@@', 1: '@@UNKNOWN@@'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_dataset.vocab.get_index_to_token_vocabulary('u1_depdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        if i not in idx_map.keys():\n",
    "          print(idx_map)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing FeaturefulBert: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing FeaturefulBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FeaturefulBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, Optional\n",
    "from transformers import BertModel, AutoTokenizer, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from featurefulbertembedder_custom2 import FeaturefulBertEmbedder\n",
    "from featureful_bert_custom2 import get_combined_feature_tensor_2 as get_combined_feature_tensor_forward\n",
    "from featureful_bert_custom2 import get_feature_modules\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class CustomPooler2(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                        requires_grad: bool = True,\n",
    "                        dropout: float = 0.0,\n",
    "                        randomize_weights: bool = False,\n",
    "                        transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "        super().__init__()\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL) #only used to pass config. BertAttentionClass used in FeatureFulBert\n",
    "        self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.pooler = copy.deepcopy(bert.pooler)\n",
    "        if randomize_weights:\n",
    "            print(self.pooler.dense.weight.shape)\n",
    "            self.pooler.dense.weight = nn.Parameter(torch.rand(self.pooler.dense.weight.shape))\n",
    "            self.pooler.dense.bias = nn.Parameter(torch.rand(self.pooler.dense.bias.shape))\n",
    "            print(self.pooler.dense.weight.shape)\n",
    "        for param in self.pooler.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        self._embedding_dim = bert.config.hidden_size\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "        pooler = self.pooler\n",
    "        \n",
    "        for _ in range(num_wrapping_dims):\n",
    "            pooler = TimeDistributed(pooler)\n",
    "        pooled = pooler(tokens)\n",
    "        pooled = self._dropout(pooled)\n",
    "        return pooled\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list, vocab):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_modules, self._feature_module_size = get_feature_modules(feature_list, vocab)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return get_combined_feature_tensor_forward(features, self.feature_list, self.feature_modules)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels, vocab):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels\n",
    "          self.feature_list = mnli_dataset.feature_list\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "\n",
    "          self.embedder = self.create_featureful_bert()\n",
    "          self.encoder = CustomPooler2()\n",
    "          self.module1 = MyModule(self.feature_list, vocab)\n",
    "          self.dropout1 = nn.Dropout(p=0.0)\n",
    "        #   self.dropout_decoder = nn.Dropout(p=0.5)\n",
    "          self._decoder_input_size = self.encoder._embedding_dim + self.module1._feature_module_size\n",
    "          self.relation_decoder = nn.Linear(self._decoder_input_size, self.num_classes)\n",
    "\n",
    "          self.history_w = {\n",
    "            'cos': [],\n",
    "            # 'l1_linear': [],\n",
    "            # 'l2': []\n",
    "          }\n",
    "          self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "          print(self.pooler_weight)\n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask, feat):\n",
    "        direction_tensor = feat['dir'].to(device)\n",
    "        embedded_sentence = self.embedder(token_ids=pair_token_ids, #featurefulmebedder\n",
    "                        mask=attention_mask, \n",
    "                        type_ids=token_type_ids,\n",
    "                        segment_concat_mask = None,\n",
    "                        direction_tensor = direction_tensor,\n",
    "                        feature_list = self.feature_list,\n",
    "                        features = feat)\n",
    "        mask = token_type_ids\n",
    "        bertpooler_output = self.encoder(tokens=embedded_sentence, mask=mask)\n",
    "        feat = self.convert_to_feature_list(feat)\n",
    "        feat = self.dropout1(feat)\n",
    "        feat = self.module1(feat)\n",
    "        # print(bertpooler_output.shape, self.module1._feature_module_size, feat.shape)\n",
    "        try:\n",
    "            feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "        except:\n",
    "            print(bertpooler_output.shape, feat.shape)\n",
    "            raise ValueError()\n",
    "        assert feat_concat.shape[-1] == self._decoder_input_size\n",
    "        feat_concat = self.dropout1(feat_concat)\n",
    "        # feat_concat = self.dropout_decoder(feat_concat)\n",
    "        linear1_output = self.relation_decoder(feat_concat)\n",
    "        return linear1_output\n",
    "\n",
    "    def compute_pooler_similarity(self):\n",
    "        cur = self.encoder.pooler.dense.weight\n",
    "        pre = self.pooler_weight\n",
    "        print(cur)\n",
    "        print(pre)\n",
    "        assert not torch.all(cur.eq(pre))\n",
    "        for metric in self.history_w.keys():\n",
    "            self.history_w[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "\n",
    "    def similarity(self, cur, pre, metric):\n",
    "        metric = 0\n",
    "        n = 0\n",
    "        for A, B in zip(cur.cpu().detach().numpy(), pre.cpu().detach().numpy()):\n",
    "            cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "            metric+= cosine\n",
    "            n+=1\n",
    "        return float(metric)/float(n), metric\n",
    "\n",
    "    def create_bert_without_activations(self):\n",
    "        config = BertConfig.from_pretrained(BERT_MODEL, hidden_act='gelu')\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "        return bert\n",
    "\n",
    "    def create_featureful_bert(self):\n",
    "        featureful_bert = FeaturefulBertEmbedder(model_name = BERT_MODEL,\n",
    "                                hidden_activation_allen = 'gelu',\n",
    "                                feature_list = self.feature_list, \n",
    "                                vocab=mnli_dataset.vocab)\n",
    "        return featureful_bert\n",
    "\n",
    "    def convert_to_feature_list(self, feat):\n",
    "        feature_linear = [feat[feature_name] for feature_name in self.feature_list]\n",
    "        feature_linear = torch.stack(feature_linear, dim=-1)\n",
    "        return feature_linear\n",
    "        \n",
    "\n",
    "model = CustomBERTModel(mnli_dataset.num_labels, mnli_dataset.vocab)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, correct_bias=False) # original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, mode='max', patience=35, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prinintg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomBERTModel(\n",
      "  (embedder): FeaturefulBertEmbedder(\n",
      "    (transformer_model): FeaturefulBert(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (feature_modules): ModuleDict(\n",
      "        (distance): Embedding(5, 3, padding_idx=0)\n",
      "        (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "        (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "        (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "        (sat_children): Identity()\n",
      "        (nuc_children): Identity()\n",
      "      )\n",
      "      (feature_projector): Linear(in_features=25, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): CustomPooler2(\n",
      "    (_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (module1): MyModule(\n",
      "    (feature_modules): ModuleDict(\n",
      "      (distance): Embedding(5, 3, padding_idx=0)\n",
      "      (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "      (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "      (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "      (sat_children): Identity()\n",
      "      (nuc_children): Identity()\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (relation_decoder): Linear(in_features=792, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n",
    "\n",
    "    model.compute_pooler_similarity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Best val_acc: 0.1066\n",
      "Epoch 1: Best val_acc: 0.1066\n",
      "Epoch 1: train_loss: 2.9974 train_acc: 0.1250 | val_loss: 2.7624 val_acc: 0.1066\n",
      "00:00:10.02\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0086,  0.0123,  ...,  0.0005, -0.0079, -0.0990],\n",
      "        [ 0.0133,  0.0056,  0.0163,  ..., -0.0029,  0.0090, -0.0128],\n",
      "        [-0.0183,  0.0177, -0.0039,  ...,  0.0211, -0.0210, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0162,  0.0058,  ...,  0.0091, -0.0015,  0.0117],\n",
      "        [ 0.0880, -0.0192,  0.0051,  ...,  0.0095, -0.0170,  0.0204],\n",
      "        [ 0.0241,  0.0016, -0.0048,  ...,  0.0064,  0.0233,  0.0118]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 2: Best val_acc: 0.2295\n",
      "Epoch 2: Best val_acc: 0.2295\n",
      "Epoch 2: train_loss: 2.6468 train_acc: 0.1977 | val_loss: 2.5270 val_acc: 0.2295\n",
      "00:00:10.24\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0410,  0.0086,  0.0125,  ...,  0.0005, -0.0081, -0.0992],\n",
      "        [ 0.0131,  0.0058,  0.0167,  ..., -0.0028,  0.0089, -0.0127],\n",
      "        [-0.0184,  0.0176, -0.0036,  ...,  0.0210, -0.0212, -0.0037],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0161,  0.0058,  ...,  0.0094, -0.0016,  0.0119],\n",
      "        [ 0.0881, -0.0194,  0.0051,  ...,  0.0096, -0.0173,  0.0206],\n",
      "        [ 0.0243,  0.0014, -0.0051,  ...,  0.0065,  0.0232,  0.0118]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0086,  0.0123,  ...,  0.0005, -0.0079, -0.0990],\n",
      "        [ 0.0133,  0.0056,  0.0163,  ..., -0.0029,  0.0090, -0.0128],\n",
      "        [-0.0183,  0.0177, -0.0039,  ...,  0.0211, -0.0210, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0162,  0.0058,  ...,  0.0091, -0.0015,  0.0117],\n",
      "        [ 0.0880, -0.0192,  0.0051,  ...,  0.0095, -0.0170,  0.0204],\n",
      "        [ 0.0241,  0.0016, -0.0048,  ...,  0.0064,  0.0233,  0.0118]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 3: Best val_acc: 0.2582\n",
      "Epoch 3: Best val_acc: 0.2582\n",
      "Epoch 3: train_loss: 2.4909 train_acc: 0.2409 | val_loss: 2.4322 val_acc: 0.2582\n",
      "00:00:09.94\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0409,  0.0087,  0.0128,  ...,  0.0005, -0.0080, -0.0994],\n",
      "        [ 0.0131,  0.0059,  0.0169,  ..., -0.0027,  0.0090, -0.0128],\n",
      "        [-0.0185,  0.0176, -0.0036,  ...,  0.0210, -0.0214, -0.0035],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0159,  0.0057,  ...,  0.0096, -0.0017,  0.0120],\n",
      "        [ 0.0881, -0.0192,  0.0053,  ...,  0.0092, -0.0172,  0.0206],\n",
      "        [ 0.0243,  0.0015, -0.0052,  ...,  0.0065,  0.0233,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0410,  0.0086,  0.0125,  ...,  0.0005, -0.0081, -0.0992],\n",
      "        [ 0.0131,  0.0058,  0.0167,  ..., -0.0028,  0.0089, -0.0127],\n",
      "        [-0.0184,  0.0176, -0.0036,  ...,  0.0210, -0.0212, -0.0037],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0161,  0.0058,  ...,  0.0094, -0.0016,  0.0119],\n",
      "        [ 0.0881, -0.0194,  0.0051,  ...,  0.0096, -0.0173,  0.0206],\n",
      "        [ 0.0243,  0.0014, -0.0051,  ...,  0.0065,  0.0232,  0.0118]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 4: Best val_acc: 0.2828\n",
      "Epoch 4: Best val_acc: 0.2828\n",
      "Epoch 4: train_loss: 2.4168 train_acc: 0.2841 | val_loss: 2.3462 val_acc: 0.2828\n",
      "00:00:10.09\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0408,  0.0087,  0.0129,  ...,  0.0003, -0.0080, -0.0995],\n",
      "        [ 0.0130,  0.0060,  0.0171,  ..., -0.0026,  0.0091, -0.0128],\n",
      "        [-0.0185,  0.0176, -0.0035,  ...,  0.0210, -0.0217, -0.0034],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0159,  0.0057,  ...,  0.0097, -0.0017,  0.0121],\n",
      "        [ 0.0882, -0.0193,  0.0052,  ...,  0.0092, -0.0172,  0.0207],\n",
      "        [ 0.0244,  0.0014, -0.0054,  ...,  0.0064,  0.0234,  0.0117]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0409,  0.0087,  0.0128,  ...,  0.0005, -0.0080, -0.0994],\n",
      "        [ 0.0131,  0.0059,  0.0169,  ..., -0.0027,  0.0090, -0.0128],\n",
      "        [-0.0185,  0.0176, -0.0036,  ...,  0.0210, -0.0214, -0.0035],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0159,  0.0057,  ...,  0.0096, -0.0017,  0.0120],\n",
      "        [ 0.0881, -0.0192,  0.0053,  ...,  0.0092, -0.0172,  0.0206],\n",
      "        [ 0.0243,  0.0015, -0.0052,  ...,  0.0065,  0.0233,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 5: Best val_acc: 0.2910\n",
      "Epoch 5: Best val_acc: 0.2910\n",
      "Epoch 5: train_loss: 2.1957 train_acc: 0.3523 | val_loss: 2.3166 val_acc: 0.2910\n",
      "00:00:09.93\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0800e-02,  8.8599e-03,  1.3043e-02,  ...,  5.9618e-05,\n",
      "         -7.9671e-03, -9.9501e-02],\n",
      "        [ 1.2918e-02,  5.9990e-03,  1.7238e-02,  ..., -2.5455e-03,\n",
      "          9.2084e-03, -1.2693e-02],\n",
      "        [-1.8562e-02,  1.7588e-02, -3.5316e-03,  ...,  2.1041e-02,\n",
      "         -2.1850e-02, -3.2186e-03],\n",
      "        ...,\n",
      "        [ 1.3956e-02,  1.5893e-02,  5.7504e-03,  ...,  9.7705e-03,\n",
      "         -1.7120e-03,  1.2135e-02],\n",
      "        [ 8.8275e-02, -1.9238e-02,  5.1660e-03,  ...,  9.1527e-03,\n",
      "         -1.7225e-02,  2.0737e-02],\n",
      "        [ 2.4456e-02,  1.3639e-03, -5.4986e-03,  ...,  6.3928e-03,\n",
      "          2.3362e-02,  1.1600e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0408,  0.0087,  0.0129,  ...,  0.0003, -0.0080, -0.0995],\n",
      "        [ 0.0130,  0.0060,  0.0171,  ..., -0.0026,  0.0091, -0.0128],\n",
      "        [-0.0185,  0.0176, -0.0035,  ...,  0.0210, -0.0217, -0.0034],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0159,  0.0057,  ...,  0.0097, -0.0017,  0.0121],\n",
      "        [ 0.0882, -0.0193,  0.0052,  ...,  0.0092, -0.0172,  0.0207],\n",
      "        [ 0.0244,  0.0014, -0.0054,  ...,  0.0064,  0.0234,  0.0117]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 6: Best val_acc: 0.2992\n",
      "Epoch 6: Best val_acc: 0.2992\n",
      "Epoch 6: train_loss: 2.1636 train_acc: 0.4000 | val_loss: 2.2581 val_acc: 0.2992\n",
      "00:00:10.34\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0863e-02,  8.8167e-03,  1.3063e-02,  ...,  6.8216e-05,\n",
      "         -7.9237e-03, -9.9481e-02],\n",
      "        [ 1.2799e-02,  5.9568e-03,  1.7292e-02,  ..., -2.5259e-03,\n",
      "          9.3472e-03, -1.2711e-02],\n",
      "        [-1.8535e-02,  1.7560e-02, -3.5453e-03,  ...,  2.1097e-02,\n",
      "         -2.1934e-02, -3.0750e-03],\n",
      "        ...,\n",
      "        [ 1.3876e-02,  1.5789e-02,  5.7586e-03,  ...,  9.8288e-03,\n",
      "         -1.7101e-03,  1.2224e-02],\n",
      "        [ 8.8251e-02, -1.9297e-02,  5.1888e-03,  ...,  9.1765e-03,\n",
      "         -1.7267e-02,  2.0792e-02],\n",
      "        [ 2.4536e-02,  1.3616e-03, -5.6165e-03,  ...,  6.3784e-03,\n",
      "          2.3393e-02,  1.1565e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0800e-02,  8.8599e-03,  1.3043e-02,  ...,  5.9618e-05,\n",
      "         -7.9671e-03, -9.9501e-02],\n",
      "        [ 1.2918e-02,  5.9990e-03,  1.7238e-02,  ..., -2.5455e-03,\n",
      "          9.2084e-03, -1.2693e-02],\n",
      "        [-1.8562e-02,  1.7588e-02, -3.5316e-03,  ...,  2.1041e-02,\n",
      "         -2.1850e-02, -3.2186e-03],\n",
      "        ...,\n",
      "        [ 1.3956e-02,  1.5893e-02,  5.7504e-03,  ...,  9.7705e-03,\n",
      "         -1.7120e-03,  1.2135e-02],\n",
      "        [ 8.8275e-02, -1.9238e-02,  5.1660e-03,  ...,  9.1527e-03,\n",
      "         -1.7225e-02,  2.0737e-02],\n",
      "        [ 2.4456e-02,  1.3639e-03, -5.4986e-03,  ...,  6.3928e-03,\n",
      "          2.3362e-02,  1.1600e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 7: Best val_acc: 0.3115\n",
      "Epoch 7: Best val_acc: 0.3115\n",
      "Epoch 7: train_loss: 2.1937 train_acc: 0.3636 | val_loss: 2.1823 val_acc: 0.3115\n",
      "00:00:09.46\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0837e-02,  8.7817e-03,  1.2993e-02,  ...,  1.5551e-05,\n",
      "         -7.8801e-03, -9.9504e-02],\n",
      "        [ 1.2763e-02,  6.0522e-03,  1.7395e-02,  ..., -2.5190e-03,\n",
      "          9.3879e-03, -1.2716e-02],\n",
      "        [-1.8493e-02,  1.7531e-02, -3.5563e-03,  ...,  2.1067e-02,\n",
      "         -2.2005e-02, -3.0181e-03],\n",
      "        ...,\n",
      "        [ 1.3804e-02,  1.5753e-02,  5.7931e-03,  ...,  9.7966e-03,\n",
      "         -1.6645e-03,  1.2222e-02],\n",
      "        [ 8.8284e-02, -1.9281e-02,  5.1524e-03,  ...,  9.1054e-03,\n",
      "         -1.7192e-02,  2.0831e-02],\n",
      "        [ 2.4567e-02,  1.3120e-03, -5.7703e-03,  ...,  6.3537e-03,\n",
      "          2.3343e-02,  1.1591e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0863e-02,  8.8167e-03,  1.3063e-02,  ...,  6.8216e-05,\n",
      "         -7.9237e-03, -9.9481e-02],\n",
      "        [ 1.2799e-02,  5.9568e-03,  1.7292e-02,  ..., -2.5259e-03,\n",
      "          9.3472e-03, -1.2711e-02],\n",
      "        [-1.8535e-02,  1.7560e-02, -3.5453e-03,  ...,  2.1097e-02,\n",
      "         -2.1934e-02, -3.0750e-03],\n",
      "        ...,\n",
      "        [ 1.3876e-02,  1.5789e-02,  5.7586e-03,  ...,  9.8288e-03,\n",
      "         -1.7101e-03,  1.2224e-02],\n",
      "        [ 8.8251e-02, -1.9297e-02,  5.1888e-03,  ...,  9.1765e-03,\n",
      "         -1.7267e-02,  2.0792e-02],\n",
      "        [ 2.4536e-02,  1.3616e-03, -5.6165e-03,  ...,  6.3784e-03,\n",
      "          2.3393e-02,  1.1565e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 8: Best val_acc: 0.3361\n",
      "Epoch 8: Best val_acc: 0.3361\n",
      "Epoch 8: train_loss: 2.1102 train_acc: 0.3932 | val_loss: 2.1108 val_acc: 0.3361\n",
      "00:00:10.17\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0804e-02,  8.7621e-03,  1.2949e-02,  ..., -1.1872e-05,\n",
      "         -7.7950e-03, -9.9533e-02],\n",
      "        [ 1.2753e-02,  5.9716e-03,  1.7465e-02,  ..., -2.5358e-03,\n",
      "          9.2665e-03, -1.2671e-02],\n",
      "        [-1.8500e-02,  1.7395e-02, -3.5316e-03,  ...,  2.1067e-02,\n",
      "         -2.2076e-02, -2.8951e-03],\n",
      "        ...,\n",
      "        [ 1.3718e-02,  1.5778e-02,  5.8755e-03,  ...,  9.9176e-03,\n",
      "         -1.5601e-03,  1.2228e-02],\n",
      "        [ 8.8369e-02, -1.9245e-02,  5.1134e-03,  ...,  8.9920e-03,\n",
      "         -1.7297e-02,  2.0845e-02],\n",
      "        [ 2.4585e-02,  1.3222e-03, -5.7986e-03,  ...,  6.4403e-03,\n",
      "          2.3306e-02,  1.1602e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0837e-02,  8.7817e-03,  1.2993e-02,  ...,  1.5551e-05,\n",
      "         -7.8801e-03, -9.9504e-02],\n",
      "        [ 1.2763e-02,  6.0522e-03,  1.7395e-02,  ..., -2.5190e-03,\n",
      "          9.3879e-03, -1.2716e-02],\n",
      "        [-1.8493e-02,  1.7531e-02, -3.5563e-03,  ...,  2.1067e-02,\n",
      "         -2.2005e-02, -3.0181e-03],\n",
      "        ...,\n",
      "        [ 1.3804e-02,  1.5753e-02,  5.7931e-03,  ...,  9.7966e-03,\n",
      "         -1.6645e-03,  1.2222e-02],\n",
      "        [ 8.8284e-02, -1.9281e-02,  5.1524e-03,  ...,  9.1054e-03,\n",
      "         -1.7192e-02,  2.0831e-02],\n",
      "        [ 2.4567e-02,  1.3120e-03, -5.7703e-03,  ...,  6.3537e-03,\n",
      "          2.3343e-02,  1.1591e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 9: train_loss: 2.0348 train_acc: 0.3636 | val_loss: 2.1204 val_acc: 0.3279\n",
      "00:00:07.85\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0732e-02,  8.6891e-03,  1.2938e-02,  ...,  5.8155e-05,\n",
      "         -7.7540e-03, -9.9493e-02],\n",
      "        [ 1.2642e-02,  5.8912e-03,  1.7411e-02,  ..., -2.4810e-03,\n",
      "          9.3456e-03, -1.2659e-02],\n",
      "        [-1.8473e-02,  1.7423e-02, -3.4446e-03,  ...,  2.1096e-02,\n",
      "         -2.2243e-02, -2.8916e-03],\n",
      "        ...,\n",
      "        [ 1.3594e-02,  1.5673e-02,  5.8971e-03,  ...,  1.0041e-02,\n",
      "         -1.5527e-03,  1.2285e-02],\n",
      "        [ 8.8518e-02, -1.9114e-02,  5.1517e-03,  ...,  8.9467e-03,\n",
      "         -1.7394e-02,  2.0819e-02],\n",
      "        [ 2.4747e-02,  1.3488e-03, -5.8985e-03,  ...,  6.2988e-03,\n",
      "          2.3347e-02,  1.1531e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0804e-02,  8.7621e-03,  1.2949e-02,  ..., -1.1872e-05,\n",
      "         -7.7950e-03, -9.9533e-02],\n",
      "        [ 1.2753e-02,  5.9716e-03,  1.7465e-02,  ..., -2.5358e-03,\n",
      "          9.2665e-03, -1.2671e-02],\n",
      "        [-1.8500e-02,  1.7395e-02, -3.5316e-03,  ...,  2.1067e-02,\n",
      "         -2.2076e-02, -2.8951e-03],\n",
      "        ...,\n",
      "        [ 1.3718e-02,  1.5778e-02,  5.8755e-03,  ...,  9.9176e-03,\n",
      "         -1.5601e-03,  1.2228e-02],\n",
      "        [ 8.8369e-02, -1.9245e-02,  5.1134e-03,  ...,  8.9920e-03,\n",
      "         -1.7297e-02,  2.0845e-02],\n",
      "        [ 2.4585e-02,  1.3222e-03, -5.7986e-03,  ...,  6.4403e-03,\n",
      "          2.3306e-02,  1.1602e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 10: train_loss: 1.8581 train_acc: 0.4977 | val_loss: 2.0711 val_acc: 0.3320\n",
      "00:00:07.59\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0407,  0.0086,  0.0128,  ...,  0.0001, -0.0079, -0.0994],\n",
      "        [ 0.0125,  0.0060,  0.0176,  ..., -0.0024,  0.0094, -0.0127],\n",
      "        [-0.0184,  0.0174, -0.0034,  ...,  0.0211, -0.0223, -0.0028],\n",
      "        ...,\n",
      "        [ 0.0136,  0.0156,  0.0059,  ...,  0.0099, -0.0015,  0.0123],\n",
      "        [ 0.0885, -0.0192,  0.0051,  ...,  0.0089, -0.0174,  0.0210],\n",
      "        [ 0.0248,  0.0013, -0.0060,  ...,  0.0064,  0.0233,  0.0115]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0732e-02,  8.6891e-03,  1.2938e-02,  ...,  5.8155e-05,\n",
      "         -7.7540e-03, -9.9493e-02],\n",
      "        [ 1.2642e-02,  5.8912e-03,  1.7411e-02,  ..., -2.4810e-03,\n",
      "          9.3456e-03, -1.2659e-02],\n",
      "        [-1.8473e-02,  1.7423e-02, -3.4446e-03,  ...,  2.1096e-02,\n",
      "         -2.2243e-02, -2.8916e-03],\n",
      "        ...,\n",
      "        [ 1.3594e-02,  1.5673e-02,  5.8971e-03,  ...,  1.0041e-02,\n",
      "         -1.5527e-03,  1.2285e-02],\n",
      "        [ 8.8518e-02, -1.9114e-02,  5.1517e-03,  ...,  8.9467e-03,\n",
      "         -1.7394e-02,  2.0819e-02],\n",
      "        [ 2.4747e-02,  1.3488e-03, -5.8985e-03,  ...,  6.2988e-03,\n",
      "          2.3347e-02,  1.1531e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 11: Best val_acc: 0.3402\n",
      "Epoch 11: Best val_acc: 0.3402\n",
      "Epoch 11: train_loss: 1.7964 train_acc: 0.5273 | val_loss: 2.1179 val_acc: 0.3402\n",
      "00:00:10.96\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0407,  0.0086,  0.0129,  ...,  0.0001, -0.0080, -0.0995],\n",
      "        [ 0.0125,  0.0061,  0.0175,  ..., -0.0025,  0.0095, -0.0128],\n",
      "        [-0.0184,  0.0174, -0.0034,  ...,  0.0211, -0.0223, -0.0027],\n",
      "        ...,\n",
      "        [ 0.0135,  0.0156,  0.0059,  ...,  0.0100, -0.0015,  0.0124],\n",
      "        [ 0.0885, -0.0192,  0.0051,  ...,  0.0088, -0.0174,  0.0210],\n",
      "        [ 0.0248,  0.0013, -0.0061,  ...,  0.0063,  0.0233,  0.0114]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0407,  0.0086,  0.0128,  ...,  0.0001, -0.0079, -0.0994],\n",
      "        [ 0.0125,  0.0060,  0.0176,  ..., -0.0024,  0.0094, -0.0127],\n",
      "        [-0.0184,  0.0174, -0.0034,  ...,  0.0211, -0.0223, -0.0028],\n",
      "        ...,\n",
      "        [ 0.0136,  0.0156,  0.0059,  ...,  0.0099, -0.0015,  0.0123],\n",
      "        [ 0.0885, -0.0192,  0.0051,  ...,  0.0089, -0.0174,  0.0210],\n",
      "        [ 0.0248,  0.0013, -0.0060,  ...,  0.0064,  0.0233,  0.0115]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 12: train_loss: 1.7708 train_acc: 0.4932 | val_loss: 2.0808 val_acc: 0.3238\n",
      "00:00:08.06\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0597e-02,  8.6264e-03,  1.2796e-02,  ...,  2.3548e-05,\n",
      "         -8.0087e-03, -9.9462e-02],\n",
      "        [ 1.2440e-02,  6.0564e-03,  1.7594e-02,  ..., -2.3418e-03,\n",
      "          9.4627e-03, -1.2694e-02],\n",
      "        [-1.8340e-02,  1.7482e-02, -3.3066e-03,  ...,  2.1113e-02,\n",
      "         -2.2346e-02, -2.6408e-03],\n",
      "        ...,\n",
      "        [ 1.3452e-02,  1.5523e-02,  5.8784e-03,  ...,  1.0002e-02,\n",
      "         -1.5300e-03,  1.2342e-02],\n",
      "        [ 8.8472e-02, -1.9054e-02,  5.1914e-03,  ...,  8.7636e-03,\n",
      "         -1.7303e-02,  2.0985e-02],\n",
      "        [ 2.4836e-02,  1.3173e-03, -6.1989e-03,  ...,  6.2171e-03,\n",
      "          2.3411e-02,  1.1370e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0407,  0.0086,  0.0129,  ...,  0.0001, -0.0080, -0.0995],\n",
      "        [ 0.0125,  0.0061,  0.0175,  ..., -0.0025,  0.0095, -0.0128],\n",
      "        [-0.0184,  0.0174, -0.0034,  ...,  0.0211, -0.0223, -0.0027],\n",
      "        ...,\n",
      "        [ 0.0135,  0.0156,  0.0059,  ...,  0.0100, -0.0015,  0.0124],\n",
      "        [ 0.0885, -0.0192,  0.0051,  ...,  0.0088, -0.0174,  0.0210],\n",
      "        [ 0.0248,  0.0013, -0.0061,  ...,  0.0063,  0.0233,  0.0114]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 13: Best val_acc: 0.3402\n",
      "Epoch 13: train_loss: 1.6952 train_acc: 0.5432 | val_loss: 2.0236 val_acc: 0.3402\n",
      "00:00:08.86\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0473e-02,  8.6638e-03,  1.2680e-02,  ..., -3.6008e-05,\n",
      "         -8.0826e-03, -9.9544e-02],\n",
      "        [ 1.2381e-02,  6.0329e-03,  1.7707e-02,  ..., -2.3015e-03,\n",
      "          9.3709e-03, -1.2630e-02],\n",
      "        [-1.8282e-02,  1.7559e-02, -3.2968e-03,  ...,  2.1070e-02,\n",
      "         -2.2431e-02, -2.6112e-03],\n",
      "        ...,\n",
      "        [ 1.3348e-02,  1.5464e-02,  5.8767e-03,  ...,  1.0049e-02,\n",
      "         -1.3767e-03,  1.2330e-02],\n",
      "        [ 8.8491e-02, -1.9036e-02,  5.1747e-03,  ...,  8.7615e-03,\n",
      "         -1.7371e-02,  2.1080e-02],\n",
      "        [ 2.4789e-02,  1.2035e-03, -6.3042e-03,  ...,  6.2149e-03,\n",
      "          2.3456e-02,  1.1421e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0597e-02,  8.6264e-03,  1.2796e-02,  ...,  2.3548e-05,\n",
      "         -8.0087e-03, -9.9462e-02],\n",
      "        [ 1.2440e-02,  6.0564e-03,  1.7594e-02,  ..., -2.3418e-03,\n",
      "          9.4627e-03, -1.2694e-02],\n",
      "        [-1.8340e-02,  1.7482e-02, -3.3066e-03,  ...,  2.1113e-02,\n",
      "         -2.2346e-02, -2.6408e-03],\n",
      "        ...,\n",
      "        [ 1.3452e-02,  1.5523e-02,  5.8784e-03,  ...,  1.0002e-02,\n",
      "         -1.5300e-03,  1.2342e-02],\n",
      "        [ 8.8472e-02, -1.9054e-02,  5.1914e-03,  ...,  8.7636e-03,\n",
      "         -1.7303e-02,  2.0985e-02],\n",
      "        [ 2.4836e-02,  1.3173e-03, -6.1989e-03,  ...,  6.2171e-03,\n",
      "          2.3411e-02,  1.1370e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 14: train_loss: 1.6186 train_acc: 0.5455 | val_loss: 2.0557 val_acc: 0.3361\n",
      "00:00:08.15\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0492e-02,  8.6518e-03,  1.2671e-02,  ..., -4.3556e-05,\n",
      "         -8.0922e-03, -9.9547e-02],\n",
      "        [ 1.2359e-02,  6.0535e-03,  1.7668e-02,  ..., -2.2753e-03,\n",
      "          9.4792e-03, -1.2569e-02],\n",
      "        [-1.8318e-02,  1.7546e-02, -3.3071e-03,  ...,  2.1072e-02,\n",
      "         -2.2435e-02, -2.5659e-03],\n",
      "        ...,\n",
      "        [ 1.3305e-02,  1.5440e-02,  5.9452e-03,  ...,  1.0124e-02,\n",
      "         -1.4489e-03,  1.2328e-02],\n",
      "        [ 8.8505e-02, -1.8976e-02,  5.1080e-03,  ...,  8.6937e-03,\n",
      "         -1.7320e-02,  2.1105e-02],\n",
      "        [ 2.4857e-02,  1.1861e-03, -6.4515e-03,  ...,  6.1607e-03,\n",
      "          2.3448e-02,  1.1374e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0473e-02,  8.6638e-03,  1.2680e-02,  ..., -3.6008e-05,\n",
      "         -8.0826e-03, -9.9544e-02],\n",
      "        [ 1.2381e-02,  6.0329e-03,  1.7707e-02,  ..., -2.3015e-03,\n",
      "          9.3709e-03, -1.2630e-02],\n",
      "        [-1.8282e-02,  1.7559e-02, -3.2968e-03,  ...,  2.1070e-02,\n",
      "         -2.2431e-02, -2.6112e-03],\n",
      "        ...,\n",
      "        [ 1.3348e-02,  1.5464e-02,  5.8767e-03,  ...,  1.0049e-02,\n",
      "         -1.3767e-03,  1.2330e-02],\n",
      "        [ 8.8491e-02, -1.9036e-02,  5.1747e-03,  ...,  8.7615e-03,\n",
      "         -1.7371e-02,  2.1080e-02],\n",
      "        [ 2.4789e-02,  1.2035e-03, -6.3042e-03,  ...,  6.2149e-03,\n",
      "          2.3456e-02,  1.1421e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 15: Best val_acc: 0.3443\n",
      "Epoch 15: Best val_acc: 0.3443\n",
      "Epoch 15: train_loss: 1.5196 train_acc: 0.5818 | val_loss: 2.0889 val_acc: 0.3443\n",
      "00:00:10.08\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0461e-02,  8.5992e-03,  1.2632e-02,  ..., -5.1660e-05,\n",
      "         -8.0650e-03, -9.9483e-02],\n",
      "        [ 1.2191e-02,  6.0091e-03,  1.7749e-02,  ..., -2.1132e-03,\n",
      "          9.4119e-03, -1.2501e-02],\n",
      "        [-1.8287e-02,  1.7549e-02, -3.3925e-03,  ...,  2.1022e-02,\n",
      "         -2.2420e-02, -2.4842e-03],\n",
      "        ...,\n",
      "        [ 1.3271e-02,  1.5413e-02,  6.0355e-03,  ...,  1.0098e-02,\n",
      "         -1.4338e-03,  1.2322e-02],\n",
      "        [ 8.8556e-02, -1.8977e-02,  5.0387e-03,  ...,  8.6264e-03,\n",
      "         -1.7271e-02,  2.1149e-02],\n",
      "        [ 2.4839e-02,  1.1424e-03, -6.5461e-03,  ...,  6.1512e-03,\n",
      "          2.3453e-02,  1.1326e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0492e-02,  8.6518e-03,  1.2671e-02,  ..., -4.3556e-05,\n",
      "         -8.0922e-03, -9.9547e-02],\n",
      "        [ 1.2359e-02,  6.0535e-03,  1.7668e-02,  ..., -2.2753e-03,\n",
      "          9.4792e-03, -1.2569e-02],\n",
      "        [-1.8318e-02,  1.7546e-02, -3.3071e-03,  ...,  2.1072e-02,\n",
      "         -2.2435e-02, -2.5659e-03],\n",
      "        ...,\n",
      "        [ 1.3305e-02,  1.5440e-02,  5.9452e-03,  ...,  1.0124e-02,\n",
      "         -1.4489e-03,  1.2328e-02],\n",
      "        [ 8.8505e-02, -1.8976e-02,  5.1080e-03,  ...,  8.6937e-03,\n",
      "         -1.7320e-02,  2.1105e-02],\n",
      "        [ 2.4857e-02,  1.1861e-03, -6.4515e-03,  ...,  6.1607e-03,\n",
      "          2.3448e-02,  1.1374e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 16: Best val_acc: 0.3648\n",
      "Epoch 16: Best val_acc: 0.3648\n",
      "Epoch 16: train_loss: 1.4310 train_acc: 0.6273 | val_loss: 2.0032 val_acc: 0.3648\n",
      "00:00:09.76\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0404,  0.0087,  0.0125,  ..., -0.0002, -0.0081, -0.0995],\n",
      "        [ 0.0122,  0.0061,  0.0178,  ..., -0.0020,  0.0094, -0.0125],\n",
      "        [-0.0183,  0.0176, -0.0033,  ...,  0.0211, -0.0225, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0132,  0.0153,  0.0060,  ...,  0.0101, -0.0013,  0.0123],\n",
      "        [ 0.0885, -0.0189,  0.0051,  ...,  0.0086, -0.0173,  0.0211],\n",
      "        [ 0.0249,  0.0012, -0.0067,  ...,  0.0060,  0.0234,  0.0114]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0461e-02,  8.5992e-03,  1.2632e-02,  ..., -5.1660e-05,\n",
      "         -8.0650e-03, -9.9483e-02],\n",
      "        [ 1.2191e-02,  6.0091e-03,  1.7749e-02,  ..., -2.1132e-03,\n",
      "          9.4119e-03, -1.2501e-02],\n",
      "        [-1.8287e-02,  1.7549e-02, -3.3925e-03,  ...,  2.1022e-02,\n",
      "         -2.2420e-02, -2.4842e-03],\n",
      "        ...,\n",
      "        [ 1.3271e-02,  1.5413e-02,  6.0355e-03,  ...,  1.0098e-02,\n",
      "         -1.4338e-03,  1.2322e-02],\n",
      "        [ 8.8556e-02, -1.8977e-02,  5.0387e-03,  ...,  8.6264e-03,\n",
      "         -1.7271e-02,  2.1149e-02],\n",
      "        [ 2.4839e-02,  1.1424e-03, -6.5461e-03,  ...,  6.1512e-03,\n",
      "          2.3453e-02,  1.1326e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 17: Best val_acc: 0.3811\n",
      "Epoch 17: Best val_acc: 0.3811\n",
      "Epoch 17: train_loss: 1.4203 train_acc: 0.6182 | val_loss: 1.9631 val_acc: 0.3811\n",
      "00:00:09.69\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0403,  0.0087,  0.0125,  ..., -0.0002, -0.0081, -0.0995],\n",
      "        [ 0.0121,  0.0060,  0.0179,  ..., -0.0020,  0.0095, -0.0125],\n",
      "        [-0.0183,  0.0176, -0.0033,  ...,  0.0211, -0.0225, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0132,  0.0154,  0.0060,  ...,  0.0101, -0.0013,  0.0122],\n",
      "        [ 0.0885, -0.0189,  0.0052,  ...,  0.0086, -0.0173,  0.0212],\n",
      "        [ 0.0250,  0.0012, -0.0068,  ...,  0.0060,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0404,  0.0087,  0.0125,  ..., -0.0002, -0.0081, -0.0995],\n",
      "        [ 0.0122,  0.0061,  0.0178,  ..., -0.0020,  0.0094, -0.0125],\n",
      "        [-0.0183,  0.0176, -0.0033,  ...,  0.0211, -0.0225, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0132,  0.0153,  0.0060,  ...,  0.0101, -0.0013,  0.0123],\n",
      "        [ 0.0885, -0.0189,  0.0051,  ...,  0.0086, -0.0173,  0.0211],\n",
      "        [ 0.0249,  0.0012, -0.0067,  ...,  0.0060,  0.0234,  0.0114]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 18: train_loss: 1.3817 train_acc: 0.6364 | val_loss: 2.0332 val_acc: 0.3607\n",
      "00:00:07.49\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.0316e-02,  8.7350e-03,  1.2474e-02,  ..., -8.6175e-05,\n",
      "         -8.1831e-03, -9.9554e-02],\n",
      "        [ 1.1999e-02,  6.0000e-03,  1.7840e-02,  ..., -2.0164e-03,\n",
      "          9.5592e-03, -1.2425e-02],\n",
      "        [-1.8240e-02,  1.7651e-02, -3.2847e-03,  ...,  2.1018e-02,\n",
      "         -2.2583e-02, -2.4239e-03],\n",
      "        ...,\n",
      "        [ 1.3143e-02,  1.5370e-02,  6.1150e-03,  ...,  1.0057e-02,\n",
      "         -1.3032e-03,  1.2265e-02],\n",
      "        [ 8.8535e-02, -1.8874e-02,  5.1383e-03,  ...,  8.5646e-03,\n",
      "         -1.7316e-02,  2.1278e-02],\n",
      "        [ 2.4962e-02,  1.2314e-03, -6.8712e-03,  ...,  6.0111e-03,\n",
      "          2.3478e-02,  1.1291e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0403,  0.0087,  0.0125,  ..., -0.0002, -0.0081, -0.0995],\n",
      "        [ 0.0121,  0.0060,  0.0179,  ..., -0.0020,  0.0095, -0.0125],\n",
      "        [-0.0183,  0.0176, -0.0033,  ...,  0.0211, -0.0225, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0132,  0.0154,  0.0060,  ...,  0.0101, -0.0013,  0.0122],\n",
      "        [ 0.0885, -0.0189,  0.0052,  ...,  0.0086, -0.0173,  0.0212],\n",
      "        [ 0.0250,  0.0012, -0.0068,  ...,  0.0060,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 19: train_loss: 1.3601 train_acc: 0.6545 | val_loss: 2.0260 val_acc: 0.3566\n",
      "00:00:07.62\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0402,  0.0088,  0.0124,  ..., -0.0001, -0.0083, -0.0995],\n",
      "        [ 0.0119,  0.0060,  0.0179,  ..., -0.0020,  0.0096, -0.0123],\n",
      "        [-0.0182,  0.0177, -0.0033,  ...,  0.0210, -0.0226, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0130,  0.0154,  0.0062,  ...,  0.0101, -0.0013,  0.0122],\n",
      "        [ 0.0886, -0.0188,  0.0050,  ...,  0.0085, -0.0173,  0.0213],\n",
      "        [ 0.0249,  0.0012, -0.0069,  ...,  0.0060,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.0316e-02,  8.7350e-03,  1.2474e-02,  ..., -8.6175e-05,\n",
      "         -8.1831e-03, -9.9554e-02],\n",
      "        [ 1.1999e-02,  6.0000e-03,  1.7840e-02,  ..., -2.0164e-03,\n",
      "          9.5592e-03, -1.2425e-02],\n",
      "        [-1.8240e-02,  1.7651e-02, -3.2847e-03,  ...,  2.1018e-02,\n",
      "         -2.2583e-02, -2.4239e-03],\n",
      "        ...,\n",
      "        [ 1.3143e-02,  1.5370e-02,  6.1150e-03,  ...,  1.0057e-02,\n",
      "         -1.3032e-03,  1.2265e-02],\n",
      "        [ 8.8535e-02, -1.8874e-02,  5.1383e-03,  ...,  8.5646e-03,\n",
      "         -1.7316e-02,  2.1278e-02],\n",
      "        [ 2.4962e-02,  1.2314e-03, -6.8712e-03,  ...,  6.0111e-03,\n",
      "          2.3478e-02,  1.1291e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 20: Best val_acc: 0.3893\n",
      "Epoch 20: Best val_acc: 0.3893\n",
      "Epoch 20: train_loss: 1.1820 train_acc: 0.7182 | val_loss: 2.0115 val_acc: 0.3893\n",
      "00:00:09.41\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0401,  0.0088,  0.0122,  ..., -0.0002, -0.0083, -0.0995],\n",
      "        [ 0.0119,  0.0060,  0.0179,  ..., -0.0018,  0.0095, -0.0123],\n",
      "        [-0.0182,  0.0178, -0.0033,  ...,  0.0210, -0.0227, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0129,  0.0153,  0.0063,  ...,  0.0101, -0.0013,  0.0122],\n",
      "        [ 0.0886, -0.0188,  0.0050,  ...,  0.0085, -0.0174,  0.0213],\n",
      "        [ 0.0250,  0.0012, -0.0070,  ...,  0.0059,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0402,  0.0088,  0.0124,  ..., -0.0001, -0.0083, -0.0995],\n",
      "        [ 0.0119,  0.0060,  0.0179,  ..., -0.0020,  0.0096, -0.0123],\n",
      "        [-0.0182,  0.0177, -0.0033,  ...,  0.0210, -0.0226, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0130,  0.0154,  0.0062,  ...,  0.0101, -0.0013,  0.0122],\n",
      "        [ 0.0886, -0.0188,  0.0050,  ...,  0.0085, -0.0173,  0.0213],\n",
      "        [ 0.0249,  0.0012, -0.0069,  ...,  0.0060,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 21: train_loss: 1.1162 train_acc: 0.7114 | val_loss: 1.9929 val_acc: 0.3770\n",
      "00:00:07.97\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0400,  0.0089,  0.0122,  ..., -0.0003, -0.0084, -0.0995],\n",
      "        [ 0.0118,  0.0060,  0.0179,  ..., -0.0018,  0.0096, -0.0121],\n",
      "        [-0.0181,  0.0178, -0.0033,  ...,  0.0209, -0.0228, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0129,  0.0154,  0.0063,  ...,  0.0102, -0.0012,  0.0121],\n",
      "        [ 0.0886, -0.0188,  0.0050,  ...,  0.0085, -0.0174,  0.0214],\n",
      "        [ 0.0250,  0.0011, -0.0071,  ...,  0.0059,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0401,  0.0088,  0.0122,  ..., -0.0002, -0.0083, -0.0995],\n",
      "        [ 0.0119,  0.0060,  0.0179,  ..., -0.0018,  0.0095, -0.0123],\n",
      "        [-0.0182,  0.0178, -0.0033,  ...,  0.0210, -0.0227, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0129,  0.0153,  0.0063,  ...,  0.0101, -0.0013,  0.0122],\n",
      "        [ 0.0886, -0.0188,  0.0050,  ...,  0.0085, -0.0174,  0.0213],\n",
      "        [ 0.0250,  0.0012, -0.0070,  ...,  0.0059,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 22: train_loss: 1.1095 train_acc: 0.7205 | val_loss: 2.0570 val_acc: 0.3770\n",
      "00:00:07.79\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0400,  0.0089,  0.0121,  ..., -0.0004, -0.0085, -0.0995],\n",
      "        [ 0.0117,  0.0060,  0.0179,  ..., -0.0017,  0.0097, -0.0121],\n",
      "        [-0.0181,  0.0179, -0.0033,  ...,  0.0208, -0.0227, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0128,  0.0154,  0.0063,  ...,  0.0102, -0.0012,  0.0120],\n",
      "        [ 0.0886, -0.0187,  0.0050,  ...,  0.0084, -0.0174,  0.0214],\n",
      "        [ 0.0250,  0.0011, -0.0073,  ...,  0.0059,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0400,  0.0089,  0.0122,  ..., -0.0003, -0.0084, -0.0995],\n",
      "        [ 0.0118,  0.0060,  0.0179,  ..., -0.0018,  0.0096, -0.0121],\n",
      "        [-0.0181,  0.0178, -0.0033,  ...,  0.0209, -0.0228, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0129,  0.0154,  0.0063,  ...,  0.0102, -0.0012,  0.0121],\n",
      "        [ 0.0886, -0.0188,  0.0050,  ...,  0.0085, -0.0174,  0.0214],\n",
      "        [ 0.0250,  0.0011, -0.0071,  ...,  0.0059,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 23: train_loss: 1.1197 train_acc: 0.7182 | val_loss: 2.1143 val_acc: 0.3443\n",
      "00:00:07.67\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0399,  0.0090,  0.0121,  ..., -0.0004, -0.0086, -0.0996],\n",
      "        [ 0.0116,  0.0059,  0.0179,  ..., -0.0016,  0.0096, -0.0119],\n",
      "        [-0.0180,  0.0180, -0.0032,  ...,  0.0208, -0.0228, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0127,  0.0154,  0.0064,  ...,  0.0102, -0.0012,  0.0119],\n",
      "        [ 0.0887, -0.0187,  0.0050,  ...,  0.0084, -0.0174,  0.0214],\n",
      "        [ 0.0251,  0.0010, -0.0074,  ...,  0.0059,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0400,  0.0089,  0.0121,  ..., -0.0004, -0.0085, -0.0995],\n",
      "        [ 0.0117,  0.0060,  0.0179,  ..., -0.0017,  0.0097, -0.0121],\n",
      "        [-0.0181,  0.0179, -0.0033,  ...,  0.0208, -0.0227, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0128,  0.0154,  0.0063,  ...,  0.0102, -0.0012,  0.0120],\n",
      "        [ 0.0886, -0.0187,  0.0050,  ...,  0.0084, -0.0174,  0.0214],\n",
      "        [ 0.0250,  0.0011, -0.0073,  ...,  0.0059,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 24: train_loss: 1.0471 train_acc: 0.7364 | val_loss: 2.0887 val_acc: 0.3811\n",
      "00:00:07.55\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0398,  0.0090,  0.0121,  ..., -0.0005, -0.0087, -0.0995],\n",
      "        [ 0.0115,  0.0059,  0.0178,  ..., -0.0016,  0.0096, -0.0119],\n",
      "        [-0.0179,  0.0181, -0.0031,  ...,  0.0208, -0.0229, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0127,  0.0154,  0.0063,  ...,  0.0102, -0.0012,  0.0119],\n",
      "        [ 0.0886, -0.0187,  0.0050,  ...,  0.0084, -0.0173,  0.0214],\n",
      "        [ 0.0251,  0.0011, -0.0075,  ...,  0.0058,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0399,  0.0090,  0.0121,  ..., -0.0004, -0.0086, -0.0996],\n",
      "        [ 0.0116,  0.0059,  0.0179,  ..., -0.0016,  0.0096, -0.0119],\n",
      "        [-0.0180,  0.0180, -0.0032,  ...,  0.0208, -0.0228, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0127,  0.0154,  0.0064,  ...,  0.0102, -0.0012,  0.0119],\n",
      "        [ 0.0887, -0.0187,  0.0050,  ...,  0.0084, -0.0174,  0.0214],\n",
      "        [ 0.0251,  0.0010, -0.0074,  ...,  0.0059,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 25: train_loss: 0.8388 train_acc: 0.8000 | val_loss: 2.0243 val_acc: 0.3852\n",
      "00:00:07.56\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0397,  0.0090,  0.0120,  ..., -0.0005, -0.0088, -0.0994],\n",
      "        [ 0.0114,  0.0058,  0.0179,  ..., -0.0015,  0.0097, -0.0118],\n",
      "        [-0.0178,  0.0181, -0.0031,  ...,  0.0207, -0.0229, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0127,  0.0155,  0.0063,  ...,  0.0102, -0.0012,  0.0119],\n",
      "        [ 0.0887, -0.0187,  0.0050,  ...,  0.0084, -0.0174,  0.0214],\n",
      "        [ 0.0251,  0.0010, -0.0075,  ...,  0.0058,  0.0235,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0398,  0.0090,  0.0121,  ..., -0.0005, -0.0087, -0.0995],\n",
      "        [ 0.0115,  0.0059,  0.0178,  ..., -0.0016,  0.0096, -0.0119],\n",
      "        [-0.0179,  0.0181, -0.0031,  ...,  0.0208, -0.0229, -0.0024],\n",
      "        ...,\n",
      "        [ 0.0127,  0.0154,  0.0063,  ...,  0.0102, -0.0012,  0.0119],\n",
      "        [ 0.0886, -0.0187,  0.0050,  ...,  0.0084, -0.0173,  0.0214],\n",
      "        [ 0.0251,  0.0011, -0.0075,  ...,  0.0058,  0.0235,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 26: Best val_acc: 0.4303\n",
      "Epoch 26: Best val_acc: 0.4303\n",
      "Epoch 26: train_loss: 0.8039 train_acc: 0.8136 | val_loss: 2.0431 val_acc: 0.4303\n",
      "00:00:09.38\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0091,  0.0120,  ..., -0.0005, -0.0088, -0.0996],\n",
      "        [ 0.0113,  0.0059,  0.0179,  ..., -0.0014,  0.0097, -0.0118],\n",
      "        [-0.0177,  0.0182, -0.0031,  ...,  0.0207, -0.0229, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0155,  0.0064,  ...,  0.0102, -0.0011,  0.0118],\n",
      "        [ 0.0887, -0.0187,  0.0050,  ...,  0.0083, -0.0174,  0.0215],\n",
      "        [ 0.0251,  0.0010, -0.0076,  ...,  0.0057,  0.0235,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0397,  0.0090,  0.0120,  ..., -0.0005, -0.0088, -0.0994],\n",
      "        [ 0.0114,  0.0058,  0.0179,  ..., -0.0015,  0.0097, -0.0118],\n",
      "        [-0.0178,  0.0181, -0.0031,  ...,  0.0207, -0.0229, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0127,  0.0155,  0.0063,  ...,  0.0102, -0.0012,  0.0119],\n",
      "        [ 0.0887, -0.0187,  0.0050,  ...,  0.0084, -0.0174,  0.0214],\n",
      "        [ 0.0251,  0.0010, -0.0075,  ...,  0.0058,  0.0235,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 27: train_loss: 0.9553 train_acc: 0.7568 | val_loss: 2.0898 val_acc: 0.3566\n",
      "00:00:07.40\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0091,  0.0118,  ..., -0.0006, -0.0089, -0.0996],\n",
      "        [ 0.0112,  0.0058,  0.0179,  ..., -0.0013,  0.0096, -0.0117],\n",
      "        [-0.0177,  0.0182, -0.0031,  ...,  0.0206, -0.0230, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0125,  0.0155,  0.0065,  ...,  0.0102, -0.0010,  0.0117],\n",
      "        [ 0.0888, -0.0186,  0.0050,  ...,  0.0083, -0.0173,  0.0215],\n",
      "        [ 0.0252,  0.0010, -0.0077,  ...,  0.0057,  0.0235,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0091,  0.0120,  ..., -0.0005, -0.0088, -0.0996],\n",
      "        [ 0.0113,  0.0059,  0.0179,  ..., -0.0014,  0.0097, -0.0118],\n",
      "        [-0.0177,  0.0182, -0.0031,  ...,  0.0207, -0.0229, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0155,  0.0064,  ...,  0.0102, -0.0011,  0.0118],\n",
      "        [ 0.0887, -0.0187,  0.0050,  ...,  0.0083, -0.0174,  0.0215],\n",
      "        [ 0.0251,  0.0010, -0.0076,  ...,  0.0057,  0.0235,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 28: train_loss: 0.9447 train_acc: 0.7432 | val_loss: 2.0572 val_acc: 0.3934\n",
      "00:00:07.70\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0091,  0.0119,  ..., -0.0007, -0.0090, -0.0996],\n",
      "        [ 0.0111,  0.0058,  0.0179,  ..., -0.0013,  0.0097, -0.0117],\n",
      "        [-0.0176,  0.0182, -0.0031,  ...,  0.0206, -0.0230, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0124,  0.0155,  0.0065,  ...,  0.0103, -0.0010,  0.0117],\n",
      "        [ 0.0888, -0.0187,  0.0050,  ...,  0.0083, -0.0173,  0.0216],\n",
      "        [ 0.0252,  0.0010, -0.0078,  ...,  0.0056,  0.0236,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0091,  0.0118,  ..., -0.0006, -0.0089, -0.0996],\n",
      "        [ 0.0112,  0.0058,  0.0179,  ..., -0.0013,  0.0096, -0.0117],\n",
      "        [-0.0177,  0.0182, -0.0031,  ...,  0.0206, -0.0230, -0.0023],\n",
      "        ...,\n",
      "        [ 0.0125,  0.0155,  0.0065,  ...,  0.0102, -0.0010,  0.0117],\n",
      "        [ 0.0888, -0.0186,  0.0050,  ...,  0.0083, -0.0173,  0.0215],\n",
      "        [ 0.0252,  0.0010, -0.0077,  ...,  0.0057,  0.0235,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 29: train_loss: 0.7189 train_acc: 0.8455 | val_loss: 2.0737 val_acc: 0.3975\n",
      "00:00:07.33\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0092,  0.0118,  ..., -0.0007, -0.0090, -0.0996],\n",
      "        [ 0.0110,  0.0057,  0.0179,  ..., -0.0013,  0.0098, -0.0117],\n",
      "        [-0.0176,  0.0183, -0.0031,  ...,  0.0207, -0.0231, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0124,  0.0156,  0.0065,  ...,  0.0103, -0.0010,  0.0116],\n",
      "        [ 0.0888, -0.0187,  0.0050,  ...,  0.0082, -0.0174,  0.0216],\n",
      "        [ 0.0253,  0.0010, -0.0079,  ...,  0.0055,  0.0236,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0091,  0.0119,  ..., -0.0007, -0.0090, -0.0996],\n",
      "        [ 0.0111,  0.0058,  0.0179,  ..., -0.0013,  0.0097, -0.0117],\n",
      "        [-0.0176,  0.0182, -0.0031,  ...,  0.0206, -0.0230, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0124,  0.0155,  0.0065,  ...,  0.0103, -0.0010,  0.0117],\n",
      "        [ 0.0888, -0.0187,  0.0050,  ...,  0.0083, -0.0173,  0.0216],\n",
      "        [ 0.0252,  0.0010, -0.0078,  ...,  0.0056,  0.0236,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 30: train_loss: 0.6753 train_acc: 0.8432 | val_loss: 2.0907 val_acc: 0.3689\n",
      "00:00:07.38\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0092,  0.0118,  ..., -0.0007, -0.0091, -0.0995],\n",
      "        [ 0.0110,  0.0057,  0.0179,  ..., -0.0012,  0.0098, -0.0116],\n",
      "        [-0.0176,  0.0183, -0.0032,  ...,  0.0206, -0.0232, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0123,  0.0156,  0.0066,  ...,  0.0103, -0.0009,  0.0116],\n",
      "        [ 0.0889, -0.0187,  0.0050,  ...,  0.0082, -0.0175,  0.0217],\n",
      "        [ 0.0253,  0.0010, -0.0079,  ...,  0.0055,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0092,  0.0118,  ..., -0.0007, -0.0090, -0.0996],\n",
      "        [ 0.0110,  0.0057,  0.0179,  ..., -0.0013,  0.0098, -0.0117],\n",
      "        [-0.0176,  0.0183, -0.0031,  ...,  0.0207, -0.0231, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0124,  0.0156,  0.0065,  ...,  0.0103, -0.0010,  0.0116],\n",
      "        [ 0.0888, -0.0187,  0.0050,  ...,  0.0082, -0.0174,  0.0216],\n",
      "        [ 0.0253,  0.0010, -0.0079,  ...,  0.0055,  0.0236,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 31: train_loss: 0.6496 train_acc: 0.8477 | val_loss: 2.0919 val_acc: 0.3934\n",
      "00:00:08.15\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0395,  0.0092,  0.0118,  ..., -0.0008, -0.0092, -0.0995],\n",
      "        [ 0.0110,  0.0056,  0.0179,  ..., -0.0012,  0.0099, -0.0115],\n",
      "        [-0.0176,  0.0183, -0.0032,  ...,  0.0206, -0.0232, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0123,  0.0156,  0.0067,  ...,  0.0102, -0.0009,  0.0115],\n",
      "        [ 0.0888, -0.0187,  0.0050,  ...,  0.0082, -0.0176,  0.0218],\n",
      "        [ 0.0254,  0.0010, -0.0080,  ...,  0.0055,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0092,  0.0118,  ..., -0.0007, -0.0091, -0.0995],\n",
      "        [ 0.0110,  0.0057,  0.0179,  ..., -0.0012,  0.0098, -0.0116],\n",
      "        [-0.0176,  0.0183, -0.0032,  ...,  0.0206, -0.0232, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0123,  0.0156,  0.0066,  ...,  0.0103, -0.0009,  0.0116],\n",
      "        [ 0.0889, -0.0187,  0.0050,  ...,  0.0082, -0.0175,  0.0217],\n",
      "        [ 0.0253,  0.0010, -0.0079,  ...,  0.0055,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 32: train_loss: 0.6341 train_acc: 0.8568 | val_loss: 2.1334 val_acc: 0.3730\n",
      "00:00:09.08\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0395,  0.0092,  0.0117,  ..., -0.0009, -0.0093, -0.0995],\n",
      "        [ 0.0110,  0.0056,  0.0179,  ..., -0.0012,  0.0099, -0.0114],\n",
      "        [-0.0175,  0.0183, -0.0032,  ...,  0.0206, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0122,  0.0157,  0.0068,  ...,  0.0102, -0.0009,  0.0115],\n",
      "        [ 0.0889, -0.0186,  0.0050,  ...,  0.0082, -0.0176,  0.0218],\n",
      "        [ 0.0254,  0.0009, -0.0082,  ...,  0.0054,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0395,  0.0092,  0.0118,  ..., -0.0008, -0.0092, -0.0995],\n",
      "        [ 0.0110,  0.0056,  0.0179,  ..., -0.0012,  0.0099, -0.0115],\n",
      "        [-0.0176,  0.0183, -0.0032,  ...,  0.0206, -0.0232, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0123,  0.0156,  0.0067,  ...,  0.0102, -0.0009,  0.0115],\n",
      "        [ 0.0888, -0.0187,  0.0050,  ...,  0.0082, -0.0176,  0.0218],\n",
      "        [ 0.0254,  0.0010, -0.0080,  ...,  0.0055,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 33: train_loss: 0.6127 train_acc: 0.8591 | val_loss: 2.2477 val_acc: 0.3648\n",
      "00:00:09.27\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0092,  0.0117,  ..., -0.0010, -0.0093, -0.0995],\n",
      "        [ 0.0108,  0.0055,  0.0179,  ..., -0.0011,  0.0099, -0.0113],\n",
      "        [-0.0175,  0.0184, -0.0032,  ...,  0.0206, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0122,  0.0157,  0.0068,  ...,  0.0103, -0.0009,  0.0115],\n",
      "        [ 0.0889, -0.0186,  0.0049,  ...,  0.0081, -0.0176,  0.0218],\n",
      "        [ 0.0255,  0.0009, -0.0083,  ...,  0.0054,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0395,  0.0092,  0.0117,  ..., -0.0009, -0.0093, -0.0995],\n",
      "        [ 0.0110,  0.0056,  0.0179,  ..., -0.0012,  0.0099, -0.0114],\n",
      "        [-0.0175,  0.0183, -0.0032,  ...,  0.0206, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0122,  0.0157,  0.0068,  ...,  0.0102, -0.0009,  0.0115],\n",
      "        [ 0.0889, -0.0186,  0.0050,  ...,  0.0082, -0.0176,  0.0218],\n",
      "        [ 0.0254,  0.0009, -0.0082,  ...,  0.0054,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 34: train_loss: 0.5688 train_acc: 0.8636 | val_loss: 2.1615 val_acc: 0.3730\n",
      "00:00:09.09\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0093,  0.0116,  ..., -0.0011, -0.0094, -0.0995],\n",
      "        [ 0.0107,  0.0055,  0.0179,  ..., -0.0010,  0.0099, -0.0113],\n",
      "        [-0.0174,  0.0184, -0.0032,  ...,  0.0205, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0157,  0.0069,  ...,  0.0102, -0.0009,  0.0115],\n",
      "        [ 0.0890, -0.0186,  0.0049,  ...,  0.0081, -0.0176,  0.0218],\n",
      "        [ 0.0256,  0.0009, -0.0084,  ...,  0.0054,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0092,  0.0117,  ..., -0.0010, -0.0093, -0.0995],\n",
      "        [ 0.0108,  0.0055,  0.0179,  ..., -0.0011,  0.0099, -0.0113],\n",
      "        [-0.0175,  0.0184, -0.0032,  ...,  0.0206, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0122,  0.0157,  0.0068,  ...,  0.0103, -0.0009,  0.0115],\n",
      "        [ 0.0889, -0.0186,  0.0049,  ...,  0.0081, -0.0176,  0.0218],\n",
      "        [ 0.0255,  0.0009, -0.0083,  ...,  0.0054,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 35: train_loss: 0.5560 train_acc: 0.8750 | val_loss: 2.2245 val_acc: 0.3689\n",
      "00:00:09.03\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0094,  0.0116,  ..., -0.0011, -0.0095, -0.0995],\n",
      "        [ 0.0107,  0.0055,  0.0178,  ..., -0.0010,  0.0099, -0.0113],\n",
      "        [-0.0174,  0.0185, -0.0032,  ...,  0.0205, -0.0232, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0157,  0.0069,  ...,  0.0103, -0.0008,  0.0114],\n",
      "        [ 0.0889, -0.0185,  0.0049,  ...,  0.0080, -0.0176,  0.0218],\n",
      "        [ 0.0255,  0.0010, -0.0085,  ...,  0.0053,  0.0237,  0.0111]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0093,  0.0116,  ..., -0.0011, -0.0094, -0.0995],\n",
      "        [ 0.0107,  0.0055,  0.0179,  ..., -0.0010,  0.0099, -0.0113],\n",
      "        [-0.0174,  0.0184, -0.0032,  ...,  0.0205, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0157,  0.0069,  ...,  0.0102, -0.0009,  0.0115],\n",
      "        [ 0.0890, -0.0186,  0.0049,  ...,  0.0081, -0.0176,  0.0218],\n",
      "        [ 0.0256,  0.0009, -0.0084,  ...,  0.0054,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 36: train_loss: 0.4672 train_acc: 0.9091 | val_loss: 2.2082 val_acc: 0.3893\n",
      "00:00:08.70\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0094,  0.0115,  ..., -0.0012, -0.0096, -0.0995],\n",
      "        [ 0.0106,  0.0054,  0.0178,  ..., -0.0010,  0.0099, -0.0112],\n",
      "        [-0.0173,  0.0186, -0.0033,  ...,  0.0204, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0158,  0.0070,  ...,  0.0102, -0.0008,  0.0114],\n",
      "        [ 0.0889, -0.0185,  0.0049,  ...,  0.0080, -0.0176,  0.0219],\n",
      "        [ 0.0256,  0.0009, -0.0086,  ...,  0.0053,  0.0236,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0094,  0.0116,  ..., -0.0011, -0.0095, -0.0995],\n",
      "        [ 0.0107,  0.0055,  0.0178,  ..., -0.0010,  0.0099, -0.0113],\n",
      "        [-0.0174,  0.0185, -0.0032,  ...,  0.0205, -0.0232, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0157,  0.0069,  ...,  0.0103, -0.0008,  0.0114],\n",
      "        [ 0.0889, -0.0185,  0.0049,  ...,  0.0080, -0.0176,  0.0218],\n",
      "        [ 0.0255,  0.0010, -0.0085,  ...,  0.0053,  0.0237,  0.0111]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 00037: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 37: train_loss: 0.4268 train_acc: 0.9114 | val_loss: 2.2516 val_acc: 0.3770\n",
      "00:00:07.35\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0094,  0.0115,  ..., -0.0013, -0.0097, -0.0995],\n",
      "        [ 0.0105,  0.0054,  0.0179,  ..., -0.0009,  0.0099, -0.0111],\n",
      "        [-0.0173,  0.0186, -0.0033,  ...,  0.0204, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0158,  0.0070,  ...,  0.0103, -0.0007,  0.0113],\n",
      "        [ 0.0890, -0.0185,  0.0049,  ...,  0.0079, -0.0177,  0.0219],\n",
      "        [ 0.0257,  0.0009, -0.0086,  ...,  0.0052,  0.0237,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0394,  0.0094,  0.0115,  ..., -0.0012, -0.0096, -0.0995],\n",
      "        [ 0.0106,  0.0054,  0.0178,  ..., -0.0010,  0.0099, -0.0112],\n",
      "        [-0.0173,  0.0186, -0.0033,  ...,  0.0204, -0.0233, -0.0020],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0158,  0.0070,  ...,  0.0102, -0.0008,  0.0114],\n",
      "        [ 0.0889, -0.0185,  0.0049,  ...,  0.0080, -0.0176,  0.0219],\n",
      "        [ 0.0256,  0.0009, -0.0086,  ...,  0.0053,  0.0236,  0.0112]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9998096957181891, 0.9999533185424904, 0.9999753075341383, 0.999984908150509, 0.9999860101379454, 0.9999878578043232, 0.9999905493265638, 0.9999909804513057, 0.9999924387472371, 0.9999923186842352, 0.9999919906258583, 0.9999928098016729, 0.9999930400711795, 0.9999941959201047, 0.9999935736414045, 0.9999934809748083, 0.9999942496263733, 0.9999947599911442, 0.999994740045319, 0.9999946218449622, 0.9999951463347921, 0.9999948154048374, 0.9999947544808189, 0.9999952469176302, 0.999995389720425, 0.9999951232845584, 0.999995460966602, 0.9999949427631994, 0.9999952785049876, 0.9999954570860913, 0.9999958615905294, 0.9999961873205999, 0.9999960616696626, 0.9999961613211781, 0.9999961053642134, 0.9999958931778868, 0.9999963607018193]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_w['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Row wise average cos similarity')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule(\n",
      "  (feature_modules): ModuleDict(\n",
      "    (distance): Embedding(5, 3, padding_idx=0)\n",
      "    (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "    (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "    (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "    (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "    (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "    (sat_children): Identity()\n",
      "    (nuc_children): Identity()\n",
      "  )\n",
      ")\n",
      "ModuleDict(\n",
      "  (distance): Embedding(5, 3, padding_idx=0)\n",
      "  (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "  (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "  (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "  (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "  (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "  (sat_children): Identity()\n",
      "  (nuc_children): Identity()\n",
      ")\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(23, 5, padding_idx=0)\n",
      "Embedding(12, 4, padding_idx=0)\n",
      "Embedding(12, 4, padding_idx=0)\n",
      "Identity()\n",
      "Identity()\n"
     ]
    }
   ],
   "source": [
    "for i in model.module1.modules():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.6175 test_acc: 0.2962\n",
      "00:00:01.00\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.33      0.28      0.30        18\n",
      "    background       0.21      0.18      0.19        17\n",
      "         cause       0.20      1.00      0.33         2\n",
      "  circumstance       0.36      0.33      0.34        15\n",
      "    concession       0.44      0.54      0.48        13\n",
      "     condition       0.47      0.89      0.62         9\n",
      "   conjunction       0.27      0.57      0.36         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.78      0.64      0.70        11\n",
      "   elaboration       0.12      0.20      0.15        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.75      0.18      0.29        17\n",
      "      evidence       0.07      0.10      0.08        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.29      0.28      0.28        29\n",
      "          list       0.56      0.38      0.45        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.67      0.50      0.57         4\n",
      "       purpose       0.67      0.67      0.67         3\n",
      "        reason       0.29      0.24      0.26        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.30       260\n",
      "     macro avg       0.26      0.28      0.24       260\n",
      "  weighted avg       0.34      0.30      0.30       260\n",
      "\n",
      "Test Loss: 2.617 |  Test Acc: 29.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#latest\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.3590 test_acc: 0.2846\n",
      "00:00:00.83\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.22      0.11      0.15        18\n",
      "    background       0.22      0.35      0.27        17\n",
      "         cause       0.25      1.00      0.40         2\n",
      "  circumstance       0.15      0.13      0.14        15\n",
      "    concession       0.44      0.54      0.48        13\n",
      "     condition       0.44      0.89      0.59         9\n",
      "   conjunction       0.23      0.43      0.30         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.67      0.55      0.60        11\n",
      "   elaboration       0.10      0.40      0.16        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.14      0.10      0.12        10\n",
      "interpretation       0.04      0.08      0.06        12\n",
      "         joint       0.26      0.21      0.23        29\n",
      "          list       0.48      0.50      0.49        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.50      0.50      0.50         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.47      0.26      0.34        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.28       260\n",
      "     macro avg       0.23      0.28      0.23       260\n",
      "  weighted avg       0.28      0.28      0.27       260\n",
      "\n",
      "Latest Test Loss: 2.359 |  Latest Test Acc: 28.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best earliest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.3590 test_acc: 0.2846\n",
      "00:00:00.94\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.22      0.11      0.15        18\n",
      "    background       0.22      0.35      0.27        17\n",
      "         cause       0.25      1.00      0.40         2\n",
      "  circumstance       0.15      0.13      0.14        15\n",
      "    concession       0.44      0.54      0.48        13\n",
      "     condition       0.44      0.89      0.59         9\n",
      "   conjunction       0.23      0.43      0.30         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.67      0.55      0.60        11\n",
      "   elaboration       0.10      0.40      0.16        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.14      0.10      0.12        10\n",
      "interpretation       0.04      0.08      0.06        12\n",
      "         joint       0.26      0.21      0.23        29\n",
      "          list       0.48      0.50      0.49        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.50      0.50      0.50         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.47      0.26      0.34        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.28       260\n",
      "     macro avg       0.23      0.28      0.23       260\n",
      "  weighted avg       0.28      0.28      0.27       260\n",
      "\n",
      "Best Test Loss: 2.359 |  Best Test Acc: 28.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best lastest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_latest', test_acc, 1)\n",
    "print(f'Best Test Loss: {test_loss:.3f} |  Best Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.0949 test_acc: 0.4180\n",
      "00:00:00.80\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.14      0.09      0.11        11\n",
      "    background       0.36      0.59      0.44        17\n",
      "         cause       0.50      0.29      0.36         7\n",
      "  circumstance       0.67      0.31      0.42        13\n",
      "    concession       0.33      0.55      0.41        11\n",
      "     condition       0.50      0.88      0.64         8\n",
      "   conjunction       0.70      0.88      0.78         8\n",
      "      contrast       0.00      0.00      0.00         3\n",
      " e-elaboration       0.62      0.38      0.48        13\n",
      "   elaboration       0.33      0.50      0.39        28\n",
      "  evaluation-n       0.00      0.00      0.00         8\n",
      "  evaluation-s       0.00      0.00      0.00         5\n",
      "      evidence       0.17      0.12      0.14         8\n",
      "interpretation       0.27      0.31      0.29        13\n",
      "         joint       0.33      0.33      0.33        18\n",
      "          list       0.42      0.56      0.48        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.89      0.73      0.80        11\n",
      "       purpose       1.00      0.60      0.75         5\n",
      "        reason       0.52      0.50      0.51        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         3\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.42       241\n",
      "     macro avg       0.32      0.32      0.31       241\n",
      "  weighted avg       0.41      0.42      0.40       241\n",
      "\n",
      "Val Loss: 2.095 |  Val Acc: 41.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best val acc\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
