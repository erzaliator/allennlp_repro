{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI6aVBQRy6LC"
   },
   "source": [
    "# 4️⃣ Zero-Shot Cross-Lingual Transfer using Adapters\n",
    "\n",
    "Beyond AdapterFusion, which we trained in [the previous notebook](https://github.com/Adapter-Hub/adapter-transformers/blob/master/notebooks/04_Cross_Lingual_Transfer.ipynb), we can compose adapters for zero-shot cross-lingual transfer between tasks. We will use the stacked adapter setup presented in **MAD-X** ([Pfeiffer et al., 2020](https://arxiv.org/pdf/2005.00052.pdf)) for this purpose.\n",
    "\n",
    "In this example, the base model is a pre-trained multilingual **XLM-R** (`xlm-roberta-base`) ([Conneau et al., 2019](https://arxiv.org/pdf/1911.02116.pdf)) model. Additionally, two types of adapters, language adapters and task adapters, are used. Here's how the MAD-X process works in detail:\n",
    "\n",
    "1. Train language adapters for the source and target language on a language modeling task. In this notebook, we won't train them ourselves but use [pre-trained language adapters from the Hub](https://adapterhub.ml/explore/text_lang/).\n",
    "2. Train a task adapter on the target task dataset. This task adapter is **stacked** upon the previously trained language adapter. During this step, only the weights of the task adapter are updated.\n",
    "3. Perform zero-shot cross-lingual transfer. In this last step, we simply replace the source language adapter with the target language adapter while keeping the stacked task adapter.\n",
    "\n",
    "Now to our concrete example: we select **XCOPA** ([Ponti et al., 2020](https://ducdauge.github.io/files/xcopa.pdf)), a multilingual extension of the **COPA** commonsence reasoning dataset ([Roemmele et al., 2011](https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF)) as our target task. The setup is trained on the original **English** dataset and then transferred to **Chinese**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L9gYpCV28OA"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Besides `adapter-transformers`, we use HuggingFace's `datasets` library for loading the data. So let's install both first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qL3Sq1HQynCq",
    "outputId": "1a53add7-208d-4767-a6f7-c51fad93787e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "MODEL_DIR = './training_output/deu_disrpt_vanilla_bert'\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP9OMSUT-FtL"
   },
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "We need the English COPA dataset for training our task adapter. It is part of the SuperGLUE benchmark and can be loaded via `datasets` using one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2164, 260, 241)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "de_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels'))\n",
    "de_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels'))\n",
    "de_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels'))\n",
    "\n",
    "len(de_train_dataset_df), len(de_test_dataset_df), len(de_valid_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit1_txt': Value(dtype='string', id=None),\n",
       " 'unit1_sent': Value(dtype='string', id=None),\n",
       " 'unit2_txt': Value(dtype='string', id=None),\n",
       " 'unit2_sent': Value(dtype='string', id=None),\n",
       " 'dir': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='string', id=None),\n",
       " 'distance': Value(dtype='string', id=None),\n",
       " 'u1_depdir': Value(dtype='string', id=None),\n",
       " 'u2_depdir': Value(dtype='string', id=None),\n",
       " 'u2_func': Value(dtype='string', id=None),\n",
       " 'u1_position': Value(dtype='string', id=None),\n",
       " 'u2_position': Value(dtype='string', id=None),\n",
       " 'sat_children': Value(dtype='string', id=None),\n",
       " 'nuc_children': Value(dtype='string', id=None),\n",
       " 'genre': Value(dtype='string', id=None),\n",
       " 'unit1_case': Value(dtype='string', id=None),\n",
       " 'unit2_case': Value(dtype='string', id=None),\n",
       " 'u1_discontinuous': Value(dtype='string', id=None),\n",
       " 'u2_discontinuous': Value(dtype='string', id=None),\n",
       " 'same_speaker': Value(dtype='string', id=None),\n",
       " 'lex_overlap_length': Value(dtype='string', id=None),\n",
       " 'u1_func': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_train_dataset_df.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INW7UEhC-I6b",
    "outputId": "b3e53380-c243-4b0c-88c5-629c272313e8"
   },
   "outputs": [],
   "source": [
    "from transformers.adapters.composition import Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epiKaEz5dDVe"
   },
   "source": [
    "Every dataset sample has a premise, a question and two possible answer choices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVa3Vk0QdNYI"
   },
   "source": [
    "In this example, we model COPA as a multiple-choice task with two choices. Thus, we encode the premise and question as well as both choices as one input to our `xlm-roberta-base` model. Using `dataset.map()`, we can pass the full dataset through the tokenizer in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 2164 examples\n",
      "read 241 examples\n",
      "read 260 examples\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from datasets import ClassLabel\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the SNLI dataset.\"\"\"\n",
    "    def __init__(self, dataset, labels, raw_text=False):\n",
    "        self.text = []\n",
    "        self.raw_text = []\n",
    "        self.raw_label = []\n",
    "        self.raw_text_flag = raw_text\n",
    "        self.num_rows = len(dataset)\n",
    "        for premise, hypothesis in zip(dataset['unit1_txt'], dataset['unit2_txt']):\n",
    "            self.text.append(tokenizer.encode_plus(premise, hypothesis, padding=\"max_length\", truncation=True, max_length=512, return_token_type_ids=True))\n",
    "            if raw_text: self.raw_text.append([premise, hypothesis])\n",
    "        # self.labels = torch.tensor(labels.str2int(dataset['label'])).to(device)\n",
    "        self.labels = labels.str2int(dataset['label'])\n",
    "        if raw_text: self.raw_label = dataset['label']\n",
    "        print('read ' + str(len(self.text)) + ' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.raw_text_flag:  \n",
    "            return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'raw_text': self.raw_text[idx],\n",
    "                'label':self.labels[idx],\n",
    "                'raw_label': self.raw_label[idx]}\n",
    "\n",
    "        return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'label':self.labels[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def combine_with_another_dataset(self, dataset2):\n",
    "        print('Adding datasets of sizes ', self.num_rows, ', ', dataset2.num_rows)\n",
    "        self.text = self.text + dataset2.text\n",
    "        self.raw_text = self.raw_text + dataset2.raw_text\n",
    "        self.raw_label = self.raw_label + dataset2.raw_label\n",
    "        self.num_rows = len(self.text) #update texts is now longer\n",
    "        assert self.raw_text_flag == dataset2.raw_text_flag\n",
    "        print('To new dataset size: ', self.num_rows)\n",
    "\n",
    "\n",
    "def load_data_snli(batch_size, train_dataset_df, valid_dataset_df, test_dataset_df, labels):\n",
    "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
    "    train_data = train_dataset_df\n",
    "    valid_data = valid_dataset_df\n",
    "    test_data = test_dataset_df\n",
    "    train_set = SNLIDataset(train_data, labels, raw_text=False)\n",
    "    valid_set = SNLIDataset(valid_data, labels, raw_text=False)\n",
    "    test_set = SNLIDataset(test_data, labels, raw_text=False)\n",
    "    return train_set, valid_set, test_set #TODO: MAKE INTO DICT\n",
    "\n",
    "de_labels = ClassLabel(names=list(set(de_train_dataset_df['label'])|set(de_test_dataset_df['label'])|set(de_valid_dataset_df['label'])))\n",
    "de_train_dataset, de_valid_dataset, de_test_dataset = load_data_snli(BATCH_SIZE, de_train_dataset_df, de_valid_dataset_df, de_test_dataset_df, de_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs21MzEQ_0v4"
   },
   "source": [
    "## Task Adapter Training\n",
    "\n",
    "In this section, we will train the task adapter on the English COPA dataset. We use a pre-trained XLM-R model from HuggingFace and instantiate our model using `AutoAdapterModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnq8n_KP_3aX",
    "outputId": "590b1cae-a454-4110-c9fb-f76f4dff423a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaAdapterModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaAdapterModel were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoAdapterModel\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    ")\n",
    "model = AutoAdapterModel.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base AutoModel. If you print model before adding the adapters, you can see that the embeddings+12 transformer layers will be shared by En and Zh adapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDCNJzTXezcn"
   },
   "source": [
    "Now we only need to set up the adapters. As described, we need two language adapters (which are assumed to be pre-trained in this example) and a task adapter (which will be trained in a few moments).\n",
    "\n",
    "First, we load both the language adapters for our source language English (`\"en\"`) and our target language Chinese (`\"zh\"`) from the Hub. Then we add a new task adapter (`\"copa\"`) for our target task.\n",
    "\n",
    "Finally, we add a multiple-choice head with the same name as our task adapter on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jRqbBgS0BoHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdapterConfig\n",
    "\n",
    "# Load the language adapters\n",
    "lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "model.load_adapter(\"en/wiki@ukp\", config=lang_adapter_config)\n",
    "model.load_adapter(\"de/wiki@ukp\", config=lang_adapter_config)\n",
    "\n",
    "# Add a new task adapter\n",
    "model.add_adapter(\"disrpt\")\n",
    "\n",
    "# Add a classification head for our target task\n",
    "num_labels=de_labels.num_classes\n",
    "print([num_labels])\n",
    "# model.add_multiple_choice_head(\"disrpt\", num_choices=num_labels)\n",
    "model.add_classification_head(\"disrpt\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `train_adapter()`, we tell our model to only train the task adapter in the following. This call will freeze the weights of the pre-trained model and the weights of the language adapters to prevent them from further finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7wBpjGWZ4v7O"
   },
   "outputs": [],
   "source": [
    "model.train_adapter([\"disrpt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60qIas8-il92"
   },
   "source": [
    "We want the task adapter to be stacked on top of the language adapter, so we have to tell our model to use this setup via the `active_adapters` property.\n",
    "\n",
    "A stack of adapters is represented by the `Stack` class, which takes the names of the adapters to be stacked as arguments.\n",
    "Of course, there are various other possibilities to compose adapters beyonde stacking. Learn more about those [in our documentation](https://docs.adapterhub.ml/adapter_composition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zgGqHJQbijgg"
   },
   "outputs": [],
   "source": [
    "# Unfreeze and activate stack setup\n",
    "model.active_adapters = Stack(\"de\", \"disrpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBDvwmUf_-mc"
   },
   "source": [
    "Great! Now, the input will be passed through the English language adapter first and the COPA task adapter second in every forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb8BY5RAmzkd"
   },
   "source": [
    "For training, we make use of the `Trainer` class built-in into `transformers`. We configure the training process using a `TrainingArguments` object.\n",
    "\n",
    "As the dataset splits of English COPA in the SuperGLUE are slightly different, we train on both the train and validation split of the dataset. Later, we will evaluate on the test split of XCOPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SHUFFLE print smples: https://discuss.huggingface.co/t/how-to-print-a-few-examples-at-the-beginning-of-training-when-using-trainer/7597/2\n",
    "# https://github.com/huggingface/datasets/blob/cd3169f3f35afcf73a36a8276113e1881d92e5e0/src/datasets/iterable_dataset.py#L223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "j0gFxQRdDkQ6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 21:27:03.245160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-01 21:27:03.456968: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-01 21:27:03.456995: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-01 21:27:03.499276: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-01 21:27:04.716247: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-01 21:27:04.716334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-01 21:27:04.716343: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps=100,\n",
    "    output_dir=MODEL_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=de_train_dataset,\n",
    "    eval_dataset=de_valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKlYjA9rm2Kp"
   },
   "source": [
    "Start the training 🚀 (this will take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMRobertaAdapterModel(\n",
      "  (shared_parameters): ModuleDict()\n",
      "  (roberta): RobertaModel(\n",
      "    (shared_parameters): ModuleDict()\n",
      "    (invertible_adapters): ModuleDict(\n",
      "      (en): NICECouplingBlock(\n",
      "        (F): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "        (G): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (de): NICECouplingBlock(\n",
      "        (F): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "        (G): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "    (prefix_tuning): PrefixTuningPool(\n",
      "      (prefix_tunings): ModuleDict()\n",
      "    )\n",
      "  )\n",
      "  (heads): ModuleDict(\n",
      "    (disrpt): ClassificationHead(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (2): Activation_Function_Class(\n",
      "        (f): Tanh()\n",
      "      )\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=768, out_features=26, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "vSUs2FjXDmsx",
    "outputId": "2b8bb989-f6ca-4702-c222-15eea9823bbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2164\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4080\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merzaliator\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/wandb/run-20230101_212715-toi2jt4e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/erzaliator/huggingface/runs/toi2jt4e\" target=\"_blank\">./training_output/deu_disrpt_vanilla_bert</a></strong> to <a href=\"https://wandb.ai/erzaliator/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4080' max='4080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4080/4080 33:03, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.973200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.974600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.966600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.960400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.967700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.960500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.951400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.952800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.958500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.944700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.933400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.933600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.931600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.946100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.945600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4080, training_loss=2.961725178886862, metrics={'train_runtime': 1991.8496, 'train_samples_per_second': 32.593, 'train_steps_per_second': 2.048, 'total_flos': 2.032778523451392e+16, 'train_loss': 2.961725178886862, 'epoch': 30.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 260\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.9827046394348145,\n",
       " 'eval_acc': 0.13076923076923078,\n",
       " 'eval_runtime': 3.6404,\n",
       " 'eval_samples_per_second': 71.421,\n",
       " 'eval_steps_per_second': 9.065}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "eval_trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output_de\", remove_unused_columns=False,),\n",
    "    eval_dataset=de_test_dataset,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "eval_trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_Cross_Lingual_Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cb7dbc5b67469b8643c0ea3e6b3921": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f3bac44e13246ab9f9c8564a44e1fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e45676711b477e9a1ce2cf4ac8f3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "11b4409af40748e0b760e91c3d91ede7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28b184f13a948d5995ee04720748871",
      "placeholder": "​",
      "style": "IPY_MODEL_2393e906e07e4e8ba661b0eafd2268e8",
      "value": " 100/0 [00:00&lt;00:00, 1191.08 examples/s]"
     }
    },
    "12ec755bb33c4ff894644e291ce33040": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13829992bf994ec5bbec71684cc824e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ccbb12bb5a548488c9b646159f893d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e70f23ca6f94a2099c2cca1eaf875d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8348929b740242d3bdc73ea2c8bcd9c8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c82fa83594a349c991626ee55b8edfa4",
      "value": 1
     }
    },
    "21bd77c2c70040548a696c5a40d81a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac8b24c5d6214716a409ca95580306f5",
      "placeholder": "​",
      "style": "IPY_MODEL_932d3ee3c9d74761bfc4bcf5c003d205",
      "value": " 1/1 [00:10&lt;00:00, 10.75s/ba]"
     }
    },
    "2393e906e07e4e8ba661b0eafd2268e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "249abcb1904c4d1ca4116b677011b017": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12ec755bb33c4ff894644e291ce33040",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df292d721c1748c485f281aa2162b9a9",
      "value": 1
     }
    },
    "2a76413cb9cd4a6f901a8bef7dc70220": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c154bfdf049147638c67d2844d25f9e6",
       "IPY_MODEL_4fe615dff7104a018c48491fd711ed45"
      ],
      "layout": "IPY_MODEL_13829992bf994ec5bbec71684cc824e6"
     }
    },
    "2d964df49d71456093b427af2a3ac6cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "315cd377eae94488b258460f06e5cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02cb7dbc5b67469b8643c0ea3e6b3921",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a8c7ea6d7ec4ec691525f6e3ca88d48",
      "value": 1
     }
    },
    "342e98cd2d99438d861d5c1cf54b573d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d85845466e5a4ffd8370ef4c8b965684",
       "IPY_MODEL_5b84c1bb95354f939bc1918b5478cf08"
      ],
      "layout": "IPY_MODEL_e3e3c18ef96e48999e14be0c60ad9f04"
     }
    },
    "3bc11633e20c460eb9058cc4b480b224": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3ccf15d7bea44e9bb91b9b3d32b3c691": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a0b61f58dfd4b2c88e7fe818c4de4b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfc579b1c3354bcd9a0be2fde370954c",
       "IPY_MODEL_ed22b18a21c943f291c6326030cb2753"
      ],
      "layout": "IPY_MODEL_bc7b5cd3163b4b60877d80be43598436"
     }
    },
    "4a23a9bdd091425cbda38222f2e4c3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58b17e932dd74756b62fb7f6ed0d37ba",
      "placeholder": "​",
      "style": "IPY_MODEL_77583bbefaf849eea83d3ae327e4070e",
      "value": " 1/1 [00:00&lt;00:00,  2.51ba/s]"
     }
    },
    "4eac0e183d8047e498d3a576f3c3a1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fe615dff7104a018c48491fd711ed45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2423ca88827446aa5b5c78ccc36a263",
      "placeholder": "​",
      "style": "IPY_MODEL_527ea785de0a47f0ba5b0d0aea72cc97",
      "value": " 500/0 [00:00&lt;00:00, 2888.43 examples/s]"
     }
    },
    "525a5c1a8ba04c8e89fc514064539d73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527ea785de0a47f0ba5b0d0aea72cc97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5321f4576a6c4fe69de0c97b43269d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "568fedab4a4e44d9baa8213d54d60d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f512c5cdfaa64005bb987f032957e530",
      "placeholder": "​",
      "style": "IPY_MODEL_87c546c1a23c402f8a6de964828dc035",
      "value": " 28.2k/? [00:00&lt;00:00, 297kB/s]"
     }
    },
    "58b17e932dd74756b62fb7f6ed0d37ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b2e4c980b6a4e15bef86d1907b20f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d964df49d71456093b427af2a3ac6cc",
      "placeholder": "​",
      "style": "IPY_MODEL_3ccf15d7bea44e9bb91b9b3d32b3c691",
      "value": " 642k/? [00:00&lt;00:00, 3.06MB/s]"
     }
    },
    "5b84c1bb95354f939bc1918b5478cf08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fec9b3f47668416f8709fd7ab80a9730",
      "placeholder": "​",
      "style": "IPY_MODEL_5d95a7e842dc43d995b3ad5f0b61ae8f",
      "value": " 1/1 [00:00&lt;00:00,  2.28ba/s]"
     }
    },
    "5d95a7e842dc43d995b3ad5f0b61ae8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5df3d17d64e24faeab6cc644d333536a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f708ccdb4f941918696d583ad9bd9c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6025f45ce1af4c8caab09042992f2094": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "630597c0e70d4792b58c8942296692a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff7c6d1bfc654c2db63e40bad4e3eb33",
       "IPY_MODEL_f964d3d5333948e0b14117555b82275b"
      ],
      "layout": "IPY_MODEL_64e51ced10004147b21e51db1343cac8"
     }
    },
    "64e51ced10004147b21e51db1343cac8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67bde4b1393e48a1a5c1b00969317131": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71b51022c34247929dcb8f11c74a2de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e70f23ca6f94a2099c2cca1eaf875d8",
       "IPY_MODEL_11b4409af40748e0b760e91c3d91ede7"
      ],
      "layout": "IPY_MODEL_8119426c8705459fb9df8b2c711d3c36"
     }
    },
    "77583bbefaf849eea83d3ae327e4070e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a31bf9dedde47188efdfaf6a262b730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a718fb0db5640fd8eb04ef18fe1e339": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8119426c8705459fb9df8b2c711d3c36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8348929b740242d3bdc73ea2c8bcd9c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c546c1a23c402f8a6de964828dc035": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89f8555b95ec48b7b3282cb365b1cfdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb6e0c49bd040b7bd5f266c4608dd31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d88b67069074ee6bc937b46cc10418a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "932d3ee3c9d74761bfc4bcf5c003d205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9380ff7e78f846babb16740cfc9cf7f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f45f9a16f75e4d07abe5dcaf2fb300f4",
       "IPY_MODEL_21bd77c2c70040548a696c5a40d81a00"
      ],
      "layout": "IPY_MODEL_7a31bf9dedde47188efdfaf6a262b730"
     }
    },
    "949971635f1f498e86e04b9d4e28d353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9a8c7ea6d7ec4ec691525f6e3ca88d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9c8548e2e4c54bf88e678c571c537867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a3da9679c78640c3be6e7cbbd5bcccae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f3bac44e13246ab9f9c8564a44e1fa3",
      "placeholder": "​",
      "style": "IPY_MODEL_7a718fb0db5640fd8eb04ef18fe1e339",
      "value": " 1/1 [00:13&lt;00:00, 13.12s/ba]"
     }
    },
    "ac8b24c5d6214716a409ca95580306f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb9523d3e594c3d84036ad2348a7a64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e71f76432d5e469d8cf742bbed6e0f1c",
       "IPY_MODEL_a3da9679c78640c3be6e7cbbd5bcccae"
      ],
      "layout": "IPY_MODEL_8d88b67069074ee6bc937b46cc10418a"
     }
    },
    "aebd284cd0ba4dfbafce1f0b99cd5213": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28b184f13a948d5995ee04720748871": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2b6f74edcdb465e94d9f07287fa506d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bc7b5cd3163b4b60877d80be43598436": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfc579b1c3354bcd9a0be2fde370954c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efbd298ec8f0461ba89793855901330b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67bde4b1393e48a1a5c1b00969317131",
      "value": 1
     }
    },
    "c154bfdf049147638c67d2844d25f9e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f708ccdb4f941918696d583ad9bd9c9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bc11633e20c460eb9058cc4b480b224",
      "value": 1
     }
    },
    "c21fa18f6c4b4bdd9621ef29180646db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_249abcb1904c4d1ca4116b677011b017",
       "IPY_MODEL_4a23a9bdd091425cbda38222f2e4c3a9"
      ],
      "layout": "IPY_MODEL_fa8da5adaacd4534b60e51ba4dce6c4a"
     }
    },
    "c2423ca88827446aa5b5c78ccc36a263": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b64289fc4445f59a94d6c51a288834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ccbb12bb5a548488c9b646159f893d3",
      "max": 1750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6025f45ce1af4c8caab09042992f2094",
      "value": 1750
     }
    },
    "c515e4e9f5b7470e8a17e4a4247878f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4b64289fc4445f59a94d6c51a288834",
       "IPY_MODEL_568fedab4a4e44d9baa8213d54d60d38"
      ],
      "layout": "IPY_MODEL_89f8555b95ec48b7b3282cb365b1cfdd"
     }
    },
    "c6ae198ebaf2467bba3f0a49f3aab196": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82fa83594a349c991626ee55b8edfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d85845466e5a4ffd8370ef4c8b965684": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6ae198ebaf2467bba3f0a49f3aab196",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2b6f74edcdb465e94d9f07287fa506d",
      "value": 1
     }
    },
    "df292d721c1748c485f281aa2162b9a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e3e3c18ef96e48999e14be0c60ad9f04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6bdcb09b73d4aa3844076829cf43f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e71f76432d5e469d8cf742bbed6e0f1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cb6e0c49bd040b7bd5f266c4608dd31",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10e45676711b477e9a1ce2cf4ac8f3a9",
      "value": 1
     }
    },
    "ea780b89e28a4348abfac40ef8fd140a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_315cd377eae94488b258460f06e5cc10",
       "IPY_MODEL_5b2e4c980b6a4e15bef86d1907b20f40"
      ],
      "layout": "IPY_MODEL_4eac0e183d8047e498d3a576f3c3a1f4"
     }
    },
    "ecac341937124f21b04479a50a05c688": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed22b18a21c943f291c6326030cb2753": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecac341937124f21b04479a50a05c688",
      "placeholder": "​",
      "style": "IPY_MODEL_e6bdcb09b73d4aa3844076829cf43f8a",
      "value": " 1/1 [04:39&lt;00:00, 279.14s/ba]"
     }
    },
    "efbd298ec8f0461ba89793855901330b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f45f9a16f75e4d07abe5dcaf2fb300f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5321f4576a6c4fe69de0c97b43269d3b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c8548e2e4c54bf88e678c571c537867",
      "value": 1
     }
    },
    "f512c5cdfaa64005bb987f032957e530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f964d3d5333948e0b14117555b82275b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_525a5c1a8ba04c8e89fc514064539d73",
      "placeholder": "​",
      "style": "IPY_MODEL_5df3d17d64e24faeab6cc644d333536a",
      "value": " 4.89k/? [00:01&lt;00:00, 3.05kB/s]"
     }
    },
    "fa8da5adaacd4534b60e51ba4dce6c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fec9b3f47668416f8709fd7ab80a9730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7c6d1bfc654c2db63e40bad4e3eb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aebd284cd0ba4dfbafce1f0b99cd5213",
      "max": 1935,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_949971635f1f498e86e04b9d4e28d353",
      "value": 1935
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
