{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2011\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "\n",
    "batch_size = 4\n",
    "batches_per_epoch = 541\n",
    "\n",
    "save_path_suffix = '19geluconfig_pooler_features_identity_dropout_double_distance_fix4_lr=1e-6_seed=2011_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label',\n",
       "       'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position',\n",
       "       'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case',\n",
       "       'unit2_case', 'u1_discontinuous', 'u2_discontinuous', 'same_speaker',\n",
       "       'lex_overlap_length', 'u1_func'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_classes_not_in_test(train_df, val_df, test_df):\n",
    "    test_labels = list(test_df['label'].unique())\n",
    "    train_df = train_df[train_df['label'].isin(test_labels)]\n",
    "    val_df = val_df[val_df['label'].isin(test_labels)]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = remove_classes_not_in_test(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.get_feature_mappings()\n",
    "    self.set_feature_list()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    self.calculate_unique_values()\n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.test_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def get_feature_mappings(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def get_distance(self, d):\n",
    "    if d<-8: return 0.0\n",
    "    elif d>=-8 and d<-2: return 0.0\n",
    "    elif d>=-2 and d<0: return 1.0\n",
    "    elif d>=0 and d<2: return 2.0\n",
    "    elif d>=2 and d<8: return 3.0\n",
    "    elif d>=8: return 4.0\n",
    "    else: raise ValueError()\n",
    "\n",
    "  def get_dep(self, d):\n",
    "    if d=='ROOT': return 0.0\n",
    "    elif d=='RIGHT': return 1.0\n",
    "    elif d=='LEFT': return 2.0\n",
    "    else: raise ValueError()\n",
    "\n",
    "  def get_boolean(self, u):\n",
    "    if u=='False': return 0.0\n",
    "    elif u=='True': return 1.0\n",
    "\n",
    "  def get_u_position(self, u):\n",
    "    if u>=0.0 and u<0.1: return 0.0\n",
    "    elif u>=0.1 and u<0.2: return 1.0\n",
    "    elif u>=0.2 and u<0.3: return 2.0\n",
    "    elif u<=0.3 and u<0.4: return 3.0\n",
    "    elif u<=0.4 and u<0.5: return 4.0\n",
    "    elif u<=0.5 and u<0.6: return 5.0\n",
    "    elif u<=0.6 and u<0.7: return 6.0\n",
    "    elif u<=0.7 and u<0.8: return 7.0\n",
    "    elif u<=0.8 and u<0.9: return 8.0\n",
    "    elif u<=0.9 and u<1.0: return 9.0\n",
    "    elif u<=1.0 and u<1e9: return 10.0\n",
    "    else: raise ValueError()\n",
    "\n",
    "  def get_lex_overlap_length(self,l):\n",
    "    if l>=0.0 and l<2.0: return 0\n",
    "    elif l>=2.0 and l<7.0: return 1\n",
    "    elif l>=7.0 and l<1e9: return 2\n",
    "    else: raise ValueError()\n",
    "\n",
    "\n",
    "  def set_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "\n",
    "    self.feature_unique_values = dict([(feature, set()) for feature in self.feature_list])\n",
    "\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features(self, features, feature_name):\n",
    "    feature_value = None\n",
    "\n",
    "    if feature_name=='distance': feature_value = self.get_distance(float(features[0]))\n",
    "    elif feature_name=='u1_depdir': feature_value = self.get_dep(features[1])\n",
    "    elif feature_name=='u2_depdir': feature_value = self.get_dep(features[2])\n",
    "    elif feature_name=='u2_func': feature_value = self.get_mapping_from_dictionary(column_name='u2_func', dict_val=features[3])\n",
    "    elif feature_name=='u1_position': feature_value = self.get_u_position(float(features[4]))\n",
    "    elif feature_name=='u2_position': feature_value = self.get_u_position(float(features[5]))\n",
    "    elif feature_name=='sat_children': feature_value = float(features[6])\n",
    "    elif feature_name=='nuc_children': feature_value = float(features[7])\n",
    "    elif feature_name=='genre': feature_value = self.get_mapping_from_dictionary(column_name='genre', dict_val=features[8])\n",
    "    elif feature_name=='unit1_case': feature_value = self.get_mapping_from_dictionary(column_name='unit1_case', dict_val=features[9])\n",
    "    elif feature_name=='unit2_case': feature_value = self.get_mapping_from_dictionary(column_name='unit2_case', dict_val=features[10])\n",
    "    elif feature_name=='u1_discontinuous': feature_value = self.get_boolean(features[11])\n",
    "    elif feature_name=='u2_discontinuous': feature_value = self.get_boolean(features[12])\n",
    "    elif feature_name=='same_speaker': feature_value = self.get_boolean(features[13])\n",
    "    elif feature_name=='lex_overlap_length': feature_value = self.get_lex_overlap_length(float(features[14]))\n",
    "    elif feature_name=='u1_func': feature_value = self.get_mapping_from_dictionary(column_name='u1_func', dict_val=features[15])\n",
    "    else:\n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    self.feature_unique_values[feature_name].add(feature_value)\n",
    "    return feature_value\n",
    "\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==16\n",
    "    return list(map(lambda i: self.get_allen_features(features, i), self.feature_list))\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature in self.feature_list:\n",
    "      self.feature_unique_values[feature] = len(self.feature_unique_values[feature])\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      distance = row['distance']\n",
    "      u1_depdir = row['u1_depdir']\n",
    "      u2_depdir = row['u2_depdir']\n",
    "      u2_func = row['u2_func']\n",
    "      u1_position = row['u1_position']\n",
    "      u2_position = row['u2_position']\n",
    "      sat_children = row['sat_children']\n",
    "      nuc_children = row['nuc_children']\n",
    "      genre = row['genre']\n",
    "      unit1_case = row['unit1_case']\n",
    "      unit2_case = row['unit2_case']\n",
    "      u1_discontinuous = row['u1_discontinuous']\n",
    "      u2_discontinuous = row['u2_discontinuous']\n",
    "      same_speaker = row['same_speaker']\n",
    "      lex_overlap_length = row['lex_overlap_length']\n",
    "      u1_func = row['u1_func']\n",
    "      features = [distance, u1_depdir, u2_depdir, u2_func, u1_position, u2_position, sat_children, nuc_children, genre, unit1_case, unit2_case, u1_discontinuous, u2_discontinuous, same_speaker,\n",
    "                  lex_overlap_length, u1_func]\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding='max_length')\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(self.transform_feature(features))\n",
    "\n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "    feats_new = []\n",
    "    for l in feats:\n",
    "      l_new = []\n",
    "      for i in l:\n",
    "        l_new.append(int(i))\n",
    "      feats_new.append(l_new)\n",
    "    feats = feats_new\n",
    "    feats = torch.tensor(feats)#.type(torch.FloatTensor)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,#shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(math.sqrt(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0}\n"
     ]
    }
   ],
   "source": [
    "distance_unique = set()\n",
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    assert mask_ids.shape[-1]==512\n",
    "    assert seg_ids.shape[-1]==512\n",
    "    assert feat.shape[-1]==8\n",
    "    for f in feat:\n",
    "        distance = f[3]\n",
    "        distance_unique.add(int(distance))\n",
    "print(distance_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance\n",
      "u1_depdir\n",
      "u2_depdir\n",
      "u2_func\n",
      "u1_position\n",
      "u2_position\n",
      "sat_children\n",
      "nuc_children\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, Optional\n",
    "from transformers import BertModel, AutoTokenizer, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "class CustomPooler2(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                        requires_grad: bool = True,\n",
    "                        dropout: float = 0.0,\n",
    "                        transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "        super().__init__()\n",
    "        model = BertModel.from_pretrained(BERT_MODEL)\n",
    "        self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.pooler = copy.deepcopy(model.pooler)\n",
    "        for param in self.pooler.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        self._embedding_dim = model.config.hidden_size\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "        pooler = self.pooler\n",
    "        \n",
    "        for _ in range(num_wrapping_dims):\n",
    "            pooler = TimeDistributed(pooler)\n",
    "        pooled = pooler(tokens)\n",
    "        pooled = self._dropout(pooled)\n",
    "        return pooled\n",
    "\n",
    "\n",
    "# class MyEmbedding(nn.Embedding):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super(MyEmbedding, self).__init__(*args, **kwargs)\n",
    "#     def forward(self, input: torch.LongTensor) -> torch.LongTensor:\n",
    "#         return super().forward(input)\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_modules = nn.ModuleDict()\n",
    "        self.dims = 0\n",
    "        for feature in feature_list:\n",
    "            print(feature)\n",
    "            if feature=='distance':\n",
    "                self.feature_modules[feature] =nn.Embedding(5, 3, padding_idx=0)\n",
    "                self.dims += 3\n",
    "            elif feature=='u1_depdir':\n",
    "                self.feature_modules[feature] = nn.Embedding(5, 3, padding_idx=0)\n",
    "                self.dims += 3\n",
    "            elif feature=='u2_depdir':\n",
    "                self.feature_modules[feature] = nn.Embedding(5, 3, padding_idx=0)\n",
    "                self.dims += 3\n",
    "            elif feature=='u2_func':\n",
    "                self.feature_modules[feature] = nn.Embedding(23, 5, padding_idx=0)\n",
    "                self.dims += 5\n",
    "            elif feature=='u1_position':\n",
    "                self.feature_modules[feature] = nn.Embedding(12, 4, padding_idx=0)\n",
    "                self.dims += 4\n",
    "            elif feature=='u2_position':\n",
    "                self.feature_modules[feature] = nn.Embedding(12, 4, padding_idx=0)\n",
    "                self.dims += 4\n",
    "            elif 'sat_children' in feature_list:        \n",
    "                self.feature_modules[feature] = nn.Identity()\n",
    "                self.dims += 1\n",
    "            elif 'nuc_children' in feature_list:\n",
    "                self.feature_modules[feature] = nn.Identity()\n",
    "                self.dims += 1\n",
    "            # elif 'genre' in feature_list:               self.modules['genre'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'unit1_case' in feature_list:          self.modules['unit1_case'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'unit2_case' in feature_list:          self.modules['unit2_case'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u1_discontinuous' in feature_list:    self.modules['u1_discontinuous'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u2_discontinuous' in feature_list:    self.modules['u2_discontinuous'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'same_speaker' in feature_list:        self.modules['same_speaker'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'lex_overlap_length' in feature_list:  self.modules['lex_overlap_length'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            # elif 'u1_func' in feature_list:             self.modules['u1_func'] = nn.Embedding(mnli_dataset.distance_unique, 3)\n",
    "            else: raise ValueError()\n",
    "\n",
    "    def get_combined_feature_tensor(self, features):\n",
    "        output_tensors = []\n",
    "        i = 0\n",
    "        for module_key in self.feature_list:\n",
    "            module = self.feature_modules[module_key]\n",
    "            feature = features[:, i:i+1].squeeze()\n",
    "            if module_key in ['sat_children', 'nuc_children']:\n",
    "                feature = feature.unsqueeze(-1)\n",
    "            output_tensor = module(feature)\n",
    "            output_tensors.append(output_tensor)\n",
    "            i += 1\n",
    "        try:\n",
    "            output_tensors = torch.cat(output_tensors, dim=1)\n",
    "        except:\n",
    "            print(output_tensors)\n",
    "            raise ValueError()\n",
    "        return output_tensors\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.get_combined_feature_tensor(features)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels\n",
    "          self.feature_list = mnli_dataset.feature_list\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "\n",
    "          self.bert = self.create_bert_without_activations()\n",
    "          self.encoder = CustomPooler2()\n",
    "          self.module1 = MyModule(self.feature_list)\n",
    "          self.dropout1 = nn.Dropout(p=0.0)\n",
    "          self.relation_decoder = nn.Linear(792, self.num_classes)\n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask, feat): \n",
    "        sequence_output, pooled_output = self.bert(input_ids=pair_token_ids, \n",
    "                        token_type_ids=token_type_ids, \n",
    "                        attention_mask=attention_mask).values()\n",
    "        bertpooler_output = self.encoder(sequence_output) #after this convert FloatTensor\n",
    "        feat = self.dropout1(feat) #after this convert LongTensor\n",
    "        feat = self.module1(feat)\n",
    "        feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "        assert feat_concat.shape[-1] == 792\n",
    "        feat_concat = self.dropout1(feat_concat)\n",
    "        linear1_output = self.relation_decoder(feat_concat)\n",
    "        return linear1_output, bertpooler_output\n",
    "\n",
    "\n",
    "    def create_bert_without_activations(self):\n",
    "        config = BertConfig.from_pretrained(BERT_MODEL, hidden_act='gelu')\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "        return bert\n",
    "\n",
    "model = CustomBERTModel(mnli_dataset.num_labels) \n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-6, correct_bias=False) # original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7, mode='max', patience=12, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "emb = nn.Embedding(5, 3, padding_idx=0)\n",
    "print(emb(torch.LongTensor([0,0,0,0,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prinintg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomBERTModel(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (encoder): CustomPooler2(\n",
      "    (_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (module1): MyModule(\n",
      "    (feature_modules): ModuleDict(\n",
      "      (distance): Embedding(5, 3, padding_idx=0)\n",
      "      (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "      (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "      (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "      (sat_children): Identity()\n",
      "      (nuc_children): Identity()\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (relation_decoder): Linear(in_features=792, out_features=24, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['events.out.tfevents.1669359505.57e5cab0c4d9.3244.0']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'_viz1/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Best val_acc: 0.1500\n",
      "Epoch 1: Best val_acc: 0.1500\n",
      "Epoch 1: train_loss: 2.9388 train_acc: 0.1197 | val_loss: 2.7648 val_acc: 0.1500\n",
      "00:01:24.43\n",
      "train_size: 541\n",
      "Epoch 2: Best val_acc: 0.2000\n",
      "Epoch 2: Best val_acc: 0.2000\n",
      "Epoch 2: train_loss: 2.6514 train_acc: 0.2029 | val_loss: 2.5971 val_acc: 0.2000\n",
      "00:01:24.58\n",
      "train_size: 541\n",
      "Epoch 3: Best val_acc: 0.2083\n",
      "Epoch 3: Best val_acc: 0.2083\n",
      "Epoch 3: train_loss: 2.5204 train_acc: 0.2606 | val_loss: 2.5003 val_acc: 0.2083\n",
      "00:01:24.53\n",
      "train_size: 541\n",
      "Epoch 4: Best val_acc: 0.2458\n",
      "Epoch 4: Best val_acc: 0.2458\n",
      "Epoch 4: train_loss: 2.4002 train_acc: 0.3099 | val_loss: 2.4332 val_acc: 0.2458\n",
      "00:01:24.89\n",
      "train_size: 541\n",
      "Epoch 5: Best val_acc: 0.2875\n",
      "Epoch 5: Best val_acc: 0.2875\n",
      "Epoch 5: train_loss: 2.3106 train_acc: 0.3358 | val_loss: 2.3658 val_acc: 0.2875\n",
      "00:01:24.93\n",
      "train_size: 541\n",
      "Epoch 6: train_loss: 2.2280 train_acc: 0.3735 | val_loss: 2.3166 val_acc: 0.2750\n",
      "00:01:23.60\n",
      "train_size: 541\n",
      "Epoch 7: Best val_acc: 0.3333\n",
      "Epoch 7: Best val_acc: 0.3333\n",
      "Epoch 7: train_loss: 2.1554 train_acc: 0.4003 | val_loss: 2.2658 val_acc: 0.3333\n",
      "00:01:27.00\n",
      "train_size: 541\n",
      "Epoch 8: Best val_acc: 0.3333\n",
      "Epoch 8: train_loss: 2.0733 train_acc: 0.4424 | val_loss: 2.2163 val_acc: 0.3333\n",
      "00:01:25.67\n",
      "train_size: 541\n",
      "Epoch 9: train_loss: 1.9908 train_acc: 0.4681 | val_loss: 2.1867 val_acc: 0.3250\n",
      "00:01:24.62\n",
      "train_size: 541\n",
      "Epoch 10: Best val_acc: 0.3500\n",
      "Epoch 10: Best val_acc: 0.3500\n",
      "Epoch 10: train_loss: 1.9503 train_acc: 0.4951 | val_loss: 2.1508 val_acc: 0.3500\n",
      "00:01:27.75\n",
      "train_size: 541\n",
      "Epoch 11: Best val_acc: 0.3542\n",
      "Epoch 11: Best val_acc: 0.3542\n",
      "Epoch 11: train_loss: 1.8591 train_acc: 0.5219 | val_loss: 2.1225 val_acc: 0.3542\n",
      "00:01:27.43\n",
      "train_size: 541\n",
      "Epoch 12: train_loss: 1.8033 train_acc: 0.5417 | val_loss: 2.0992 val_acc: 0.3458\n",
      "00:01:24.56\n",
      "train_size: 541\n",
      "Epoch 13: Best val_acc: 0.3708\n",
      "Epoch 13: Best val_acc: 0.3708\n",
      "Epoch 13: train_loss: 1.7308 train_acc: 0.5632 | val_loss: 2.0614 val_acc: 0.3708\n",
      "00:01:27.59\n",
      "train_size: 541\n",
      "Epoch 00014: reducing learning rate of group 0 to 7.0000e-07.\n",
      "Epoch 14: Best val_acc: 0.3875\n",
      "Epoch 14: Best val_acc: 0.3875\n",
      "Epoch 14: train_loss: 1.6710 train_acc: 0.5783 | val_loss: 2.0382 val_acc: 0.3875\n",
      "00:01:27.66\n",
      "train_size: 541\n",
      "Epoch 15: train_loss: 1.5900 train_acc: 0.6077 | val_loss: 2.0192 val_acc: 0.3708\n",
      "00:01:25.05\n",
      "train_size: 541\n",
      "Epoch 16: train_loss: 1.5707 train_acc: 0.6163 | val_loss: 2.0153 val_acc: 0.3667\n",
      "00:01:25.03\n",
      "train_size: 541\n",
      "Epoch 17: train_loss: 1.4900 train_acc: 0.6462 | val_loss: 2.0285 val_acc: 0.3583\n",
      "00:01:25.00\n",
      "train_size: 541\n",
      "Epoch 18: train_loss: 1.4671 train_acc: 0.6431 | val_loss: 1.9833 val_acc: 0.3708\n",
      "00:01:25.12\n",
      "train_size: 541\n",
      "Epoch 19: train_loss: 1.4079 train_acc: 0.6767 | val_loss: 1.9865 val_acc: 0.3625\n",
      "00:01:24.99\n",
      "train_size: 541\n",
      "Epoch 20: train_loss: 1.3620 train_acc: 0.6738 | val_loss: 1.9684 val_acc: 0.3708\n",
      "00:01:24.70\n",
      "train_size: 541\n",
      "Epoch 21: train_loss: 1.3289 train_acc: 0.6791 | val_loss: 1.9713 val_acc: 0.3625\n",
      "00:01:24.81\n",
      "train_size: 541\n",
      "Epoch 22: train_loss: 1.2712 train_acc: 0.7073 | val_loss: 1.9735 val_acc: 0.3583\n",
      "00:01:24.85\n",
      "train_size: 541\n",
      "Epoch 23: train_loss: 1.2328 train_acc: 0.7183 | val_loss: 1.9840 val_acc: 0.3500\n",
      "00:01:24.65\n",
      "train_size: 541\n",
      "Epoch 24: train_loss: 1.1886 train_acc: 0.7295 | val_loss: 1.9719 val_acc: 0.3583\n",
      "00:01:24.28\n",
      "train_size: 541\n",
      "Epoch 25: train_loss: 1.1356 train_acc: 0.7434 | val_loss: 1.9609 val_acc: 0.3583\n",
      "00:01:24.26\n",
      "train_size: 541\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latest\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 4.4977 test_acc: 0.0038\n",
      "00:00:03.02\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.00      0.00      0.00        18\n",
      "    background       0.00      0.00      0.00        17\n",
      "         cause       0.00      0.00      0.00         2\n",
      "  circumstance       0.00      0.00      0.00        15\n",
      "    concession       0.00      0.00      0.00        13\n",
      "     condition       0.00      0.00      0.00         9\n",
      "   conjunction       0.00      0.00      0.00         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.00      0.00      0.00        11\n",
      "   elaboration       0.00      0.00      0.00        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.00      0.00      0.00        10\n",
      "interpretation       0.03      0.08      0.04        12\n",
      "         joint       0.00      0.00      0.00        29\n",
      "          list       0.00      0.00      0.00        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.00      0.00      0.00         4\n",
      "       purpose       0.00      0.00      0.00         3\n",
      "        reason       0.00      0.00      0.00        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.00       260\n",
      "     macro avg       0.00      0.00      0.00       260\n",
      "  weighted avg       0.00      0.00      0.00       260\n",
      "\n",
      "Latest Test Loss: 4.498 |  Latest Test Acc: 0.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best earliest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_token_ids = None\n",
    "mask_ids = None\n",
    "seg_ids = None\n",
    "feat = None\n",
    "y = None\n",
    "\n",
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "# print(pair_token_ids)\n",
    "outputs = model(pair_token_ids.to(device), \n",
    "                token_type_ids=seg_ids.to(device), \n",
    "                attention_mask=mask_ids.to(device),\n",
    "                feat=feat.to(device))\n",
    "bertpooleroutput = outputs[-1]\n",
    "\n",
    "\n",
    "\n",
    "bertpooleroutput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.pooler.dense.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.54223120e-01,  1.77842155e-01,  4.89818454e-02, ...,\n",
       "        -5.29733971e-02, -7.14551955e-02, -1.18803168e-02],\n",
       "       [ 1.22249406e-03, -1.87259354e-03, -3.97209777e-03, ...,\n",
       "        -7.05363043e-03,  2.29791012e-02, -1.31956842e-02],\n",
       "       [-2.67129373e-02,  1.70170292e-02, -2.00083130e-03, ...,\n",
       "        -8.65909364e-03,  1.58971455e-02,  1.88870542e-02],\n",
       "       ...,\n",
       "       [-1.41868275e-02, -6.74810866e-03, -1.61513046e-04, ...,\n",
       "        -8.59235041e-03,  2.43463907e-02,  1.08030168e-02],\n",
       "       [-1.33844882e-01,  1.02687612e-01,  7.44487792e-02, ...,\n",
       "         1.50867132e-02, -5.81034087e-03, -9.93019436e-04],\n",
       "       [-5.14969565e-02,  3.43010388e-02, -3.78418081e-02, ...,\n",
       "        -3.79230008e-02, -2.56991889e-02, -1.75314099e-02]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "bertpooleroutput_np = model.encoder.pooler.dense.weight.to('cpu').detach().numpy()\n",
    "principalComponents = pca.fit_transform(bertpooleroutput_np)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = model.encoder.pooler.dense.weight.to('cpu').detach().numpy()\n",
    "b = principalComponents\n",
    "heatmap = plt.imshow(X_sparse_tsvd, cmap='hot') #d, \n",
    "plt.colorbar(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.95, 0.00, 0.00, ..., 0.00, 0.00, 0.00],\n",
       "       [0.00, 3.57, 0.00, ..., 0.00, 0.00, 0.00],\n",
       "       [0.00, 0.00, 3.03, ..., 0.00, 0.00, 0.00],\n",
       "       ...,\n",
       "       [0.00, 0.00, 0.00, ..., 0.86, 0.00, 0.00],\n",
       "       [0.00, 0.00, 0.00, ..., 0.00, 0.86, 0.00],\n",
       "       [0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.85]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general svd, take the diagonal for visualization\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "float_formatter = lambda x: \"%.2f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "image = a\n",
    "U, s, V = np.linalg.svd(image)\n",
    "top_n_eigens = 100\n",
    "s = s[:top_n_eigens]\n",
    "d = np.diag(s)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55, 0.18, -0.05, ..., -0.11, 0.10, -0.03],\n",
       "       [0.01, 0.00, 0.01, ..., 0.02, -0.01, -0.01],\n",
       "       [-0.02, 0.02, 0.00, ..., -0.02, 0.02, -0.01],\n",
       "       ...,\n",
       "       [-0.06, 0.06, 0.04, ..., 0.00, 0.01, 0.00],\n",
       "       [-0.01, 0.01, 0.02, ..., 0.02, -0.02, 0.03],\n",
       "       [-0.02, 0.02, 0.01, ..., -0.01, -0.01, 0.02]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# truncated svd = LSA. Not centred unlike PCA so used for sparse matrices\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def truncate_2d(matrix):\n",
    "    tsvd = TruncatedSVD(n_components=50)\n",
    "    matrix = tsvd.fit(matrix).transform(matrix)\n",
    "    # matrix = matrix.T\n",
    "    # matrix = tsvd.fit(matrix).transform(matrix)\n",
    "    return matrix[:100]\n",
    "    \n",
    "X_sparse_tsvd = truncate_2d(a)\n",
    "X_sparse_tsvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evidence\n",
      "purpose\n",
      "background\n",
      "e-elaboration\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, pd.Series([mnli_dataset.rev_label_dict[x] for x in y.tolist()])], axis = 1)\n",
    "finalDf.columns = ['principal component 1', 'principal component 2', 'target']\n",
    "\n",
    "fig = plt.figure(figsize = (4,4))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = mnli_dataset.label_dict.keys()\n",
    "# print(targets)\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "for target, color in zip(targets,colors):\n",
    "    print(target)\n",
    "    indicesToKeep = finalDf['target'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "plt.xlim([-5, 7])\n",
    "plt.ylim([-5, 7])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.0303 test_acc: 0.3875\n",
      "00:00:02.93\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.20      0.09      0.13        11\n",
      "    background       0.32      0.71      0.44        17\n",
      "         cause       0.00      0.00      0.00         7\n",
      "  circumstance       0.00      0.00      0.00        13\n",
      "    concession       0.29      0.36      0.32        11\n",
      "     condition       0.44      0.88      0.58         8\n",
      "   conjunction       0.75      0.75      0.75         8\n",
      "      contrast       0.00      0.00      0.00         3\n",
      " e-elaboration       0.73      0.62      0.67        13\n",
      "   elaboration       0.28      0.29      0.28        28\n",
      "  evaluation-n       0.00      0.00      0.00         8\n",
      "  evaluation-s       0.00      0.00      0.00         5\n",
      "      evidence       0.00      0.00      0.00         8\n",
      "interpretation       0.20      0.15      0.17        13\n",
      "         joint       0.24      0.44      0.31        18\n",
      "          list       0.38      0.61      0.47        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.67      0.73      0.70        11\n",
      "       purpose       1.00      0.40      0.57         5\n",
      "        reason       0.52      0.54      0.53        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.39       238\n",
      "     macro avg       0.26      0.29      0.26       238\n",
      "  weighted avg       0.33      0.39      0.34       238\n",
      "\n",
      "Val Loss: 2.030 |  Val Acc: 38.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best val acc\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
