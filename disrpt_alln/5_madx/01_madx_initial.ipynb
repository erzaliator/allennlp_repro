{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI6aVBQRy6LC"
   },
   "source": [
    "# 4️⃣ Zero-Shot Cross-Lingual Transfer using Adapters\n",
    "\n",
    "Beyond AdapterFusion, which we trained in [the previous notebook](https://github.com/Adapter-Hub/adapter-transformers/blob/master/notebooks/04_Cross_Lingual_Transfer.ipynb), we can compose adapters for zero-shot cross-lingual transfer between tasks. We will use the stacked adapter setup presented in **MAD-X** ([Pfeiffer et al., 2020](https://arxiv.org/pdf/2005.00052.pdf)) for this purpose.\n",
    "\n",
    "In this example, the base model is a pre-trained multilingual **XLM-R** (`xlm-roberta-base`) ([Conneau et al., 2019](https://arxiv.org/pdf/1911.02116.pdf)) model. Additionally, two types of adapters, language adapters and task adapters, are used. Here's how the MAD-X process works in detail:\n",
    "\n",
    "1. Train language adapters for the source and target language on a language modeling task. In this notebook, we won't train them ourselves but use [pre-trained language adapters from the Hub](https://adapterhub.ml/explore/text_lang/).\n",
    "2. Train a task adapter on the target task dataset. This task adapter is **stacked** upon the previously trained language adapter. During this step, only the weights of the task adapter are updated.\n",
    "3. Perform zero-shot cross-lingual transfer. In this last step, we simply replace the source language adapter with the target language adapter while keeping the stacked task adapter.\n",
    "\n",
    "Now to our concrete example: we select **XCOPA** ([Ponti et al., 2020](https://ducdauge.github.io/files/xcopa.pdf)), a multilingual extension of the **COPA** commonsence reasoning dataset ([Roemmele et al., 2011](https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF)) as our target task. The setup is trained on the original **English** dataset and then transferred to **Chinese**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L9gYpCV28OA"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Besides `adapter-transformers`, we use HuggingFace's `datasets` library for loading the data. So let's install both first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qL3Sq1HQynCq",
    "outputId": "1a53add7-208d-4767-a6f7-c51fad93787e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BERT_MODEL = 'bert-base-multilingual-cased'\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Mad'\n",
    "lr = 'lr=AdafactorDefault'\n",
    "model_name = 'plm='+BERT_MODEL\n",
    "additional_info = 'Info=v1_test1'\n",
    "lang1 = 'en'\n",
    "lang2 = 'de'\n",
    "name = '_'.join([experiment_name, lr, model_name, additional_info, lang1, lang2])\n",
    "\n",
    "MODEL_DIR = 'runs/'+name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merzaliator\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/5_madx/wandb/run-20230323_212934-vfyt7m9o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/erzaliator/allennlp_repro-disrpt_alln_5_madx/runs/vfyt7m9o\" target=\"_blank\">wandering-feather-23</a></strong> to <a href=\"https://wandb.ai/erzaliator/allennlp_repro-disrpt_alln_5_madx\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/erzaliator/allennlp_repro-disrpt_alln_5_madx\" target=\"_blank\">https://wandb.ai/erzaliator/allennlp_repro-disrpt_alln_5_madx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/erzaliator/allennlp_repro-disrpt_alln_5_madx/runs/vfyt7m9o\" target=\"_blank\">https://wandb.ai/erzaliator/allennlp_repro-disrpt_alln_5_madx/runs/vfyt7m9o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#WANDB\n",
    "wandb.init(reinit=True)\n",
    "wandb.run.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with params: BERT_MODEL=bert-base-multilingual-cased lr=lr=AdafactorDefault\n"
     ]
    }
   ],
   "source": [
    "# LOGGING\n",
    "from utils.logger import Logger\n",
    "logger = Logger(MODEL_DIR, wandb, wandb_flag=True)\n",
    "print('Running with params: BERT_MODEL='+ BERT_MODEL+ ' lr='+ str(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP9OMSUT-FtL"
   },
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "We need the English COPA dataset for training our task adapter. It is part of the SuperGLUE benchmark and can be loaded via `datasets` using one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16002, 2155, 1621)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "en_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_train_enriched.rels'))\n",
    "en_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_test_enriched.rels'))\n",
    "en_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_dev_enriched.rels'))\n",
    "\n",
    "de_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels'))\n",
    "de_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels'))\n",
    "de_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels'))\n",
    "\n",
    "len(en_train_dataset_df), len(en_test_dataset_df), len(en_valid_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit1_txt': Value(dtype='string', id=None),\n",
       " 'unit1_sent': Value(dtype='string', id=None),\n",
       " 'unit2_txt': Value(dtype='string', id=None),\n",
       " 'unit2_sent': Value(dtype='string', id=None),\n",
       " 'dir': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='string', id=None),\n",
       " 'distance': Value(dtype='string', id=None),\n",
       " 'u1_depdir': Value(dtype='string', id=None),\n",
       " 'u2_depdir': Value(dtype='string', id=None),\n",
       " 'u2_func': Value(dtype='string', id=None),\n",
       " 'u1_position': Value(dtype='string', id=None),\n",
       " 'u2_position': Value(dtype='string', id=None),\n",
       " 'sat_children': Value(dtype='string', id=None),\n",
       " 'nuc_children': Value(dtype='string', id=None),\n",
       " 'genre': Value(dtype='string', id=None),\n",
       " 'unit1_case': Value(dtype='string', id=None),\n",
       " 'unit2_case': Value(dtype='string', id=None),\n",
       " 'u1_discontinuous': Value(dtype='string', id=None),\n",
       " 'u2_discontinuous': Value(dtype='string', id=None),\n",
       " 'same_speaker': Value(dtype='string', id=None),\n",
       " 'lex_overlap_length': Value(dtype='string', id=None),\n",
       " 'u1_func': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train_dataset_df.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVa3Vk0QdNYI"
   },
   "source": [
    "In this example, we model COPA as a multiple-choice task with two choices. Thus, we encode the premise and question as well as both choices as one input to our `xlm-roberta-base` model. Using `dataset.map()`, we can pass the full dataset through the tokenizer in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 16002 examples\n",
      "read 1621 examples\n",
      "read 2155 examples\n",
      "read 2164 examples\n",
      "read 241 examples\n",
      "read 260 examples\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from datasets import ClassLabel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the SNLI dataset.\"\"\"\n",
    "    def __init__(self, dataset, labels, raw_text=False):\n",
    "        self.text = []\n",
    "        self.raw_text = []\n",
    "        self.raw_label = []\n",
    "        self.raw_text_flag = raw_text\n",
    "        self.num_rows = len(dataset)\n",
    "        for premise, hypothesis in zip(dataset['unit1_txt'], dataset['unit2_txt']):\n",
    "            self.text.append(tokenizer.encode_plus(premise, hypothesis, padding=\"max_length\", truncation=True, max_length=512, return_token_type_ids=True))\n",
    "            if raw_text: self.raw_text.append([premise, hypothesis])\n",
    "        # self.labels = torch.tensor(labels.str2int(dataset['label'])).to(device)\n",
    "        self.labels = labels.str2int(dataset['label'])\n",
    "        if raw_text: self.raw_label = dataset['label']\n",
    "        print('read ' + str(len(self.text)) + ' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.raw_text_flag:  \n",
    "            return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'raw_text': self.raw_text[idx],\n",
    "                'label':self.labels[idx],\n",
    "                'raw_label': self.raw_label[idx]}\n",
    "\n",
    "        return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'label':self.labels[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def combine_with_another_dataset(self, dataset2):\n",
    "        print('Adding datasets of sizes ', self.num_rows, ', ', dataset2.num_rows)\n",
    "        self.text = self.text + dataset2.text\n",
    "        self.raw_text = self.raw_text + dataset2.raw_text\n",
    "        self.raw_label = self.raw_label + dataset2.raw_label\n",
    "        self.num_rows = len(self.text) #update texts is now longer\n",
    "        assert self.raw_text_flag == dataset2.raw_text_flag\n",
    "        print('To new dataset size: ', self.num_rows)\n",
    "\n",
    "\n",
    "def load_data_snli(batch_size, train_dataset_df, valid_dataset_df, test_dataset_df, labels):\n",
    "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
    "    train_data = train_dataset_df\n",
    "    valid_data = valid_dataset_df\n",
    "    test_data = test_dataset_df\n",
    "    train_set = SNLIDataset(train_data, labels, raw_text=False)\n",
    "    valid_set = SNLIDataset(valid_data, labels, raw_text=False)\n",
    "    test_set = SNLIDataset(test_data, labels, raw_text=False)\n",
    "    return train_set, valid_set, test_set\n",
    "\n",
    "en_labels = ClassLabel(names=list(set(en_train_dataset_df['label'])|set(en_test_dataset_df['label'])|set(en_valid_dataset_df['label'])))\n",
    "en_train_dataset, en_valid_dataset, en_test_dataset = load_data_snli(BATCH_SIZE, en_train_dataset_df, en_valid_dataset_df, en_test_dataset_df, en_labels)\n",
    "de_labels = ClassLabel(names=list(set(de_train_dataset_df['label'])|set(de_test_dataset_df['label'])|set(de_valid_dataset_df['label'])))\n",
    "de_train_dataset, de_valid_dataset, de_test_dataset = load_data_snli(BATCH_SIZE, de_train_dataset_df, de_valid_dataset_df, de_test_dataset_df, de_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs21MzEQ_0v4"
   },
   "source": [
    "## Task Adapter Training\n",
    "\n",
    "In this section, we will train the task adapter on the English COPA dataset. We use a pre-trained XLM-R model from HuggingFace and instantiate our model using `AutoAdapterModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnq8n_KP_3aX",
    "outputId": "590b1cae-a454-4110-c9fb-f76f4dff423a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertAdapterModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoAdapterModel\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    BERT_MODEL,\n",
    ")\n",
    "model = AutoAdapterModel.from_pretrained(\n",
    "    BERT_MODEL,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jRqbBgS0BoHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdapterConfig\n",
    "\n",
    "# Load the language adapters\n",
    "lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "model.load_adapter(\"en/wiki@ukp\", config=lang_adapter_config)\n",
    "model.load_adapter(\"de/wiki@ukp\", config=lang_adapter_config)\n",
    "\n",
    "# Add a new task adapter\n",
    "model.add_adapter(\"disrpt\")\n",
    "\n",
    "# Add a classification head for our target task\n",
    "num_labels=de_labels.num_classes\n",
    "print([num_labels])\n",
    "model.add_classification_head(\"disrpt\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7wBpjGWZ4v7O"
   },
   "outputs": [],
   "source": [
    "model.train_adapter([\"disrpt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zgGqHJQbijgg"
   },
   "outputs": [],
   "source": [
    "# Unfreeze and activate stack setup\n",
    "from transformers.adapters.composition import Stack\n",
    "\n",
    "lang = 'en'\n",
    "model.active_adapters = Stack(lang, \"disrpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertAdapterModel(\n",
      "  (shared_parameters): ModuleDict()\n",
      "  (bert): BertModel(\n",
      "    (shared_parameters): ModuleDict()\n",
      "    (invertible_adapters): ModuleDict(\n",
      "      (en): NICECouplingBlock(\n",
      "        (F): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "        (G): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (de): NICECouplingBlock(\n",
      "        (F): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): NewGELUActivation()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "        (G): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): NewGELUActivation()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "    (prefix_tuning): PrefixTuningPool(\n",
      "      (prefix_tunings): ModuleDict()\n",
      "    )\n",
      "  )\n",
      "  (heads): ModuleDict(\n",
      "    (disrpt): ClassificationHead(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (2): Activation_Function_Class(\n",
      "        (f): Tanh()\n",
      "      )\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=768, out_features=26, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train@\"+lang)\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, log_loss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "import os\n",
    "    \n",
    "def compute_metrics(pred):\n",
    "    global num_labels\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    # confusion matrix\n",
    "    class_names = en_labels if lang=='en' else de_labels\n",
    "    wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None, y_true=labels, preds=preds, class_names=class_names._int2str)})\n",
    "    labels2 = [class_names._int2str[x.item()] for x in labels]\n",
    "    preds2 = [class_names._int2str[x.item()] for x in preds]\n",
    "    # log predictions\n",
    "    output_predict_folder = MODEL_DIR+'_'+lang\n",
    "    if not os.path.exists(output_predict_folder): os.makedirs(output_predict_folder)\n",
    "    output_predict_file = os.path.join(output_predict_folder, \"predictions.txt\")\n",
    "    with open(output_predict_file, \"w\") as writer:\n",
    "        writer.write(str({'prefix': lang, 'labels': labels2, 'preds': preds2}))\n",
    "    wandb.save(os.path.join(output_predict_file))\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    logits = torch.tensor(pred.predictions)\n",
    "    labels = torch.tensor(labels)\n",
    "    loss = loss_fct(logits.view(-1, num_labels), labels.view(-1))\n",
    "\n",
    "    return {\n",
    "        'accuracy@'+lang: acc,\n",
    "        'f1@'+lang: f1,\n",
    "        'precision@'+lang: precision,\n",
    "        'recall@'+lang: recall,\n",
    "        'loss@'+lang: loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "j0gFxQRdDkQ6"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    output_dir=MODEL_DIR+'_'+lang,\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=en_train_dataset, #CHANGE\n",
    "    eval_dataset=en_valid_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.add_callback(CustomCallback(trainer)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "vSUs2FjXDmsx",
    "outputId": "2b8bb989-f6ca-4702-c222-15eea9823bbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 16002\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8008\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='8008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/8008 00:00 < 55:29, 2.40 it/s, Epoch 0.00/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/en/adapter_config.json\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1000/en/adapter_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16002\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16002\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16002\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-2500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16002\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-4500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-5500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16002\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-6500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16002\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1621\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-8000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_en/checkpoint-8000/en/adapter_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train_log metrics *****\n",
      "  epoch                    =        8.0\n",
      "  total_flos               = 37331542GF\n",
      "  train_loss               =     1.0452\n",
      "  train_runtime            = 1:24:02.53\n",
      "  train_samples_per_second =     25.387\n",
      "  train_steps_per_second   =      1.588\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train_log\", metrics)\n",
    "trainer.save_metrics(\"train_log\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2155\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/135 00:00 < 00:26, 5.10 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_en_loss': 1.2087045907974243,\n",
       " 'test_en_accuracy@en': 0.6519721577726219,\n",
       " 'test_en_f1@en': 0.4828209714935802,\n",
       " 'test_en_precision@en': 0.5587316549447741,\n",
       " 'test_en_recall@en': 0.45135070136556504,\n",
       " 'test_en_loss@en': 1.2087047100067139,\n",
       " 'test_en_runtime': 26.2237,\n",
       " 'test_en_samples_per_second': 82.178,\n",
       " 'test_en_steps_per_second': 5.148,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(metric_key_prefix='test_en',\n",
    "                eval_dataset=en_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 260\n",
      "  Batch size = 16\n",
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_de(en)_loss': 6.265538215637207,\n",
       " 'test_de(en)_accuracy@de(en)': 0.05,\n",
       " 'test_de(en)_f1@de(en)': 0.019683919944789508,\n",
       " 'test_de(en)_precision@de(en)': 0.017743589743589742,\n",
       " 'test_de(en)_recall@de(en)': 0.0317526395173454,\n",
       " 'test_de(en)_loss@de(en)': 6.265538692474365,\n",
       " 'test_de(en)_runtime': 3.4177,\n",
       " 'test_de(en)_samples_per_second': 76.075,\n",
       " 'test_de(en)_steps_per_second': 4.974,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = 'de(en)'\n",
    "\n",
    "trainer.evaluate(metric_key_prefix='test_de(en)',\n",
    "                eval_dataset=de_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axvDsmnJnGUG"
   },
   "source": [
    "## Cross-lingual transfer\n",
    "\n",
    "With the model and all adapters trained and ready, we can come to the cross-lingual transfer step here. We will evaluate our setup on the Chinese split of the XCOPA dataset.\n",
    "Therefore, we'll first download the data and preprocess it using the same method as the English dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "V04UntKfeK_z"
   },
   "outputs": [],
   "source": [
    "lang = 'de'\n",
    "model.active_adapters = Stack(lang, \"disrpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set training args for de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread SystemMonitor:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 118, in _start\n",
      "    asset.start()\n",
      "  File \"/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/cpu.py\", line 166, in start\n",
      "    self.metrics_monitor.start()\n",
      "  File \"/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 168, in start\n",
      "    logger.info(f\"Started {self._process.name}\")\n",
      "AttributeError: 'NoneType' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir=MODEL_DIR+'_'+lang,\n",
    "    overwrite_output_dir=False,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=1,\n",
    "    # resume_from_checkpoint=MODEL_DIR+'/last-checkpoint',\n",
    ")\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=de_train_dataset,\n",
    "    eval_dataset=de_valid_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.add_callback(CustomCallback(trainer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2164\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2168\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='2168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/2168 00:00 < 08:26, 4.27 it/s, Epoch 0.01/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2164\n",
      "  Batch size = 8\n",
      "  Num examples = 2164\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2164\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2164\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1000/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2164\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2164\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500/disrpt/head_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2164\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2164\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/en/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/en/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/de/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/de/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/disrpt/adapter_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/disrpt/head_config.json\n",
      "Module weights saved in runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-2000/disrpt/pytorch_model_head.bin\n",
      "Deleting older checkpoint [runs/Mad_lr=AdafactorDefault_plm=bert-base-multilingual-cased_Info=v1_test1_en_de_de/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2164\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 241\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train_logger metrics *****\n",
      "  epoch                    =        8.0\n",
      "  total_flos               = 37331542GF\n",
      "  train_loss               =     1.0452\n",
      "  train_runtime            = 1:24:02.53\n",
      "  train_samples_per_second =     25.387\n",
      "  train_steps_per_second   =      1.588\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train_logger\", metrics)\n",
    "trainer.save_metrics(\"train_logger\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "CrW1cJyaeMox",
    "outputId": "f3f504c1-9518-4c21-e10f-b5202ae1c39f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 260\n",
      "  Batch size = 8\n",
      "  Num examples = 260\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_de_loss': 2.5744662284851074,\n",
       " 'test_de_accuracy@de': 0.2923076923076923,\n",
       " 'test_de_f1@de': 0.23475593004467768,\n",
       " 'test_de_precision@de': 0.2478756341697518,\n",
       " 'test_de_recall@de': 0.2699608662691827,\n",
       " 'test_de_loss@de': 2.5744662284851074,\n",
       " 'test_de_runtime': 3.6001,\n",
       " 'test_de_samples_per_second': 72.22,\n",
       " 'test_de_steps_per_second': 9.166,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(metric_key_prefix='test_de',\n",
    "                eval_dataset=de_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "CrW1cJyaeMox",
    "outputId": "f3f504c1-9518-4c21-e10f-b5202ae1c39f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2155\n",
      "  Batch size = 8\n",
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_en(de)_loss': 3.009084463119507,\n",
       " 'test_en(de)_accuracy@en(de)': 0.17540603248259862,\n",
       " 'test_en(de)_f1@en(de)': 0.06975860652048695,\n",
       " 'test_en(de)_precision@en(de)': 0.08361451184580698,\n",
       " 'test_en(de)_recall@en(de)': 0.0916845074726499,\n",
       " 'test_en(de)_loss@en(de)': 3.0090839862823486,\n",
       " 'test_en(de)_runtime': 27.5999,\n",
       " 'test_en(de)_samples_per_second': 78.08,\n",
       " 'test_en(de)_steps_per_second': 9.783,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = 'en(de)'\n",
    "\n",
    "trainer.evaluate(metric_key_prefix='test_en(de)',\n",
    "                eval_dataset=en_test_dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_Cross_Lingual_Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "adapters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cb7dbc5b67469b8643c0ea3e6b3921": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f3bac44e13246ab9f9c8564a44e1fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e45676711b477e9a1ce2cf4ac8f3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "11b4409af40748e0b760e91c3d91ede7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28b184f13a948d5995ee04720748871",
      "placeholder": "​",
      "style": "IPY_MODEL_2393e906e07e4e8ba661b0eafd2268e8",
      "value": " 100/0 [00:00&lt;00:00, 1191.08 examples/s]"
     }
    },
    "12ec755bb33c4ff894644e291ce33040": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13829992bf994ec5bbec71684cc824e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ccbb12bb5a548488c9b646159f893d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e70f23ca6f94a2099c2cca1eaf875d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8348929b740242d3bdc73ea2c8bcd9c8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c82fa83594a349c991626ee55b8edfa4",
      "value": 1
     }
    },
    "21bd77c2c70040548a696c5a40d81a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac8b24c5d6214716a409ca95580306f5",
      "placeholder": "​",
      "style": "IPY_MODEL_932d3ee3c9d74761bfc4bcf5c003d205",
      "value": " 1/1 [00:10&lt;00:00, 10.75s/ba]"
     }
    },
    "2393e906e07e4e8ba661b0eafd2268e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "249abcb1904c4d1ca4116b677011b017": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12ec755bb33c4ff894644e291ce33040",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df292d721c1748c485f281aa2162b9a9",
      "value": 1
     }
    },
    "2a76413cb9cd4a6f901a8bef7dc70220": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c154bfdf049147638c67d2844d25f9e6",
       "IPY_MODEL_4fe615dff7104a018c48491fd711ed45"
      ],
      "layout": "IPY_MODEL_13829992bf994ec5bbec71684cc824e6"
     }
    },
    "2d964df49d71456093b427af2a3ac6cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "315cd377eae94488b258460f06e5cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02cb7dbc5b67469b8643c0ea3e6b3921",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a8c7ea6d7ec4ec691525f6e3ca88d48",
      "value": 1
     }
    },
    "342e98cd2d99438d861d5c1cf54b573d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d85845466e5a4ffd8370ef4c8b965684",
       "IPY_MODEL_5b84c1bb95354f939bc1918b5478cf08"
      ],
      "layout": "IPY_MODEL_e3e3c18ef96e48999e14be0c60ad9f04"
     }
    },
    "3bc11633e20c460eb9058cc4b480b224": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3ccf15d7bea44e9bb91b9b3d32b3c691": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a0b61f58dfd4b2c88e7fe818c4de4b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfc579b1c3354bcd9a0be2fde370954c",
       "IPY_MODEL_ed22b18a21c943f291c6326030cb2753"
      ],
      "layout": "IPY_MODEL_bc7b5cd3163b4b60877d80be43598436"
     }
    },
    "4a23a9bdd091425cbda38222f2e4c3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58b17e932dd74756b62fb7f6ed0d37ba",
      "placeholder": "​",
      "style": "IPY_MODEL_77583bbefaf849eea83d3ae327e4070e",
      "value": " 1/1 [00:00&lt;00:00,  2.51ba/s]"
     }
    },
    "4eac0e183d8047e498d3a576f3c3a1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fe615dff7104a018c48491fd711ed45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2423ca88827446aa5b5c78ccc36a263",
      "placeholder": "​",
      "style": "IPY_MODEL_527ea785de0a47f0ba5b0d0aea72cc97",
      "value": " 500/0 [00:00&lt;00:00, 2888.43 examples/s]"
     }
    },
    "525a5c1a8ba04c8e89fc514064539d73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527ea785de0a47f0ba5b0d0aea72cc97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5321f4576a6c4fe69de0c97b43269d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "568fedab4a4e44d9baa8213d54d60d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f512c5cdfaa64005bb987f032957e530",
      "placeholder": "​",
      "style": "IPY_MODEL_87c546c1a23c402f8a6de964828dc035",
      "value": " 28.2k/? [00:00&lt;00:00, 297kB/s]"
     }
    },
    "58b17e932dd74756b62fb7f6ed0d37ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b2e4c980b6a4e15bef86d1907b20f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d964df49d71456093b427af2a3ac6cc",
      "placeholder": "​",
      "style": "IPY_MODEL_3ccf15d7bea44e9bb91b9b3d32b3c691",
      "value": " 642k/? [00:00&lt;00:00, 3.06MB/s]"
     }
    },
    "5b84c1bb95354f939bc1918b5478cf08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fec9b3f47668416f8709fd7ab80a9730",
      "placeholder": "​",
      "style": "IPY_MODEL_5d95a7e842dc43d995b3ad5f0b61ae8f",
      "value": " 1/1 [00:00&lt;00:00,  2.28ba/s]"
     }
    },
    "5d95a7e842dc43d995b3ad5f0b61ae8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5df3d17d64e24faeab6cc644d333536a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f708ccdb4f941918696d583ad9bd9c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6025f45ce1af4c8caab09042992f2094": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "630597c0e70d4792b58c8942296692a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff7c6d1bfc654c2db63e40bad4e3eb33",
       "IPY_MODEL_f964d3d5333948e0b14117555b82275b"
      ],
      "layout": "IPY_MODEL_64e51ced10004147b21e51db1343cac8"
     }
    },
    "64e51ced10004147b21e51db1343cac8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67bde4b1393e48a1a5c1b00969317131": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71b51022c34247929dcb8f11c74a2de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e70f23ca6f94a2099c2cca1eaf875d8",
       "IPY_MODEL_11b4409af40748e0b760e91c3d91ede7"
      ],
      "layout": "IPY_MODEL_8119426c8705459fb9df8b2c711d3c36"
     }
    },
    "77583bbefaf849eea83d3ae327e4070e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a31bf9dedde47188efdfaf6a262b730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a718fb0db5640fd8eb04ef18fe1e339": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8119426c8705459fb9df8b2c711d3c36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8348929b740242d3bdc73ea2c8bcd9c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c546c1a23c402f8a6de964828dc035": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89f8555b95ec48b7b3282cb365b1cfdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb6e0c49bd040b7bd5f266c4608dd31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d88b67069074ee6bc937b46cc10418a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "932d3ee3c9d74761bfc4bcf5c003d205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9380ff7e78f846babb16740cfc9cf7f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f45f9a16f75e4d07abe5dcaf2fb300f4",
       "IPY_MODEL_21bd77c2c70040548a696c5a40d81a00"
      ],
      "layout": "IPY_MODEL_7a31bf9dedde47188efdfaf6a262b730"
     }
    },
    "949971635f1f498e86e04b9d4e28d353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9a8c7ea6d7ec4ec691525f6e3ca88d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9c8548e2e4c54bf88e678c571c537867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a3da9679c78640c3be6e7cbbd5bcccae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f3bac44e13246ab9f9c8564a44e1fa3",
      "placeholder": "​",
      "style": "IPY_MODEL_7a718fb0db5640fd8eb04ef18fe1e339",
      "value": " 1/1 [00:13&lt;00:00, 13.12s/ba]"
     }
    },
    "ac8b24c5d6214716a409ca95580306f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb9523d3e594c3d84036ad2348a7a64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e71f76432d5e469d8cf742bbed6e0f1c",
       "IPY_MODEL_a3da9679c78640c3be6e7cbbd5bcccae"
      ],
      "layout": "IPY_MODEL_8d88b67069074ee6bc937b46cc10418a"
     }
    },
    "aebd284cd0ba4dfbafce1f0b99cd5213": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28b184f13a948d5995ee04720748871": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2b6f74edcdb465e94d9f07287fa506d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bc7b5cd3163b4b60877d80be43598436": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfc579b1c3354bcd9a0be2fde370954c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efbd298ec8f0461ba89793855901330b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67bde4b1393e48a1a5c1b00969317131",
      "value": 1
     }
    },
    "c154bfdf049147638c67d2844d25f9e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f708ccdb4f941918696d583ad9bd9c9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bc11633e20c460eb9058cc4b480b224",
      "value": 1
     }
    },
    "c21fa18f6c4b4bdd9621ef29180646db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_249abcb1904c4d1ca4116b677011b017",
       "IPY_MODEL_4a23a9bdd091425cbda38222f2e4c3a9"
      ],
      "layout": "IPY_MODEL_fa8da5adaacd4534b60e51ba4dce6c4a"
     }
    },
    "c2423ca88827446aa5b5c78ccc36a263": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b64289fc4445f59a94d6c51a288834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ccbb12bb5a548488c9b646159f893d3",
      "max": 1750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6025f45ce1af4c8caab09042992f2094",
      "value": 1750
     }
    },
    "c515e4e9f5b7470e8a17e4a4247878f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4b64289fc4445f59a94d6c51a288834",
       "IPY_MODEL_568fedab4a4e44d9baa8213d54d60d38"
      ],
      "layout": "IPY_MODEL_89f8555b95ec48b7b3282cb365b1cfdd"
     }
    },
    "c6ae198ebaf2467bba3f0a49f3aab196": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82fa83594a349c991626ee55b8edfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d85845466e5a4ffd8370ef4c8b965684": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6ae198ebaf2467bba3f0a49f3aab196",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2b6f74edcdb465e94d9f07287fa506d",
      "value": 1
     }
    },
    "df292d721c1748c485f281aa2162b9a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e3e3c18ef96e48999e14be0c60ad9f04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6bdcb09b73d4aa3844076829cf43f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e71f76432d5e469d8cf742bbed6e0f1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cb6e0c49bd040b7bd5f266c4608dd31",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10e45676711b477e9a1ce2cf4ac8f3a9",
      "value": 1
     }
    },
    "ea780b89e28a4348abfac40ef8fd140a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_315cd377eae94488b258460f06e5cc10",
       "IPY_MODEL_5b2e4c980b6a4e15bef86d1907b20f40"
      ],
      "layout": "IPY_MODEL_4eac0e183d8047e498d3a576f3c3a1f4"
     }
    },
    "ecac341937124f21b04479a50a05c688": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed22b18a21c943f291c6326030cb2753": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecac341937124f21b04479a50a05c688",
      "placeholder": "​",
      "style": "IPY_MODEL_e6bdcb09b73d4aa3844076829cf43f8a",
      "value": " 1/1 [04:39&lt;00:00, 279.14s/ba]"
     }
    },
    "efbd298ec8f0461ba89793855901330b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f45f9a16f75e4d07abe5dcaf2fb300f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5321f4576a6c4fe69de0c97b43269d3b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c8548e2e4c54bf88e678c571c537867",
      "value": 1
     }
    },
    "f512c5cdfaa64005bb987f032957e530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f964d3d5333948e0b14117555b82275b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_525a5c1a8ba04c8e89fc514064539d73",
      "placeholder": "​",
      "style": "IPY_MODEL_5df3d17d64e24faeab6cc644d333536a",
      "value": " 4.89k/? [00:01&lt;00:00, 3.05kB/s]"
     }
    },
    "fa8da5adaacd4534b60e51ba4dce6c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fec9b3f47668416f8709fd7ab80a9730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7c6d1bfc654c2db63e40bad4e3eb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aebd284cd0ba4dfbafce1f0b99cd5213",
      "max": 1935,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_949971635f1f498e86e04b9d4e28d353",
      "value": 1935
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
