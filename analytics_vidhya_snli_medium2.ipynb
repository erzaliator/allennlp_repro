{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "SEED = 1111\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# import os\n",
    "# os.environment[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "This notebook has been copied from analytics_vidya_snli_medium.ipynb to investigate how encoding arguments together impacts performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-cased'\n",
    "CORPUS = 'eng.rst.gum'\n",
    "MAX_SEQ_LENGTH = 51\n",
    "batches_per_epoch = 1700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aesthetic Appreciation and Spanish Art :</td>\n",
       "      <td>In this study we used eye-tracking in the firs...</td>\n",
       "      <td>Aesthetic Appreciation and Spanish Art :</td>\n",
       "      <td>In this study we used eye-tracking in the firs...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aesthetic Appreciation and Spanish Art :</td>\n",
       "      <td>Insights from Eye-Tracking</td>\n",
       "      <td>Aesthetic Appreciation and Spanish Art :</td>\n",
       "      <td>Insights from Eye-Tracking</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>elaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Claire Bailey-Ross claire.bailey-ross@port.ac....</td>\n",
       "      <td>In this study we used eye-tracking in the firs...</td>\n",
       "      <td>Claire Bailey-Ross claire.bailey-ross@port.ac....</td>\n",
       "      <td>In this study we used eye-tracking in the firs...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>attribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Claire Bailey-Ross claire.bailey-ross@port.ac....</td>\n",
       "      <td>Andrew Beresford a.m.beresford@durham.ac.uk Du...</td>\n",
       "      <td>Claire Bailey-Ross claire.bailey-ross@port.ac....</td>\n",
       "      <td>Andrew Beresford a.m.beresford@durham.ac.uk Du...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>joint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Claire Bailey-Ross claire.bailey-ross@port.ac....</td>\n",
       "      <td>Daniel Smith daniel.smith2@durham.ac.uk Durham...</td>\n",
       "      <td>Claire Bailey-Ross claire.bailey-ross@port.ac....</td>\n",
       "      <td>Daniel Smith daniel.smith2@durham.ac.uk Durham...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>joint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0           Aesthetic Appreciation and Spanish Art :   \n",
       "1           Aesthetic Appreciation and Spanish Art :   \n",
       "2  Claire Bailey-Ross claire.bailey-ross@port.ac....   \n",
       "3  Claire Bailey-Ross claire.bailey-ross@port.ac....   \n",
       "4  Claire Bailey-Ross claire.bailey-ross@port.ac....   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  In this study we used eye-tracking in the firs...   \n",
       "1                         Insights from Eye-Tracking   \n",
       "2  In this study we used eye-tracking in the firs...   \n",
       "3  Andrew Beresford a.m.beresford@durham.ac.uk Du...   \n",
       "4  Daniel Smith daniel.smith2@durham.ac.uk Durham...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0           Aesthetic Appreciation and Spanish Art :   \n",
       "1           Aesthetic Appreciation and Spanish Art :   \n",
       "2  Claire Bailey-Ross claire.bailey-ross@port.ac....   \n",
       "3  Claire Bailey-Ross claire.bailey-ross@port.ac....   \n",
       "4  Claire Bailey-Ross claire.bailey-ross@port.ac....   \n",
       "\n",
       "                                          unit2_sent  dir        label  \n",
       "0  In this study we used eye-tracking in the firs...  1>2  preparation  \n",
       "1                         Insights from Eye-Tracking  1<2  elaboration  \n",
       "2  In this study we used eye-tracking in the firs...  1>2  attribution  \n",
       "3  Andrew Beresford a.m.beresford@durham.ac.uk Du...  1<2        joint  \n",
       "4  Daniel Smith daniel.smith2@durham.ac.uk Durham...  1<2        joint  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# we only need specific columns\n",
    "train_df = pd.read_csv('./eng.rst.gum_train_enriched.rels', sep='\\t', usecols = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label'])\n",
    "val_df = pd.read_csv('./eng.rst.gum_test_enriched.rels', sep='\\t', usecols = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label'])\n",
    "test_df = pd.read_csv('./eng.rst.gum_dev_enriched.rels', sep='\\t', usecols = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label'])\n",
    "\n",
    "# /home/VD/kaveri/DisCoDisCo/gucorpling_models/rel/flair_clone_dataset_reader.py\n",
    "# with open(rels_file_path, \"r\") as f:\n",
    "#     reader = csv.DictReader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "#     for i, row in enumerate(reader):\n",
    "#         yield self.text_to_instance(\n",
    "#             unit1_txt=row[\"unit1_txt\"],\n",
    "#             unit1_sent=row[\"unit1_sent\"],\n",
    "#             unit2_txt=row[\"unit2_txt\"],\n",
    "#             unit2_sent=row[\"unit2_sent\"],\n",
    "#             dir=row[\"dir\"],\n",
    "#             label=row[\"label\"],\n",
    "#             features=features[i]\n",
    "#         )\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "train_df = train_df[:int(len(train_df)/100)]\n",
    "val_df = train_df[:int(len(val_df)/100)]\n",
    "test_df = train_df[:int(len(test_df)/100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'combined_body': [101,\n",
       "  198,\n",
       "  13492,\n",
       "  13542,\n",
       "  1105,\n",
       "  8492,\n",
       "  2944,\n",
       "  1893,\n",
       "  131,\n",
       "  135,\n",
       "  102,\n",
       "  1107,\n",
       "  1142,\n",
       "  2025,\n",
       "  1195,\n",
       "  1215,\n",
       "  2552,\n",
       "  118,\n",
       "  10066,\n",
       "  1107,\n",
       "  1103,\n",
       "  1148,\n",
       "  2016,\n",
       "  102],\n",
       " 'combined_sentence': [101,\n",
       "  198,\n",
       "  13492,\n",
       "  13542,\n",
       "  1105,\n",
       "  8492,\n",
       "  2944,\n",
       "  1893,\n",
       "  131,\n",
       "  135,\n",
       "  102,\n",
       "  1107,\n",
       "  1142,\n",
       "  2025,\n",
       "  1195,\n",
       "  1215,\n",
       "  2552,\n",
       "  118,\n",
       "  10066,\n",
       "  1107,\n",
       "  1103,\n",
       "  1148,\n",
       "  2016,\n",
       "  1104,\n",
       "  12138,\n",
       "  3703,\n",
       "  2541,\n",
       "  1104,\n",
       "  1103,\n",
       "  4154,\n",
       "  8492,\n",
       "  2944,\n",
       "  1893,\n",
       "  6286,\n",
       "  1104,\n",
       "  2514,\n",
       "  3840,\n",
       "  1197,\n",
       "  2522,\n",
       "  117,\n",
       "  1104,\n",
       "  1134,\n",
       "  1103,\n",
       "  1492,\n",
       "  23199,\n",
       "  18228,\n",
       "  1179,\n",
       "  25466,\n",
       "  113,\n",
       "  1175,\n",
       "  1132,\n",
       "  102],\n",
       " 'direction': 1,\n",
       " 'relation': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_labels(train_df, test_df, val_df):\n",
    "    \n",
    "\n",
    "labels = get_labels(train_df, test_df, val_df)\n",
    "\n",
    "\n",
    "\n",
    "unit1_txt = train_df['unit1_txt'][0]\n",
    "unit1_sent = train_df['unit1_sent'][0]\n",
    "unit2_txt = train_df['unit2_txt'][0]\n",
    "unit2_sent = train_df['unit2_sent'][0]\n",
    "dir = train_df['dir'][0]\n",
    "label = train_df['label'][0]\n",
    "\n",
    "text_to_instance(mnli_dataset, unit1_txt, unit1_sent, unit2_txt, unit2_sent, dir, label, label_dict=labels, features = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb#ch0000012vscode-remote?line=20'>21</a>\u001b[0m                 j \u001b[39m=\u001b[39m target[i]\u001b[39m.\u001b[39margmax()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb#ch0000012vscode-remote?line=21'>22</a>\u001b[0m             target_refined[i, j] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb#ch0000012vscode-remote?line=23'>24</a>\u001b[0m evaluate_accuracy(np\u001b[39m.\u001b[39;49marray([[\u001b[39m0.5\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m0.0\u001b[39;49m]]), np\u001b[39m.\u001b[39;49marray([[\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m]]))\n",
      "\u001b[1;32m/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb Cell 14'\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[0;34m(pred, target, prefered_target)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb#ch0000012vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_examples):\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb#ch0000012vscode-remote?line=10'>11</a>\u001b[0m     j \u001b[39m=\u001b[39m pred[i]\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb#ch0000012vscode-remote?line=11'>12</a>\u001b[0m     pred_refined[i, j] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb#ch0000012vscode-remote?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(j)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6c695f6b61766572695f74657374222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d795f746f6e795f736572766572227d7d/home/VD/kaveri/bert_categorical_tutorial/analytics_vidhya_snli_medium2.ipynb#ch0000012vscode-remote?line=13'>14</a>\u001b[0m     \u001b[39mif\u001b[39;00m target[i, j]:\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_accuracy(pred, target, prefered_target=None):\n",
    "    num_examples, num_classes = target.shape\n",
    "\n",
    "    correct = 0\n",
    "    pred_refined = np.zeros_like(target)\n",
    "    target_refined = np.zeros_like(target)\n",
    "    # print(pred_refined)\n",
    "    for i in range(num_examples):\n",
    "        j = pred[i]\n",
    "        pred_refined[i, j] = 1\n",
    "        print(j)\n",
    "        if target[i, j]:\n",
    "            correct += 1\n",
    "            target_refined[i, j] = 1\n",
    "        else:\n",
    "            if prefered_target is not None:\n",
    "                j = prefered_target[i]\n",
    "            else:\n",
    "                j = target[i].argmax()\n",
    "            target_refined[i, j] = 1\n",
    "\n",
    "evaluate_accuracy(np.array([[0.5, 0.3, 0.2, 0.1, 0.0]]), np.array([[1, 0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    # self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.train_data = self.load_data(self.train_df)\n",
    "    self.val_data = self.load_data(self.val_df)\n",
    "    self.test_data = self.load_data(self.test_df)\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels_list# {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def text_to_instance(self, unit1_txt: str, unit1_sent: str, unit2_txt: str, unit2_sent: str, dir: str, label: str = None, label_dict = None, features = None):\n",
    "    # line 34, /home/VD/kaveri/DisCoDisCo/gucorpling_models/rel/flair_clone_dataset_reader.py\n",
    "    unit1_txt_tokens = self.tokenizer.tokenize(unit1_txt)\n",
    "    unit1_sent_tokens = self.tokenizer.tokenize(unit1_sent)\n",
    "    unit2_txt_tokens = self.tokenizer.tokenize(unit2_txt)\n",
    "    unit2_sent_tokens = self.tokenizer.tokenize(unit2_sent)\n",
    "\n",
    "    for tokens in [unit1_txt_tokens, unit1_sent_tokens, unit2_txt_tokens, unit2_sent_tokens]:\n",
    "        tokens.insert(0, '[CLS]')\n",
    "        tokens.append('[SEP]')\n",
    "    cls_token = unit1_txt_tokens[0]\n",
    "    sep_token = unit1_txt_tokens[-1]\n",
    "\n",
    "    if cls_token not in [\"[CLS]\", '<s>']:\n",
    "        raise Exception(f\"Unrecognized cls token: {cls_token}\")\n",
    "    if sep_token not in [\"[SEP]\", '</s>']:\n",
    "        raise Exception(f\"Unrecognized sep token: {sep_token}\")\n",
    "\n",
    "    dir = '1>2'\n",
    "    if dir == \"1<2\":\n",
    "        left_tokens = []\n",
    "        right_tokens = [\"{\"]\n",
    "        dir_tokens = self.tokenizer.tokenize(sep_token + \" <\")#[0:-1]\n",
    "        # print(left_tokens, right_tokens, dir_tokens, dir_tokens[0:-1])\n",
    "    else:\n",
    "        left_tokens = [\"}\"]\n",
    "        right_tokens = []\n",
    "        dir_tokens = self.tokenizer.tokenize(\"> \" + sep_token)#[1:-1]\n",
    "        # print(left_tokens, right_tokens, dir_tokens, dir_tokens[1:-1])\n",
    "    # [CLS] } do we start ? > [SEP] no [SEP]\n",
    "    # [CLS] thanks [SEP] < im ok { [SEP]\n",
    "    combined_txt_tokens = (\n",
    "        unit1_txt_tokens[:1]\n",
    "        + left_tokens\n",
    "        + unit1_txt_tokens[1:-1]\n",
    "        + dir_tokens\n",
    "        + unit2_txt_tokens[1:-1]\n",
    "        + right_tokens\n",
    "        + unit2_txt_tokens[-1:])[:MAX_SEQ_LENGTH]\n",
    "    combined_sent_tokens = (\n",
    "        unit1_sent_tokens[:1]\n",
    "        + left_tokens\n",
    "        + unit1_sent_tokens[1:-1]\n",
    "        + dir_tokens\n",
    "        + unit2_sent_tokens[1:-1]\n",
    "        + right_tokens\n",
    "        + unit2_sent_tokens[-1:]\n",
    "    )[:MAX_SEQ_LENGTH]\n",
    "\n",
    "    if dir == \"1<2\" and \"{\" not in combined_sent_tokens: combined_sent_tokens[-1] = \"{\"\n",
    "    if dir == \"1<2\" and \"{\" not in combined_txt_tokens: combined_txt_tokens[-1] = \"{\"\n",
    "\n",
    "    if combined_txt_tokens[-1]!='[SEP]': combined_txt_tokens.append('[SEP]')\n",
    "    if combined_sent_tokens[-1]!='[SEP]': combined_sent_tokens.append('[SEP]')\n",
    "\n",
    "    fields = {\n",
    "        \"combined_body\": self.tokenizer.convert_tokens_to_ids(combined_txt_tokens),\n",
    "        \"combined_sentence\": self.tokenizer.convert_tokens_to_ids(combined_sent_tokens),\n",
    "        \"direction\": {\"1<2\":0, \"1>2\":1}[dir],\n",
    "        }\n",
    "\n",
    "    # # read in handcrafted features\n",
    "    # if self.features is not None:\n",
    "    #     features_configs = self.features.features\n",
    "\n",
    "    #     for feature_name, feature_config in features_configs.items():\n",
    "    #         if feature_name not in features:\n",
    "    #             raise Exception(f\"Feature {feature_name} not found. Pair:\\n  {unit1_txt}\\n  {unit2_txt}\")\n",
    "    #         if feature_name not in self.features.corpus_keys:\n",
    "    #             continue\n",
    "    #         feature_data = features[feature_name]\n",
    "    #         fields[feature_name] = get_feature_field(feature_config, feature_data)\n",
    "\n",
    "    if label:\n",
    "        fields[\"relation\"] = label_dict[label]\n",
    "    return fields\n",
    "\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 # dont need to enforce this now because snli is a sanitized dataset where sentence lenghts are reasonable. otherwise the beert model doesn't have enough parameters to handle long length sentences\n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['unit1_txt'].to_list()\n",
    "    p_sent_list = df['unit1_sent'].to_list()\n",
    "    hypothesis_list = df['unit2_txt'].to_list()\n",
    "    h_sent_list = df['unit2_sent'].to_list()\n",
    "    label_list = df['label'].to_list()\n",
    "\n",
    "    for (premise, hypothesis, p_sent, h_sent, label) in zip(premise_list, hypothesis_list, p_sent_list, h_sent_list, label_list):\n",
    "      # premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "      # hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "      # pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      # premise_len = len(premise_id)\n",
    "      # hypothesis_len = len(hypothesis_id)\n",
    "      fields = self.text_to_instance(premise, p_sent, hypothesis, h_sent, dir, label, self.label_dict, None)\n",
    "      premise_hypothesis = fields['combined_sentence']\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    print('token_ids: ', token_ids[2])\n",
    "    print('seg_ids: ', seg_ids[2])\n",
    "    print('mask_ids: ', mask_ids[2])\n",
    "\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
    "    train_loader = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "# train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders()\n",
    "# label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy\n",
    "# rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=3).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(data_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      \n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            labels=labels).values()\n",
    "      \n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      argmax_predictions = torch.argmax(prediction,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, rev_label_dict):  \n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "\n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict)\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.8215 train_acc: 0.6229 | val_loss: 0.3005 val_acc: 0.9062\n",
      "00:01:08.58\n",
      "Epoch 2: train_loss: 0.4633 train_acc: 0.8307 | val_loss: 0.2943 val_acc: 0.9453\n",
      "00:01:07.73\n",
      "Epoch 3: train_loss: 0.2784 train_acc: 0.9073 | val_loss: 0.0823 val_acc: 0.9844\n",
      "00:01:07.75\n",
      "Epoch 4: train_loss: 0.1557 train_acc: 0.9539 | val_loss: 0.0491 val_acc: 0.9922\n",
      "00:01:07.69\n",
      "Epoch 5: train_loss: 0.1111 train_acc: 0.9664 | val_loss: 0.0103 val_acc: 1.0000\n",
      "00:01:07.70\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer, rev_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'bert-nli-.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 0.8967 test_acc: 0.5625\n",
      "00:00:00.12\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.91      0.30      0.45        33\n",
      "   entailment       0.75      0.83      0.79        36\n",
      "      neutral       0.51      0.81      0.62        31\n",
      "\n",
      "     accuracy                           0.65       100\n",
      "    macro avg       0.72      0.65      0.62       100\n",
      " weighted avg       0.73      0.65      0.63       100\n",
      "\n",
      "Test Loss: 0.897 |  Test Acc: 56.25%\n"
     ]
    }
   ],
   "source": [
    "def validate(model, test_loader, optimizer, rev_label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load('bert-nli.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Medium page.\n",
    "# TODO: Make code modular. eg - evaluation called for dev and test adn train. Loss and prediction can become loss and logits. Another wrapper to return basic predictions/log them in it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
