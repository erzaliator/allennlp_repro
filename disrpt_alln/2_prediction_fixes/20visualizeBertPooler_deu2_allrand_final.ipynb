{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2011\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "batch_size = 4\n",
    "batches_per_epoch = 110\n",
    "\n",
    "save_path_suffix = '20visualizeBertPooler_randtrue_deu2013_debug_all+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'15': 1,\n",
       "         '1': 142,\n",
       "         '2': 41,\n",
       "         '3': 23,\n",
       "         '5': 9,\n",
       "         '6': 4,\n",
       "         '4': 10,\n",
       "         '7': 3,\n",
       "         '9': 3,\n",
       "         '12': 1,\n",
       "         '14': 1,\n",
       "         '8': 1,\n",
       "         '16': 1,\n",
       "         '10': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "Counter(val_df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label',\n",
       "       'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position',\n",
       "       'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case',\n",
       "       'unit2_case', 'u1_discontinuous', 'u2_discontinuous', 'same_speaker',\n",
       "       'lex_overlap_length', 'u1_func'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 05:03:03.033331: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 05:03:03.294836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-16 05:03:03.294884: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 05:03:03.343861: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-16 05:03:04.608967: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-16 05:03:04.609062: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-16 05:03:04.609070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, ConcatDataset\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate, Vocabulary\n",
    "from features_custom2 import get_vocab_feature_name\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.vocab = Vocabulary(counter=None, max_vocab_size=100000)\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.init_feature_list()\n",
    "    self.init_feature_mappings_and_bins()\n",
    "    self.apply_bins()\n",
    "    self.calculate_unique_values()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    \n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def init_feature_mappings_and_bins(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "    self.bins = {\n",
    "      'distance': [[-1e9, -8], [-8, -2], [-2, 0], [0, 2], [2, 8], [8, 1e9]],\n",
    "      'u1_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'u2_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'lex_overlap_length': [[0, 2], [2, 7], [7, 1e9]]\n",
    "    }   \n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def init_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "    else: \n",
    "      raise ValueError()\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features_list(self, features, feature_name):\n",
    "    if feature_name in ['distance', 'u1_depdir', 'u2_depdir', 'u1_func', 'u2_func', \n",
    "    'u1_position', 'u2_position', 'genre', 'same_speaker', 'unit1_case', 'unit2_case',\n",
    "    'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'dir']: feature_value = self.apply_vocab(features[feature_name], feature_name) #for categorical values\n",
    "    elif feature_name in ['sat_children', 'nuc_children']: feature_value = float(features[feature_name]) #for identiy values\n",
    "    else: \n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    return feature_value\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==17\n",
    "    #after applying the vocab. we need to pass them as int\n",
    "    return {feature_name: torch.tensor(int(self.get_allen_features_list(features, feature_name))).to(device) for feature_name in self.feature_list+['dir']}\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature_name in self.feature_list+['dir']:\n",
    "      vocab_feature_name = get_vocab_feature_name(feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(train_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(val_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "\n",
    "  def apply_bins(self):\n",
    "    for df in [self.train_df, self.test_df, self.val_df]:\n",
    "      for feature_name in self.bins.keys():\n",
    "        df[feature_name] = df[feature_name].apply(lambda x: self.get_mapping_from_bin(feature_name, float(x)))\n",
    "\n",
    "  def get_mapping_from_bin(self, column_name, dict_val):\n",
    "    bins = self.bins[column_name]\n",
    "    for b,i in zip(bins, range(len(bins))):\n",
    "      left = b[0]\n",
    "      right = b[1]\n",
    "      if left<=dict_val and right>=dict_val: return i\n",
    "\n",
    "  def apply_vocab(self, feature_value, feature_name):\n",
    "    return self.vocab.get_token_index(str(feature_value), namespace=get_vocab_feature_name(feature_name))\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      features = {'distance': row['distance'],\n",
    "                'u1_depdir': row['u1_depdir'],\n",
    "                'u2_depdir': row['u2_depdir'],\n",
    "                'u1_func': row['u1_func'],\n",
    "                'u2_func': row['u2_func'],\n",
    "                'u1_position': row['u1_position'],\n",
    "                'u2_position': row['u2_position'],\n",
    "                'sat_children': row['sat_children'],\n",
    "                'nuc_children': row['nuc_children'],\n",
    "                'genre': row['genre'],\n",
    "                'unit1_case': row['unit1_case'],\n",
    "                'unit2_case': row['unit2_case'],\n",
    "                'u1_discontinuous': row['u1_discontinuous'],\n",
    "                'u2_discontinuous': row['u2_discontinuous'],\n",
    "                'same_speaker': row['same_speaker'],\n",
    "                'lex_overlap_length': row['lex_overlap_length'],\n",
    "                'dir': row['dir']}\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding=False) #padding='max_length'\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      features = self.transform_feature(features)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(features)\n",
    "      \n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "      \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "\n",
    "    class featureDataset(Dataset):\n",
    "      def __init__(self, token_ids, mask_ids, seg_ids, feats, y, idx):\n",
    "          self.token_ids = token_ids\n",
    "          self.mask_ids = mask_ids\n",
    "          self.seg_ids = seg_ids\n",
    "          self.feats = feats\n",
    "          self.y = y\n",
    "          self.idx = idx\n",
    "\n",
    "      def __len__(self):\n",
    "          return len(self.feats)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "          return self.token_ids[idx], self.mask_ids[idx], self.seg_ids[idx], self.feats[idx], self.y[idx], self.idx[idx]\n",
    "\n",
    "    dataset = featureDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '3': 2, '4': 3, '5': 4}\n",
      "u1_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_func :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'root': 2, 'conj': 3, 'advcl': 4, 'acl': 5, 'xcomp': 6, 'obl': 7, 'ccomp': 8, 'parataxis': 9, 'advmod': 10, 'dep': 11, 'csubj': 12, 'nmod': 13, 'punct': 14, 'cc': 15, 'appos': 16, 'aux': 17, 'obj': 18, 'iobj': 19, 'nsubj': 20, 'nsubj:pass': 21, 'csubj:pass': 22}\n",
      "u1_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '1': 11}\n",
      "u2_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '1': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
      "sat_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '4': 3, '1': 4, '2': 5, '3': 6, '5': 7, '6': 8}\n",
      "nuc_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '4': 2, '3': 3, '1': 4, '2': 5, '5': 6, '6': 7, '7': 8, '8': 9}\n",
      "dir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '1>2': 2, '1<2': 3}\n"
     ]
    }
   ],
   "source": [
    "for feature in mnli_dataset.feature_list:\n",
    "    vocab_feature_name = get_vocab_feature_name(feature)\n",
    "    print(feature, ': ', mnli_dataset.vocab.get_token_to_index_vocabulary(vocab_feature_name))\n",
    "print('dir', ': ', mnli_dataset.vocab.get_token_to_index_vocabulary('dir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    # assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    # assert mask_ids.shape[-1]==512\n",
    "    # assert seg_ids.shape[-1]==512\n",
    "    assert len(feat)==len(mnli_dataset.feature_list)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '@@PADDING@@', 1: '@@UNKNOWN@@'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_dataset.vocab.get_index_to_token_vocabulary('u1_depdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        if i not in idx_map.keys():\n",
    "          print(idx_map)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing FeaturefulBert: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing FeaturefulBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FeaturefulBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1791, 0.4914,  ..., 0.8033, 0.1800, 0.7565],\n",
      "        [0.2525, 0.7510, 0.4346,  ..., 0.7418, 0.5287, 0.5078],\n",
      "        [0.6666, 0.2743, 0.3049,  ..., 0.3149, 0.3701, 0.8864],\n",
      "        ...,\n",
      "        [0.4879, 0.1848, 0.8009,  ..., 0.6173, 0.2064, 0.7918],\n",
      "        [0.9213, 0.3528, 0.9720,  ..., 0.8329, 0.9012, 0.6019],\n",
      "        [0.9650, 0.1516, 0.0451,  ..., 0.4805, 0.9559, 0.3503]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, Optional\n",
    "from transformers import BertModel, AutoTokenizer, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from featurefulbertembedder_custom2 import FeaturefulBertEmbedder\n",
    "from featureful_bert_custom2 import get_combined_feature_tensor_2 as get_combined_feature_tensor_forward\n",
    "from featureful_bert_custom2 import get_feature_modules\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class CustomPooler2(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                        requires_grad: bool = True,\n",
    "                        dropout: float = 0.0,\n",
    "                        randomize_weights: bool = False,\n",
    "                        transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "        super().__init__()\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL) #only used to pass config. BertAttentionClass used in FeatureFulBert\n",
    "        self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.pooler = copy.deepcopy(bert.pooler)\n",
    "        if randomize_weights:\n",
    "            print(self.pooler.dense.weight.shape)\n",
    "            self.pooler.dense.weight = nn.Parameter(torch.rand(self.pooler.dense.weight.shape))\n",
    "            self.pooler.dense.bias = nn.Parameter(torch.rand(self.pooler.dense.bias.shape))\n",
    "            print(self.pooler.dense.weight.shape)\n",
    "        for param in self.pooler.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        self._embedding_dim = bert.config.hidden_size\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "        pooler = self.pooler\n",
    "        \n",
    "        for _ in range(num_wrapping_dims):\n",
    "            pooler = TimeDistributed(pooler)\n",
    "        pooled = pooler(tokens)\n",
    "        pooled = self._dropout(pooled)\n",
    "        return pooled\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list, vocab):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_modules, self._feature_module_size = get_feature_modules(feature_list, vocab)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return get_combined_feature_tensor_forward(features, self.feature_list, self.feature_modules)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels, vocab):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels\n",
    "          self.feature_list = mnli_dataset.feature_list\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "\n",
    "          self.embedder = self.create_featureful_bert()\n",
    "          self.encoder = CustomPooler2(randomize_weights=True)\n",
    "          self.module1 = MyModule(self.feature_list, vocab)\n",
    "          self.dropout1 = nn.Dropout(p=0.0)\n",
    "        #   self.dropout_decoder = nn.Dropout(p=0.5)\n",
    "          self._decoder_input_size = self.encoder._embedding_dim + self.module1._feature_module_size\n",
    "          self.relation_decoder = nn.Linear(self._decoder_input_size, self.num_classes)\n",
    "\n",
    "          self.history_outerpooler = {\n",
    "            'cos': [],\n",
    "            'l2': []\n",
    "          }\n",
    "          self.history_innerpooler = {\n",
    "            'cos': [],\n",
    "            'l2': []\n",
    "          }\n",
    "          self.history_transformerlayer = {\n",
    "            'cos': [],\n",
    "            'l2': []\n",
    "          }\n",
    "          self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "          self.innerpooler_weight = copy.deepcopy(self.embedder.transformer_model.pooler.dense.weight)\n",
    "          self.transformerlayer_weight = copy.deepcopy(self.embedder.transformer_model.encoder.layer[11].output.dense.weight)\n",
    "          print(self.pooler_weight)\n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask, feat):\n",
    "        direction_tensor = feat['dir'].to(device)\n",
    "        embedded_sentence = self.embedder(token_ids=pair_token_ids, #featurefulmebedder\n",
    "                        mask=attention_mask, \n",
    "                        type_ids=token_type_ids,\n",
    "                        segment_concat_mask = None,\n",
    "                        direction_tensor = direction_tensor,\n",
    "                        feature_list = self.feature_list,\n",
    "                        features = feat)\n",
    "        mask = token_type_ids\n",
    "        bertpooler_output = self.encoder(tokens=embedded_sentence, mask=mask)\n",
    "        feat = self.convert_to_feature_list(feat)\n",
    "        feat = self.dropout1(feat)\n",
    "        feat = self.module1(feat)\n",
    "        # print(bertpooler_output.shape, self.module1._feature_module_size, feat.shape)\n",
    "        try:\n",
    "            feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "        except:\n",
    "            print(bertpooler_output.shape, feat.shape)\n",
    "            raise ValueError()\n",
    "        assert feat_concat.shape[-1] == self._decoder_input_size\n",
    "        feat_concat = self.dropout1(feat_concat)\n",
    "        # feat_concat = self.dropout_decoder(feat_concat)\n",
    "        linear1_output = self.relation_decoder(feat_concat)\n",
    "        return linear1_output\n",
    "\n",
    "    def compute_pooler_similarity(self):\n",
    "        cur = self.encoder.pooler.dense.weight\n",
    "        pre = self.pooler_weight\n",
    "        print('self.pooler_weight')\n",
    "        print(cur)\n",
    "        assert not torch.all(cur.eq(pre))\n",
    "        for metric in self.history_outerpooler.keys():\n",
    "            self.history_outerpooler[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "\n",
    "        cur = self.embedder.transformer_model.pooler.dense.weight\n",
    "        pre = self.innerpooler_weight\n",
    "        print('self.innerpooler_weight')\n",
    "        print(cur)\n",
    "        for metric in self.history_innerpooler.keys():\n",
    "            self.history_innerpooler[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.innerpooler_weight = copy.deepcopy(self.embedder.transformer_model.pooler.dense.weight)\n",
    "\n",
    "        cur = self.embedder.transformer_model.encoder.layer[11].output.dense.weight\n",
    "        pre = self.transformerlayer_weight\n",
    "        print('self.transformerlayer_weight')\n",
    "        print(cur)\n",
    "        assert not torch.all(cur.eq(pre))\n",
    "        for metric in self.history_transformerlayer.keys():\n",
    "            self.history_transformerlayer[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.transformerlayer_weight = copy.deepcopy(self.embedder.transformer_model.encoder.layer[11].output.dense.weight)\n",
    "\n",
    "    def similarity(self, cur, pre, metric_name):\n",
    "        metric = 0\n",
    "        n = 0\n",
    "        A = copy.deepcopy(cur)\n",
    "        B = copy.deepcopy(pre)\n",
    "        A = cur.cpu().detach().numpy().ravel()\n",
    "        B = B.cpu().detach().numpy().ravel()\n",
    "        for A, B in zip(A, B):\n",
    "            cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "            euclid = np.linalg.norm(A - B) #Frobenius norm\n",
    "            if metric_name=='cos': metric+= cosine\n",
    "            elif metric_name=='l2': metric+= euclid\n",
    "            n+=1\n",
    "        del A, B\n",
    "        return float(metric)/float(n), metric\n",
    "\n",
    "    def create_bert_without_activations(self):\n",
    "        config = BertConfig.from_pretrained(BERT_MODEL, hidden_act='gelu')\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "        return bert\n",
    "\n",
    "    def create_featureful_bert(self):\n",
    "        featureful_bert = FeaturefulBertEmbedder(model_name = BERT_MODEL,\n",
    "                                hidden_activation_allen = 'gelu',\n",
    "                                feature_list = self.feature_list, \n",
    "                                vocab=mnli_dataset.vocab)\n",
    "        return featureful_bert\n",
    "\n",
    "    def convert_to_feature_list(self, feat):\n",
    "        feature_linear = [feat[feature_name] for feature_name in self.feature_list]\n",
    "        feature_linear = torch.stack(feature_linear, dim=-1)\n",
    "        return feature_linear\n",
    "        \n",
    "\n",
    "model = CustomBERTModel(mnli_dataset.num_labels, mnli_dataset.vocab)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, correct_bias=False) # original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, mode='max', patience=35, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prinintg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomBERTModel(\n",
      "  (embedder): FeaturefulBertEmbedder(\n",
      "    (transformer_model): FeaturefulBert(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (feature_modules): ModuleDict(\n",
      "        (distance): Embedding(5, 3, padding_idx=0)\n",
      "        (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "        (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "        (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "        (sat_children): Identity()\n",
      "        (nuc_children): Identity()\n",
      "      )\n",
      "      (feature_projector): Linear(in_features=25, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): CustomPooler2(\n",
      "    (_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (module1): MyModule(\n",
      "    (feature_modules): ModuleDict(\n",
      "      (distance): Embedding(5, 3, padding_idx=0)\n",
      "      (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "      (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "      (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "      (sat_children): Identity()\n",
      "      (nuc_children): Identity()\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (relation_decoder): Linear(in_features=792, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['events.out.tfevents.1671163029.57e5cab0c4d9.14615.0']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n",
    "\n",
    "    model.compute_pooler_similarity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Best val_acc: 0.0984\n",
      "Epoch 1: Best val_acc: 0.0984\n",
      "Epoch 1: train_loss: 3.0931 train_acc: 0.1250 | val_loss: 2.9686 val_acc: 0.0984\n",
      "00:00:15.85\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1793, 0.4916,  ..., 0.8036, 0.1798, 0.7561],\n",
      "        [0.2525, 0.7512, 0.4348,  ..., 0.7414, 0.5285, 0.5078],\n",
      "        [0.6668, 0.2742, 0.3052,  ..., 0.3148, 0.3701, 0.8865],\n",
      "        ...,\n",
      "        [0.4877, 0.1850, 0.8009,  ..., 0.6175, 0.2066, 0.7916],\n",
      "        [0.9217, 0.3526, 0.9725,  ..., 0.8329, 0.9015, 0.6019],\n",
      "        [0.9649, 0.1522, 0.0448,  ..., 0.4806, 0.9558, 0.3505]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1002,  0.0367,  ...,  0.0121, -0.0203,  0.0079],\n",
      "        [ 0.0213,  0.0124, -0.0100,  ..., -0.0119,  0.0439,  0.0561],\n",
      "        [ 0.0217,  0.0408, -0.0241,  ...,  0.0174,  0.0340,  0.0051],\n",
      "        ...,\n",
      "        [-0.0152, -0.0275, -0.0469,  ..., -0.0363,  0.0166, -0.0931],\n",
      "        [-0.0295, -0.0359,  0.0803,  ..., -0.0316, -0.0589,  0.0301],\n",
      "        [ 0.0020, -0.0481,  0.0045,  ...,  0.0474,  0.0399,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 2: Best val_acc: 0.1557\n",
      "Epoch 2: Best val_acc: 0.1557\n",
      "Epoch 2: train_loss: 2.8602 train_acc: 0.1114 | val_loss: 2.7499 val_acc: 0.1557\n",
      "00:00:11.29\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1793, 0.4916,  ..., 0.8037, 0.1797, 0.7561],\n",
      "        [0.2525, 0.7511, 0.4349,  ..., 0.7415, 0.5284, 0.5079],\n",
      "        [0.6668, 0.2741, 0.3054,  ..., 0.3147, 0.3702, 0.8864],\n",
      "        ...,\n",
      "        [0.4878, 0.1851, 0.8008,  ..., 0.6175, 0.2065, 0.7916],\n",
      "        [0.9217, 0.3526, 0.9725,  ..., 0.8329, 0.9015, 0.6019],\n",
      "        [0.9649, 0.1522, 0.0448,  ..., 0.4806, 0.9557, 0.3505]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1003,  0.0366,  ...,  0.0121, -0.0202,  0.0077],\n",
      "        [ 0.0213,  0.0125, -0.0099,  ..., -0.0121,  0.0441,  0.0563],\n",
      "        [ 0.0218,  0.0408, -0.0240,  ...,  0.0174,  0.0341,  0.0052],\n",
      "        ...,\n",
      "        [-0.0150, -0.0276, -0.0468,  ..., -0.0361,  0.0164, -0.0931],\n",
      "        [-0.0294, -0.0360,  0.0804,  ..., -0.0317, -0.0588,  0.0302],\n",
      "        [ 0.0019, -0.0481,  0.0045,  ...,  0.0473,  0.0400,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 3: Best val_acc: 0.2090\n",
      "Epoch 3: Best val_acc: 0.2090\n",
      "Epoch 3: train_loss: 2.6755 train_acc: 0.1727 | val_loss: 2.5998 val_acc: 0.2090\n",
      "00:00:10.80\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8673, 0.1792, 0.4915,  ..., 0.8038, 0.1797, 0.7560],\n",
      "        [0.2525, 0.7511, 0.4351,  ..., 0.7415, 0.5283, 0.5077],\n",
      "        [0.6669, 0.2741, 0.3056,  ..., 0.3144, 0.3704, 0.8864],\n",
      "        ...,\n",
      "        [0.4878, 0.1851, 0.8007,  ..., 0.6175, 0.2066, 0.7916],\n",
      "        [0.9217, 0.3527, 0.9724,  ..., 0.8329, 0.9014, 0.6020],\n",
      "        [0.9649, 0.1522, 0.0447,  ..., 0.4806, 0.9557, 0.3504]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1002,  0.0365,  ...,  0.0121, -0.0202,  0.0077],\n",
      "        [ 0.0214,  0.0127, -0.0099,  ..., -0.0119,  0.0442,  0.0565],\n",
      "        [ 0.0217,  0.0406, -0.0240,  ...,  0.0173,  0.0340,  0.0052],\n",
      "        ...,\n",
      "        [-0.0150, -0.0276, -0.0469,  ..., -0.0362,  0.0164, -0.0932],\n",
      "        [-0.0294, -0.0363,  0.0801,  ..., -0.0321, -0.0589,  0.0299],\n",
      "        [ 0.0017, -0.0482,  0.0046,  ...,  0.0472,  0.0402,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 4: Best val_acc: 0.2377\n",
      "Epoch 4: Best val_acc: 0.2377\n",
      "Epoch 4: train_loss: 2.5843 train_acc: 0.2000 | val_loss: 2.5239 val_acc: 0.2377\n",
      "00:00:11.28\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8672, 0.1794, 0.4914,  ..., 0.8039, 0.1797, 0.7560],\n",
      "        [0.2526, 0.7511, 0.4351,  ..., 0.7415, 0.5283, 0.5078],\n",
      "        [0.6669, 0.2739, 0.3057,  ..., 0.3145, 0.3702, 0.8863],\n",
      "        ...,\n",
      "        [0.4878, 0.1852, 0.8006,  ..., 0.6174, 0.2067, 0.7917],\n",
      "        [0.9215, 0.3528, 0.9722,  ..., 0.8328, 0.9014, 0.6021],\n",
      "        [0.9648, 0.1522, 0.0448,  ..., 0.4806, 0.9557, 0.3504]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1002,  0.0366,  ...,  0.0122, -0.0201,  0.0077],\n",
      "        [ 0.0213,  0.0127, -0.0099,  ..., -0.0119,  0.0444,  0.0565],\n",
      "        [ 0.0217,  0.0405, -0.0241,  ...,  0.0171,  0.0338,  0.0052],\n",
      "        ...,\n",
      "        [-0.0150, -0.0276, -0.0469,  ..., -0.0361,  0.0163, -0.0933],\n",
      "        [-0.0293, -0.0364,  0.0802,  ..., -0.0320, -0.0590,  0.0299],\n",
      "        [ 0.0016, -0.0482,  0.0046,  ...,  0.0472,  0.0403,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 5: train_loss: 2.4117 train_acc: 0.2682 | val_loss: 2.4977 val_acc: 0.2295\n",
      "00:00:08.07\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8673, 0.1795, 0.4913,  ..., 0.8041, 0.1797, 0.7562],\n",
      "        [0.2524, 0.7510, 0.4351,  ..., 0.7418, 0.5282, 0.5075],\n",
      "        [0.6668, 0.2739, 0.3057,  ..., 0.3146, 0.3702, 0.8863],\n",
      "        ...,\n",
      "        [0.4878, 0.1852, 0.8006,  ..., 0.6174, 0.2067, 0.7917],\n",
      "        [0.9217, 0.3529, 0.9723,  ..., 0.8330, 0.9012, 0.6021],\n",
      "        [0.9649, 0.1522, 0.0448,  ..., 0.4806, 0.9556, 0.3504]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1002,  0.0367,  ...,  0.0124, -0.0201,  0.0078],\n",
      "        [ 0.0211,  0.0128, -0.0098,  ..., -0.0119,  0.0446,  0.0564],\n",
      "        [ 0.0215,  0.0404, -0.0242,  ...,  0.0171,  0.0336,  0.0051],\n",
      "        ...,\n",
      "        [-0.0149, -0.0277, -0.0469,  ..., -0.0361,  0.0161, -0.0933],\n",
      "        [-0.0293, -0.0363,  0.0802,  ..., -0.0319, -0.0590,  0.0298],\n",
      "        [ 0.0016, -0.0484,  0.0046,  ...,  0.0470,  0.0403,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 6: Best val_acc: 0.2951\n",
      "Epoch 6: Best val_acc: 0.2951\n",
      "Epoch 6: train_loss: 2.4285 train_acc: 0.2614 | val_loss: 2.4029 val_acc: 0.2951\n",
      "00:00:12.67\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1795, 0.4913,  ..., 0.8042, 0.1796, 0.7562],\n",
      "        [0.2526, 0.7511, 0.4351,  ..., 0.7418, 0.5282, 0.5077],\n",
      "        [0.6668, 0.2738, 0.3057,  ..., 0.3146, 0.3702, 0.8864],\n",
      "        ...,\n",
      "        [0.4878, 0.1852, 0.8006,  ..., 0.6174, 0.2067, 0.7917],\n",
      "        [0.9218, 0.3527, 0.9723,  ..., 0.8330, 0.9010, 0.6022],\n",
      "        [0.9649, 0.1523, 0.0449,  ..., 0.4806, 0.9556, 0.3505]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1002,  0.0367,  ...,  0.0124, -0.0201,  0.0078],\n",
      "        [ 0.0210,  0.0129, -0.0099,  ..., -0.0120,  0.0446,  0.0564],\n",
      "        [ 0.0215,  0.0404, -0.0242,  ...,  0.0171,  0.0337,  0.0051],\n",
      "        ...,\n",
      "        [-0.0148, -0.0276, -0.0470,  ..., -0.0361,  0.0160, -0.0934],\n",
      "        [-0.0292, -0.0363,  0.0801,  ..., -0.0320, -0.0591,  0.0299],\n",
      "        [ 0.0014, -0.0483,  0.0047,  ...,  0.0471,  0.0405,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 7: train_loss: 2.4719 train_acc: 0.2682 | val_loss: 2.3781 val_acc: 0.2705\n",
      "00:00:23.83\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1795, 0.4914,  ..., 0.8042, 0.1796, 0.7561],\n",
      "        [0.2526, 0.7512, 0.4351,  ..., 0.7418, 0.5283, 0.5078],\n",
      "        [0.6668, 0.2737, 0.3058,  ..., 0.3146, 0.3701, 0.8863],\n",
      "        ...,\n",
      "        [0.4878, 0.1852, 0.8006,  ..., 0.6174, 0.2067, 0.7917],\n",
      "        [0.9218, 0.3527, 0.9722,  ..., 0.8330, 0.9011, 0.6021],\n",
      "        [0.9650, 0.1522, 0.0448,  ..., 0.4805, 0.9557, 0.3507]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1002,  0.0368,  ...,  0.0123, -0.0200,  0.0078],\n",
      "        [ 0.0210,  0.0130, -0.0097,  ..., -0.0119,  0.0446,  0.0565],\n",
      "        [ 0.0217,  0.0405, -0.0242,  ...,  0.0172,  0.0336,  0.0052],\n",
      "        ...,\n",
      "        [-0.0148, -0.0276, -0.0470,  ..., -0.0362,  0.0158, -0.0934],\n",
      "        [-0.0291, -0.0362,  0.0801,  ..., -0.0320, -0.0590,  0.0299],\n",
      "        [ 0.0013, -0.0484,  0.0047,  ...,  0.0471,  0.0406,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 8: train_loss: 2.3025 train_acc: 0.3250 | val_loss: 2.3277 val_acc: 0.2828\n",
      "00:00:27.11\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1796, 0.4913,  ..., 0.8041, 0.1797, 0.7563],\n",
      "        [0.2527, 0.7513, 0.4351,  ..., 0.7417, 0.5282, 0.5079],\n",
      "        [0.6668, 0.2738, 0.3057,  ..., 0.3145, 0.3702, 0.8863],\n",
      "        ...,\n",
      "        [0.4878, 0.1852, 0.8006,  ..., 0.6174, 0.2067, 0.7917],\n",
      "        [0.9218, 0.3527, 0.9723,  ..., 0.8330, 0.9010, 0.6022],\n",
      "        [0.9651, 0.1522, 0.0446,  ..., 0.4804, 0.9558, 0.3507]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1002,  0.0367,  ...,  0.0123, -0.0200,  0.0078],\n",
      "        [ 0.0209,  0.0130, -0.0098,  ..., -0.0120,  0.0446,  0.0565],\n",
      "        [ 0.0217,  0.0405, -0.0241,  ...,  0.0171,  0.0336,  0.0051],\n",
      "        ...,\n",
      "        [-0.0148, -0.0275, -0.0470,  ..., -0.0361,  0.0158, -0.0934],\n",
      "        [-0.0291, -0.0362,  0.0802,  ..., -0.0319, -0.0590,  0.0300],\n",
      "        [ 0.0012, -0.0484,  0.0046,  ...,  0.0469,  0.0407,  0.0097]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 9: Best val_acc: 0.3115\n",
      "Epoch 9: Best val_acc: 0.3115\n",
      "Epoch 9: train_loss: 2.3004 train_acc: 0.3568 | val_loss: 2.2805 val_acc: 0.3115\n",
      "00:00:12.75\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1797, 0.4912,  ..., 0.8041, 0.1798, 0.7563],\n",
      "        [0.2527, 0.7514, 0.4351,  ..., 0.7418, 0.5282, 0.5079],\n",
      "        [0.6668, 0.2738, 0.3058,  ..., 0.3145, 0.3703, 0.8863],\n",
      "        ...,\n",
      "        [0.4877, 0.1852, 0.8006,  ..., 0.6174, 0.2067, 0.7917],\n",
      "        [0.9218, 0.3527, 0.9723,  ..., 0.8330, 0.9009, 0.6022],\n",
      "        [0.9649, 0.1522, 0.0445,  ..., 0.4805, 0.9557, 0.3506]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1002,  0.0368,  ...,  0.0123, -0.0200,  0.0078],\n",
      "        [ 0.0210,  0.0131, -0.0097,  ..., -0.0119,  0.0447,  0.0565],\n",
      "        [ 0.0217,  0.0404, -0.0242,  ...,  0.0171,  0.0335,  0.0051],\n",
      "        ...,\n",
      "        [-0.0148, -0.0276, -0.0470,  ..., -0.0362,  0.0158, -0.0934],\n",
      "        [-0.0291, -0.0362,  0.0802,  ..., -0.0319, -0.0591,  0.0300],\n",
      "        [ 0.0011, -0.0484,  0.0047,  ...,  0.0470,  0.0407,  0.0097]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 10: train_loss: 2.1635 train_acc: 0.3795 | val_loss: 2.2848 val_acc: 0.3033\n",
      "00:00:08.20\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8672, 0.1798, 0.4911,  ..., 0.8041, 0.1797, 0.7563],\n",
      "        [0.2526, 0.7515, 0.4350,  ..., 0.7417, 0.5283, 0.5080],\n",
      "        [0.6667, 0.2738, 0.3057,  ..., 0.3145, 0.3703, 0.8863],\n",
      "        ...,\n",
      "        [0.4877, 0.1852, 0.8006,  ..., 0.6174, 0.2067, 0.7917],\n",
      "        [0.9217, 0.3527, 0.9722,  ..., 0.8330, 0.9008, 0.6022],\n",
      "        [0.9649, 0.1522, 0.0445,  ..., 0.4804, 0.9557, 0.3507]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1003,  0.0368,  ...,  0.0123, -0.0201,  0.0079],\n",
      "        [ 0.0210,  0.0131, -0.0097,  ..., -0.0119,  0.0446,  0.0565],\n",
      "        [ 0.0217,  0.0405, -0.0242,  ...,  0.0171,  0.0334,  0.0051],\n",
      "        ...,\n",
      "        [-0.0149, -0.0275, -0.0470,  ..., -0.0362,  0.0158, -0.0934],\n",
      "        [-0.0292, -0.0362,  0.0801,  ..., -0.0319, -0.0591,  0.0299],\n",
      "        [ 0.0011, -0.0485,  0.0047,  ...,  0.0470,  0.0408,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 11: Best val_acc: 0.3115\n",
      "Epoch 11: train_loss: 2.1253 train_acc: 0.4114 | val_loss: 2.2534 val_acc: 0.3115\n",
      "00:00:08.58\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8673, 0.1798, 0.4911,  ..., 0.8040, 0.1797, 0.7563],\n",
      "        [0.2526, 0.7516, 0.4350,  ..., 0.7416, 0.5284, 0.5081],\n",
      "        [0.6667, 0.2738, 0.3057,  ..., 0.3144, 0.3704, 0.8865],\n",
      "        ...,\n",
      "        [0.4879, 0.1852, 0.8006,  ..., 0.6175, 0.2068, 0.7918],\n",
      "        [0.9216, 0.3528, 0.9723,  ..., 0.8330, 0.9008, 0.6022],\n",
      "        [0.9649, 0.1522, 0.0443,  ..., 0.4803, 0.9557, 0.3507]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1003,  0.0369,  ...,  0.0124, -0.0202,  0.0080],\n",
      "        [ 0.0210,  0.0131, -0.0098,  ..., -0.0120,  0.0446,  0.0565],\n",
      "        [ 0.0217,  0.0404, -0.0242,  ...,  0.0170,  0.0334,  0.0051],\n",
      "        ...,\n",
      "        [-0.0149, -0.0274, -0.0469,  ..., -0.0361,  0.0156, -0.0934],\n",
      "        [-0.0293, -0.0362,  0.0800,  ..., -0.0319, -0.0591,  0.0299],\n",
      "        [ 0.0012, -0.0484,  0.0047,  ...,  0.0470,  0.0409,  0.0097]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 12: train_loss: 2.0819 train_acc: 0.3955 | val_loss: 2.2123 val_acc: 0.2992\n",
      "00:00:08.48\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1796, 0.4912,  ..., 0.8042, 0.1795, 0.7562],\n",
      "        [0.2526, 0.7518, 0.4350,  ..., 0.7415, 0.5285, 0.5082],\n",
      "        [0.6667, 0.2739, 0.3058,  ..., 0.3144, 0.3704, 0.8865],\n",
      "        ...,\n",
      "        [0.4878, 0.1852, 0.8007,  ..., 0.6174, 0.2069, 0.7918],\n",
      "        [0.9218, 0.3527, 0.9725,  ..., 0.8329, 0.9008, 0.6024],\n",
      "        [0.9649, 0.1521, 0.0442,  ..., 0.4803, 0.9558, 0.3508]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1004,  0.0368,  ...,  0.0123, -0.0203,  0.0080],\n",
      "        [ 0.0210,  0.0131, -0.0098,  ..., -0.0121,  0.0447,  0.0565],\n",
      "        [ 0.0217,  0.0404, -0.0242,  ...,  0.0171,  0.0334,  0.0052],\n",
      "        ...,\n",
      "        [-0.0149, -0.0273, -0.0469,  ..., -0.0361,  0.0156, -0.0933],\n",
      "        [-0.0294, -0.0362,  0.0799,  ..., -0.0321, -0.0591,  0.0298],\n",
      "        [ 0.0012, -0.0484,  0.0047,  ...,  0.0470,  0.0410,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 13: Best val_acc: 0.3238\n",
      "Epoch 13: Best val_acc: 0.3238\n",
      "Epoch 13: train_loss: 2.1079 train_acc: 0.4068 | val_loss: 2.2088 val_acc: 0.3238\n",
      "00:00:10.31\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1796, 0.4911,  ..., 0.8042, 0.1794, 0.7562],\n",
      "        [0.2526, 0.7518, 0.4349,  ..., 0.7416, 0.5285, 0.5082],\n",
      "        [0.6668, 0.2739, 0.3058,  ..., 0.3144, 0.3704, 0.8866],\n",
      "        ...,\n",
      "        [0.4878, 0.1852, 0.8006,  ..., 0.6174, 0.2069, 0.7918],\n",
      "        [0.9218, 0.3526, 0.9725,  ..., 0.8329, 0.9008, 0.6023],\n",
      "        [0.9649, 0.1521, 0.0442,  ..., 0.4803, 0.9559, 0.3508]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1005,  0.0369,  ...,  0.0124, -0.0203,  0.0080],\n",
      "        [ 0.0209,  0.0130, -0.0099,  ..., -0.0121,  0.0447,  0.0564],\n",
      "        [ 0.0217,  0.0404, -0.0241,  ...,  0.0171,  0.0332,  0.0052],\n",
      "        ...,\n",
      "        [-0.0150, -0.0273, -0.0470,  ..., -0.0361,  0.0157, -0.0934],\n",
      "        [-0.0294, -0.0362,  0.0798,  ..., -0.0321, -0.0592,  0.0297],\n",
      "        [ 0.0012, -0.0484,  0.0047,  ...,  0.0471,  0.0410,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 14: Best val_acc: 0.3279\n",
      "Epoch 14: Best val_acc: 0.3279\n",
      "Epoch 14: train_loss: 1.9756 train_acc: 0.4273 | val_loss: 2.2106 val_acc: 0.3279\n",
      "00:00:10.33\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1796, 0.4912,  ..., 0.8044, 0.1792, 0.7562],\n",
      "        [0.2526, 0.7518, 0.4349,  ..., 0.7418, 0.5284, 0.5081],\n",
      "        [0.6667, 0.2738, 0.3058,  ..., 0.3144, 0.3704, 0.8866],\n",
      "        ...,\n",
      "        [0.4877, 0.1852, 0.8006,  ..., 0.6174, 0.2069, 0.7919],\n",
      "        [0.9218, 0.3526, 0.9725,  ..., 0.8330, 0.9007, 0.6023],\n",
      "        [0.9648, 0.1521, 0.0441,  ..., 0.4802, 0.9558, 0.3509]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1006,  0.0370,  ...,  0.0124, -0.0203,  0.0080],\n",
      "        [ 0.0210,  0.0130, -0.0098,  ..., -0.0121,  0.0447,  0.0565],\n",
      "        [ 0.0218,  0.0403, -0.0241,  ...,  0.0171,  0.0331,  0.0052],\n",
      "        ...,\n",
      "        [-0.0149, -0.0272, -0.0469,  ..., -0.0361,  0.0158, -0.0934],\n",
      "        [-0.0294, -0.0364,  0.0799,  ..., -0.0321, -0.0592,  0.0298],\n",
      "        [ 0.0012, -0.0483,  0.0047,  ...,  0.0471,  0.0410,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 15: train_loss: 1.8995 train_acc: 0.4705 | val_loss: 2.1434 val_acc: 0.3197\n",
      "00:00:08.47\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1795, 0.4913,  ..., 0.8046, 0.1791, 0.7561],\n",
      "        [0.2526, 0.7519, 0.4349,  ..., 0.7417, 0.5284, 0.5082],\n",
      "        [0.6668, 0.2738, 0.3059,  ..., 0.3146, 0.3704, 0.8866],\n",
      "        ...,\n",
      "        [0.4877, 0.1852, 0.8006,  ..., 0.6173, 0.2069, 0.7918],\n",
      "        [0.9218, 0.3525, 0.9725,  ..., 0.8330, 0.9006, 0.6023],\n",
      "        [0.9647, 0.1521, 0.0440,  ..., 0.4801, 0.9558, 0.3509]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1006,  0.0370,  ...,  0.0125, -0.0204,  0.0081],\n",
      "        [ 0.0210,  0.0130, -0.0097,  ..., -0.0121,  0.0447,  0.0565],\n",
      "        [ 0.0216,  0.0404, -0.0242,  ...,  0.0171,  0.0330,  0.0050],\n",
      "        ...,\n",
      "        [-0.0148, -0.0272, -0.0469,  ..., -0.0360,  0.0158, -0.0934],\n",
      "        [-0.0295, -0.0364,  0.0799,  ..., -0.0321, -0.0592,  0.0298],\n",
      "        [ 0.0013, -0.0483,  0.0048,  ...,  0.0471,  0.0410,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 16: Best val_acc: 0.3402\n",
      "Epoch 16: Best val_acc: 0.3402\n",
      "Epoch 16: train_loss: 1.9236 train_acc: 0.4818 | val_loss: 2.1376 val_acc: 0.3402\n",
      "00:00:10.48\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1795, 0.4913,  ..., 0.8046, 0.1790, 0.7561],\n",
      "        [0.2525, 0.7520, 0.4349,  ..., 0.7416, 0.5284, 0.5083],\n",
      "        [0.6668, 0.2738, 0.3059,  ..., 0.3146, 0.3704, 0.8867],\n",
      "        ...,\n",
      "        [0.4877, 0.1852, 0.8006,  ..., 0.6173, 0.2069, 0.7918],\n",
      "        [0.9218, 0.3525, 0.9725,  ..., 0.8330, 0.9006, 0.6023],\n",
      "        [0.9648, 0.1521, 0.0440,  ..., 0.4800, 0.9559, 0.3509]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1006,  0.0370,  ...,  0.0125, -0.0203,  0.0081],\n",
      "        [ 0.0210,  0.0130, -0.0097,  ..., -0.0121,  0.0447,  0.0565],\n",
      "        [ 0.0217,  0.0404, -0.0243,  ...,  0.0170,  0.0330,  0.0050],\n",
      "        ...,\n",
      "        [-0.0148, -0.0272, -0.0469,  ..., -0.0360,  0.0157, -0.0934],\n",
      "        [-0.0295, -0.0365,  0.0799,  ..., -0.0321, -0.0593,  0.0298],\n",
      "        [ 0.0013, -0.0483,  0.0048,  ...,  0.0471,  0.0410,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 17: Best val_acc: 0.3525\n",
      "Epoch 17: Best val_acc: 0.3525\n",
      "Epoch 17: train_loss: 1.8288 train_acc: 0.4659 | val_loss: 2.1064 val_acc: 0.3525\n",
      "00:00:10.58\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1795, 0.4912,  ..., 0.8046, 0.1790, 0.7561],\n",
      "        [0.2526, 0.7519, 0.4349,  ..., 0.7417, 0.5284, 0.5082],\n",
      "        [0.6668, 0.2738, 0.3059,  ..., 0.3146, 0.3705, 0.8867],\n",
      "        ...,\n",
      "        [0.4876, 0.1852, 0.8006,  ..., 0.6173, 0.2070, 0.7918],\n",
      "        [0.9218, 0.3525, 0.9725,  ..., 0.8330, 0.9006, 0.6023],\n",
      "        [0.9647, 0.1520, 0.0441,  ..., 0.4800, 0.9559, 0.3509]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1006,  0.0370,  ...,  0.0126, -0.0203,  0.0082],\n",
      "        [ 0.0210,  0.0130, -0.0098,  ..., -0.0121,  0.0448,  0.0565],\n",
      "        [ 0.0216,  0.0405, -0.0244,  ...,  0.0170,  0.0331,  0.0049],\n",
      "        ...,\n",
      "        [-0.0149, -0.0272, -0.0470,  ..., -0.0362,  0.0156, -0.0935],\n",
      "        [-0.0295, -0.0364,  0.0799,  ..., -0.0320, -0.0593,  0.0298],\n",
      "        [ 0.0012, -0.0482,  0.0048,  ...,  0.0471,  0.0410,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 18: train_loss: 1.8986 train_acc: 0.4795 | val_loss: 2.1167 val_acc: 0.3156\n",
      "00:00:08.37\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1795, 0.4911,  ..., 0.8046, 0.1790, 0.7560],\n",
      "        [0.2526, 0.7519, 0.4349,  ..., 0.7417, 0.5283, 0.5083],\n",
      "        [0.6668, 0.2737, 0.3059,  ..., 0.3146, 0.3705, 0.8868],\n",
      "        ...,\n",
      "        [0.4876, 0.1852, 0.8006,  ..., 0.6173, 0.2070, 0.7919],\n",
      "        [0.9217, 0.3525, 0.9725,  ..., 0.8330, 0.9006, 0.6023],\n",
      "        [0.9647, 0.1519, 0.0442,  ..., 0.4801, 0.9559, 0.3509]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0240, -0.1007,  0.0370,  ...,  0.0126, -0.0202,  0.0082],\n",
      "        [ 0.0210,  0.0130, -0.0097,  ..., -0.0120,  0.0450,  0.0565],\n",
      "        [ 0.0216,  0.0404, -0.0244,  ...,  0.0170,  0.0331,  0.0050],\n",
      "        ...,\n",
      "        [-0.0148, -0.0272, -0.0470,  ..., -0.0361,  0.0156, -0.0935],\n",
      "        [-0.0295, -0.0363,  0.0799,  ..., -0.0320, -0.0593,  0.0298],\n",
      "        [ 0.0013, -0.0483,  0.0048,  ...,  0.0471,  0.0410,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 19: Best val_acc: 0.3566\n",
      "Epoch 19: Best val_acc: 0.3566\n",
      "Epoch 19: train_loss: 1.8379 train_acc: 0.4932 | val_loss: 2.0701 val_acc: 0.3566\n",
      "00:00:10.64\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8676, 0.1795, 0.4911,  ..., 0.8047, 0.1790, 0.7559],\n",
      "        [0.2526, 0.7519, 0.4349,  ..., 0.7417, 0.5284, 0.5083],\n",
      "        [0.6669, 0.2737, 0.3059,  ..., 0.3146, 0.3705, 0.8868],\n",
      "        ...,\n",
      "        [0.4876, 0.1853, 0.8006,  ..., 0.6172, 0.2069, 0.7920],\n",
      "        [0.9217, 0.3525, 0.9725,  ..., 0.8330, 0.9006, 0.6023],\n",
      "        [0.9647, 0.1519, 0.0441,  ..., 0.4801, 0.9559, 0.3509]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1007,  0.0370,  ...,  0.0124, -0.0201,  0.0082],\n",
      "        [ 0.0211,  0.0130, -0.0097,  ..., -0.0121,  0.0450,  0.0566],\n",
      "        [ 0.0216,  0.0404, -0.0244,  ...,  0.0171,  0.0330,  0.0050],\n",
      "        ...,\n",
      "        [-0.0148, -0.0272, -0.0470,  ..., -0.0361,  0.0155, -0.0936],\n",
      "        [-0.0294, -0.0363,  0.0800,  ..., -0.0319, -0.0593,  0.0299],\n",
      "        [ 0.0013, -0.0483,  0.0048,  ...,  0.0472,  0.0410,  0.0100]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 20: Best val_acc: 0.3730\n",
      "Epoch 20: Best val_acc: 0.3730\n",
      "Epoch 20: train_loss: 1.7087 train_acc: 0.5341 | val_loss: 2.0289 val_acc: 0.3730\n",
      "00:00:10.34\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1795, 0.4911,  ..., 0.8047, 0.1790, 0.7560],\n",
      "        [0.2526, 0.7518, 0.4349,  ..., 0.7418, 0.5283, 0.5083],\n",
      "        [0.6669, 0.2737, 0.3059,  ..., 0.3146, 0.3705, 0.8867],\n",
      "        ...,\n",
      "        [0.4876, 0.1852, 0.8006,  ..., 0.6172, 0.2069, 0.7920],\n",
      "        [0.9217, 0.3525, 0.9725,  ..., 0.8330, 0.9006, 0.6023],\n",
      "        [0.9647, 0.1521, 0.0441,  ..., 0.4800, 0.9559, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1008,  0.0370,  ...,  0.0125, -0.0202,  0.0084],\n",
      "        [ 0.0211,  0.0130, -0.0096,  ..., -0.0120,  0.0451,  0.0566],\n",
      "        [ 0.0214,  0.0404, -0.0245,  ...,  0.0170,  0.0330,  0.0050],\n",
      "        ...,\n",
      "        [-0.0148, -0.0272, -0.0470,  ..., -0.0362,  0.0155, -0.0935],\n",
      "        [-0.0294, -0.0363,  0.0799,  ..., -0.0320, -0.0593,  0.0299],\n",
      "        [ 0.0013, -0.0482,  0.0048,  ...,  0.0472,  0.0410,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 21: train_loss: 1.5996 train_acc: 0.5318 | val_loss: 2.0797 val_acc: 0.3402\n",
      "00:00:07.82\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8676, 0.1794, 0.4911,  ..., 0.8047, 0.1790, 0.7560],\n",
      "        [0.2526, 0.7517, 0.4350,  ..., 0.7419, 0.5283, 0.5083],\n",
      "        [0.6670, 0.2737, 0.3059,  ..., 0.3145, 0.3706, 0.8867],\n",
      "        ...,\n",
      "        [0.4875, 0.1852, 0.8005,  ..., 0.6172, 0.2069, 0.7920],\n",
      "        [0.9217, 0.3525, 0.9725,  ..., 0.8329, 0.9007, 0.6024],\n",
      "        [0.9647, 0.1520, 0.0440,  ..., 0.4800, 0.9559, 0.3511]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1009,  0.0369,  ...,  0.0125, -0.0203,  0.0083],\n",
      "        [ 0.0211,  0.0130, -0.0096,  ..., -0.0120,  0.0451,  0.0567],\n",
      "        [ 0.0214,  0.0405, -0.0245,  ...,  0.0170,  0.0331,  0.0049],\n",
      "        ...,\n",
      "        [-0.0148, -0.0270, -0.0470,  ..., -0.0361,  0.0154, -0.0935],\n",
      "        [-0.0294, -0.0363,  0.0799,  ..., -0.0320, -0.0593,  0.0300],\n",
      "        [ 0.0014, -0.0482,  0.0049,  ...,  0.0472,  0.0410,  0.0100]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 22: train_loss: 1.7332 train_acc: 0.4886 | val_loss: 2.0529 val_acc: 0.3279\n",
      "00:00:07.85\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8676, 0.1795, 0.4911,  ..., 0.8047, 0.1791, 0.7561],\n",
      "        [0.2526, 0.7518, 0.4350,  ..., 0.7418, 0.5283, 0.5083],\n",
      "        [0.6670, 0.2737, 0.3059,  ..., 0.3145, 0.3705, 0.8867],\n",
      "        ...,\n",
      "        [0.4876, 0.1852, 0.8004,  ..., 0.6172, 0.2069, 0.7920],\n",
      "        [0.9216, 0.3524, 0.9725,  ..., 0.8329, 0.9007, 0.6024],\n",
      "        [0.9647, 0.1520, 0.0441,  ..., 0.4800, 0.9559, 0.3511]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1009,  0.0369,  ...,  0.0125, -0.0203,  0.0083],\n",
      "        [ 0.0211,  0.0130, -0.0096,  ..., -0.0120,  0.0450,  0.0567],\n",
      "        [ 0.0214,  0.0404, -0.0245,  ...,  0.0170,  0.0331,  0.0048],\n",
      "        ...,\n",
      "        [-0.0147, -0.0270, -0.0469,  ..., -0.0360,  0.0153, -0.0933],\n",
      "        [-0.0293, -0.0363,  0.0800,  ..., -0.0320, -0.0593,  0.0300],\n",
      "        [ 0.0014, -0.0482,  0.0049,  ...,  0.0472,  0.0411,  0.0100]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 23: train_loss: 1.7363 train_acc: 0.5091 | val_loss: 2.0478 val_acc: 0.3484\n",
      "00:00:08.44\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1795, 0.4910,  ..., 0.8047, 0.1791, 0.7561],\n",
      "        [0.2526, 0.7518, 0.4350,  ..., 0.7417, 0.5283, 0.5084],\n",
      "        [0.6670, 0.2737, 0.3060,  ..., 0.3145, 0.3706, 0.8867],\n",
      "        ...,\n",
      "        [0.4878, 0.1853, 0.8004,  ..., 0.6175, 0.2067, 0.7922],\n",
      "        [0.9216, 0.3524, 0.9724,  ..., 0.8329, 0.9007, 0.6024],\n",
      "        [0.9647, 0.1518, 0.0441,  ..., 0.4800, 0.9559, 0.3511]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1010,  0.0370,  ...,  0.0125, -0.0202,  0.0084],\n",
      "        [ 0.0211,  0.0131, -0.0096,  ..., -0.0120,  0.0451,  0.0567],\n",
      "        [ 0.0214,  0.0404, -0.0245,  ...,  0.0171,  0.0331,  0.0048],\n",
      "        ...,\n",
      "        [-0.0148, -0.0269, -0.0470,  ..., -0.0360,  0.0153, -0.0934],\n",
      "        [-0.0293, -0.0364,  0.0800,  ..., -0.0320, -0.0593,  0.0300],\n",
      "        [ 0.0014, -0.0483,  0.0049,  ...,  0.0472,  0.0410,  0.0100]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 24: Best val_acc: 0.3730\n",
      "Epoch 24: train_loss: 1.5791 train_acc: 0.5432 | val_loss: 2.0331 val_acc: 0.3730\n",
      "00:00:09.14\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1796, 0.4909,  ..., 0.8047, 0.1790, 0.7561],\n",
      "        [0.2526, 0.7519, 0.4350,  ..., 0.7417, 0.5283, 0.5084],\n",
      "        [0.6670, 0.2738, 0.3060,  ..., 0.3144, 0.3706, 0.8868],\n",
      "        ...,\n",
      "        [0.4877, 0.1853, 0.8005,  ..., 0.6173, 0.2068, 0.7923],\n",
      "        [0.9216, 0.3525, 0.9724,  ..., 0.8328, 0.9007, 0.6025],\n",
      "        [0.9647, 0.1519, 0.0442,  ..., 0.4801, 0.9560, 0.3511]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1010,  0.0369,  ...,  0.0124, -0.0201,  0.0084],\n",
      "        [ 0.0211,  0.0131, -0.0096,  ..., -0.0120,  0.0451,  0.0567],\n",
      "        [ 0.0215,  0.0405, -0.0244,  ...,  0.0172,  0.0330,  0.0049],\n",
      "        ...,\n",
      "        [-0.0148, -0.0270, -0.0469,  ..., -0.0360,  0.0154, -0.0934],\n",
      "        [-0.0294, -0.0365,  0.0799,  ..., -0.0320, -0.0593,  0.0300],\n",
      "        [ 0.0014, -0.0484,  0.0048,  ...,  0.0471,  0.0409,  0.0100]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 25: Best val_acc: 0.3770\n",
      "Epoch 25: Best val_acc: 0.3770\n",
      "Epoch 25: train_loss: 1.4991 train_acc: 0.5932 | val_loss: 2.0359 val_acc: 0.3770\n",
      "00:00:10.05\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1796, 0.4909,  ..., 0.8047, 0.1790, 0.7560],\n",
      "        [0.2526, 0.7518, 0.4350,  ..., 0.7417, 0.5283, 0.5084],\n",
      "        [0.6670, 0.2738, 0.3060,  ..., 0.3143, 0.3707, 0.8868],\n",
      "        ...,\n",
      "        [0.4876, 0.1854, 0.8005,  ..., 0.6173, 0.2068, 0.7923],\n",
      "        [0.9216, 0.3524, 0.9724,  ..., 0.8328, 0.9007, 0.6024],\n",
      "        [0.9647, 0.1518, 0.0442,  ..., 0.4801, 0.9561, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1010,  0.0369,  ...,  0.0124, -0.0202,  0.0083],\n",
      "        [ 0.0212,  0.0132, -0.0095,  ..., -0.0119,  0.0451,  0.0568],\n",
      "        [ 0.0215,  0.0405, -0.0245,  ...,  0.0172,  0.0331,  0.0049],\n",
      "        ...,\n",
      "        [-0.0148, -0.0270, -0.0470,  ..., -0.0360,  0.0155, -0.0933],\n",
      "        [-0.0295, -0.0364,  0.0798,  ..., -0.0321, -0.0592,  0.0298],\n",
      "        [ 0.0013, -0.0484,  0.0048,  ...,  0.0470,  0.0410,  0.0100]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 26: train_loss: 1.5267 train_acc: 0.5864 | val_loss: 2.0072 val_acc: 0.3689\n",
      "00:00:07.89\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1797, 0.4908,  ..., 0.8047, 0.1790, 0.7559],\n",
      "        [0.2526, 0.7518, 0.4350,  ..., 0.7418, 0.5283, 0.5083],\n",
      "        [0.6670, 0.2738, 0.3060,  ..., 0.3143, 0.3707, 0.8868],\n",
      "        ...,\n",
      "        [0.4875, 0.1855, 0.8004,  ..., 0.6172, 0.2069, 0.7923],\n",
      "        [0.9216, 0.3524, 0.9724,  ..., 0.8329, 0.9007, 0.6023],\n",
      "        [0.9646, 0.1518, 0.0443,  ..., 0.4802, 0.9561, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1010,  0.0369,  ...,  0.0124, -0.0202,  0.0084],\n",
      "        [ 0.0212,  0.0132, -0.0095,  ..., -0.0120,  0.0451,  0.0568],\n",
      "        [ 0.0215,  0.0405, -0.0244,  ...,  0.0172,  0.0331,  0.0049],\n",
      "        ...,\n",
      "        [-0.0148, -0.0269, -0.0470,  ..., -0.0360,  0.0155, -0.0933],\n",
      "        [-0.0295, -0.0363,  0.0798,  ..., -0.0321, -0.0592,  0.0298],\n",
      "        [ 0.0013, -0.0482,  0.0048,  ...,  0.0470,  0.0410,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 27: train_loss: 1.5145 train_acc: 0.5932 | val_loss: 2.0013 val_acc: 0.3730\n",
      "00:00:07.84\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1797, 0.4908,  ..., 0.8046, 0.1790, 0.7559],\n",
      "        [0.2527, 0.7518, 0.4350,  ..., 0.7417, 0.5283, 0.5084],\n",
      "        [0.6670, 0.2737, 0.3061,  ..., 0.3143, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4875, 0.1856, 0.8003,  ..., 0.6172, 0.2069, 0.7924],\n",
      "        [0.9216, 0.3525, 0.9723,  ..., 0.8328, 0.9006, 0.6024],\n",
      "        [0.9646, 0.1519, 0.0442,  ..., 0.4802, 0.9560, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1010,  0.0370,  ...,  0.0124, -0.0202,  0.0084],\n",
      "        [ 0.0212,  0.0132, -0.0095,  ..., -0.0120,  0.0452,  0.0568],\n",
      "        [ 0.0214,  0.0406, -0.0244,  ...,  0.0171,  0.0331,  0.0049],\n",
      "        ...,\n",
      "        [-0.0147, -0.0269, -0.0470,  ..., -0.0359,  0.0155, -0.0932],\n",
      "        [-0.0295, -0.0363,  0.0798,  ..., -0.0321, -0.0592,  0.0298],\n",
      "        [ 0.0013, -0.0482,  0.0049,  ...,  0.0470,  0.0410,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 28: train_loss: 1.5028 train_acc: 0.5818 | val_loss: 1.9988 val_acc: 0.3730\n",
      "00:00:07.74\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1797, 0.4908,  ..., 0.8047, 0.1791, 0.7559],\n",
      "        [0.2526, 0.7518, 0.4351,  ..., 0.7418, 0.5283, 0.5084],\n",
      "        [0.6668, 0.2737, 0.3061,  ..., 0.3143, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4874, 0.1856, 0.8003,  ..., 0.6171, 0.2070, 0.7925],\n",
      "        [0.9216, 0.3524, 0.9724,  ..., 0.8328, 0.9007, 0.6025],\n",
      "        [0.9647, 0.1519, 0.0442,  ..., 0.4801, 0.9559, 0.3513]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1011,  0.0370,  ...,  0.0124, -0.0201,  0.0085],\n",
      "        [ 0.0212,  0.0132, -0.0095,  ..., -0.0120,  0.0452,  0.0569],\n",
      "        [ 0.0214,  0.0405, -0.0245,  ...,  0.0170,  0.0331,  0.0048],\n",
      "        ...,\n",
      "        [-0.0147, -0.0268, -0.0469,  ..., -0.0359,  0.0154, -0.0931],\n",
      "        [-0.0295, -0.0363,  0.0798,  ..., -0.0320, -0.0592,  0.0298],\n",
      "        [ 0.0013, -0.0482,  0.0048,  ...,  0.0470,  0.0410,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 29: train_loss: 1.4001 train_acc: 0.6159 | val_loss: 1.9709 val_acc: 0.3607\n",
      "00:00:08.28\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1796, 0.4907,  ..., 0.8047, 0.1791, 0.7559],\n",
      "        [0.2527, 0.7519, 0.4352,  ..., 0.7418, 0.5282, 0.5085],\n",
      "        [0.6668, 0.2737, 0.3061,  ..., 0.3143, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4873, 0.1856, 0.8003,  ..., 0.6170, 0.2072, 0.7925],\n",
      "        [0.9217, 0.3524, 0.9724,  ..., 0.8329, 0.9006, 0.6025],\n",
      "        [0.9648, 0.1519, 0.0442,  ..., 0.4800, 0.9559, 0.3513]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.1011,  0.0370,  ...,  0.0124, -0.0200,  0.0086],\n",
      "        [ 0.0212,  0.0132, -0.0095,  ..., -0.0120,  0.0452,  0.0569],\n",
      "        [ 0.0213,  0.0406, -0.0246,  ...,  0.0170,  0.0332,  0.0048],\n",
      "        ...,\n",
      "        [-0.0148, -0.0269, -0.0469,  ..., -0.0360,  0.0154, -0.0932],\n",
      "        [-0.0294, -0.0363,  0.0798,  ..., -0.0320, -0.0592,  0.0299],\n",
      "        [ 0.0014, -0.0482,  0.0049,  ...,  0.0471,  0.0410,  0.0099]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 30: train_loss: 1.3704 train_acc: 0.6455 | val_loss: 1.9845 val_acc: 0.3689\n",
      "00:00:07.28\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1796, 0.4907,  ..., 0.8047, 0.1791, 0.7560],\n",
      "        [0.2527, 0.7518, 0.4351,  ..., 0.7418, 0.5282, 0.5085],\n",
      "        [0.6668, 0.2737, 0.3060,  ..., 0.3142, 0.3708, 0.8867],\n",
      "        ...,\n",
      "        [0.4873, 0.1855, 0.8004,  ..., 0.6171, 0.2072, 0.7927],\n",
      "        [0.9217, 0.3523, 0.9723,  ..., 0.8330, 0.9006, 0.6026],\n",
      "        [0.9648, 0.1519, 0.0442,  ..., 0.4800, 0.9559, 0.3513]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1012,  0.0370,  ...,  0.0124, -0.0200,  0.0086],\n",
      "        [ 0.0213,  0.0131, -0.0094,  ..., -0.0119,  0.0452,  0.0571],\n",
      "        [ 0.0213,  0.0406, -0.0247,  ...,  0.0170,  0.0331,  0.0047],\n",
      "        ...,\n",
      "        [-0.0148, -0.0268, -0.0469,  ..., -0.0359,  0.0155, -0.0931],\n",
      "        [-0.0294, -0.0363,  0.0799,  ..., -0.0320, -0.0591,  0.0299],\n",
      "        [ 0.0014, -0.0482,  0.0049,  ...,  0.0471,  0.0409,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 31: train_loss: 1.2251 train_acc: 0.6841 | val_loss: 2.0149 val_acc: 0.3525\n",
      "00:00:07.94\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1797, 0.4906,  ..., 0.8046, 0.1792, 0.7560],\n",
      "        [0.2527, 0.7517, 0.4351,  ..., 0.7418, 0.5283, 0.5085],\n",
      "        [0.6668, 0.2736, 0.3060,  ..., 0.3143, 0.3708, 0.8867],\n",
      "        ...,\n",
      "        [0.4872, 0.1855, 0.8004,  ..., 0.6171, 0.2073, 0.7926],\n",
      "        [0.9217, 0.3522, 0.9723,  ..., 0.8330, 0.9006, 0.6026],\n",
      "        [0.9648, 0.1520, 0.0441,  ..., 0.4800, 0.9559, 0.3513]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1012,  0.0370,  ...,  0.0124, -0.0201,  0.0086],\n",
      "        [ 0.0213,  0.0130, -0.0094,  ..., -0.0120,  0.0453,  0.0571],\n",
      "        [ 0.0212,  0.0406, -0.0247,  ...,  0.0170,  0.0330,  0.0048],\n",
      "        ...,\n",
      "        [-0.0149, -0.0268, -0.0469,  ..., -0.0360,  0.0155, -0.0931],\n",
      "        [-0.0293, -0.0364,  0.0799,  ..., -0.0320, -0.0592,  0.0300],\n",
      "        [ 0.0015, -0.0483,  0.0049,  ...,  0.0471,  0.0409,  0.0097]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 32: train_loss: 1.3377 train_acc: 0.6545 | val_loss: 1.9914 val_acc: 0.3730\n",
      "00:00:07.35\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1798, 0.4906,  ..., 0.8046, 0.1793, 0.7561],\n",
      "        [0.2527, 0.7518, 0.4351,  ..., 0.7418, 0.5283, 0.5086],\n",
      "        [0.6668, 0.2735, 0.3061,  ..., 0.3143, 0.3707, 0.8867],\n",
      "        ...,\n",
      "        [0.4870, 0.1856, 0.8003,  ..., 0.6168, 0.2074, 0.7925],\n",
      "        [0.9217, 0.3522, 0.9723,  ..., 0.8331, 0.9005, 0.6026],\n",
      "        [0.9647, 0.1520, 0.0440,  ..., 0.4800, 0.9558, 0.3513]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1011,  0.0370,  ...,  0.0124, -0.0201,  0.0084],\n",
      "        [ 0.0213,  0.0130, -0.0093,  ..., -0.0119,  0.0453,  0.0571],\n",
      "        [ 0.0212,  0.0406, -0.0247,  ...,  0.0169,  0.0330,  0.0048],\n",
      "        ...,\n",
      "        [-0.0149, -0.0268, -0.0469,  ..., -0.0360,  0.0155, -0.0932],\n",
      "        [-0.0293, -0.0364,  0.0799,  ..., -0.0321, -0.0592,  0.0300],\n",
      "        [ 0.0015, -0.0482,  0.0049,  ...,  0.0470,  0.0409,  0.0098]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 33: Best val_acc: 0.3893\n",
      "Epoch 33: Best val_acc: 0.3893\n",
      "Epoch 33: train_loss: 1.3126 train_acc: 0.6341 | val_loss: 1.9783 val_acc: 0.3893\n",
      "00:00:09.20\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1798, 0.4905,  ..., 0.8045, 0.1793, 0.7560],\n",
      "        [0.2528, 0.7518, 0.4352,  ..., 0.7418, 0.5283, 0.5086],\n",
      "        [0.6668, 0.2736, 0.3061,  ..., 0.3143, 0.3708, 0.8867],\n",
      "        ...,\n",
      "        [0.4870, 0.1856, 0.8003,  ..., 0.6167, 0.2075, 0.7924],\n",
      "        [0.9217, 0.3522, 0.9724,  ..., 0.8332, 0.9005, 0.6026],\n",
      "        [0.9648, 0.1520, 0.0440,  ..., 0.4799, 0.9559, 0.3513]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.1012,  0.0371,  ...,  0.0125, -0.0202,  0.0085],\n",
      "        [ 0.0213,  0.0131, -0.0093,  ..., -0.0119,  0.0453,  0.0571],\n",
      "        [ 0.0212,  0.0406, -0.0247,  ...,  0.0170,  0.0329,  0.0048],\n",
      "        ...,\n",
      "        [-0.0149, -0.0267, -0.0469,  ..., -0.0360,  0.0156, -0.0931],\n",
      "        [-0.0294, -0.0364,  0.0799,  ..., -0.0322, -0.0591,  0.0301],\n",
      "        [ 0.0016, -0.0482,  0.0050,  ...,  0.0471,  0.0409,  0.0097]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 34: train_loss: 1.1891 train_acc: 0.6841 | val_loss: 1.9784 val_acc: 0.3730\n",
      "00:00:07.61\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1798, 0.4904,  ..., 0.8046, 0.1793, 0.7560],\n",
      "        [0.2528, 0.7518, 0.4352,  ..., 0.7418, 0.5284, 0.5087],\n",
      "        [0.6669, 0.2735, 0.3061,  ..., 0.3143, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4871, 0.1855, 0.8004,  ..., 0.6167, 0.2075, 0.7925],\n",
      "        [0.9216, 0.3522, 0.9723,  ..., 0.8331, 0.9006, 0.6027],\n",
      "        [0.9648, 0.1520, 0.0440,  ..., 0.4798, 0.9559, 0.3513]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1012,  0.0371,  ...,  0.0124, -0.0202,  0.0085],\n",
      "        [ 0.0213,  0.0131, -0.0093,  ..., -0.0119,  0.0454,  0.0571],\n",
      "        [ 0.0212,  0.0407, -0.0247,  ...,  0.0169,  0.0328,  0.0049],\n",
      "        ...,\n",
      "        [-0.0148, -0.0266, -0.0469,  ..., -0.0360,  0.0156, -0.0932],\n",
      "        [-0.0294, -0.0364,  0.0799,  ..., -0.0322, -0.0591,  0.0300],\n",
      "        [ 0.0016, -0.0482,  0.0050,  ...,  0.0470,  0.0409,  0.0097]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 35: train_loss: 1.1041 train_acc: 0.7364 | val_loss: 2.0179 val_acc: 0.3648\n",
      "00:00:07.49\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1797, 0.4904,  ..., 0.8046, 0.1794, 0.7560],\n",
      "        [0.2529, 0.7518, 0.4353,  ..., 0.7417, 0.5284, 0.5088],\n",
      "        [0.6668, 0.2735, 0.3061,  ..., 0.3142, 0.3707, 0.8867],\n",
      "        ...,\n",
      "        [0.4871, 0.1855, 0.8004,  ..., 0.6167, 0.2075, 0.7925],\n",
      "        [0.9216, 0.3522, 0.9723,  ..., 0.8331, 0.9006, 0.6027],\n",
      "        [0.9648, 0.1521, 0.0440,  ..., 0.4798, 0.9560, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1012,  0.0371,  ...,  0.0124, -0.0202,  0.0084],\n",
      "        [ 0.0213,  0.0131, -0.0093,  ..., -0.0118,  0.0455,  0.0571],\n",
      "        [ 0.0211,  0.0407, -0.0247,  ...,  0.0169,  0.0328,  0.0050],\n",
      "        ...,\n",
      "        [-0.0149, -0.0265, -0.0469,  ..., -0.0360,  0.0157, -0.0932],\n",
      "        [-0.0294, -0.0364,  0.0799,  ..., -0.0321, -0.0592,  0.0301],\n",
      "        [ 0.0017, -0.0483,  0.0050,  ...,  0.0470,  0.0409,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 36: train_loss: 1.1344 train_acc: 0.6818 | val_loss: 1.9766 val_acc: 0.3730\n",
      "00:00:07.66\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8673, 0.1798, 0.4903,  ..., 0.8045, 0.1794, 0.7560],\n",
      "        [0.2529, 0.7519, 0.4352,  ..., 0.7417, 0.5285, 0.5088],\n",
      "        [0.6668, 0.2734, 0.3061,  ..., 0.3141, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4870, 0.1855, 0.8003,  ..., 0.6167, 0.2075, 0.7925],\n",
      "        [0.9216, 0.3521, 0.9723,  ..., 0.8332, 0.9006, 0.6026],\n",
      "        [0.9648, 0.1521, 0.0439,  ..., 0.4798, 0.9559, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1012,  0.0371,  ...,  0.0123, -0.0202,  0.0084],\n",
      "        [ 0.0213,  0.0132, -0.0092,  ..., -0.0118,  0.0455,  0.0571],\n",
      "        [ 0.0211,  0.0407, -0.0247,  ...,  0.0168,  0.0328,  0.0050],\n",
      "        ...,\n",
      "        [-0.0149, -0.0266, -0.0469,  ..., -0.0360,  0.0156, -0.0932],\n",
      "        [-0.0294, -0.0364,  0.0799,  ..., -0.0322, -0.0591,  0.0301],\n",
      "        [ 0.0016, -0.0483,  0.0050,  ...,  0.0470,  0.0409,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 00037: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 37: train_loss: 1.1632 train_acc: 0.7205 | val_loss: 1.9844 val_acc: 0.3689\n",
      "00:00:07.89\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1798, 0.4903,  ..., 0.8045, 0.1794, 0.7560],\n",
      "        [0.2529, 0.7518, 0.4352,  ..., 0.7418, 0.5285, 0.5088],\n",
      "        [0.6668, 0.2734, 0.3061,  ..., 0.3141, 0.3707, 0.8868],\n",
      "        ...,\n",
      "        [0.4869, 0.1855, 0.8003,  ..., 0.6167, 0.2075, 0.7926],\n",
      "        [0.9215, 0.3521, 0.9724,  ..., 0.8332, 0.9007, 0.6026],\n",
      "        [0.9648, 0.1521, 0.0440,  ..., 0.4797, 0.9560, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1013,  0.0371,  ...,  0.0123, -0.0203,  0.0083],\n",
      "        [ 0.0213,  0.0131, -0.0092,  ..., -0.0118,  0.0454,  0.0572],\n",
      "        [ 0.0211,  0.0408, -0.0248,  ...,  0.0167,  0.0328,  0.0049],\n",
      "        ...,\n",
      "        [-0.0149, -0.0266, -0.0470,  ..., -0.0360,  0.0156, -0.0932],\n",
      "        [-0.0295, -0.0363,  0.0799,  ..., -0.0323, -0.0590,  0.0302],\n",
      "        [ 0.0017, -0.0482,  0.0050,  ...,  0.0470,  0.0409,  0.0096]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 38: Best val_acc: 0.3934\n",
      "Epoch 38: Best val_acc: 0.3934\n",
      "Epoch 38: train_loss: 1.1843 train_acc: 0.6773 | val_loss: 1.9631 val_acc: 0.3934\n",
      "00:00:09.62\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1797, 0.4902,  ..., 0.8046, 0.1794, 0.7561],\n",
      "        [0.2529, 0.7518, 0.4353,  ..., 0.7418, 0.5284, 0.5089],\n",
      "        [0.6668, 0.2734, 0.3061,  ..., 0.3141, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4869, 0.1856, 0.8003,  ..., 0.6166, 0.2076, 0.7926],\n",
      "        [0.9215, 0.3520, 0.9724,  ..., 0.8332, 0.9007, 0.6026],\n",
      "        [0.9648, 0.1521, 0.0439,  ..., 0.4797, 0.9560, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0371,  ...,  0.0124, -0.0204,  0.0083],\n",
      "        [ 0.0213,  0.0132, -0.0092,  ..., -0.0117,  0.0454,  0.0572],\n",
      "        [ 0.0211,  0.0408, -0.0247,  ...,  0.0167,  0.0329,  0.0050],\n",
      "        ...,\n",
      "        [-0.0148, -0.0266, -0.0470,  ..., -0.0360,  0.0156, -0.0931],\n",
      "        [-0.0294, -0.0363,  0.0799,  ..., -0.0322, -0.0591,  0.0302],\n",
      "        [ 0.0016, -0.0482,  0.0050,  ...,  0.0470,  0.0409,  0.0096]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 39: train_loss: 1.0471 train_acc: 0.7318 | val_loss: 2.0204 val_acc: 0.3730\n",
      "00:00:07.12\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1798, 0.4902,  ..., 0.8046, 0.1794, 0.7561],\n",
      "        [0.2529, 0.7518, 0.4353,  ..., 0.7418, 0.5284, 0.5089],\n",
      "        [0.6668, 0.2734, 0.3061,  ..., 0.3141, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4869, 0.1856, 0.8003,  ..., 0.6166, 0.2076, 0.7926],\n",
      "        [0.9215, 0.3520, 0.9724,  ..., 0.8332, 0.9007, 0.6026],\n",
      "        [0.9648, 0.1522, 0.0439,  ..., 0.4798, 0.9559, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0371,  ...,  0.0124, -0.0203,  0.0083],\n",
      "        [ 0.0213,  0.0132, -0.0092,  ..., -0.0117,  0.0455,  0.0572],\n",
      "        [ 0.0211,  0.0409, -0.0247,  ...,  0.0168,  0.0329,  0.0050],\n",
      "        ...,\n",
      "        [-0.0149, -0.0265, -0.0470,  ..., -0.0360,  0.0157, -0.0931],\n",
      "        [-0.0294, -0.0365,  0.0800,  ..., -0.0322, -0.0591,  0.0302],\n",
      "        [ 0.0015, -0.0482,  0.0050,  ...,  0.0470,  0.0408,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 40: train_loss: 1.0330 train_acc: 0.7568 | val_loss: 1.9711 val_acc: 0.3730\n",
      "00:00:07.44\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1798, 0.4902,  ..., 0.8046, 0.1795, 0.7561],\n",
      "        [0.2530, 0.7518, 0.4353,  ..., 0.7417, 0.5285, 0.5089],\n",
      "        [0.6668, 0.2734, 0.3062,  ..., 0.3141, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4869, 0.1856, 0.8003,  ..., 0.6165, 0.2077, 0.7926],\n",
      "        [0.9215, 0.3521, 0.9724,  ..., 0.8332, 0.9007, 0.6025],\n",
      "        [0.9648, 0.1522, 0.0439,  ..., 0.4798, 0.9559, 0.3512]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0371,  ...,  0.0124, -0.0204,  0.0084],\n",
      "        [ 0.0213,  0.0132, -0.0092,  ..., -0.0117,  0.0455,  0.0572],\n",
      "        [ 0.0212,  0.0409, -0.0247,  ...,  0.0167,  0.0328,  0.0050],\n",
      "        ...,\n",
      "        [-0.0149, -0.0265, -0.0470,  ..., -0.0360,  0.0156, -0.0931],\n",
      "        [-0.0294, -0.0365,  0.0800,  ..., -0.0321, -0.0590,  0.0303],\n",
      "        [ 0.0015, -0.0482,  0.0050,  ...,  0.0470,  0.0410,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 41: train_loss: 0.9343 train_acc: 0.7955 | val_loss: 1.9605 val_acc: 0.3770\n",
      "00:00:07.82\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1798, 0.4902,  ..., 0.8047, 0.1794, 0.7561],\n",
      "        [0.2530, 0.7518, 0.4354,  ..., 0.7417, 0.5285, 0.5089],\n",
      "        [0.6668, 0.2734, 0.3062,  ..., 0.3141, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4869, 0.1856, 0.8003,  ..., 0.6165, 0.2077, 0.7926],\n",
      "        [0.9215, 0.3521, 0.9724,  ..., 0.8333, 0.9007, 0.6025],\n",
      "        [0.9649, 0.1522, 0.0439,  ..., 0.4797, 0.9560, 0.3511]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0370,  ...,  0.0124, -0.0204,  0.0083],\n",
      "        [ 0.0213,  0.0131, -0.0092,  ..., -0.0117,  0.0455,  0.0573],\n",
      "        [ 0.0211,  0.0409, -0.0248,  ...,  0.0167,  0.0329,  0.0050],\n",
      "        ...,\n",
      "        [-0.0149, -0.0265, -0.0470,  ..., -0.0360,  0.0156, -0.0931],\n",
      "        [-0.0294, -0.0365,  0.0800,  ..., -0.0321, -0.0589,  0.0303],\n",
      "        [ 0.0015, -0.0483,  0.0050,  ...,  0.0470,  0.0411,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 42: train_loss: 0.9929 train_acc: 0.7500 | val_loss: 1.9709 val_acc: 0.3852\n",
      "00:00:07.85\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1799, 0.4902,  ..., 0.8046, 0.1795, 0.7561],\n",
      "        [0.2530, 0.7519, 0.4354,  ..., 0.7417, 0.5285, 0.5090],\n",
      "        [0.6669, 0.2734, 0.3063,  ..., 0.3141, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4868, 0.1856, 0.8002,  ..., 0.6164, 0.2077, 0.7926],\n",
      "        [0.9215, 0.3521, 0.9724,  ..., 0.8333, 0.9006, 0.6025],\n",
      "        [0.9649, 0.1523, 0.0439,  ..., 0.4798, 0.9560, 0.3511]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1013,  0.0370,  ...,  0.0124, -0.0203,  0.0083],\n",
      "        [ 0.0213,  0.0131, -0.0093,  ..., -0.0118,  0.0455,  0.0573],\n",
      "        [ 0.0211,  0.0409, -0.0248,  ...,  0.0167,  0.0329,  0.0050],\n",
      "        ...,\n",
      "        [-0.0149, -0.0265, -0.0471,  ..., -0.0360,  0.0157, -0.0931],\n",
      "        [-0.0294, -0.0365,  0.0800,  ..., -0.0322, -0.0590,  0.0304],\n",
      "        [ 0.0015, -0.0483,  0.0050,  ...,  0.0470,  0.0411,  0.0094]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 43: Best val_acc: 0.4016\n",
      "Epoch 43: Best val_acc: 0.4016\n",
      "Epoch 43: train_loss: 0.9755 train_acc: 0.7682 | val_loss: 1.9748 val_acc: 0.4016\n",
      "00:00:09.91\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1799, 0.4902,  ..., 0.8046, 0.1795, 0.7561],\n",
      "        [0.2530, 0.7519, 0.4354,  ..., 0.7417, 0.5285, 0.5090],\n",
      "        [0.6668, 0.2734, 0.3063,  ..., 0.3141, 0.3708, 0.8868],\n",
      "        ...,\n",
      "        [0.4868, 0.1855, 0.8003,  ..., 0.6165, 0.2077, 0.7926],\n",
      "        [0.9215, 0.3520, 0.9724,  ..., 0.8333, 0.9006, 0.6025],\n",
      "        [0.9648, 0.1523, 0.0439,  ..., 0.4798, 0.9560, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0370,  ...,  0.0124, -0.0203,  0.0083],\n",
      "        [ 0.0214,  0.0132, -0.0093,  ..., -0.0117,  0.0456,  0.0574],\n",
      "        [ 0.0211,  0.0409, -0.0249,  ...,  0.0166,  0.0329,  0.0050],\n",
      "        ...,\n",
      "        [-0.0150, -0.0265, -0.0471,  ..., -0.0360,  0.0157, -0.0930],\n",
      "        [-0.0294, -0.0364,  0.0800,  ..., -0.0322, -0.0590,  0.0303],\n",
      "        [ 0.0015, -0.0483,  0.0051,  ...,  0.0469,  0.0412,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 44: train_loss: 0.8806 train_acc: 0.7955 | val_loss: 1.9854 val_acc: 0.3811\n",
      "00:00:07.90\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1799, 0.4902,  ..., 0.8045, 0.1795, 0.7561],\n",
      "        [0.2531, 0.7519, 0.4355,  ..., 0.7417, 0.5285, 0.5090],\n",
      "        [0.6668, 0.2734, 0.3063,  ..., 0.3141, 0.3708, 0.8869],\n",
      "        ...,\n",
      "        [0.4867, 0.1854, 0.8003,  ..., 0.6165, 0.2077, 0.7927],\n",
      "        [0.9216, 0.3520, 0.9725,  ..., 0.8334, 0.9006, 0.6025],\n",
      "        [0.9648, 0.1522, 0.0439,  ..., 0.4797, 0.9560, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0370,  ...,  0.0124, -0.0203,  0.0083],\n",
      "        [ 0.0213,  0.0132, -0.0093,  ..., -0.0118,  0.0455,  0.0575],\n",
      "        [ 0.0210,  0.0409, -0.0248,  ...,  0.0166,  0.0329,  0.0050],\n",
      "        ...,\n",
      "        [-0.0150, -0.0265, -0.0472,  ..., -0.0361,  0.0157, -0.0930],\n",
      "        [-0.0294, -0.0364,  0.0799,  ..., -0.0322, -0.0590,  0.0304],\n",
      "        [ 0.0015, -0.0483,  0.0051,  ...,  0.0469,  0.0411,  0.0094]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 45: train_loss: 0.8321 train_acc: 0.7932 | val_loss: 2.0063 val_acc: 0.3852\n",
      "00:00:07.91\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8675, 0.1799, 0.4901,  ..., 0.8045, 0.1795, 0.7561],\n",
      "        [0.2532, 0.7519, 0.4355,  ..., 0.7417, 0.5285, 0.5090],\n",
      "        [0.6668, 0.2734, 0.3063,  ..., 0.3141, 0.3708, 0.8869],\n",
      "        ...,\n",
      "        [0.4868, 0.1854, 0.8003,  ..., 0.6165, 0.2077, 0.7927],\n",
      "        [0.9216, 0.3520, 0.9724,  ..., 0.8333, 0.9006, 0.6025],\n",
      "        [0.9648, 0.1523, 0.0439,  ..., 0.4797, 0.9560, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1012,  0.0370,  ...,  0.0124, -0.0203,  0.0083],\n",
      "        [ 0.0214,  0.0131, -0.0093,  ..., -0.0117,  0.0456,  0.0575],\n",
      "        [ 0.0211,  0.0409, -0.0248,  ...,  0.0166,  0.0329,  0.0049],\n",
      "        ...,\n",
      "        [-0.0150, -0.0265, -0.0472,  ..., -0.0360,  0.0158, -0.0931],\n",
      "        [-0.0294, -0.0365,  0.0799,  ..., -0.0322, -0.0590,  0.0304],\n",
      "        [ 0.0015, -0.0483,  0.0051,  ...,  0.0469,  0.0411,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 46: train_loss: 0.8673 train_acc: 0.7886 | val_loss: 2.0209 val_acc: 0.3893\n",
      "00:00:07.68\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1799, 0.4901,  ..., 0.8044, 0.1796, 0.7561],\n",
      "        [0.2531, 0.7519, 0.4355,  ..., 0.7417, 0.5285, 0.5091],\n",
      "        [0.6668, 0.2734, 0.3063,  ..., 0.3141, 0.3708, 0.8869],\n",
      "        ...,\n",
      "        [0.4868, 0.1854, 0.8002,  ..., 0.6165, 0.2077, 0.7927],\n",
      "        [0.9216, 0.3520, 0.9723,  ..., 0.8333, 0.9006, 0.6025],\n",
      "        [0.9648, 0.1523, 0.0440,  ..., 0.4797, 0.9560, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1012,  0.0370,  ...,  0.0124, -0.0203,  0.0084],\n",
      "        [ 0.0214,  0.0131, -0.0093,  ..., -0.0118,  0.0457,  0.0575],\n",
      "        [ 0.0211,  0.0409, -0.0249,  ...,  0.0166,  0.0329,  0.0049],\n",
      "        ...,\n",
      "        [-0.0150, -0.0265, -0.0471,  ..., -0.0361,  0.0158, -0.0931],\n",
      "        [-0.0293, -0.0364,  0.0799,  ..., -0.0321, -0.0590,  0.0304],\n",
      "        [ 0.0015, -0.0483,  0.0051,  ...,  0.0470,  0.0411,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 47: train_loss: 0.9445 train_acc: 0.7568 | val_loss: 2.0059 val_acc: 0.3893\n",
      "00:00:08.01\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1799, 0.4901,  ..., 0.8044, 0.1796, 0.7560],\n",
      "        [0.2531, 0.7519, 0.4355,  ..., 0.7417, 0.5285, 0.5091],\n",
      "        [0.6667, 0.2734, 0.3064,  ..., 0.3141, 0.3708, 0.8869],\n",
      "        ...,\n",
      "        [0.4868, 0.1855, 0.8002,  ..., 0.6165, 0.2078, 0.7927],\n",
      "        [0.9216, 0.3519, 0.9723,  ..., 0.8334, 0.9005, 0.6025],\n",
      "        [0.9647, 0.1523, 0.0439,  ..., 0.4797, 0.9560, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0371,  ...,  0.0124, -0.0202,  0.0083],\n",
      "        [ 0.0213,  0.0131, -0.0093,  ..., -0.0118,  0.0457,  0.0575],\n",
      "        [ 0.0211,  0.0408, -0.0248,  ...,  0.0166,  0.0329,  0.0049],\n",
      "        ...,\n",
      "        [-0.0150, -0.0266, -0.0472,  ..., -0.0361,  0.0158, -0.0931],\n",
      "        [-0.0294, -0.0365,  0.0800,  ..., -0.0321, -0.0591,  0.0305],\n",
      "        [ 0.0015, -0.0484,  0.0051,  ...,  0.0470,  0.0412,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 48: train_loss: 0.8983 train_acc: 0.7932 | val_loss: 2.0116 val_acc: 0.3607\n",
      "00:00:07.45\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1799, 0.4901,  ..., 0.8044, 0.1795, 0.7560],\n",
      "        [0.2531, 0.7518, 0.4355,  ..., 0.7417, 0.5286, 0.5091],\n",
      "        [0.6668, 0.2734, 0.3064,  ..., 0.3140, 0.3709, 0.8869],\n",
      "        ...,\n",
      "        [0.4867, 0.1855, 0.8003,  ..., 0.6165, 0.2078, 0.7928],\n",
      "        [0.9216, 0.3519, 0.9722,  ..., 0.8334, 0.9005, 0.6025],\n",
      "        [0.9647, 0.1524, 0.0439,  ..., 0.4798, 0.9559, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1013,  0.0371,  ...,  0.0123, -0.0202,  0.0083],\n",
      "        [ 0.0214,  0.0131, -0.0093,  ..., -0.0118,  0.0457,  0.0575],\n",
      "        [ 0.0211,  0.0408, -0.0248,  ...,  0.0166,  0.0329,  0.0049],\n",
      "        ...,\n",
      "        [-0.0150, -0.0265, -0.0472,  ..., -0.0361,  0.0158, -0.0930],\n",
      "        [-0.0293, -0.0365,  0.0800,  ..., -0.0321, -0.0591,  0.0306],\n",
      "        [ 0.0015, -0.0485,  0.0051,  ...,  0.0469,  0.0413,  0.0094]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 49: train_loss: 0.7199 train_acc: 0.8545 | val_loss: 2.0066 val_acc: 0.3893\n",
      "00:00:07.82\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1799, 0.4900,  ..., 0.8044, 0.1796, 0.7560],\n",
      "        [0.2531, 0.7518, 0.4356,  ..., 0.7418, 0.5286, 0.5091],\n",
      "        [0.6668, 0.2734, 0.3064,  ..., 0.3140, 0.3709, 0.8870],\n",
      "        ...,\n",
      "        [0.4866, 0.1855, 0.8002,  ..., 0.6164, 0.2078, 0.7928],\n",
      "        [0.9216, 0.3518, 0.9722,  ..., 0.8335, 0.9006, 0.6024],\n",
      "        [0.9647, 0.1523, 0.0439,  ..., 0.4798, 0.9559, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0370,  ...,  0.0122, -0.0203,  0.0084],\n",
      "        [ 0.0214,  0.0131, -0.0093,  ..., -0.0118,  0.0457,  0.0576],\n",
      "        [ 0.0211,  0.0408, -0.0248,  ...,  0.0166,  0.0328,  0.0049],\n",
      "        ...,\n",
      "        [-0.0150, -0.0264, -0.0472,  ..., -0.0362,  0.0159, -0.0930],\n",
      "        [-0.0294, -0.0365,  0.0800,  ..., -0.0321, -0.0591,  0.0306],\n",
      "        [ 0.0015, -0.0484,  0.0051,  ...,  0.0469,  0.0413,  0.0094]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 50: train_loss: 0.7590 train_acc: 0.8477 | val_loss: 2.0529 val_acc: 0.3770\n",
      "00:00:07.61\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1799, 0.4900,  ..., 0.8044, 0.1796, 0.7560],\n",
      "        [0.2531, 0.7519, 0.4356,  ..., 0.7417, 0.5286, 0.5091],\n",
      "        [0.6668, 0.2734, 0.3064,  ..., 0.3141, 0.3709, 0.8870],\n",
      "        ...,\n",
      "        [0.4866, 0.1855, 0.8002,  ..., 0.6165, 0.2078, 0.7928],\n",
      "        [0.9216, 0.3518, 0.9721,  ..., 0.8335, 0.9006, 0.6024],\n",
      "        [0.9647, 0.1524, 0.0440,  ..., 0.4798, 0.9559, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1012,  0.0371,  ...,  0.0122, -0.0203,  0.0084],\n",
      "        [ 0.0213,  0.0132, -0.0093,  ..., -0.0118,  0.0458,  0.0576],\n",
      "        [ 0.0211,  0.0408, -0.0249,  ...,  0.0166,  0.0329,  0.0049],\n",
      "        ...,\n",
      "        [-0.0150, -0.0264, -0.0472,  ..., -0.0361,  0.0158, -0.0930],\n",
      "        [-0.0294, -0.0364,  0.0800,  ..., -0.0321, -0.0591,  0.0307],\n",
      "        [ 0.0014, -0.0484,  0.0051,  ...,  0.0470,  0.0414,  0.0094]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 51: train_loss: 0.7947 train_acc: 0.8227 | val_loss: 2.0437 val_acc: 0.3730\n",
      "00:00:08.53\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1800, 0.4900,  ..., 0.8044, 0.1796, 0.7560],\n",
      "        [0.2531, 0.7519, 0.4356,  ..., 0.7418, 0.5286, 0.5091],\n",
      "        [0.6668, 0.2734, 0.3064,  ..., 0.3140, 0.3709, 0.8870],\n",
      "        ...,\n",
      "        [0.4866, 0.1855, 0.8002,  ..., 0.6165, 0.2077, 0.7929],\n",
      "        [0.9216, 0.3518, 0.9721,  ..., 0.8335, 0.9006, 0.6024],\n",
      "        [0.9647, 0.1525, 0.0440,  ..., 0.4797, 0.9561, 0.3511]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1013,  0.0371,  ...,  0.0122, -0.0203,  0.0084],\n",
      "        [ 0.0213,  0.0131, -0.0093,  ..., -0.0119,  0.0458,  0.0576],\n",
      "        [ 0.0211,  0.0408, -0.0249,  ...,  0.0166,  0.0329,  0.0049],\n",
      "        ...,\n",
      "        [-0.0150, -0.0264, -0.0473,  ..., -0.0361,  0.0159, -0.0930],\n",
      "        [-0.0293, -0.0365,  0.0800,  ..., -0.0321, -0.0591,  0.0307],\n",
      "        [ 0.0015, -0.0484,  0.0051,  ...,  0.0469,  0.0414,  0.0094]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 52: train_loss: 0.7624 train_acc: 0.8318 | val_loss: 2.0141 val_acc: 0.3893\n",
      "00:00:07.49\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1799, 0.4900,  ..., 0.8044, 0.1796, 0.7560],\n",
      "        [0.2531, 0.7519, 0.4356,  ..., 0.7418, 0.5285, 0.5091],\n",
      "        [0.6668, 0.2734, 0.3065,  ..., 0.3141, 0.3708, 0.8871],\n",
      "        ...,\n",
      "        [0.4866, 0.1855, 0.8001,  ..., 0.6165, 0.2077, 0.7929],\n",
      "        [0.9216, 0.3518, 0.9721,  ..., 0.8335, 0.9006, 0.6024],\n",
      "        [0.9647, 0.1524, 0.0440,  ..., 0.4797, 0.9561, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1013,  0.0371,  ...,  0.0122, -0.0203,  0.0083],\n",
      "        [ 0.0213,  0.0131, -0.0092,  ..., -0.0118,  0.0458,  0.0576],\n",
      "        [ 0.0210,  0.0409, -0.0249,  ...,  0.0166,  0.0329,  0.0050],\n",
      "        ...,\n",
      "        [-0.0150, -0.0265, -0.0472,  ..., -0.0361,  0.0159, -0.0931],\n",
      "        [-0.0293, -0.0365,  0.0799,  ..., -0.0321, -0.0591,  0.0308],\n",
      "        [ 0.0014, -0.0483,  0.0051,  ...,  0.0469,  0.0414,  0.0093]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 53: train_loss: 0.7591 train_acc: 0.8227 | val_loss: 2.0374 val_acc: 0.3893\n",
      "00:00:07.83\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1799, 0.4899,  ..., 0.8044, 0.1795, 0.7559],\n",
      "        [0.2531, 0.7519, 0.4357,  ..., 0.7418, 0.5285, 0.5091],\n",
      "        [0.6668, 0.2734, 0.3065,  ..., 0.3141, 0.3708, 0.8870],\n",
      "        ...,\n",
      "        [0.4866, 0.1855, 0.8001,  ..., 0.6165, 0.2077, 0.7929],\n",
      "        [0.9217, 0.3517, 0.9721,  ..., 0.8335, 0.9005, 0.6024],\n",
      "        [0.9647, 0.1525, 0.0440,  ..., 0.4797, 0.9561, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1013,  0.0371,  ...,  0.0122, -0.0203,  0.0082],\n",
      "        [ 0.0213,  0.0131, -0.0092,  ..., -0.0118,  0.0458,  0.0577],\n",
      "        [ 0.0210,  0.0409, -0.0250,  ...,  0.0166,  0.0329,  0.0051],\n",
      "        ...,\n",
      "        [-0.0150, -0.0265, -0.0472,  ..., -0.0361,  0.0159, -0.0931],\n",
      "        [-0.0293, -0.0366,  0.0799,  ..., -0.0322, -0.0591,  0.0308],\n",
      "        [ 0.0014, -0.0483,  0.0051,  ...,  0.0469,  0.0414,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 54: train_loss: 0.6862 train_acc: 0.8295 | val_loss: 2.0757 val_acc: 0.3730\n",
      "00:00:07.99\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[0.8674, 0.1798, 0.4899,  ..., 0.8045, 0.1795, 0.7560],\n",
      "        [0.2532, 0.7519, 0.4357,  ..., 0.7418, 0.5285, 0.5091],\n",
      "        [0.6668, 0.2733, 0.3065,  ..., 0.3141, 0.3708, 0.8870],\n",
      "        ...,\n",
      "        [0.4865, 0.1855, 0.8001,  ..., 0.6166, 0.2076, 0.7929],\n",
      "        [0.9216, 0.3516, 0.9721,  ..., 0.8335, 0.9005, 0.6024],\n",
      "        [0.9647, 0.1525, 0.0440,  ..., 0.4796, 0.9561, 0.3510]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.1013,  0.0371,  ...,  0.0122, -0.0203,  0.0082],\n",
      "        [ 0.0212,  0.0131, -0.0093,  ..., -0.0118,  0.0458,  0.0577],\n",
      "        [ 0.0210,  0.0409, -0.0250,  ...,  0.0166,  0.0329,  0.0052],\n",
      "        ...,\n",
      "        [-0.0151, -0.0266, -0.0472,  ..., -0.0361,  0.0159, -0.0931],\n",
      "        [-0.0293, -0.0365,  0.0799,  ..., -0.0322, -0.0591,  0.0308],\n",
      "        [ 0.0015, -0.0483,  0.0050,  ...,  0.0469,  0.0414,  0.0095]],\n",
      "       device='cuda:2', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 0.9999118381076388, 0.9999254014756944, 0.9999321831597222, 0.9999152289496528, 0.9999321831597222, 0.99993896484375, 0.9999423556857638, 0.9999220106336806, 0.9999355740017362, 0.9999525282118056, 0.9999593098958334, 0.9999423556857638, 0.9999660915798612, 0.999969482421875, 0.9999593098958334, 0.9999593098958334, 0.9999525282118056, 0.9999559190538194, 0.9999660915798612, 0.9999593098958334, 0.9999627007378472, 0.999969482421875, 0.9999559190538194, 0.9999423556857638, 0.9999593098958334, 0.9999559190538194, 0.9999559190538194, 0.9999423556857638, 0.9999728732638888, 0.9999627007378472, 0.9999796549479166, 0.9999796549479166, 0.9999627007378472, 0.9999660915798612, 0.9999796549479166, 0.9999593098958334, 0.9999728732638888, 0.9999762641059028, 0.9999660915798612, 0.9999660915798612, 0.9999830457899306, 0.9999830457899306, 0.999969482421875, 0.9999830457899306, 0.9999830457899306, 0.9999796549479166, 0.999969482421875, 0.9999728732638888, 0.9999762641059028, 0.9999627007378472, 0.999969482421875, 0.9999762641059028, 0.9999830457899306]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_outerpooler['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: Cos: BertPooler')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001884048391666899, 8.288241492897869e-05, 8.064514840001252e-05, 6.723498226991444e-05, 5.920040278716473e-05, 5.983781949097285e-05, 5.636493466496204e-05, 5.3112438685812817e-05, 5.377576501196015e-05, 5.132600350364922e-05, 4.996806659907402e-05, 4.8892030546636434e-05, 4.7652744105252604e-05, 4.9588001124716165e-05, 4.662330278336154e-05, 4.6574953674546585e-05, 4.606064669585944e-05, 4.6445637632833774e-05, 4.4235881642973626e-05, 4.45159475196503e-05, 4.567903696655776e-05, 4.2667627027176414e-05, 4.307503270402743e-05, 4.319091605179157e-05, 4.087129537217059e-05, 4.3311870979289816e-05, 4.3161073145094815e-05, 4.1403724910865943e-05, 4.094959642648844e-05, 3.97748591757014e-05, 4.158890389712131e-05, 4.1946271568856305e-05, 4.13322362044877e-05, 4.045586864861234e-05, 3.903021867934478e-05, 4.008661803311787e-05, 3.924901357058647e-05, 3.2191467547180073e-05, 3.158551225489655e-05, 3.015699601706698e-05, 3.056050655803595e-05, 3.058952005027815e-05, 3.086524662647416e-05, 3.099029900794806e-05, 2.9785781905268692e-05, 2.898612580296309e-05, 3.143714985043134e-05, 3.1700159117266676e-05, 2.8662807479546475e-05, 2.956152571161978e-05, 3.145824433268066e-05, 2.9631179741708657e-05, 3.08465119762834e-05, 2.9617450383165476e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_outerpooler['l2']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: L2: BertPooler')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9949824015299479, 0.9977052476671007, 0.998091803656684, 0.9984859890407987, 0.9985690646701388, 0.9985453287760416, 0.9987013075086806, 0.998795403374566, 0.9988394843207465, 0.9988954332139757, 0.9988615247938368, 0.9988801744249132, 0.9989403618706597, 0.9989327324761285, 0.9989802042643229, 0.9990310668945312, 0.9989751180013021, 0.9989742702907987, 0.9990819295247396, 0.9990759955512153, 0.9989598592122396, 0.9990327623155382, 0.9990310668945312, 0.9990564982096354, 0.9990590413411459, 0.9990064832899306, 0.9990149603949653, 0.9990929497612847, 0.9991412692599826, 0.9990937974717882, 0.9990870157877604, 0.9990370008680556, 0.9990132649739584, 0.9990946451822916, 0.9991370307074653, 0.9990827772352431, 0.999114990234375, 0.9992896185980903, 0.9993158976236979, 0.9992997911241319, 0.999312506781684, 0.9992574055989584, 0.9993091159396701, 0.999253167046441, 0.9993091159396701, 0.9993413289388021, 0.9992862277560763, 0.9992523193359375, 0.9993023342556424, 0.9992896185980903, 0.9992582533094618, 0.9992752075195312, 0.9993040296766493, 0.9993048773871528]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_transformerlayer['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: Cos: Last Dense Layer')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00021197052842002748, 9.328777778004346e-05, 7.898298218959018e-05, 6.386192084905974e-05, 5.757138519429463e-05, 5.815983322478647e-05, 5.404474216375024e-05, 4.9409872992570175e-05, 4.725182455963921e-05, 4.666109843465281e-05, 4.731076169019061e-05, 4.680511199402119e-05, 4.5697704682910114e-05, 4.453893324032477e-05, 4.2707748322105666e-05, 4.26897685193343e-05, 4.367498407117077e-05, 4.258723953670195e-05, 4.0872024735522134e-05, 3.9380400121621775e-05, 4.278510529097029e-05, 4.23974883115396e-05, 4.1127470393379e-05, 4.028461278771609e-05, 3.905358142214656e-05, 4.151708597675444e-05, 4.130178408188543e-05, 4.0119548540692144e-05, 3.811599721906265e-05, 3.871909511444332e-05, 3.9947568047253436e-05, 4.00256598942798e-05, 4.1202488875691085e-05, 3.9750364018639387e-05, 3.7911490367250945e-05, 3.905575924644193e-05, 3.817844232561529e-05, 3.148842047817412e-05, 3.0862043783031566e-05, 3.0077393534116393e-05, 2.94441365664509e-05, 2.9563862103265347e-05, 2.912166957431888e-05, 3.0201309825947454e-05, 2.9130167122843143e-05, 2.862399348588323e-05, 3.100356662068935e-05, 3.138673311159752e-05, 2.8278324205305156e-05, 2.9266028051068162e-05, 3.088712617712656e-05, 2.9708054770282565e-05, 3.090602462584641e-05, 2.9399297896327375e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_transformerlayer['l2']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: L2: Last Dense Layer')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_innerpooler['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: Cos: InnerPooler')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19661/337760207.py:10: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_innerpooler['l2']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: L2: InnerPooler')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.3550 test_acc: 0.3462\n",
      "00:00:01.07\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.50      0.39      0.44        18\n",
      "    background       0.25      0.41      0.31        17\n",
      "         cause       0.25      0.50      0.33         2\n",
      "  circumstance       0.50      0.20      0.29        15\n",
      "    concession       0.43      0.46      0.44        13\n",
      "     condition       0.47      0.89      0.62         9\n",
      "   conjunction       0.29      0.29      0.29         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.64      0.64      0.64        11\n",
      "   elaboration       0.21      0.40      0.28        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       1.00      0.06      0.11        17\n",
      "      evidence       0.33      0.10      0.15        10\n",
      "interpretation       0.12      0.25      0.16        12\n",
      "         joint       0.29      0.45      0.35        29\n",
      "          list       0.50      0.31      0.38        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.60      0.75      0.67         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.33      0.41      0.37        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.35       260\n",
      "     macro avg       0.31      0.29      0.26       260\n",
      "  weighted avg       0.39      0.35      0.32       260\n",
      "\n",
      "Test Loss: 2.355 |  Test Acc: 34.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#latest\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.2601 test_acc: 0.3577\n",
      "00:00:01.24\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.67      0.33      0.44        18\n",
      "    background       0.31      0.65      0.42        17\n",
      "         cause       0.50      1.00      0.67         2\n",
      "  circumstance       0.50      0.27      0.35        15\n",
      "    concession       0.43      0.46      0.44        13\n",
      "     condition       0.56      1.00      0.72         9\n",
      "   conjunction       0.33      0.29      0.31         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.78      0.64      0.70        11\n",
      "   elaboration       0.22      0.50      0.30        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.00      0.00      0.00        10\n",
      "interpretation       0.11      0.25      0.15        12\n",
      "         joint       0.28      0.52      0.36        29\n",
      "          list       0.52      0.46      0.49        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.60      0.75      0.67         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.27      0.18      0.21        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.36       260\n",
      "     macro avg       0.28      0.32      0.28       260\n",
      "  weighted avg       0.34      0.36      0.32       260\n",
      "\n",
      "Latest Test Loss: 2.260 |  Latest Test Acc: 35.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best earliest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.2601 test_acc: 0.3577\n",
      "00:00:01.05\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.67      0.33      0.44        18\n",
      "    background       0.31      0.65      0.42        17\n",
      "         cause       0.50      1.00      0.67         2\n",
      "  circumstance       0.50      0.27      0.35        15\n",
      "    concession       0.43      0.46      0.44        13\n",
      "     condition       0.56      1.00      0.72         9\n",
      "   conjunction       0.33      0.29      0.31         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.78      0.64      0.70        11\n",
      "   elaboration       0.22      0.50      0.30        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.00      0.00      0.00        10\n",
      "interpretation       0.11      0.25      0.15        12\n",
      "         joint       0.28      0.52      0.36        29\n",
      "          list       0.52      0.46      0.49        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.60      0.75      0.67         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.27      0.18      0.21        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         0\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.36       260\n",
      "     macro avg       0.28      0.32      0.28       260\n",
      "  weighted avg       0.34      0.36      0.32       260\n",
      "\n",
      "Best Test Loss: 2.260 |  Best Test Acc: 35.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best lastest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_latest', test_acc, 1)\n",
    "print(f'Best Test Loss: {test_loss:.3f} |  Best Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.0010 test_acc: 0.3893\n",
      "00:00:00.93\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.14      0.09      0.11        11\n",
      "    background       0.33      0.65      0.44        17\n",
      "         cause       0.50      0.29      0.36         7\n",
      "  circumstance       1.00      0.15      0.27        13\n",
      "    concession       0.55      0.55      0.55        11\n",
      "     condition       0.47      0.88      0.61         8\n",
      "   conjunction       0.67      0.75      0.71         8\n",
      "      contrast       0.00      0.00      0.00         3\n",
      " e-elaboration       0.78      0.54      0.64        13\n",
      "   elaboration       0.21      0.18      0.19        28\n",
      "  evaluation-n       0.00      0.00      0.00         8\n",
      "  evaluation-s       0.00      0.00      0.00         5\n",
      "      evidence       0.33      0.38      0.35         8\n",
      "interpretation       0.13      0.15      0.14        13\n",
      "         joint       0.20      0.39      0.26        18\n",
      "          list       0.42      0.56      0.48        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.80      0.73      0.76        11\n",
      "       purpose       0.75      0.60      0.67         5\n",
      "        reason       0.50      0.54      0.52        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         3\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.39       241\n",
      "     macro avg       0.32      0.31      0.29       241\n",
      "  weighted avg       0.40      0.39      0.37       241\n",
      "\n",
      "Val Loss: 2.001 |  Val Acc: 38.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best val acc\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
