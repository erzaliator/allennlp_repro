{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI6aVBQRy6LC"
   },
   "source": [
    "# 4️⃣ Zero-Shot Cross-Lingual Transfer using Adapters\n",
    "\n",
    "Beyond AdapterFusion, which we trained in [the previous notebook](https://github.com/Adapter-Hub/adapter-transformers/blob/master/notebooks/04_Cross_Lingual_Transfer.ipynb), we can compose adapters for zero-shot cross-lingual transfer between tasks. We will use the stacked adapter setup presented in **MAD-X** ([Pfeiffer et al., 2020](https://arxiv.org/pdf/2005.00052.pdf)) for this purpose.\n",
    "\n",
    "In this example, the base model is a pre-trained multilingual **XLM-R** (`xlm-roberta-base`) ([Conneau et al., 2019](https://arxiv.org/pdf/1911.02116.pdf)) model. Additionally, two types of adapters, language adapters and task adapters, are used. Here's how the MAD-X process works in detail:\n",
    "\n",
    "1. Train language adapters for the source and target language on a language modeling task. In this notebook, we won't train them ourselves but use [pre-trained language adapters from the Hub](https://adapterhub.ml/explore/text_lang/).\n",
    "2. Train a task adapter on the target task dataset. This task adapter is **stacked** upon the previously trained language adapter. During this step, only the weights of the task adapter are updated.\n",
    "3. Perform zero-shot cross-lingual transfer. In this last step, we simply replace the source language adapter with the target language adapter while keeping the stacked task adapter.\n",
    "\n",
    "Now to our concrete example: we select **XCOPA** ([Ponti et al., 2020](https://ducdauge.github.io/files/xcopa.pdf)), a multilingual extension of the **COPA** commonsence reasoning dataset ([Roemmele et al., 2011](https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF)) as our target task. The setup is trained on the original **English** dataset and then transferred to **Chinese**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L9gYpCV28OA"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Besides `adapter-transformers`, we use HuggingFace's `datasets` library for loading the data. So let's install both first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qL3Sq1HQynCq",
    "outputId": "1a53add7-208d-4767-a6f7-c51fad93787e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "MODEL_DIR = './training_output/deu_disrpt_vanilla_bert'\n",
    "BERT_MODEL = 'bert-base-multilingual-cased'\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP9OMSUT-FtL"
   },
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "We need the English COPA dataset for training our task adapter. It is part of the SuperGLUE benchmark and can be loaded via `datasets` using one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16002, 2155, 1621)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "en_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_train_enriched.rels'))\n",
    "en_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_test_enriched.rels'))\n",
    "en_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_dev_enriched.rels'))\n",
    "\n",
    "de_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels'))\n",
    "de_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels'))\n",
    "de_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels'))\n",
    "\n",
    "len(en_train_dataset_df), len(en_test_dataset_df), len(en_valid_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit1_txt': Value(dtype='string', id=None),\n",
       " 'unit1_sent': Value(dtype='string', id=None),\n",
       " 'unit2_txt': Value(dtype='string', id=None),\n",
       " 'unit2_sent': Value(dtype='string', id=None),\n",
       " 'dir': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='string', id=None),\n",
       " 'distance': Value(dtype='string', id=None),\n",
       " 'u1_depdir': Value(dtype='string', id=None),\n",
       " 'u2_depdir': Value(dtype='string', id=None),\n",
       " 'u2_func': Value(dtype='string', id=None),\n",
       " 'u1_position': Value(dtype='string', id=None),\n",
       " 'u2_position': Value(dtype='string', id=None),\n",
       " 'sat_children': Value(dtype='string', id=None),\n",
       " 'nuc_children': Value(dtype='string', id=None),\n",
       " 'genre': Value(dtype='string', id=None),\n",
       " 'unit1_case': Value(dtype='string', id=None),\n",
       " 'unit2_case': Value(dtype='string', id=None),\n",
       " 'u1_discontinuous': Value(dtype='string', id=None),\n",
       " 'u2_discontinuous': Value(dtype='string', id=None),\n",
       " 'same_speaker': Value(dtype='string', id=None),\n",
       " 'lex_overlap_length': Value(dtype='string', id=None),\n",
       " 'u1_func': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train_dataset_df.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INW7UEhC-I6b",
    "outputId": "b3e53380-c243-4b0c-88c5-629c272313e8"
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "from transformers.adapters.composition import Stack\n",
    "\n",
    "# dataset_en = load_dataset(\"super_glue\", \"copa\")\n",
    "# dataset_en.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epiKaEz5dDVe"
   },
   "source": [
    "Every dataset sample has a premise, a question and two possible answer choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifu4q5IJ-hYI",
    "outputId": "6ae68d07-3033-431b-ac31-5fcb24a2f24e"
   },
   "outputs": [],
   "source": [
    "# dataset_en['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVa3Vk0QdNYI"
   },
   "source": [
    "In this example, we model COPA as a multiple-choice task with two choices. Thus, we encode the premise and question as well as both choices as one input to our `xlm-roberta-base` model. Using `dataset.map()`, we can pass the full dataset through the tokenizer in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206,
     "referenced_widgets": [
      "acb9523d3e594c3d84036ad2348a7a64",
      "8d88b67069074ee6bc937b46cc10418a",
      "e71f76432d5e469d8cf742bbed6e0f1c",
      "a3da9679c78640c3be6e7cbbd5bcccae",
      "10e45676711b477e9a1ce2cf4ac8f3a9",
      "8cb6e0c49bd040b7bd5f266c4608dd31",
      "7a718fb0db5640fd8eb04ef18fe1e339",
      "0f3bac44e13246ab9f9c8564a44e1fa3",
      "c21fa18f6c4b4bdd9621ef29180646db",
      "fa8da5adaacd4534b60e51ba4dce6c4a",
      "249abcb1904c4d1ca4116b677011b017",
      "4a23a9bdd091425cbda38222f2e4c3a9",
      "df292d721c1748c485f281aa2162b9a9",
      "12ec755bb33c4ff894644e291ce33040",
      "77583bbefaf849eea83d3ae327e4070e",
      "58b17e932dd74756b62fb7f6ed0d37ba",
      "9380ff7e78f846babb16740cfc9cf7f8",
      "7a31bf9dedde47188efdfaf6a262b730",
      "f45f9a16f75e4d07abe5dcaf2fb300f4",
      "21bd77c2c70040548a696c5a40d81a00",
      "9c8548e2e4c54bf88e678c571c537867",
      "5321f4576a6c4fe69de0c97b43269d3b",
      "932d3ee3c9d74761bfc4bcf5c003d205",
      "ac8b24c5d6214716a409ca95580306f5"
     ]
    },
    "id": "hEnRCQfE_Oi3",
    "outputId": "27270898-730b-42a7-f028-875e2acf6a05"
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# def encode_batch(examples):\n",
    "#   \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "#   all_encoded = {\"input_ids\": [], \"attention_mask\": []}\n",
    "#   # Iterate through all examples in this batch\n",
    "#   for premise, question, choice1, choice2 in zip(examples[\"premise\"], examples[\"question\"], examples[\"choice1\"], examples[\"choice2\"]):\n",
    "#     sentences_a = [premise + \" \" + question for _ in range(2)]\n",
    "#     # Both answer choices are passed in an array according to the format needed for the multiple-choice prediction head\n",
    "#     sentences_b = [choice1, choice2]\n",
    "#     encoded = tokenizer(\n",
    "#         sentences_a,\n",
    "#         sentences_b,\n",
    "#         max_length=60,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "#     all_encoded[\"input_ids\"].append(encoded[\"input_ids\"])\n",
    "#     all_encoded[\"attention_mask\"].append(encoded[\"attention_mask\"])\n",
    "#   return all_encoded\n",
    "\n",
    "# def preprocess_dataset(dataset):\n",
    "#   # Encode the input data\n",
    "#   dataset = dataset.map(encode_batch, batched=True)\n",
    "#   # The transformers model expects the target class column to be named \"labels\"\n",
    "#   # dataset.rename_column(\"label\", \"labels\")\n",
    "#   # Transform to pytorch tensors and only output the required columns\n",
    "#   dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "#   return dataset\n",
    "\n",
    "# dataset_en = preprocess_dataset(dataset_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 16002 examples\n",
      "read 1621 examples\n",
      "read 2155 examples\n",
      "read 2164 examples\n",
      "read 241 examples\n",
      "read 260 examples\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from datasets import ClassLabel\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the SNLI dataset.\"\"\"\n",
    "    def __init__(self, dataset, labels, raw_text=False):\n",
    "        self.text = []\n",
    "        self.raw_text = []\n",
    "        self.raw_label = []\n",
    "        self.raw_text_flag = raw_text\n",
    "        self.num_rows = len(dataset)\n",
    "        for premise, hypothesis in zip(dataset['unit1_txt'], dataset['unit2_txt']):\n",
    "            self.text.append(tokenizer.encode_plus(premise, hypothesis, padding=\"max_length\", truncation=True, max_length=512, return_token_type_ids=True))\n",
    "            if raw_text: self.raw_text.append([premise, hypothesis])\n",
    "        # self.labels = torch.tensor(labels.str2int(dataset['label'])).to(device)\n",
    "        self.labels = labels.str2int(dataset['label'])\n",
    "        if raw_text: self.raw_label = dataset['label']\n",
    "        print('read ' + str(len(self.text)) + ' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.raw_text_flag:  \n",
    "            return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'raw_text': self.raw_text[idx],\n",
    "                'label':self.labels[idx],\n",
    "                'raw_label': self.raw_label[idx]}\n",
    "\n",
    "        return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'label':self.labels[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def combine_with_another_dataset(self, dataset2):\n",
    "        print('Adding datasets of sizes ', self.num_rows, ', ', dataset2.num_rows)\n",
    "        self.text = self.text + dataset2.text\n",
    "        self.raw_text = self.raw_text + dataset2.raw_text\n",
    "        self.raw_label = self.raw_label + dataset2.raw_label\n",
    "        self.num_rows = len(self.text) #update texts is now longer\n",
    "        assert self.raw_text_flag == dataset2.raw_text_flag\n",
    "        print('To new dataset size: ', self.num_rows)\n",
    "\n",
    "\n",
    "def load_data_snli(batch_size, train_dataset_df, valid_dataset_df, test_dataset_df, labels):\n",
    "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
    "    train_data = train_dataset_df\n",
    "    valid_data = valid_dataset_df\n",
    "    test_data = test_dataset_df\n",
    "    train_set = SNLIDataset(train_data, labels, raw_text=False)\n",
    "    valid_set = SNLIDataset(valid_data, labels, raw_text=False)\n",
    "    test_set = SNLIDataset(test_data, labels, raw_text=False)\n",
    "    return train_set, valid_set, test_set #TODO: MAKE INTO DICT\n",
    "\n",
    "en_labels = ClassLabel(names=list(set(en_train_dataset_df['label'])|set(en_test_dataset_df['label'])|set(en_valid_dataset_df['label'])))\n",
    "en_train_dataset, en_valid_dataset, en_test_dataset = load_data_snli(BATCH_SIZE, en_train_dataset_df, en_valid_dataset_df, en_test_dataset_df, en_labels)\n",
    "de_labels = ClassLabel(names=list(set(de_train_dataset_df['label'])|set(de_test_dataset_df['label'])|set(de_valid_dataset_df['label'])))\n",
    "de_train_dataset, de_valid_dataset, de_test_dataset = load_data_snli(BATCH_SIZE, de_train_dataset_df, de_valid_dataset_df, de_test_dataset_df, de_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs21MzEQ_0v4"
   },
   "source": [
    "## Task Adapter Training\n",
    "\n",
    "In this section, we will train the task adapter on the English COPA dataset. We use a pre-trained XLM-R model from HuggingFace and instantiate our model using `AutoAdapterModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnq8n_KP_3aX",
    "outputId": "590b1cae-a454-4110-c9fb-f76f4dff423a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertAdapterModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoAdapterModel\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    BERT_MODEL,\n",
    ")\n",
    "model = AutoAdapterModel.from_pretrained(\n",
    "    BERT_MODEL,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base AutoModel. If you print model before adding the adapters, you can see that the embeddings+12 transformer layers will be shared by En and Zh adapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDCNJzTXezcn"
   },
   "source": [
    "Now we only need to set up the adapters. As described, we need two language adapters (which are assumed to be pre-trained in this example) and a task adapter (which will be trained in a few moments).\n",
    "\n",
    "First, we load both the language adapters for our source language English (`\"en\"`) and our target language Chinese (`\"zh\"`) from the Hub. Then we add a new task adapter (`\"copa\"`) for our target task.\n",
    "\n",
    "Finally, we add a multiple-choice head with the same name as our task adapter on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jRqbBgS0BoHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdapterConfig\n",
    "\n",
    "# Load the language adapters\n",
    "lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "model.load_adapter(\"en/wiki@ukp\", config=lang_adapter_config)\n",
    "model.load_adapter(\"de/wiki@ukp\", config=lang_adapter_config)\n",
    "\n",
    "# Add a new task adapter\n",
    "model.add_adapter(\"disrpt\")\n",
    "\n",
    "# Add a classification head for our target task\n",
    "num_labels=de_labels.num_classes\n",
    "print([num_labels])\n",
    "# model.add_multiple_choice_head(\"disrpt\", num_choices=num_labels)\n",
    "model.add_classification_head(\"disrpt\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `train_adapter()`, we tell our model to only train the task adapter in the following. This call will freeze the weights of the pre-trained model and the weights of the language adapters to prevent them from further finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7wBpjGWZ4v7O"
   },
   "outputs": [],
   "source": [
    "model.train_adapter([\"disrpt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60qIas8-il92"
   },
   "source": [
    "We want the task adapter to be stacked on top of the language adapter, so we have to tell our model to use this setup via the `active_adapters` property.\n",
    "\n",
    "A stack of adapters is represented by the `Stack` class, which takes the names of the adapters to be stacked as arguments.\n",
    "Of course, there are various other possibilities to compose adapters beyonde stacking. Learn more about those [in our documentation](https://docs.adapterhub.ml/adapter_composition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zgGqHJQbijgg"
   },
   "outputs": [],
   "source": [
    "# Unfreeze and activate stack setup\n",
    "model.active_adapters = Stack(\"en\", \"disrpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBDvwmUf_-mc"
   },
   "source": [
    "Great! Now, the input will be passed through the English language adapter first and the COPA task adapter second in every forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb8BY5RAmzkd"
   },
   "source": [
    "For training, we make use of the `Trainer` class built-in into `transformers`. We configure the training process using a `TrainingArguments` object.\n",
    "\n",
    "As the dataset splits of English COPA in the SuperGLUE are slightly different, we train on both the train and validation split of the dataset. Later, we will evaluate on the test split of XCOPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SHUFFLE print smples: https://discuss.huggingface.co/t/how-to-print-a-few-examples-at-the-beginning-of-training-when-using-trainer/7597/2\n",
    "# https://github.com/huggingface/datasets/blob/cd3169f3f35afcf73a36a8276113e1881d92e5e0/src/datasets/iterable_dataset.py#L223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "j0gFxQRdDkQ6"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer\n",
    "# from datasets import concatenate_datasets\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def concatenate_datasets(dataset1, dataset2, shuffle=True):\n",
    "    y_iter = chain(dataset1, dataset2)\n",
    "    return y_iter\n",
    "    # tmp = list(yielding(y_iter))\n",
    "    # random.shuffle(tmp)\n",
    "    # for i in tmp:\n",
    "    #     print i\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps=100,\n",
    "    output_dir=MODEL_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# train_dataset.combine_with_another_dataset(valid_dataset)\n",
    "# train_dataset = concatenate_datasets([dataset_en[\"train\"], dataset_en[\"validation\"]])\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=en_train_dataset,\n",
    "    eval_dataset=en_valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKlYjA9rm2Kp"
   },
   "source": [
    "Start the training 🚀 (this will take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertAdapterModel(\n",
      "  (shared_parameters): ModuleDict()\n",
      "  (bert): BertModel(\n",
      "    (shared_parameters): ModuleDict()\n",
      "    (invertible_adapters): ModuleDict(\n",
      "      (en): NICECouplingBlock(\n",
      "        (F): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "        (G): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (de): NICECouplingBlock(\n",
      "        (F): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): NewGELUActivation()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "        (G): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): NewGELUActivation()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): NewGELUActivation()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): NewGELUActivation()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "    (prefix_tuning): PrefixTuningPool(\n",
      "      (prefix_tunings): ModuleDict()\n",
      "    )\n",
      "  )\n",
      "  (heads): ModuleDict(\n",
      "    (disrpt): ClassificationHead(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (2): Activation_Function_Class(\n",
      "        (f): Tanh()\n",
      "      )\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=768, out_features=26, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "vSUs2FjXDmsx",
    "outputId": "2b8bb989-f6ca-4702-c222-15eea9823bbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 16002\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8008\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merzaliator\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/VD/kaveri/bert_categorical_tutorial/allennlp_repro/disrpt_alln/4_adapter/wandb/run-20230203_112215-elgjgs21</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/erzaliator/huggingface/runs/elgjgs21\" target=\"_blank\">./training_output/deu_disrpt_vanilla_bert</a></strong> to <a href=\"https://wandb.ai/erzaliator/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/erzaliator/huggingface\" target=\"_blank\">https://wandb.ai/erzaliator/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/erzaliator/huggingface/runs/elgjgs21\" target=\"_blank\">https://wandb.ai/erzaliator/huggingface/runs/elgjgs21</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/trainer.py:1498\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1495\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1497\u001b[0m )\n\u001b[0;32m-> 1498\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1499\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1500\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1501\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1502\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1503\u001b[0m )\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/trainer.py:1740\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1739\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1743\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1744\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1745\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1746\u001b[0m ):\n\u001b[1;32m   1747\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/trainer.py:2470\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2469\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2470\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2472\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2473\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/trainer.py:2502\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2501\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2502\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2503\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2504\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2505\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/adapters/models/bert/adapter_model.py:63\u001b[0m, in \u001b[0;36mBertAdapterModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, head, output_adapter_gating_scores, output_adapter_fusion_attentions, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m inputs_embeds \u001b[39m=\u001b[39m (\n\u001b[1;32m     56\u001b[0m     inputs_embeds\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, inputs_embeds\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m), inputs_embeds\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m---> 63\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m     64\u001b[0m     input_ids,\n\u001b[1;32m     65\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m     66\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m     67\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m     68\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m     69\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m     70\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m     71\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m     72\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m     73\u001b[0m     output_adapter_gating_scores\u001b[39m=\u001b[39;49moutput_adapter_gating_scores,\n\u001b[1;32m     74\u001b[0m     output_adapter_fusion_attentions\u001b[39m=\u001b[39;49moutput_adapter_fusion_attentions,\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     76\u001b[0m \u001b[39m# BERT & RoBERTa return the pooled output as second item, we don't need that in these heads\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/adapters/context.py:108\u001b[0m, in \u001b[0;36mForwardContext.wrap.<locals>.wrapper_func\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    105\u001b[0m     kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    106\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39moutput_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcontext_attributes\n\u001b[1;32m    107\u001b[0m     }\n\u001b[0;32m--> 108\u001b[0m     results \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    110\u001b[0m     \u001b[39m# append output attributes\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1042\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1042\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m   1043\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1044\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1045\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1046\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1047\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m   1048\u001b[0m )\n\u001b[1;32m   1050\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minvertible_adapters_forward(embedding_output)\n\u001b[1;32m   1051\u001b[0m \u001b[39m#KAVERI: inject discodisco line 244-260\u001b[39;00m\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/VD/kaveri/anaconda3/envs/adapters/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:248\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    245\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings(input_ids)\n\u001b[1;32m    246\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m--> 248\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39;49m token_type_embeddings\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    250\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2155\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2329370975494385,\n",
       " 'eval_acc': 0.645939675174014,\n",
       " 'eval_runtime': 58.9523,\n",
       " 'eval_samples_per_second': 36.555,\n",
       " 'eval_steps_per_second': 4.58}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "eval_trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output_en\", remove_unused_columns=False,),\n",
    "    eval_dataset=en_test_dataset,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "eval_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axvDsmnJnGUG"
   },
   "source": [
    "## Cross-lingual transfer\n",
    "\n",
    "With the model and all adapters trained and ready, we can come to the cross-lingual transfer step here. We will evaluate our setup on the Chinese split of the XCOPA dataset.\n",
    "Therefore, we'll first download the data and preprocess it using the same method as the English dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344,
     "referenced_widgets": [
      "630597c0e70d4792b58c8942296692a4",
      "64e51ced10004147b21e51db1343cac8",
      "ff7c6d1bfc654c2db63e40bad4e3eb33",
      "f964d3d5333948e0b14117555b82275b",
      "949971635f1f498e86e04b9d4e28d353",
      "aebd284cd0ba4dfbafce1f0b99cd5213",
      "5df3d17d64e24faeab6cc644d333536a",
      "525a5c1a8ba04c8e89fc514064539d73",
      "c515e4e9f5b7470e8a17e4a4247878f5",
      "89f8555b95ec48b7b3282cb365b1cfdd",
      "c4b64289fc4445f59a94d6c51a288834",
      "568fedab4a4e44d9baa8213d54d60d38",
      "6025f45ce1af4c8caab09042992f2094",
      "1ccbb12bb5a548488c9b646159f893d3",
      "87c546c1a23c402f8a6de964828dc035",
      "f512c5cdfaa64005bb987f032957e530",
      "ea780b89e28a4348abfac40ef8fd140a",
      "4eac0e183d8047e498d3a576f3c3a1f4",
      "315cd377eae94488b258460f06e5cc10",
      "5b2e4c980b6a4e15bef86d1907b20f40",
      "9a8c7ea6d7ec4ec691525f6e3ca88d48",
      "02cb7dbc5b67469b8643c0ea3e6b3921",
      "3ccf15d7bea44e9bb91b9b3d32b3c691",
      "2d964df49d71456093b427af2a3ac6cc",
      "2a76413cb9cd4a6f901a8bef7dc70220",
      "13829992bf994ec5bbec71684cc824e6",
      "c154bfdf049147638c67d2844d25f9e6",
      "4fe615dff7104a018c48491fd711ed45",
      "3bc11633e20c460eb9058cc4b480b224",
      "5f708ccdb4f941918696d583ad9bd9c9",
      "527ea785de0a47f0ba5b0d0aea72cc97",
      "c2423ca88827446aa5b5c78ccc36a263",
      "71b51022c34247929dcb8f11c74a2de4",
      "8119426c8705459fb9df8b2c711d3c36",
      "1e70f23ca6f94a2099c2cca1eaf875d8",
      "11b4409af40748e0b760e91c3d91ede7",
      "c82fa83594a349c991626ee55b8edfa4",
      "8348929b740242d3bdc73ea2c8bcd9c8",
      "2393e906e07e4e8ba661b0eafd2268e8",
      "b28b184f13a948d5995ee04720748871",
      "342e98cd2d99438d861d5c1cf54b573d",
      "e3e3c18ef96e48999e14be0c60ad9f04",
      "d85845466e5a4ffd8370ef4c8b965684",
      "5b84c1bb95354f939bc1918b5478cf08",
      "b2b6f74edcdb465e94d9f07287fa506d",
      "c6ae198ebaf2467bba3f0a49f3aab196",
      "5d95a7e842dc43d995b3ad5f0b61ae8f",
      "fec9b3f47668416f8709fd7ab80a9730",
      "4a0b61f58dfd4b2c88e7fe818c4de4b8",
      "bc7b5cd3163b4b60877d80be43598436",
      "bfc579b1c3354bcd9a0be2fde370954c",
      "ed22b18a21c943f291c6326030cb2753",
      "67bde4b1393e48a1a5c1b00969317131",
      "efbd298ec8f0461ba89793855901330b",
      "e6bdcb09b73d4aa3844076829cf43f8a",
      "ecac341937124f21b04479a50a05c688"
     ]
    },
    "id": "cMgM1supdxpw",
    "outputId": "6cd4f3a5-6a95-41ea-dd98-f45e528d9f5f"
   },
   "outputs": [],
   "source": [
    "# dataset_zh = load_dataset(\"xcopa\", \"zh\", ignore_verifications=True)\n",
    "# dataset_zh = preprocess_dataset(dataset_zh)\n",
    "# print(dataset_zh[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0w3ofGZC4Oi"
   },
   "source": [
    "Next, let's adapt our setup to the new language. We simply replace the English language adapter with the Chinese language adapter we already loaded previously. The task adapter we just trained is kept. Again, we set this architecture using `active_adapters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V04UntKfeK_z"
   },
   "outputs": [],
   "source": [
    "model.active_adapters = Stack(\"de\", \"disrpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9RAmZLzDk-j"
   },
   "source": [
    "Finally, let's see how well our adapter setup performs on the new language. We measure the zero-shot accuracy on the test split of the target language dataset. Evaluation is also performed using the built-in `Trainer` class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set training args for de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps=100,\n",
    "    output_dir=MODEL_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=de_train_dataset,\n",
    "    eval_dataset=de_valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2164\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1088\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1088' max='1088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1088/1088 15:46, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.300400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.497400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.156500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.995500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1088, training_loss=2.3000141732832966, metrics={'train_runtime': 947.9979, 'train_samples_per_second': 18.262, 'train_steps_per_second': 1.148, 'total_flos': 5420742729203712.0, 'train_loss': 2.3000141732832966, 'epoch': 8.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "CrW1cJyaeMox",
    "outputId": "f3f504c1-9518-4c21-e10f-b5202ae1c39f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 260\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.541905641555786,\n",
       " 'eval_acc': 0.2923076923076923,\n",
       " 'eval_runtime': 7.1326,\n",
       " 'eval_samples_per_second': 36.452,\n",
       " 'eval_steps_per_second': 4.627}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "eval_trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output\", remove_unused_columns=False,),\n",
    "    eval_dataset=de_test_dataset,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "eval_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "CrW1cJyaeMox",
    "outputId": "f3f504c1-9518-4c21-e10f-b5202ae1c39f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2155\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.1672592163085938,\n",
       " 'eval_acc': 0.20649651972157773,\n",
       " 'eval_runtime': 58.3581,\n",
       " 'eval_samples_per_second': 36.927,\n",
       " 'eval_steps_per_second': 4.627}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "eval_trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output_en\", remove_unused_columns=False,),\n",
    "    eval_dataset=en_test_dataset,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "eval_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op8M7AfYnWhs"
   },
   "source": [
    "You should get an overall accuracy of about 56 which is on-par with full finetuning on COPA only but below the state-of-the-art which is sequentially finetuned on an additional dataset before finetuning on COPA.\n",
    "\n",
    "For results on different languages and a sequential finetuning setup which yields better results, make sure to check out [the MAD-X paper](https://arxiv.org/pdf/2005.00052.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you mean to say that even the SOTAs struggle to match randomized baseline for Zh."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_Cross_Lingual_Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "adapters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "538362faa380fbb80ddcaf6d9f6913f6ed78cda1190d5a8d3f36f9cc39426106"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cb7dbc5b67469b8643c0ea3e6b3921": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f3bac44e13246ab9f9c8564a44e1fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e45676711b477e9a1ce2cf4ac8f3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "11b4409af40748e0b760e91c3d91ede7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28b184f13a948d5995ee04720748871",
      "placeholder": "​",
      "style": "IPY_MODEL_2393e906e07e4e8ba661b0eafd2268e8",
      "value": " 100/0 [00:00&lt;00:00, 1191.08 examples/s]"
     }
    },
    "12ec755bb33c4ff894644e291ce33040": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13829992bf994ec5bbec71684cc824e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ccbb12bb5a548488c9b646159f893d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e70f23ca6f94a2099c2cca1eaf875d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8348929b740242d3bdc73ea2c8bcd9c8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c82fa83594a349c991626ee55b8edfa4",
      "value": 1
     }
    },
    "21bd77c2c70040548a696c5a40d81a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac8b24c5d6214716a409ca95580306f5",
      "placeholder": "​",
      "style": "IPY_MODEL_932d3ee3c9d74761bfc4bcf5c003d205",
      "value": " 1/1 [00:10&lt;00:00, 10.75s/ba]"
     }
    },
    "2393e906e07e4e8ba661b0eafd2268e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "249abcb1904c4d1ca4116b677011b017": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12ec755bb33c4ff894644e291ce33040",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df292d721c1748c485f281aa2162b9a9",
      "value": 1
     }
    },
    "2a76413cb9cd4a6f901a8bef7dc70220": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c154bfdf049147638c67d2844d25f9e6",
       "IPY_MODEL_4fe615dff7104a018c48491fd711ed45"
      ],
      "layout": "IPY_MODEL_13829992bf994ec5bbec71684cc824e6"
     }
    },
    "2d964df49d71456093b427af2a3ac6cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "315cd377eae94488b258460f06e5cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02cb7dbc5b67469b8643c0ea3e6b3921",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a8c7ea6d7ec4ec691525f6e3ca88d48",
      "value": 1
     }
    },
    "342e98cd2d99438d861d5c1cf54b573d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d85845466e5a4ffd8370ef4c8b965684",
       "IPY_MODEL_5b84c1bb95354f939bc1918b5478cf08"
      ],
      "layout": "IPY_MODEL_e3e3c18ef96e48999e14be0c60ad9f04"
     }
    },
    "3bc11633e20c460eb9058cc4b480b224": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3ccf15d7bea44e9bb91b9b3d32b3c691": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a0b61f58dfd4b2c88e7fe818c4de4b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfc579b1c3354bcd9a0be2fde370954c",
       "IPY_MODEL_ed22b18a21c943f291c6326030cb2753"
      ],
      "layout": "IPY_MODEL_bc7b5cd3163b4b60877d80be43598436"
     }
    },
    "4a23a9bdd091425cbda38222f2e4c3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58b17e932dd74756b62fb7f6ed0d37ba",
      "placeholder": "​",
      "style": "IPY_MODEL_77583bbefaf849eea83d3ae327e4070e",
      "value": " 1/1 [00:00&lt;00:00,  2.51ba/s]"
     }
    },
    "4eac0e183d8047e498d3a576f3c3a1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fe615dff7104a018c48491fd711ed45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2423ca88827446aa5b5c78ccc36a263",
      "placeholder": "​",
      "style": "IPY_MODEL_527ea785de0a47f0ba5b0d0aea72cc97",
      "value": " 500/0 [00:00&lt;00:00, 2888.43 examples/s]"
     }
    },
    "525a5c1a8ba04c8e89fc514064539d73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527ea785de0a47f0ba5b0d0aea72cc97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5321f4576a6c4fe69de0c97b43269d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "568fedab4a4e44d9baa8213d54d60d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f512c5cdfaa64005bb987f032957e530",
      "placeholder": "​",
      "style": "IPY_MODEL_87c546c1a23c402f8a6de964828dc035",
      "value": " 28.2k/? [00:00&lt;00:00, 297kB/s]"
     }
    },
    "58b17e932dd74756b62fb7f6ed0d37ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b2e4c980b6a4e15bef86d1907b20f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d964df49d71456093b427af2a3ac6cc",
      "placeholder": "​",
      "style": "IPY_MODEL_3ccf15d7bea44e9bb91b9b3d32b3c691",
      "value": " 642k/? [00:00&lt;00:00, 3.06MB/s]"
     }
    },
    "5b84c1bb95354f939bc1918b5478cf08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fec9b3f47668416f8709fd7ab80a9730",
      "placeholder": "​",
      "style": "IPY_MODEL_5d95a7e842dc43d995b3ad5f0b61ae8f",
      "value": " 1/1 [00:00&lt;00:00,  2.28ba/s]"
     }
    },
    "5d95a7e842dc43d995b3ad5f0b61ae8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5df3d17d64e24faeab6cc644d333536a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f708ccdb4f941918696d583ad9bd9c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6025f45ce1af4c8caab09042992f2094": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "630597c0e70d4792b58c8942296692a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff7c6d1bfc654c2db63e40bad4e3eb33",
       "IPY_MODEL_f964d3d5333948e0b14117555b82275b"
      ],
      "layout": "IPY_MODEL_64e51ced10004147b21e51db1343cac8"
     }
    },
    "64e51ced10004147b21e51db1343cac8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67bde4b1393e48a1a5c1b00969317131": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71b51022c34247929dcb8f11c74a2de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e70f23ca6f94a2099c2cca1eaf875d8",
       "IPY_MODEL_11b4409af40748e0b760e91c3d91ede7"
      ],
      "layout": "IPY_MODEL_8119426c8705459fb9df8b2c711d3c36"
     }
    },
    "77583bbefaf849eea83d3ae327e4070e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a31bf9dedde47188efdfaf6a262b730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a718fb0db5640fd8eb04ef18fe1e339": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8119426c8705459fb9df8b2c711d3c36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8348929b740242d3bdc73ea2c8bcd9c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c546c1a23c402f8a6de964828dc035": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89f8555b95ec48b7b3282cb365b1cfdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb6e0c49bd040b7bd5f266c4608dd31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d88b67069074ee6bc937b46cc10418a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "932d3ee3c9d74761bfc4bcf5c003d205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9380ff7e78f846babb16740cfc9cf7f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f45f9a16f75e4d07abe5dcaf2fb300f4",
       "IPY_MODEL_21bd77c2c70040548a696c5a40d81a00"
      ],
      "layout": "IPY_MODEL_7a31bf9dedde47188efdfaf6a262b730"
     }
    },
    "949971635f1f498e86e04b9d4e28d353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9a8c7ea6d7ec4ec691525f6e3ca88d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9c8548e2e4c54bf88e678c571c537867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a3da9679c78640c3be6e7cbbd5bcccae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f3bac44e13246ab9f9c8564a44e1fa3",
      "placeholder": "​",
      "style": "IPY_MODEL_7a718fb0db5640fd8eb04ef18fe1e339",
      "value": " 1/1 [00:13&lt;00:00, 13.12s/ba]"
     }
    },
    "ac8b24c5d6214716a409ca95580306f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb9523d3e594c3d84036ad2348a7a64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e71f76432d5e469d8cf742bbed6e0f1c",
       "IPY_MODEL_a3da9679c78640c3be6e7cbbd5bcccae"
      ],
      "layout": "IPY_MODEL_8d88b67069074ee6bc937b46cc10418a"
     }
    },
    "aebd284cd0ba4dfbafce1f0b99cd5213": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28b184f13a948d5995ee04720748871": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2b6f74edcdb465e94d9f07287fa506d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bc7b5cd3163b4b60877d80be43598436": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfc579b1c3354bcd9a0be2fde370954c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efbd298ec8f0461ba89793855901330b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67bde4b1393e48a1a5c1b00969317131",
      "value": 1
     }
    },
    "c154bfdf049147638c67d2844d25f9e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f708ccdb4f941918696d583ad9bd9c9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bc11633e20c460eb9058cc4b480b224",
      "value": 1
     }
    },
    "c21fa18f6c4b4bdd9621ef29180646db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_249abcb1904c4d1ca4116b677011b017",
       "IPY_MODEL_4a23a9bdd091425cbda38222f2e4c3a9"
      ],
      "layout": "IPY_MODEL_fa8da5adaacd4534b60e51ba4dce6c4a"
     }
    },
    "c2423ca88827446aa5b5c78ccc36a263": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b64289fc4445f59a94d6c51a288834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ccbb12bb5a548488c9b646159f893d3",
      "max": 1750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6025f45ce1af4c8caab09042992f2094",
      "value": 1750
     }
    },
    "c515e4e9f5b7470e8a17e4a4247878f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4b64289fc4445f59a94d6c51a288834",
       "IPY_MODEL_568fedab4a4e44d9baa8213d54d60d38"
      ],
      "layout": "IPY_MODEL_89f8555b95ec48b7b3282cb365b1cfdd"
     }
    },
    "c6ae198ebaf2467bba3f0a49f3aab196": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82fa83594a349c991626ee55b8edfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d85845466e5a4ffd8370ef4c8b965684": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6ae198ebaf2467bba3f0a49f3aab196",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2b6f74edcdb465e94d9f07287fa506d",
      "value": 1
     }
    },
    "df292d721c1748c485f281aa2162b9a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e3e3c18ef96e48999e14be0c60ad9f04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6bdcb09b73d4aa3844076829cf43f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e71f76432d5e469d8cf742bbed6e0f1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cb6e0c49bd040b7bd5f266c4608dd31",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10e45676711b477e9a1ce2cf4ac8f3a9",
      "value": 1
     }
    },
    "ea780b89e28a4348abfac40ef8fd140a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_315cd377eae94488b258460f06e5cc10",
       "IPY_MODEL_5b2e4c980b6a4e15bef86d1907b20f40"
      ],
      "layout": "IPY_MODEL_4eac0e183d8047e498d3a576f3c3a1f4"
     }
    },
    "ecac341937124f21b04479a50a05c688": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed22b18a21c943f291c6326030cb2753": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecac341937124f21b04479a50a05c688",
      "placeholder": "​",
      "style": "IPY_MODEL_e6bdcb09b73d4aa3844076829cf43f8a",
      "value": " 1/1 [04:39&lt;00:00, 279.14s/ba]"
     }
    },
    "efbd298ec8f0461ba89793855901330b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f45f9a16f75e4d07abe5dcaf2fb300f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5321f4576a6c4fe69de0c97b43269d3b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c8548e2e4c54bf88e678c571c537867",
      "value": 1
     }
    },
    "f512c5cdfaa64005bb987f032957e530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f964d3d5333948e0b14117555b82275b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_525a5c1a8ba04c8e89fc514064539d73",
      "placeholder": "​",
      "style": "IPY_MODEL_5df3d17d64e24faeab6cc644d333536a",
      "value": " 4.89k/? [00:01&lt;00:00, 3.05kB/s]"
     }
    },
    "fa8da5adaacd4534b60e51ba4dce6c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fec9b3f47668416f8709fd7ab80a9730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7c6d1bfc654c2db63e40bad4e3eb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aebd284cd0ba4dfbafce1f0b99cd5213",
      "max": 1935,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_949971635f1f498e86e04b9d4e28d353",
      "value": 1935
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
