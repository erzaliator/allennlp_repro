{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2013\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "batch_size = 4\n",
    "batches_per_epoch = 110\n",
    "\n",
    "save_path_suffix = '20visualizeBertPooler_rand_deu2013_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'15': 1,\n",
       "         '1': 142,\n",
       "         '2': 41,\n",
       "         '3': 23,\n",
       "         '5': 9,\n",
       "         '6': 4,\n",
       "         '4': 10,\n",
       "         '7': 3,\n",
       "         '9': 3,\n",
       "         '12': 1,\n",
       "         '14': 1,\n",
       "         '8': 1,\n",
       "         '16': 1,\n",
       "         '10': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "Counter(val_df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label',\n",
       "       'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position',\n",
       "       'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case',\n",
       "       'unit2_case', 'u1_discontinuous', 'u2_discontinuous', 'same_speaker',\n",
       "       'lex_overlap_length', 'u1_func'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 13:36:15.153129: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 13:36:15.329650: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-12 13:36:15.329670: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 13:36:15.371810: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-12 13:36:16.278950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-12 13:36:16.279050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-12 13:36:16.279057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, ConcatDataset\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate, Vocabulary\n",
    "from features_custom2 import get_vocab_feature_name\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.vocab = Vocabulary(counter=None, max_vocab_size=100000)\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.init_feature_list()\n",
    "    self.init_feature_mappings_and_bins()\n",
    "    self.apply_bins()\n",
    "    self.calculate_unique_values()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    \n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def init_feature_mappings_and_bins(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "    self.bins = {\n",
    "      'distance': [[-1e9, -8], [-8, -2], [-2, 0], [0, 2], [2, 8], [8, 1e9]],\n",
    "      'u1_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'u2_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'lex_overlap_length': [[0, 2], [2, 7], [7, 1e9]]\n",
    "    }   \n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def init_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "    else: \n",
    "      raise ValueError()\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features_list(self, features, feature_name):\n",
    "    if feature_name in ['distance', 'u1_depdir', 'u2_depdir', 'u1_func', 'u2_func', \n",
    "    'u1_position', 'u2_position', 'genre', 'same_speaker', 'unit1_case', 'unit2_case',\n",
    "    'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'dir']: feature_value = self.apply_vocab(features[feature_name], feature_name) #for categorical values\n",
    "    elif feature_name in ['sat_children', 'nuc_children']: feature_value = float(features[feature_name]) #for identiy values\n",
    "    else: \n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    return feature_value\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==17\n",
    "    #after applying the vocab. we need to pass them as int\n",
    "    return {feature_name: torch.tensor(int(self.get_allen_features_list(features, feature_name))).to(device) for feature_name in self.feature_list+['dir']}\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature_name in self.feature_list+['dir']:\n",
    "      vocab_feature_name = get_vocab_feature_name(feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(train_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(val_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "\n",
    "  def apply_bins(self):\n",
    "    for df in [self.train_df, self.test_df, self.val_df]:\n",
    "      for feature_name in self.bins.keys():\n",
    "        df[feature_name] = df[feature_name].apply(lambda x: self.get_mapping_from_bin(feature_name, float(x)))\n",
    "\n",
    "  def get_mapping_from_bin(self, column_name, dict_val):\n",
    "    bins = self.bins[column_name]\n",
    "    for b,i in zip(bins, range(len(bins))):\n",
    "      left = b[0]\n",
    "      right = b[1]\n",
    "      if left<=dict_val and right>=dict_val: return i\n",
    "\n",
    "  def apply_vocab(self, feature_value, feature_name):\n",
    "    return self.vocab.get_token_index(str(feature_value), namespace=get_vocab_feature_name(feature_name))\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      features = {'distance': row['distance'],\n",
    "                'u1_depdir': row['u1_depdir'],\n",
    "                'u2_depdir': row['u2_depdir'],\n",
    "                'u1_func': row['u1_func'],\n",
    "                'u2_func': row['u2_func'],\n",
    "                'u1_position': row['u1_position'],\n",
    "                'u2_position': row['u2_position'],\n",
    "                'sat_children': row['sat_children'],\n",
    "                'nuc_children': row['nuc_children'],\n",
    "                'genre': row['genre'],\n",
    "                'unit1_case': row['unit1_case'],\n",
    "                'unit2_case': row['unit2_case'],\n",
    "                'u1_discontinuous': row['u1_discontinuous'],\n",
    "                'u2_discontinuous': row['u2_discontinuous'],\n",
    "                'same_speaker': row['same_speaker'],\n",
    "                'lex_overlap_length': row['lex_overlap_length'],\n",
    "                'dir': row['dir']}\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding=False) #padding='max_length'\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      features = self.transform_feature(features)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(features)\n",
    "      \n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "      \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "\n",
    "    class featureDataset(Dataset):\n",
    "      def __init__(self, token_ids, mask_ids, seg_ids, feats, y, idx):\n",
    "          self.token_ids = token_ids\n",
    "          self.mask_ids = mask_ids\n",
    "          self.seg_ids = seg_ids\n",
    "          self.feats = feats\n",
    "          self.y = y\n",
    "          self.idx = idx\n",
    "\n",
    "      def __len__(self):\n",
    "          return len(self.feats)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "          return self.token_ids[idx], self.mask_ids[idx], self.seg_ids[idx], self.feats[idx], self.y[idx], self.idx[idx]\n",
    "\n",
    "    dataset = featureDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '3': 2, '4': 3, '5': 4}\n",
      "u1_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_func :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'root': 2, 'conj': 3, 'advcl': 4, 'acl': 5, 'xcomp': 6, 'obl': 7, 'ccomp': 8, 'parataxis': 9, 'advmod': 10, 'dep': 11, 'csubj': 12, 'nmod': 13, 'punct': 14, 'cc': 15, 'appos': 16, 'aux': 17, 'obj': 18, 'iobj': 19, 'nsubj': 20, 'nsubj:pass': 21, 'csubj:pass': 22}\n",
      "u1_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '1': 11}\n",
      "u2_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '1': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
      "sat_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '4': 3, '1': 4, '2': 5, '3': 6, '5': 7, '6': 8}\n",
      "nuc_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '4': 2, '3': 3, '1': 4, '2': 5, '5': 6, '6': 7, '7': 8, '8': 9}\n",
      "dir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '1>2': 2, '1<2': 3}\n"
     ]
    }
   ],
   "source": [
    "for feature in mnli_dataset.feature_list:\n",
    "    vocab_feature_name = get_vocab_feature_name(feature)\n",
    "    print(feature, ': ', mnli_dataset.vocab.get_token_to_index_vocabulary(vocab_feature_name))\n",
    "print('dir', ': ', mnli_dataset.vocab.get_token_to_index_vocabulary('dir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    # assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    # assert mask_ids.shape[-1]==512\n",
    "    # assert seg_ids.shape[-1]==512\n",
    "    assert len(feat)==len(mnli_dataset.feature_list)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '@@PADDING@@', 1: '@@UNKNOWN@@'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_dataset.vocab.get_index_to_token_vocabulary('u1_depdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        if i not in idx_map.keys():\n",
    "          print(idx_map)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing FeaturefulBert: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing FeaturefulBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FeaturefulBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, Optional\n",
    "from transformers import BertModel, AutoTokenizer, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from featurefulbertembedder_custom2 import FeaturefulBertEmbedder\n",
    "from featureful_bert_custom2 import get_combined_feature_tensor_2 as get_combined_feature_tensor_forward\n",
    "from featureful_bert_custom2 import get_feature_modules\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class CustomPooler2(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                        requires_grad: bool = True,\n",
    "                        dropout: float = 0.0,\n",
    "                        randomize_weights: bool = False,\n",
    "                        transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "        super().__init__()\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL) #only used to pass config. BertAttentionClass used in FeatureFulBert\n",
    "        self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.pooler = copy.deepcopy(bert.pooler)\n",
    "        if randomize_weights:\n",
    "            print(self.pooler.dense.weight.shape)\n",
    "            self.pooler.dense.weight = nn.Parameter(torch.rand(self.pooler.dense.weight.shape))\n",
    "            self.pooler.dense.bias = nn.Parameter(torch.rand(self.pooler.dense.bias.shape))\n",
    "            print(self.pooler.dense.weight.shape)\n",
    "        for param in self.pooler.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        self._embedding_dim = bert.config.hidden_size\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "        pooler = self.pooler\n",
    "        \n",
    "        for _ in range(num_wrapping_dims):\n",
    "            pooler = TimeDistributed(pooler)\n",
    "        pooled = pooler(tokens)\n",
    "        pooled = self._dropout(pooled)\n",
    "        return pooled\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list, vocab):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_modules, self._feature_module_size = get_feature_modules(feature_list, vocab)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return get_combined_feature_tensor_forward(features, self.feature_list, self.feature_modules)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels, vocab):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels\n",
    "          self.feature_list = mnli_dataset.feature_list\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "\n",
    "          self.embedder = self.create_featureful_bert()\n",
    "          self.encoder = CustomPooler2()\n",
    "          self.module1 = MyModule(self.feature_list, vocab)\n",
    "          self.dropout1 = nn.Dropout(p=0.0)\n",
    "        #   self.dropout_decoder = nn.Dropout(p=0.5)\n",
    "          self._decoder_input_size = self.encoder._embedding_dim + self.module1._feature_module_size\n",
    "          self.relation_decoder = nn.Linear(self._decoder_input_size, self.num_classes)\n",
    "\n",
    "          self.history_w = {\n",
    "            'cos': [],\n",
    "            # 'l1_linear': [],\n",
    "            # 'l2': []\n",
    "          }\n",
    "          self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "          print(self.pooler_weight)\n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask, feat):\n",
    "        direction_tensor = feat['dir'].to(device)\n",
    "        embedded_sentence = self.embedder(token_ids=pair_token_ids, #featurefulmebedder\n",
    "                        mask=attention_mask, \n",
    "                        type_ids=token_type_ids,\n",
    "                        segment_concat_mask = None,\n",
    "                        direction_tensor = direction_tensor,\n",
    "                        feature_list = self.feature_list,\n",
    "                        features = feat)\n",
    "        mask = token_type_ids\n",
    "        bertpooler_output = self.encoder(tokens=embedded_sentence, mask=mask)\n",
    "        feat = self.convert_to_feature_list(feat)\n",
    "        feat = self.dropout1(feat)\n",
    "        feat = self.module1(feat)\n",
    "        # print(bertpooler_output.shape, self.module1._feature_module_size, feat.shape)\n",
    "        try:\n",
    "            feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "        except:\n",
    "            print(bertpooler_output.shape, feat.shape)\n",
    "            raise ValueError()\n",
    "        assert feat_concat.shape[-1] == self._decoder_input_size\n",
    "        feat_concat = self.dropout1(feat_concat)\n",
    "        # feat_concat = self.dropout_decoder(feat_concat)\n",
    "        linear1_output = self.relation_decoder(feat_concat)\n",
    "        return linear1_output\n",
    "\n",
    "    def compute_pooler_similarity(self):\n",
    "        cur = self.encoder.pooler.dense.weight\n",
    "        pre = self.pooler_weight\n",
    "        print(cur)\n",
    "        print(pre)\n",
    "        assert not torch.all(cur.eq(pre))\n",
    "        for metric in self.history_w.keys():\n",
    "            self.history_w[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "\n",
    "    def similarity(self, cur, pre, metric):\n",
    "        metric = 0\n",
    "        n = 0\n",
    "        for A, B in zip(cur.cpu().detach().numpy(), pre.cpu().detach().numpy()):\n",
    "            cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "            metric+= cosine\n",
    "            n+=1\n",
    "        return float(metric)/float(n), metric\n",
    "\n",
    "    def create_bert_without_activations(self):\n",
    "        config = BertConfig.from_pretrained(BERT_MODEL, hidden_act='gelu')\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "        return bert\n",
    "\n",
    "    def create_featureful_bert(self):\n",
    "        featureful_bert = FeaturefulBertEmbedder(model_name = BERT_MODEL,\n",
    "                                hidden_activation_allen = 'gelu',\n",
    "                                feature_list = self.feature_list, \n",
    "                                vocab=mnli_dataset.vocab)\n",
    "        return featureful_bert\n",
    "\n",
    "    def convert_to_feature_list(self, feat):\n",
    "        feature_linear = [feat[feature_name] for feature_name in self.feature_list]\n",
    "        feature_linear = torch.stack(feature_linear, dim=-1)\n",
    "        return feature_linear\n",
    "        \n",
    "\n",
    "model = CustomBERTModel(mnli_dataset.num_labels, mnli_dataset.vocab)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, correct_bias=False) # original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, mode='max', patience=35, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prinintg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomBERTModel(\n",
      "  (embedder): FeaturefulBertEmbedder(\n",
      "    (transformer_model): FeaturefulBert(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (feature_modules): ModuleDict(\n",
      "        (distance): Embedding(5, 3, padding_idx=0)\n",
      "        (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "        (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "        (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "        (sat_children): Identity()\n",
      "        (nuc_children): Identity()\n",
      "      )\n",
      "      (feature_projector): Linear(in_features=25, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): CustomPooler2(\n",
      "    (_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (module1): MyModule(\n",
      "    (feature_modules): ModuleDict(\n",
      "      (distance): Embedding(5, 3, padding_idx=0)\n",
      "      (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "      (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "      (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "      (sat_children): Identity()\n",
      "      (nuc_children): Identity()\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (relation_decoder): Linear(in_features=792, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n",
    "\n",
    "    model.compute_pooler_similarity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Best val_acc: 0.1148\n",
      "Epoch 1: Best val_acc: 0.1148\n",
      "Epoch 1: train_loss: 2.9731 train_acc: 0.1045 | val_loss: 2.7828 val_acc: 0.1148\n",
      "00:00:09.06\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0089,  0.0123,  ...,  0.0005, -0.0083, -0.0990],\n",
      "        [ 0.0133,  0.0063,  0.0169,  ..., -0.0027,  0.0091, -0.0128],\n",
      "        [-0.0173,  0.0165, -0.0047,  ...,  0.0201, -0.0203, -0.0039],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0160,  0.0059,  ...,  0.0082, -0.0017,  0.0124],\n",
      "        [ 0.0872, -0.0184,  0.0054,  ...,  0.0103, -0.0165,  0.0200],\n",
      "        [ 0.0240,  0.0019, -0.0042,  ...,  0.0064,  0.0228,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 2: Best val_acc: 0.2049\n",
      "Epoch 2: Best val_acc: 0.2049\n",
      "Epoch 2: train_loss: 2.6583 train_acc: 0.1795 | val_loss: 2.5461 val_acc: 0.2049\n",
      "00:00:08.45\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0088,  0.0128,  ...,  0.0005, -0.0082, -0.0991],\n",
      "        [ 0.0134,  0.0063,  0.0170,  ..., -0.0029,  0.0090, -0.0128],\n",
      "        [-0.0175,  0.0165, -0.0047,  ...,  0.0196, -0.0202, -0.0041],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0160,  0.0060,  ...,  0.0080, -0.0015,  0.0125],\n",
      "        [ 0.0872, -0.0184,  0.0053,  ...,  0.0106, -0.0165,  0.0198],\n",
      "        [ 0.0240,  0.0018, -0.0041,  ...,  0.0065,  0.0229,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0411,  0.0089,  0.0123,  ...,  0.0005, -0.0083, -0.0990],\n",
      "        [ 0.0133,  0.0063,  0.0169,  ..., -0.0027,  0.0091, -0.0128],\n",
      "        [-0.0173,  0.0165, -0.0047,  ...,  0.0201, -0.0203, -0.0039],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0160,  0.0059,  ...,  0.0082, -0.0017,  0.0124],\n",
      "        [ 0.0872, -0.0184,  0.0054,  ...,  0.0103, -0.0165,  0.0200],\n",
      "        [ 0.0240,  0.0019, -0.0042,  ...,  0.0064,  0.0228,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 3: train_loss: 2.5083 train_acc: 0.2409 | val_loss: 2.4527 val_acc: 0.1926\n",
      "00:00:07.35\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0092,  0.0129,  ...,  0.0005, -0.0083, -0.0989],\n",
      "        [ 0.0135,  0.0063,  0.0171,  ..., -0.0029,  0.0091, -0.0130],\n",
      "        [-0.0176,  0.0164, -0.0046,  ...,  0.0195, -0.0198, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0160,  0.0061,  ...,  0.0080, -0.0014,  0.0126],\n",
      "        [ 0.0871, -0.0183,  0.0053,  ...,  0.0107, -0.0165,  0.0196],\n",
      "        [ 0.0243,  0.0018, -0.0042,  ...,  0.0068,  0.0229,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0088,  0.0128,  ...,  0.0005, -0.0082, -0.0991],\n",
      "        [ 0.0134,  0.0063,  0.0170,  ..., -0.0029,  0.0090, -0.0128],\n",
      "        [-0.0175,  0.0165, -0.0047,  ...,  0.0196, -0.0202, -0.0041],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0160,  0.0060,  ...,  0.0080, -0.0015,  0.0125],\n",
      "        [ 0.0872, -0.0184,  0.0053,  ...,  0.0106, -0.0165,  0.0198],\n",
      "        [ 0.0240,  0.0018, -0.0041,  ...,  0.0065,  0.0229,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 4: Best val_acc: 0.3197\n",
      "Epoch 4: Best val_acc: 0.3197\n",
      "Epoch 4: train_loss: 2.4504 train_acc: 0.2750 | val_loss: 2.3369 val_acc: 0.3197\n",
      "00:00:09.00\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0091,  0.0131,  ...,  0.0003, -0.0083, -0.0988],\n",
      "        [ 0.0134,  0.0065,  0.0172,  ..., -0.0028,  0.0091, -0.0129],\n",
      "        [-0.0178,  0.0163, -0.0045,  ...,  0.0194, -0.0194, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0160,  0.0062,  ...,  0.0078, -0.0016,  0.0127],\n",
      "        [ 0.0870, -0.0183,  0.0053,  ...,  0.0107, -0.0163,  0.0196],\n",
      "        [ 0.0244,  0.0019, -0.0042,  ...,  0.0069,  0.0228,  0.0117]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0092,  0.0129,  ...,  0.0005, -0.0083, -0.0989],\n",
      "        [ 0.0135,  0.0063,  0.0171,  ..., -0.0029,  0.0091, -0.0130],\n",
      "        [-0.0176,  0.0164, -0.0046,  ...,  0.0195, -0.0198, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0160,  0.0061,  ...,  0.0080, -0.0014,  0.0126],\n",
      "        [ 0.0871, -0.0183,  0.0053,  ...,  0.0107, -0.0165,  0.0196],\n",
      "        [ 0.0243,  0.0018, -0.0042,  ...,  0.0068,  0.0229,  0.0116]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 5: train_loss: 2.1881 train_acc: 0.3477 | val_loss: 2.2936 val_acc: 0.2869\n",
      "00:00:07.42\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.1504e-02,  8.9615e-03,  1.3287e-02,  ..., -3.7067e-05,\n",
      "         -8.2128e-03, -9.8596e-02],\n",
      "        [ 1.3377e-02,  6.4616e-03,  1.7281e-02,  ..., -2.8558e-03,\n",
      "          9.2152e-03, -1.2800e-02],\n",
      "        [-1.7927e-02,  1.6329e-02, -4.6157e-03,  ...,  1.9310e-02,\n",
      "         -1.9272e-02, -4.2625e-03],\n",
      "        ...,\n",
      "        [ 1.5037e-02,  1.5982e-02,  6.1873e-03,  ...,  7.6056e-03,\n",
      "         -1.4803e-03,  1.2722e-02],\n",
      "        [ 8.7047e-02, -1.8282e-02,  5.3017e-03,  ...,  1.0767e-02,\n",
      "         -1.6336e-02,  1.9596e-02],\n",
      "        [ 2.4495e-02,  1.9224e-03, -4.3002e-03,  ...,  6.9973e-03,\n",
      "          2.2750e-02,  1.1739e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0091,  0.0131,  ...,  0.0003, -0.0083, -0.0988],\n",
      "        [ 0.0134,  0.0065,  0.0172,  ..., -0.0028,  0.0091, -0.0129],\n",
      "        [-0.0178,  0.0163, -0.0045,  ...,  0.0194, -0.0194, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0160,  0.0062,  ...,  0.0078, -0.0016,  0.0127],\n",
      "        [ 0.0870, -0.0183,  0.0053,  ...,  0.0107, -0.0163,  0.0196],\n",
      "        [ 0.0244,  0.0019, -0.0042,  ...,  0.0069,  0.0228,  0.0117]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 6: Best val_acc: 0.3402\n",
      "Epoch 6: Best val_acc: 0.3402\n",
      "Epoch 6: train_loss: 2.1982 train_acc: 0.3591 | val_loss: 2.1967 val_acc: 0.3402\n",
      "00:00:08.84\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.1388e-02,  8.7566e-03,  1.3159e-02,  ..., -8.2756e-05,\n",
      "         -8.3897e-03, -9.8340e-02],\n",
      "        [ 1.3315e-02,  6.4188e-03,  1.7342e-02,  ..., -2.9711e-03,\n",
      "          9.1533e-03, -1.2682e-02],\n",
      "        [-1.8020e-02,  1.6288e-02, -4.5227e-03,  ...,  1.9238e-02,\n",
      "         -1.9036e-02, -4.3056e-03],\n",
      "        ...,\n",
      "        [ 1.4955e-02,  1.5972e-02,  6.1430e-03,  ...,  7.5200e-03,\n",
      "         -1.4166e-03,  1.2787e-02],\n",
      "        [ 8.7054e-02, -1.8296e-02,  5.3802e-03,  ...,  1.0826e-02,\n",
      "         -1.6403e-02,  1.9508e-02],\n",
      "        [ 2.4475e-02,  1.9208e-03, -4.2119e-03,  ...,  7.0298e-03,\n",
      "          2.2784e-02,  1.1754e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.1504e-02,  8.9615e-03,  1.3287e-02,  ..., -3.7067e-05,\n",
      "         -8.2128e-03, -9.8596e-02],\n",
      "        [ 1.3377e-02,  6.4616e-03,  1.7281e-02,  ..., -2.8558e-03,\n",
      "          9.2152e-03, -1.2800e-02],\n",
      "        [-1.7927e-02,  1.6329e-02, -4.6157e-03,  ...,  1.9310e-02,\n",
      "         -1.9272e-02, -4.2625e-03],\n",
      "        ...,\n",
      "        [ 1.5037e-02,  1.5982e-02,  6.1873e-03,  ...,  7.6056e-03,\n",
      "         -1.4803e-03,  1.2722e-02],\n",
      "        [ 8.7047e-02, -1.8282e-02,  5.3017e-03,  ...,  1.0767e-02,\n",
      "         -1.6336e-02,  1.9596e-02],\n",
      "        [ 2.4495e-02,  1.9224e-03, -4.3002e-03,  ...,  6.9973e-03,\n",
      "          2.2750e-02,  1.1739e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 7: Best val_acc: 0.3402\n",
      "Epoch 7: train_loss: 2.1008 train_acc: 0.4023 | val_loss: 2.1732 val_acc: 0.3402\n",
      "00:00:08.61\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0089,  0.0130,  ..., -0.0001, -0.0083, -0.0981],\n",
      "        [ 0.0133,  0.0065,  0.0174,  ..., -0.0029,  0.0093, -0.0126],\n",
      "        [-0.0181,  0.0163, -0.0044,  ...,  0.0192, -0.0188, -0.0044],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0160,  0.0061,  ...,  0.0074, -0.0015,  0.0129],\n",
      "        [ 0.0870, -0.0183,  0.0054,  ...,  0.0109, -0.0163,  0.0194],\n",
      "        [ 0.0245,  0.0020, -0.0042,  ...,  0.0070,  0.0228,  0.0118]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.1388e-02,  8.7566e-03,  1.3159e-02,  ..., -8.2756e-05,\n",
      "         -8.3897e-03, -9.8340e-02],\n",
      "        [ 1.3315e-02,  6.4188e-03,  1.7342e-02,  ..., -2.9711e-03,\n",
      "          9.1533e-03, -1.2682e-02],\n",
      "        [-1.8020e-02,  1.6288e-02, -4.5227e-03,  ...,  1.9238e-02,\n",
      "         -1.9036e-02, -4.3056e-03],\n",
      "        ...,\n",
      "        [ 1.4955e-02,  1.5972e-02,  6.1430e-03,  ...,  7.5200e-03,\n",
      "         -1.4166e-03,  1.2787e-02],\n",
      "        [ 8.7054e-02, -1.8296e-02,  5.3802e-03,  ...,  1.0826e-02,\n",
      "         -1.6403e-02,  1.9508e-02],\n",
      "        [ 2.4475e-02,  1.9208e-03, -4.2119e-03,  ...,  7.0298e-03,\n",
      "          2.2784e-02,  1.1754e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 8: Best val_acc: 0.3689\n",
      "Epoch 8: Best val_acc: 0.3689\n",
      "Epoch 8: train_loss: 2.1423 train_acc: 0.3545 | val_loss: 2.1202 val_acc: 0.3689\n",
      "00:00:09.28\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.1125e-02,  8.8484e-03,  1.3007e-02,  ..., -2.9454e-05,\n",
      "         -8.3298e-03, -9.8113e-02],\n",
      "        [ 1.3357e-02,  6.5911e-03,  1.7460e-02,  ..., -2.8235e-03,\n",
      "          9.1920e-03, -1.2551e-02],\n",
      "        [-1.8308e-02,  1.6272e-02, -4.4152e-03,  ...,  1.9044e-02,\n",
      "         -1.8545e-02, -4.5508e-03],\n",
      "        ...,\n",
      "        [ 1.4807e-02,  1.5961e-02,  6.1956e-03,  ...,  7.3198e-03,\n",
      "         -1.5230e-03,  1.2863e-02],\n",
      "        [ 8.7009e-02, -1.8208e-02,  5.4318e-03,  ...,  1.0837e-02,\n",
      "         -1.6301e-02,  1.9415e-02],\n",
      "        [ 2.4474e-02,  1.9169e-03, -4.2523e-03,  ...,  7.0502e-03,\n",
      "          2.2770e-02,  1.1785e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0089,  0.0130,  ..., -0.0001, -0.0083, -0.0981],\n",
      "        [ 0.0133,  0.0065,  0.0174,  ..., -0.0029,  0.0093, -0.0126],\n",
      "        [-0.0181,  0.0163, -0.0044,  ...,  0.0192, -0.0188, -0.0044],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0160,  0.0061,  ...,  0.0074, -0.0015,  0.0129],\n",
      "        [ 0.0870, -0.0183,  0.0054,  ...,  0.0109, -0.0163,  0.0194],\n",
      "        [ 0.0245,  0.0020, -0.0042,  ...,  0.0070,  0.0228,  0.0118]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 9: Best val_acc: 0.3730\n",
      "Epoch 9: Best val_acc: 0.3730\n",
      "Epoch 9: train_loss: 2.0637 train_acc: 0.3955 | val_loss: 2.1332 val_acc: 0.3730\n",
      "00:00:08.99\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0087,  0.0130,  ..., -0.0001, -0.0083, -0.0981],\n",
      "        [ 0.0133,  0.0066,  0.0174,  ..., -0.0029,  0.0092, -0.0124],\n",
      "        [-0.0185,  0.0164, -0.0045,  ...,  0.0190, -0.0185, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0160,  0.0062,  ...,  0.0072, -0.0016,  0.0129],\n",
      "        [ 0.0870, -0.0181,  0.0054,  ...,  0.0109, -0.0163,  0.0195],\n",
      "        [ 0.0246,  0.0020, -0.0043,  ...,  0.0071,  0.0226,  0.0119]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.1125e-02,  8.8484e-03,  1.3007e-02,  ..., -2.9454e-05,\n",
      "         -8.3298e-03, -9.8113e-02],\n",
      "        [ 1.3357e-02,  6.5911e-03,  1.7460e-02,  ..., -2.8235e-03,\n",
      "          9.1920e-03, -1.2551e-02],\n",
      "        [-1.8308e-02,  1.6272e-02, -4.4152e-03,  ...,  1.9044e-02,\n",
      "         -1.8545e-02, -4.5508e-03],\n",
      "        ...,\n",
      "        [ 1.4807e-02,  1.5961e-02,  6.1956e-03,  ...,  7.3198e-03,\n",
      "         -1.5230e-03,  1.2863e-02],\n",
      "        [ 8.7009e-02, -1.8208e-02,  5.4318e-03,  ...,  1.0837e-02,\n",
      "         -1.6301e-02,  1.9415e-02],\n",
      "        [ 2.4474e-02,  1.9169e-03, -4.2523e-03,  ...,  7.0502e-03,\n",
      "          2.2770e-02,  1.1785e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 10: Best val_acc: 0.3770\n",
      "Epoch 10: Best val_acc: 0.3770\n",
      "Epoch 10: train_loss: 1.7947 train_acc: 0.5227 | val_loss: 2.0966 val_acc: 0.3770\n",
      "00:00:09.03\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0087,  0.0131,  ..., -0.0002, -0.0083, -0.0980],\n",
      "        [ 0.0133,  0.0067,  0.0175,  ..., -0.0028,  0.0092, -0.0123],\n",
      "        [-0.0186,  0.0164, -0.0045,  ...,  0.0190, -0.0184, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0160,  0.0062,  ...,  0.0071, -0.0016,  0.0130],\n",
      "        [ 0.0870, -0.0180,  0.0055,  ...,  0.0109, -0.0163,  0.0194],\n",
      "        [ 0.0246,  0.0021, -0.0044,  ...,  0.0072,  0.0225,  0.0120]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0412,  0.0087,  0.0130,  ..., -0.0001, -0.0083, -0.0981],\n",
      "        [ 0.0133,  0.0066,  0.0174,  ..., -0.0029,  0.0092, -0.0124],\n",
      "        [-0.0185,  0.0164, -0.0045,  ...,  0.0190, -0.0185, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0160,  0.0062,  ...,  0.0072, -0.0016,  0.0129],\n",
      "        [ 0.0870, -0.0181,  0.0054,  ...,  0.0109, -0.0163,  0.0195],\n",
      "        [ 0.0246,  0.0020, -0.0043,  ...,  0.0071,  0.0226,  0.0119]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 11: Best val_acc: 0.3770\n",
      "Epoch 11: train_loss: 1.8662 train_acc: 0.5000 | val_loss: 2.0558 val_acc: 0.3770\n",
      "00:00:08.45\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0088,  0.0130,  ..., -0.0002, -0.0083, -0.0979],\n",
      "        [ 0.0131,  0.0067,  0.0176,  ..., -0.0028,  0.0092, -0.0122],\n",
      "        [-0.0187,  0.0165, -0.0045,  ...,  0.0189, -0.0184, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0159,  0.0062,  ...,  0.0069, -0.0015,  0.0129],\n",
      "        [ 0.0871, -0.0179,  0.0054,  ...,  0.0110, -0.0163,  0.0194],\n",
      "        [ 0.0246,  0.0020, -0.0043,  ...,  0.0072,  0.0226,  0.0120]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0087,  0.0131,  ..., -0.0002, -0.0083, -0.0980],\n",
      "        [ 0.0133,  0.0067,  0.0175,  ..., -0.0028,  0.0092, -0.0123],\n",
      "        [-0.0186,  0.0164, -0.0045,  ...,  0.0190, -0.0184, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0148,  0.0160,  0.0062,  ...,  0.0071, -0.0016,  0.0130],\n",
      "        [ 0.0870, -0.0180,  0.0055,  ...,  0.0109, -0.0163,  0.0194],\n",
      "        [ 0.0246,  0.0021, -0.0044,  ...,  0.0072,  0.0225,  0.0120]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 12: train_loss: 1.8069 train_acc: 0.4682 | val_loss: 2.0607 val_acc: 0.3648\n",
      "00:00:07.22\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0086,  0.0129,  ..., -0.0002, -0.0083, -0.0979],\n",
      "        [ 0.0131,  0.0067,  0.0176,  ..., -0.0028,  0.0092, -0.0122],\n",
      "        [-0.0187,  0.0165, -0.0044,  ...,  0.0189, -0.0181, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0160,  0.0062,  ...,  0.0068, -0.0015,  0.0130],\n",
      "        [ 0.0871, -0.0180,  0.0054,  ...,  0.0111, -0.0164,  0.0194],\n",
      "        [ 0.0246,  0.0021, -0.0043,  ...,  0.0072,  0.0226,  0.0121]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0088,  0.0130,  ..., -0.0002, -0.0083, -0.0979],\n",
      "        [ 0.0131,  0.0067,  0.0176,  ..., -0.0028,  0.0092, -0.0122],\n",
      "        [-0.0187,  0.0165, -0.0045,  ...,  0.0189, -0.0184, -0.0045],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0159,  0.0062,  ...,  0.0069, -0.0015,  0.0129],\n",
      "        [ 0.0871, -0.0179,  0.0054,  ...,  0.0110, -0.0163,  0.0194],\n",
      "        [ 0.0246,  0.0020, -0.0043,  ...,  0.0072,  0.0226,  0.0120]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 13: train_loss: 1.8267 train_acc: 0.4909 | val_loss: 2.0523 val_acc: 0.3689\n",
      "00:00:07.48\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0086,  0.0129,  ..., -0.0003, -0.0083, -0.0979],\n",
      "        [ 0.0130,  0.0067,  0.0176,  ..., -0.0027,  0.0092, -0.0121],\n",
      "        [-0.0188,  0.0164, -0.0043,  ...,  0.0188, -0.0179, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0160,  0.0061,  ...,  0.0068, -0.0015,  0.0129],\n",
      "        [ 0.0872, -0.0180,  0.0054,  ...,  0.0111, -0.0164,  0.0195],\n",
      "        [ 0.0247,  0.0021, -0.0044,  ...,  0.0073,  0.0226,  0.0122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0086,  0.0129,  ..., -0.0002, -0.0083, -0.0979],\n",
      "        [ 0.0131,  0.0067,  0.0176,  ..., -0.0028,  0.0092, -0.0122],\n",
      "        [-0.0187,  0.0165, -0.0044,  ...,  0.0189, -0.0181, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0160,  0.0062,  ...,  0.0068, -0.0015,  0.0130],\n",
      "        [ 0.0871, -0.0180,  0.0054,  ...,  0.0111, -0.0164,  0.0194],\n",
      "        [ 0.0246,  0.0021, -0.0043,  ...,  0.0072,  0.0226,  0.0121]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 14: train_loss: 1.7338 train_acc: 0.4841 | val_loss: 2.0016 val_acc: 0.3730\n",
      "00:00:07.59\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0130,  ..., -0.0002, -0.0084, -0.0979],\n",
      "        [ 0.0130,  0.0068,  0.0177,  ..., -0.0026,  0.0092, -0.0121],\n",
      "        [-0.0190,  0.0164, -0.0042,  ...,  0.0187, -0.0178, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0159,  0.0061,  ...,  0.0068, -0.0015,  0.0129],\n",
      "        [ 0.0871, -0.0179,  0.0054,  ...,  0.0112, -0.0164,  0.0195],\n",
      "        [ 0.0247,  0.0021, -0.0045,  ...,  0.0073,  0.0226,  0.0122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0086,  0.0129,  ..., -0.0003, -0.0083, -0.0979],\n",
      "        [ 0.0130,  0.0067,  0.0176,  ..., -0.0027,  0.0092, -0.0121],\n",
      "        [-0.0188,  0.0164, -0.0043,  ...,  0.0188, -0.0179, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0160,  0.0061,  ...,  0.0068, -0.0015,  0.0129],\n",
      "        [ 0.0872, -0.0180,  0.0054,  ...,  0.0111, -0.0164,  0.0195],\n",
      "        [ 0.0247,  0.0021, -0.0044,  ...,  0.0073,  0.0226,  0.0122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 15: Best val_acc: 0.3770\n",
      "Epoch 15: train_loss: 1.4698 train_acc: 0.6477 | val_loss: 2.0024 val_acc: 0.3770\n",
      "00:00:07.87\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0086,  0.0131,  ..., -0.0002, -0.0084, -0.0978],\n",
      "        [ 0.0129,  0.0068,  0.0178,  ..., -0.0026,  0.0093, -0.0120],\n",
      "        [-0.0191,  0.0165, -0.0043,  ...,  0.0188, -0.0177, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0159,  0.0060,  ...,  0.0067, -0.0015,  0.0130],\n",
      "        [ 0.0871, -0.0178,  0.0055,  ...,  0.0113, -0.0165,  0.0195],\n",
      "        [ 0.0247,  0.0021, -0.0046,  ...,  0.0074,  0.0226,  0.0122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0130,  ..., -0.0002, -0.0084, -0.0979],\n",
      "        [ 0.0130,  0.0068,  0.0177,  ..., -0.0026,  0.0092, -0.0121],\n",
      "        [-0.0190,  0.0164, -0.0042,  ...,  0.0187, -0.0178, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0159,  0.0061,  ...,  0.0068, -0.0015,  0.0129],\n",
      "        [ 0.0871, -0.0179,  0.0054,  ...,  0.0112, -0.0164,  0.0195],\n",
      "        [ 0.0247,  0.0021, -0.0045,  ...,  0.0073,  0.0226,  0.0122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 16: Best val_acc: 0.3975\n",
      "Epoch 16: Best val_acc: 0.3975\n",
      "Epoch 16: train_loss: 1.4810 train_acc: 0.5886 | val_loss: 1.9776 val_acc: 0.3975\n",
      "00:00:08.57\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0418,  0.0085,  0.0131,  ..., -0.0001, -0.0083, -0.0977],\n",
      "        [ 0.0128,  0.0068,  0.0177,  ..., -0.0026,  0.0093, -0.0120],\n",
      "        [-0.0192,  0.0165, -0.0042,  ...,  0.0188, -0.0176, -0.0048],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0159,  0.0059,  ...,  0.0066, -0.0015,  0.0129],\n",
      "        [ 0.0872, -0.0178,  0.0054,  ...,  0.0113, -0.0165,  0.0195],\n",
      "        [ 0.0247,  0.0022, -0.0046,  ...,  0.0075,  0.0226,  0.0122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0416,  0.0086,  0.0131,  ..., -0.0002, -0.0084, -0.0978],\n",
      "        [ 0.0129,  0.0068,  0.0178,  ..., -0.0026,  0.0093, -0.0120],\n",
      "        [-0.0191,  0.0165, -0.0043,  ...,  0.0188, -0.0177, -0.0047],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0159,  0.0060,  ...,  0.0067, -0.0015,  0.0130],\n",
      "        [ 0.0871, -0.0178,  0.0055,  ...,  0.0113, -0.0165,  0.0195],\n",
      "        [ 0.0247,  0.0021, -0.0046,  ...,  0.0074,  0.0226,  0.0122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 17: train_loss: 1.5574 train_acc: 0.5636 | val_loss: 2.0000 val_acc: 0.3934\n",
      "00:00:07.44\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0419,  0.0084,  0.0131,  ..., -0.0001, -0.0082, -0.0977],\n",
      "        [ 0.0128,  0.0068,  0.0177,  ..., -0.0024,  0.0094, -0.0119],\n",
      "        [-0.0192,  0.0165, -0.0042,  ...,  0.0188, -0.0174, -0.0049],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0159,  0.0059,  ...,  0.0066, -0.0015,  0.0130],\n",
      "        [ 0.0872, -0.0177,  0.0054,  ...,  0.0113, -0.0166,  0.0195],\n",
      "        [ 0.0248,  0.0022, -0.0047,  ...,  0.0076,  0.0226,  0.0123]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0418,  0.0085,  0.0131,  ..., -0.0001, -0.0083, -0.0977],\n",
      "        [ 0.0128,  0.0068,  0.0177,  ..., -0.0026,  0.0093, -0.0120],\n",
      "        [-0.0192,  0.0165, -0.0042,  ...,  0.0188, -0.0176, -0.0048],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0159,  0.0059,  ...,  0.0066, -0.0015,  0.0129],\n",
      "        [ 0.0872, -0.0178,  0.0054,  ...,  0.0113, -0.0165,  0.0195],\n",
      "        [ 0.0247,  0.0022, -0.0046,  ...,  0.0075,  0.0226,  0.0122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 18: train_loss: 1.3929 train_acc: 0.6114 | val_loss: 1.9596 val_acc: 0.3934\n",
      "00:00:07.48\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0420,  0.0083,  0.0131,  ..., -0.0002, -0.0082, -0.0977],\n",
      "        [ 0.0128,  0.0068,  0.0177,  ..., -0.0025,  0.0094, -0.0119],\n",
      "        [-0.0193,  0.0165, -0.0042,  ...,  0.0187, -0.0173, -0.0050],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0159,  0.0059,  ...,  0.0064, -0.0015,  0.0130],\n",
      "        [ 0.0873, -0.0177,  0.0054,  ...,  0.0113, -0.0166,  0.0195],\n",
      "        [ 0.0248,  0.0022, -0.0047,  ...,  0.0076,  0.0226,  0.0123]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0419,  0.0084,  0.0131,  ..., -0.0001, -0.0082, -0.0977],\n",
      "        [ 0.0128,  0.0068,  0.0177,  ..., -0.0024,  0.0094, -0.0119],\n",
      "        [-0.0192,  0.0165, -0.0042,  ...,  0.0188, -0.0174, -0.0049],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0159,  0.0059,  ...,  0.0066, -0.0015,  0.0130],\n",
      "        [ 0.0872, -0.0177,  0.0054,  ...,  0.0113, -0.0166,  0.0195],\n",
      "        [ 0.0248,  0.0022, -0.0047,  ...,  0.0076,  0.0226,  0.0123]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 19: train_loss: 1.4005 train_acc: 0.6068 | val_loss: 1.9440 val_acc: 0.3893\n",
      "00:00:07.30\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0422,  0.0082,  0.0132,  ..., -0.0002, -0.0081, -0.0977],\n",
      "        [ 0.0128,  0.0069,  0.0177,  ..., -0.0025,  0.0094, -0.0118],\n",
      "        [-0.0195,  0.0164, -0.0042,  ...,  0.0188, -0.0172, -0.0051],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0159,  0.0059,  ...,  0.0063, -0.0015,  0.0130],\n",
      "        [ 0.0873, -0.0176,  0.0053,  ...,  0.0114, -0.0167,  0.0195],\n",
      "        [ 0.0249,  0.0022, -0.0047,  ...,  0.0076,  0.0225,  0.0123]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0420,  0.0083,  0.0131,  ..., -0.0002, -0.0082, -0.0977],\n",
      "        [ 0.0128,  0.0068,  0.0177,  ..., -0.0025,  0.0094, -0.0119],\n",
      "        [-0.0193,  0.0165, -0.0042,  ...,  0.0187, -0.0173, -0.0050],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0159,  0.0059,  ...,  0.0064, -0.0015,  0.0130],\n",
      "        [ 0.0873, -0.0177,  0.0054,  ...,  0.0113, -0.0166,  0.0195],\n",
      "        [ 0.0248,  0.0022, -0.0047,  ...,  0.0076,  0.0226,  0.0123]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 20: train_loss: 1.1660 train_acc: 0.7295 | val_loss: 1.9692 val_acc: 0.3730\n",
      "00:00:06.91\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0423,  0.0083,  0.0132,  ..., -0.0002, -0.0081, -0.0977],\n",
      "        [ 0.0127,  0.0069,  0.0177,  ..., -0.0024,  0.0094, -0.0118],\n",
      "        [-0.0196,  0.0164, -0.0042,  ...,  0.0187, -0.0171, -0.0052],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0159,  0.0059,  ...,  0.0063, -0.0014,  0.0131],\n",
      "        [ 0.0874, -0.0176,  0.0054,  ...,  0.0114, -0.0167,  0.0194],\n",
      "        [ 0.0249,  0.0023, -0.0048,  ...,  0.0076,  0.0225,  0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0422,  0.0082,  0.0132,  ..., -0.0002, -0.0081, -0.0977],\n",
      "        [ 0.0128,  0.0069,  0.0177,  ..., -0.0025,  0.0094, -0.0118],\n",
      "        [-0.0195,  0.0164, -0.0042,  ...,  0.0188, -0.0172, -0.0051],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0159,  0.0059,  ...,  0.0063, -0.0015,  0.0130],\n",
      "        [ 0.0873, -0.0176,  0.0053,  ...,  0.0114, -0.0167,  0.0195],\n",
      "        [ 0.0249,  0.0022, -0.0047,  ...,  0.0076,  0.0225,  0.0123]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 21: train_loss: 1.2396 train_acc: 0.6705 | val_loss: 2.0165 val_acc: 0.3811\n",
      "00:00:07.11\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0424,  0.0083,  0.0132,  ..., -0.0001, -0.0080, -0.0975],\n",
      "        [ 0.0128,  0.0070,  0.0178,  ..., -0.0024,  0.0095, -0.0118],\n",
      "        [-0.0198,  0.0164, -0.0042,  ...,  0.0186, -0.0169, -0.0052],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0159,  0.0060,  ...,  0.0062, -0.0015,  0.0131],\n",
      "        [ 0.0875, -0.0176,  0.0054,  ...,  0.0114, -0.0167,  0.0195],\n",
      "        [ 0.0249,  0.0023, -0.0047,  ...,  0.0077,  0.0226,  0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0423,  0.0083,  0.0132,  ..., -0.0002, -0.0081, -0.0977],\n",
      "        [ 0.0127,  0.0069,  0.0177,  ..., -0.0024,  0.0094, -0.0118],\n",
      "        [-0.0196,  0.0164, -0.0042,  ...,  0.0187, -0.0171, -0.0052],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0159,  0.0059,  ...,  0.0063, -0.0014,  0.0131],\n",
      "        [ 0.0874, -0.0176,  0.0054,  ...,  0.0114, -0.0167,  0.0194],\n",
      "        [ 0.0249,  0.0023, -0.0048,  ...,  0.0076,  0.0225,  0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 22: train_loss: 1.1483 train_acc: 0.7227 | val_loss: 1.9634 val_acc: 0.3934\n",
      "00:00:08.57\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0425,  0.0083,  0.0132,  ..., -0.0002, -0.0080, -0.0974],\n",
      "        [ 0.0127,  0.0070,  0.0178,  ..., -0.0024,  0.0095, -0.0117],\n",
      "        [-0.0198,  0.0165, -0.0041,  ...,  0.0187, -0.0169, -0.0053],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0159,  0.0060,  ...,  0.0061, -0.0015,  0.0131],\n",
      "        [ 0.0876, -0.0175,  0.0053,  ...,  0.0115, -0.0168,  0.0195],\n",
      "        [ 0.0249,  0.0023, -0.0047,  ...,  0.0078,  0.0226,  0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0424,  0.0083,  0.0132,  ..., -0.0001, -0.0080, -0.0975],\n",
      "        [ 0.0128,  0.0070,  0.0178,  ..., -0.0024,  0.0095, -0.0118],\n",
      "        [-0.0198,  0.0164, -0.0042,  ...,  0.0186, -0.0169, -0.0052],\n",
      "        ...,\n",
      "        [ 0.0144,  0.0159,  0.0060,  ...,  0.0062, -0.0015,  0.0131],\n",
      "        [ 0.0875, -0.0176,  0.0054,  ...,  0.0114, -0.0167,  0.0195],\n",
      "        [ 0.0249,  0.0023, -0.0047,  ...,  0.0077,  0.0226,  0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 23: train_loss: 1.2062 train_acc: 0.6909 | val_loss: 2.0181 val_acc: 0.3689\n",
      "00:00:08.39\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0426,  0.0083,  0.0132,  ..., -0.0001, -0.0081, -0.0974],\n",
      "        [ 0.0127,  0.0069,  0.0178,  ..., -0.0024,  0.0094, -0.0116],\n",
      "        [-0.0199,  0.0166, -0.0041,  ...,  0.0187, -0.0167, -0.0054],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0159,  0.0060,  ...,  0.0060, -0.0015,  0.0131],\n",
      "        [ 0.0876, -0.0174,  0.0053,  ...,  0.0115, -0.0168,  0.0195],\n",
      "        [ 0.0249,  0.0023, -0.0047,  ...,  0.0078,  0.0226,  0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0425,  0.0083,  0.0132,  ..., -0.0002, -0.0080, -0.0974],\n",
      "        [ 0.0127,  0.0070,  0.0178,  ..., -0.0024,  0.0095, -0.0117],\n",
      "        [-0.0198,  0.0165, -0.0041,  ...,  0.0187, -0.0169, -0.0053],\n",
      "        ...,\n",
      "        [ 0.0142,  0.0159,  0.0060,  ...,  0.0061, -0.0015,  0.0131],\n",
      "        [ 0.0876, -0.0175,  0.0053,  ...,  0.0115, -0.0168,  0.0195],\n",
      "        [ 0.0249,  0.0023, -0.0047,  ...,  0.0078,  0.0226,  0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 24: train_loss: 1.0475 train_acc: 0.7455 | val_loss: 2.0142 val_acc: 0.3730\n",
      "00:00:09.51\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0427,  0.0082,  0.0131,  ..., -0.0001, -0.0081, -0.0974],\n",
      "        [ 0.0127,  0.0069,  0.0178,  ..., -0.0023,  0.0094, -0.0116],\n",
      "        [-0.0199,  0.0166, -0.0041,  ...,  0.0187, -0.0166, -0.0054],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0160,  0.0060,  ...,  0.0060, -0.0015,  0.0131],\n",
      "        [ 0.0875, -0.0174,  0.0052,  ...,  0.0115, -0.0168,  0.0195],\n",
      "        [ 0.0249,  0.0024, -0.0047,  ...,  0.0079,  0.0226,  0.0125]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0426,  0.0083,  0.0132,  ..., -0.0001, -0.0081, -0.0974],\n",
      "        [ 0.0127,  0.0069,  0.0178,  ..., -0.0024,  0.0094, -0.0116],\n",
      "        [-0.0199,  0.0166, -0.0041,  ...,  0.0187, -0.0167, -0.0054],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0159,  0.0060,  ...,  0.0060, -0.0015,  0.0131],\n",
      "        [ 0.0876, -0.0174,  0.0053,  ...,  0.0115, -0.0168,  0.0195],\n",
      "        [ 0.0249,  0.0023, -0.0047,  ...,  0.0078,  0.0226,  0.0124]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 25: train_loss: 0.9367 train_acc: 0.7545 | val_loss: 2.0679 val_acc: 0.3607\n",
      "00:00:08.06\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2703e-02,  8.1386e-03,  1.3162e-02,  ..., -2.1898e-05,\n",
      "         -8.0748e-03, -9.7340e-02],\n",
      "        [ 1.2650e-02,  6.8350e-03,  1.7862e-02,  ..., -2.2664e-03,\n",
      "          9.3511e-03, -1.1445e-02],\n",
      "        [-1.9940e-02,  1.6651e-02, -4.0479e-03,  ...,  1.8702e-02,\n",
      "         -1.6545e-02, -5.4748e-03],\n",
      "        ...,\n",
      "        [ 1.4038e-02,  1.5979e-02,  5.9741e-03,  ...,  5.9088e-03,\n",
      "         -1.4521e-03,  1.3136e-02],\n",
      "        [ 8.7538e-02, -1.7317e-02,  5.2353e-03,  ...,  1.1518e-02,\n",
      "         -1.6918e-02,  1.9483e-02],\n",
      "        [ 2.4908e-02,  2.3912e-03, -4.7208e-03,  ...,  7.8532e-03,\n",
      "          2.2487e-02,  1.2495e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0427,  0.0082,  0.0131,  ..., -0.0001, -0.0081, -0.0974],\n",
      "        [ 0.0127,  0.0069,  0.0178,  ..., -0.0023,  0.0094, -0.0116],\n",
      "        [-0.0199,  0.0166, -0.0041,  ...,  0.0187, -0.0166, -0.0054],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0160,  0.0060,  ...,  0.0060, -0.0015,  0.0131],\n",
      "        [ 0.0875, -0.0174,  0.0052,  ...,  0.0115, -0.0168,  0.0195],\n",
      "        [ 0.0249,  0.0024, -0.0047,  ...,  0.0079,  0.0226,  0.0125]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 26: train_loss: 0.9106 train_acc: 0.7841 | val_loss: 2.0475 val_acc: 0.3689\n",
      "00:00:07.44\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2770e-02,  8.0448e-03,  1.3229e-02,  ...,  4.0212e-06,\n",
      "         -8.0243e-03, -9.7339e-02],\n",
      "        [ 1.2629e-02,  6.8063e-03,  1.7863e-02,  ..., -2.1841e-03,\n",
      "          9.3207e-03, -1.1366e-02],\n",
      "        [-2.0012e-02,  1.6684e-02, -4.0658e-03,  ...,  1.8698e-02,\n",
      "         -1.6418e-02, -5.5166e-03],\n",
      "        ...,\n",
      "        [ 1.3968e-02,  1.5974e-02,  5.9614e-03,  ...,  5.7876e-03,\n",
      "         -1.4177e-03,  1.3142e-02],\n",
      "        [ 8.7548e-02, -1.7265e-02,  5.2658e-03,  ...,  1.1553e-02,\n",
      "         -1.6979e-02,  1.9480e-02],\n",
      "        [ 2.4934e-02,  2.3937e-03, -4.7597e-03,  ...,  7.8462e-03,\n",
      "          2.2490e-02,  1.2557e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2703e-02,  8.1386e-03,  1.3162e-02,  ..., -2.1898e-05,\n",
      "         -8.0748e-03, -9.7340e-02],\n",
      "        [ 1.2650e-02,  6.8350e-03,  1.7862e-02,  ..., -2.2664e-03,\n",
      "          9.3511e-03, -1.1445e-02],\n",
      "        [-1.9940e-02,  1.6651e-02, -4.0479e-03,  ...,  1.8702e-02,\n",
      "         -1.6545e-02, -5.4748e-03],\n",
      "        ...,\n",
      "        [ 1.4038e-02,  1.5979e-02,  5.9741e-03,  ...,  5.9088e-03,\n",
      "         -1.4521e-03,  1.3136e-02],\n",
      "        [ 8.7538e-02, -1.7317e-02,  5.2353e-03,  ...,  1.1518e-02,\n",
      "         -1.6918e-02,  1.9483e-02],\n",
      "        [ 2.4908e-02,  2.3912e-03, -4.7208e-03,  ...,  7.8532e-03,\n",
      "          2.2487e-02,  1.2495e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 27: train_loss: 0.9415 train_acc: 0.7682 | val_loss: 2.0412 val_acc: 0.3811\n",
      "00:00:08.28\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2864e-02,  8.0858e-03,  1.3173e-02,  ..., -3.3035e-05,\n",
      "         -7.9516e-03, -9.7309e-02],\n",
      "        [ 1.2520e-02,  6.8318e-03,  1.7899e-02,  ..., -2.1662e-03,\n",
      "          9.3198e-03, -1.1305e-02],\n",
      "        [-2.0034e-02,  1.6757e-02, -4.0869e-03,  ...,  1.8599e-02,\n",
      "         -1.6303e-02, -5.5076e-03],\n",
      "        ...,\n",
      "        [ 1.3868e-02,  1.5986e-02,  5.9826e-03,  ...,  5.7346e-03,\n",
      "         -1.3971e-03,  1.3063e-02],\n",
      "        [ 8.7606e-02, -1.7222e-02,  5.2079e-03,  ...,  1.1584e-02,\n",
      "         -1.7036e-02,  1.9511e-02],\n",
      "        [ 2.4905e-02,  2.4351e-03, -4.6598e-03,  ...,  7.9035e-03,\n",
      "          2.2477e-02,  1.2565e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2770e-02,  8.0448e-03,  1.3229e-02,  ...,  4.0212e-06,\n",
      "         -8.0243e-03, -9.7339e-02],\n",
      "        [ 1.2629e-02,  6.8063e-03,  1.7863e-02,  ..., -2.1841e-03,\n",
      "          9.3207e-03, -1.1366e-02],\n",
      "        [-2.0012e-02,  1.6684e-02, -4.0658e-03,  ...,  1.8698e-02,\n",
      "         -1.6418e-02, -5.5166e-03],\n",
      "        ...,\n",
      "        [ 1.3968e-02,  1.5974e-02,  5.9614e-03,  ...,  5.7876e-03,\n",
      "         -1.4177e-03,  1.3142e-02],\n",
      "        [ 8.7548e-02, -1.7265e-02,  5.2658e-03,  ...,  1.1553e-02,\n",
      "         -1.6979e-02,  1.9480e-02],\n",
      "        [ 2.4934e-02,  2.3937e-03, -4.7597e-03,  ...,  7.8462e-03,\n",
      "          2.2490e-02,  1.2557e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 28: Best val_acc: 0.4139\n",
      "Epoch 28: Best val_acc: 0.4139\n",
      "Epoch 28: train_loss: 0.8765 train_acc: 0.7841 | val_loss: 1.9772 val_acc: 0.4139\n",
      "00:00:09.10\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.2977e-02,  8.1102e-03,  1.3213e-02,  ..., -5.9207e-05,\n",
      "         -7.8733e-03, -9.7262e-02],\n",
      "        [ 1.2477e-02,  6.8486e-03,  1.7899e-02,  ..., -2.1504e-03,\n",
      "          9.3679e-03, -1.1228e-02],\n",
      "        [-2.0137e-02,  1.6755e-02, -4.0422e-03,  ...,  1.8573e-02,\n",
      "         -1.6138e-02, -5.5907e-03],\n",
      "        ...,\n",
      "        [ 1.3779e-02,  1.5947e-02,  5.9496e-03,  ...,  5.6778e-03,\n",
      "         -1.3807e-03,  1.3029e-02],\n",
      "        [ 8.7633e-02, -1.7165e-02,  5.1821e-03,  ...,  1.1543e-02,\n",
      "         -1.7091e-02,  1.9493e-02],\n",
      "        [ 2.4913e-02,  2.4729e-03, -4.6331e-03,  ...,  7.9047e-03,\n",
      "          2.2477e-02,  1.2553e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2864e-02,  8.0858e-03,  1.3173e-02,  ..., -3.3035e-05,\n",
      "         -7.9516e-03, -9.7309e-02],\n",
      "        [ 1.2520e-02,  6.8318e-03,  1.7899e-02,  ..., -2.1662e-03,\n",
      "          9.3198e-03, -1.1305e-02],\n",
      "        [-2.0034e-02,  1.6757e-02, -4.0869e-03,  ...,  1.8599e-02,\n",
      "         -1.6303e-02, -5.5076e-03],\n",
      "        ...,\n",
      "        [ 1.3868e-02,  1.5986e-02,  5.9826e-03,  ...,  5.7346e-03,\n",
      "         -1.3971e-03,  1.3063e-02],\n",
      "        [ 8.7606e-02, -1.7222e-02,  5.2079e-03,  ...,  1.1584e-02,\n",
      "         -1.7036e-02,  1.9511e-02],\n",
      "        [ 2.4905e-02,  2.4351e-03, -4.6598e-03,  ...,  7.9035e-03,\n",
      "          2.2477e-02,  1.2565e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 29: train_loss: 0.8004 train_acc: 0.8250 | val_loss: 2.0492 val_acc: 0.3648\n",
      "00:00:07.52\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.3040e-02,  8.0334e-03,  1.3233e-02,  ..., -8.2436e-05,\n",
      "         -7.8339e-03, -9.7200e-02],\n",
      "        [ 1.2461e-02,  6.8111e-03,  1.7888e-02,  ..., -2.1059e-03,\n",
      "          9.3804e-03, -1.1161e-02],\n",
      "        [-2.0218e-02,  1.6855e-02, -3.9894e-03,  ...,  1.8567e-02,\n",
      "         -1.5957e-02, -5.6655e-03],\n",
      "        ...,\n",
      "        [ 1.3710e-02,  1.5948e-02,  5.9355e-03,  ...,  5.5720e-03,\n",
      "         -1.3737e-03,  1.2988e-02],\n",
      "        [ 8.7665e-02, -1.7158e-02,  5.1428e-03,  ...,  1.1525e-02,\n",
      "         -1.7077e-02,  1.9493e-02],\n",
      "        [ 2.4858e-02,  2.4976e-03, -4.6096e-03,  ...,  7.9006e-03,\n",
      "          2.2510e-02,  1.2555e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.2977e-02,  8.1102e-03,  1.3213e-02,  ..., -5.9207e-05,\n",
      "         -7.8733e-03, -9.7262e-02],\n",
      "        [ 1.2477e-02,  6.8486e-03,  1.7899e-02,  ..., -2.1504e-03,\n",
      "          9.3679e-03, -1.1228e-02],\n",
      "        [-2.0137e-02,  1.6755e-02, -4.0422e-03,  ...,  1.8573e-02,\n",
      "         -1.6138e-02, -5.5907e-03],\n",
      "        ...,\n",
      "        [ 1.3779e-02,  1.5947e-02,  5.9496e-03,  ...,  5.6778e-03,\n",
      "         -1.3807e-03,  1.3029e-02],\n",
      "        [ 8.7633e-02, -1.7165e-02,  5.1821e-03,  ...,  1.1543e-02,\n",
      "         -1.7091e-02,  1.9493e-02],\n",
      "        [ 2.4913e-02,  2.4729e-03, -4.6331e-03,  ...,  7.9047e-03,\n",
      "          2.2477e-02,  1.2553e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 30: train_loss: 0.6522 train_acc: 0.8705 | val_loss: 2.0009 val_acc: 0.3770\n",
      "00:00:07.85\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.3104e-02,  8.0653e-03,  1.3305e-02,  ...,  3.8906e-05,\n",
      "         -7.8070e-03, -9.7112e-02],\n",
      "        [ 1.2406e-02,  6.8455e-03,  1.7901e-02,  ..., -2.0488e-03,\n",
      "          9.4182e-03, -1.0998e-02],\n",
      "        [-2.0247e-02,  1.6907e-02, -4.0134e-03,  ...,  1.8542e-02,\n",
      "         -1.5922e-02, -5.7426e-03],\n",
      "        ...,\n",
      "        [ 1.3623e-02,  1.5979e-02,  5.9241e-03,  ...,  5.5092e-03,\n",
      "         -1.3765e-03,  1.3003e-02],\n",
      "        [ 8.7713e-02, -1.7126e-02,  5.1219e-03,  ...,  1.1564e-02,\n",
      "         -1.7100e-02,  1.9518e-02],\n",
      "        [ 2.4853e-02,  2.5906e-03, -4.6268e-03,  ...,  7.9373e-03,\n",
      "          2.2471e-02,  1.2655e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.3040e-02,  8.0334e-03,  1.3233e-02,  ..., -8.2436e-05,\n",
      "         -7.8339e-03, -9.7200e-02],\n",
      "        [ 1.2461e-02,  6.8111e-03,  1.7888e-02,  ..., -2.1059e-03,\n",
      "          9.3804e-03, -1.1161e-02],\n",
      "        [-2.0218e-02,  1.6855e-02, -3.9894e-03,  ...,  1.8567e-02,\n",
      "         -1.5957e-02, -5.6655e-03],\n",
      "        ...,\n",
      "        [ 1.3710e-02,  1.5948e-02,  5.9355e-03,  ...,  5.5720e-03,\n",
      "         -1.3737e-03,  1.2988e-02],\n",
      "        [ 8.7665e-02, -1.7158e-02,  5.1428e-03,  ...,  1.1525e-02,\n",
      "         -1.7077e-02,  1.9493e-02],\n",
      "        [ 2.4858e-02,  2.4976e-03, -4.6096e-03,  ...,  7.9006e-03,\n",
      "          2.2510e-02,  1.2555e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 31: train_loss: 0.7562 train_acc: 0.8159 | val_loss: 2.0791 val_acc: 0.3811\n",
      "00:00:07.11\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.3255e-02,  8.0703e-03,  1.3353e-02,  ...,  1.6724e-05,\n",
      "         -7.7612e-03, -9.7070e-02],\n",
      "        [ 1.2336e-02,  6.8417e-03,  1.7893e-02,  ..., -2.0506e-03,\n",
      "          9.4563e-03, -1.0905e-02],\n",
      "        [-2.0302e-02,  1.6972e-02, -4.0749e-03,  ...,  1.8505e-02,\n",
      "         -1.5821e-02, -5.7211e-03],\n",
      "        ...,\n",
      "        [ 1.3557e-02,  1.5988e-02,  5.9793e-03,  ...,  5.4199e-03,\n",
      "         -1.3184e-03,  1.2960e-02],\n",
      "        [ 8.7784e-02, -1.7126e-02,  5.1321e-03,  ...,  1.1639e-02,\n",
      "         -1.7113e-02,  1.9447e-02],\n",
      "        [ 2.4814e-02,  2.5882e-03, -4.5625e-03,  ...,  7.8698e-03,\n",
      "          2.2515e-02,  1.2621e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.3104e-02,  8.0653e-03,  1.3305e-02,  ...,  3.8906e-05,\n",
      "         -7.8070e-03, -9.7112e-02],\n",
      "        [ 1.2406e-02,  6.8455e-03,  1.7901e-02,  ..., -2.0488e-03,\n",
      "          9.4182e-03, -1.0998e-02],\n",
      "        [-2.0247e-02,  1.6907e-02, -4.0134e-03,  ...,  1.8542e-02,\n",
      "         -1.5922e-02, -5.7426e-03],\n",
      "        ...,\n",
      "        [ 1.3623e-02,  1.5979e-02,  5.9241e-03,  ...,  5.5092e-03,\n",
      "         -1.3765e-03,  1.3003e-02],\n",
      "        [ 8.7713e-02, -1.7126e-02,  5.1219e-03,  ...,  1.1564e-02,\n",
      "         -1.7100e-02,  1.9518e-02],\n",
      "        [ 2.4853e-02,  2.5906e-03, -4.6268e-03,  ...,  7.9373e-03,\n",
      "          2.2471e-02,  1.2655e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 32: train_loss: 0.7252 train_acc: 0.8273 | val_loss: 2.0952 val_acc: 0.3893\n",
      "00:00:07.23\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-4.3344e-02,  8.0857e-03,  1.3445e-02,  ...,  6.8689e-05,\n",
      "         -7.7483e-03, -9.7137e-02],\n",
      "        [ 1.2348e-02,  6.8211e-03,  1.7880e-02,  ..., -1.9915e-03,\n",
      "          9.4796e-03, -1.0861e-02],\n",
      "        [-2.0329e-02,  1.7024e-02, -4.0864e-03,  ...,  1.8519e-02,\n",
      "         -1.5681e-02, -5.7731e-03],\n",
      "        ...,\n",
      "        [ 1.3479e-02,  1.6001e-02,  5.9600e-03,  ...,  5.4042e-03,\n",
      "         -1.3188e-03,  1.2984e-02],\n",
      "        [ 8.7756e-02, -1.7164e-02,  5.1479e-03,  ...,  1.1553e-02,\n",
      "         -1.7136e-02,  1.9377e-02],\n",
      "        [ 2.4832e-02,  2.6094e-03, -4.6437e-03,  ...,  7.9777e-03,\n",
      "          2.2477e-02,  1.2698e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.3255e-02,  8.0703e-03,  1.3353e-02,  ...,  1.6724e-05,\n",
      "         -7.7612e-03, -9.7070e-02],\n",
      "        [ 1.2336e-02,  6.8417e-03,  1.7893e-02,  ..., -2.0506e-03,\n",
      "          9.4563e-03, -1.0905e-02],\n",
      "        [-2.0302e-02,  1.6972e-02, -4.0749e-03,  ...,  1.8505e-02,\n",
      "         -1.5821e-02, -5.7211e-03],\n",
      "        ...,\n",
      "        [ 1.3557e-02,  1.5988e-02,  5.9793e-03,  ...,  5.4199e-03,\n",
      "         -1.3184e-03,  1.2960e-02],\n",
      "        [ 8.7784e-02, -1.7126e-02,  5.1321e-03,  ...,  1.1639e-02,\n",
      "         -1.7113e-02,  1.9447e-02],\n",
      "        [ 2.4814e-02,  2.5882e-03, -4.5625e-03,  ...,  7.8698e-03,\n",
      "          2.2515e-02,  1.2621e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 33: train_loss: 0.6789 train_acc: 0.8432 | val_loss: 2.1560 val_acc: 0.3607\n",
      "00:00:07.12\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0434,  0.0081,  0.0135,  ...,  0.0001, -0.0076, -0.0971],\n",
      "        [ 0.0123,  0.0068,  0.0179,  ..., -0.0019,  0.0095, -0.0108],\n",
      "        [-0.0204,  0.0170, -0.0041,  ...,  0.0185, -0.0155, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0134,  0.0160,  0.0059,  ...,  0.0054, -0.0014,  0.0130],\n",
      "        [ 0.0878, -0.0171,  0.0051,  ...,  0.0115, -0.0172,  0.0193],\n",
      "        [ 0.0248,  0.0026, -0.0047,  ...,  0.0080,  0.0225,  0.0128]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.3344e-02,  8.0857e-03,  1.3445e-02,  ...,  6.8689e-05,\n",
      "         -7.7483e-03, -9.7137e-02],\n",
      "        [ 1.2348e-02,  6.8211e-03,  1.7880e-02,  ..., -1.9915e-03,\n",
      "          9.4796e-03, -1.0861e-02],\n",
      "        [-2.0329e-02,  1.7024e-02, -4.0864e-03,  ...,  1.8519e-02,\n",
      "         -1.5681e-02, -5.7731e-03],\n",
      "        ...,\n",
      "        [ 1.3479e-02,  1.6001e-02,  5.9600e-03,  ...,  5.4042e-03,\n",
      "         -1.3188e-03,  1.2984e-02],\n",
      "        [ 8.7756e-02, -1.7164e-02,  5.1479e-03,  ...,  1.1553e-02,\n",
      "         -1.7136e-02,  1.9377e-02],\n",
      "        [ 2.4832e-02,  2.6094e-03, -4.6437e-03,  ...,  7.9777e-03,\n",
      "          2.2477e-02,  1.2698e-02]], device='cuda:0', requires_grad=True)\n",
      "Epoch 34: train_loss: 0.6355 train_acc: 0.8614 | val_loss: 2.1018 val_acc: 0.3770\n",
      "00:00:06.98\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0435,  0.0081,  0.0135,  ...,  0.0002, -0.0076, -0.0970],\n",
      "        [ 0.0123,  0.0068,  0.0179,  ..., -0.0019,  0.0095, -0.0107],\n",
      "        [-0.0205,  0.0170, -0.0041,  ...,  0.0185, -0.0154, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0134,  0.0160,  0.0059,  ...,  0.0053, -0.0013,  0.0130],\n",
      "        [ 0.0878, -0.0171,  0.0051,  ...,  0.0115, -0.0172,  0.0193],\n",
      "        [ 0.0249,  0.0026, -0.0047,  ...,  0.0080,  0.0224,  0.0128]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0434,  0.0081,  0.0135,  ...,  0.0001, -0.0076, -0.0971],\n",
      "        [ 0.0123,  0.0068,  0.0179,  ..., -0.0019,  0.0095, -0.0108],\n",
      "        [-0.0204,  0.0170, -0.0041,  ...,  0.0185, -0.0155, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0134,  0.0160,  0.0059,  ...,  0.0054, -0.0014,  0.0130],\n",
      "        [ 0.0878, -0.0171,  0.0051,  ...,  0.0115, -0.0172,  0.0193],\n",
      "        [ 0.0248,  0.0026, -0.0047,  ...,  0.0080,  0.0225,  0.0128]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 35: train_loss: 0.5586 train_acc: 0.8864 | val_loss: 2.1599 val_acc: 0.3770\n",
      "00:00:06.79\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0436,  0.0082,  0.0136,  ...,  0.0002, -0.0075, -0.0969],\n",
      "        [ 0.0122,  0.0069,  0.0179,  ..., -0.0019,  0.0096, -0.0106],\n",
      "        [-0.0205,  0.0170, -0.0040,  ...,  0.0184, -0.0153, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0160,  0.0059,  ...,  0.0052, -0.0013,  0.0130],\n",
      "        [ 0.0878, -0.0170,  0.0052,  ...,  0.0116, -0.0172,  0.0193],\n",
      "        [ 0.0248,  0.0027, -0.0047,  ...,  0.0080,  0.0224,  0.0128]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0435,  0.0081,  0.0135,  ...,  0.0002, -0.0076, -0.0970],\n",
      "        [ 0.0123,  0.0068,  0.0179,  ..., -0.0019,  0.0095, -0.0107],\n",
      "        [-0.0205,  0.0170, -0.0041,  ...,  0.0185, -0.0154, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0134,  0.0160,  0.0059,  ...,  0.0053, -0.0013,  0.0130],\n",
      "        [ 0.0878, -0.0171,  0.0051,  ...,  0.0115, -0.0172,  0.0193],\n",
      "        [ 0.0249,  0.0026, -0.0047,  ...,  0.0080,  0.0224,  0.0128]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 36: train_loss: 0.5016 train_acc: 0.9045 | val_loss: 2.1823 val_acc: 0.4016\n",
      "00:00:06.78\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0436,  0.0082,  0.0136,  ...,  0.0002, -0.0075, -0.0969],\n",
      "        [ 0.0122,  0.0069,  0.0179,  ..., -0.0019,  0.0096, -0.0105],\n",
      "        [-0.0206,  0.0171, -0.0040,  ...,  0.0184, -0.0152, -0.0060],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0161,  0.0059,  ...,  0.0052, -0.0012,  0.0129],\n",
      "        [ 0.0878, -0.0170,  0.0052,  ...,  0.0115, -0.0173,  0.0192],\n",
      "        [ 0.0248,  0.0027, -0.0047,  ...,  0.0080,  0.0225,  0.0129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0436,  0.0082,  0.0136,  ...,  0.0002, -0.0075, -0.0969],\n",
      "        [ 0.0122,  0.0069,  0.0179,  ..., -0.0019,  0.0096, -0.0106],\n",
      "        [-0.0205,  0.0170, -0.0040,  ...,  0.0184, -0.0153, -0.0059],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0160,  0.0059,  ...,  0.0052, -0.0013,  0.0130],\n",
      "        [ 0.0878, -0.0170,  0.0052,  ...,  0.0116, -0.0172,  0.0193],\n",
      "        [ 0.0248,  0.0027, -0.0047,  ...,  0.0080,  0.0224,  0.0128]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 00037: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Epoch 37: train_loss: 0.5067 train_acc: 0.8795 | val_loss: 2.1910 val_acc: 0.3607\n",
      "00:00:07.43\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0437,  0.0082,  0.0136,  ...,  0.0002, -0.0074, -0.0969],\n",
      "        [ 0.0122,  0.0070,  0.0179,  ..., -0.0018,  0.0096, -0.0104],\n",
      "        [-0.0206,  0.0171, -0.0040,  ...,  0.0184, -0.0151, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0161,  0.0059,  ...,  0.0052, -0.0012,  0.0129],\n",
      "        [ 0.0878, -0.0170,  0.0052,  ...,  0.0116, -0.0173,  0.0192],\n",
      "        [ 0.0249,  0.0028, -0.0047,  ...,  0.0081,  0.0225,  0.0129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0436,  0.0082,  0.0136,  ...,  0.0002, -0.0075, -0.0969],\n",
      "        [ 0.0122,  0.0069,  0.0179,  ..., -0.0019,  0.0096, -0.0105],\n",
      "        [-0.0206,  0.0171, -0.0040,  ...,  0.0184, -0.0152, -0.0060],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0161,  0.0059,  ...,  0.0052, -0.0012,  0.0129],\n",
      "        [ 0.0878, -0.0170,  0.0052,  ...,  0.0115, -0.0173,  0.0192],\n",
      "        [ 0.0248,  0.0027, -0.0047,  ...,  0.0080,  0.0225,  0.0129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 38: train_loss: 0.5499 train_acc: 0.8818 | val_loss: 2.1825 val_acc: 0.3730\n",
      "00:00:07.24\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0438,  0.0082,  0.0136,  ...,  0.0002, -0.0074, -0.0968],\n",
      "        [ 0.0122,  0.0069,  0.0178,  ..., -0.0018,  0.0096, -0.0103],\n",
      "        [-0.0206,  0.0171, -0.0041,  ...,  0.0183, -0.0150, -0.0060],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0161,  0.0059,  ...,  0.0051, -0.0011,  0.0129],\n",
      "        [ 0.0879, -0.0170,  0.0052,  ...,  0.0116, -0.0174,  0.0192],\n",
      "        [ 0.0249,  0.0028, -0.0048,  ...,  0.0081,  0.0224,  0.0129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0437,  0.0082,  0.0136,  ...,  0.0002, -0.0074, -0.0969],\n",
      "        [ 0.0122,  0.0070,  0.0179,  ..., -0.0018,  0.0096, -0.0104],\n",
      "        [-0.0206,  0.0171, -0.0040,  ...,  0.0184, -0.0151, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0161,  0.0059,  ...,  0.0052, -0.0012,  0.0129],\n",
      "        [ 0.0878, -0.0170,  0.0052,  ...,  0.0116, -0.0173,  0.0192],\n",
      "        [ 0.0249,  0.0028, -0.0047,  ...,  0.0081,  0.0225,  0.0129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 39: train_loss: 0.4462 train_acc: 0.9159 | val_loss: 2.2222 val_acc: 0.3852\n",
      "00:00:07.04\n",
      "train_size: 110\n",
      "Parameter containing:\n",
      "tensor([[-0.0438,  0.0082,  0.0136,  ...,  0.0002, -0.0074, -0.0968],\n",
      "        [ 0.0122,  0.0069,  0.0178,  ..., -0.0018,  0.0096, -0.0102],\n",
      "        [-0.0207,  0.0171, -0.0041,  ...,  0.0182, -0.0150, -0.0060],\n",
      "        ...,\n",
      "        [ 0.0132,  0.0162,  0.0060,  ...,  0.0051, -0.0011,  0.0128],\n",
      "        [ 0.0879, -0.0170,  0.0052,  ...,  0.0115, -0.0174,  0.0191],\n",
      "        [ 0.0249,  0.0028, -0.0048,  ...,  0.0081,  0.0225,  0.0129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0438,  0.0082,  0.0136,  ...,  0.0002, -0.0074, -0.0968],\n",
      "        [ 0.0122,  0.0069,  0.0178,  ..., -0.0018,  0.0096, -0.0103],\n",
      "        [-0.0206,  0.0171, -0.0041,  ...,  0.0183, -0.0150, -0.0060],\n",
      "        ...,\n",
      "        [ 0.0133,  0.0161,  0.0059,  ...,  0.0051, -0.0011,  0.0129],\n",
      "        [ 0.0879, -0.0170,  0.0052,  ...,  0.0116, -0.0174,  0.0192],\n",
      "        [ 0.0249,  0.0028, -0.0048,  ...,  0.0081,  0.0224,  0.0129]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9997811204132935, 0.9999483302235603, 0.9999727183021605, 0.9999827754218131, 0.9999846587888896, 0.9999877513231089, 0.999990133025373, 0.999991335052376, 0.9999922647451361, 0.9999911802976081, 0.9999916703285029, 0.999991724655653, 0.999993740192925, 0.9999935283946494, 0.9999932125986865, 0.9999939362363269, 0.9999941986364623, 0.9999937352258712, 0.9999943999573588, 0.9999944386072457, 0.9999946366685132, 0.9999938524949054, 0.9999946347282579, 0.9999950156391909, 0.999995154949526, 0.9999953110236675, 0.9999955052044243, 0.9999955190966526, 0.99999537706996, 0.9999956431177756, 0.9999958554593226, 0.9999955842116227, 0.9999955148280909, 0.9999955270128945, 0.9999962352837125, 0.999995875172317, 0.9999964487118026, 0.9999974041711539, 0.9999974376211563]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_w['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Row wise average cos similarity')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule(\n",
      "  (feature_modules): ModuleDict(\n",
      "    (distance): Embedding(5, 3, padding_idx=0)\n",
      "    (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "    (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "    (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "    (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "    (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "    (sat_children): Identity()\n",
      "    (nuc_children): Identity()\n",
      "  )\n",
      ")\n",
      "ModuleDict(\n",
      "  (distance): Embedding(5, 3, padding_idx=0)\n",
      "  (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "  (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "  (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "  (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "  (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "  (sat_children): Identity()\n",
      "  (nuc_children): Identity()\n",
      ")\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(5, 3, padding_idx=0)\n",
      "Embedding(23, 5, padding_idx=0)\n",
      "Embedding(12, 4, padding_idx=0)\n",
      "Embedding(12, 4, padding_idx=0)\n",
      "Identity()\n",
      "Identity()\n"
     ]
    }
   ],
   "source": [
    "for i in model.module1.modules():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.4759 test_acc: 0.3538\n",
      "00:00:01.05\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.50      0.33      0.40        18\n",
      "    background       0.36      0.76      0.49        17\n",
      "         cause       0.40      1.00      0.57         2\n",
      "  circumstance       0.36      0.33      0.34        15\n",
      "    concession       0.75      0.46      0.57        13\n",
      "     condition       0.64      0.78      0.70         9\n",
      "   conjunction       0.33      0.43      0.38         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.73      0.73      0.73        11\n",
      "   elaboration       0.08      0.20      0.12        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.50      0.20      0.29        10\n",
      "interpretation       0.04      0.08      0.05        12\n",
      "         joint       0.30      0.38      0.33        29\n",
      "          list       0.52      0.46      0.49        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.80      1.00      0.89         4\n",
      "       purpose       0.67      0.67      0.67         3\n",
      "        reason       0.32      0.24      0.27        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.35       260\n",
      "     macro avg       0.30      0.34      0.30       260\n",
      "  weighted avg       0.35      0.35      0.34       260\n",
      "\n",
      "Test Loss: 2.476 |  Test Acc: 35.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#latest\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.2709 test_acc: 0.3538\n",
      "00:00:00.83\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.50      0.28      0.36        18\n",
      "    background       0.36      0.71      0.48        17\n",
      "         cause       0.33      1.00      0.50         2\n",
      "  circumstance       0.44      0.47      0.45        15\n",
      "    concession       0.60      0.46      0.52        13\n",
      "     condition       0.58      0.78      0.67         9\n",
      "   conjunction       0.33      0.43      0.38         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.57      0.73      0.64        11\n",
      "   elaboration       0.13      0.40      0.20        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.50      0.20      0.29        10\n",
      "interpretation       0.06      0.17      0.09        12\n",
      "         joint       0.30      0.24      0.27        29\n",
      "          list       0.44      0.46      0.45        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.80      1.00      0.89         4\n",
      "       purpose       0.67      0.67      0.67         3\n",
      "        reason       0.33      0.26      0.30        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.35       260\n",
      "     macro avg       0.29      0.34      0.30       260\n",
      "  weighted avg       0.34      0.35      0.33       260\n",
      "\n",
      "Latest Test Loss: 2.271 |  Latest Test Acc: 35.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best earliest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.2709 test_acc: 0.3538\n",
      "00:00:00.89\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.50      0.28      0.36        18\n",
      "    background       0.36      0.71      0.48        17\n",
      "         cause       0.33      1.00      0.50         2\n",
      "  circumstance       0.44      0.47      0.45        15\n",
      "    concession       0.60      0.46      0.52        13\n",
      "     condition       0.58      0.78      0.67         9\n",
      "   conjunction       0.33      0.43      0.38         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.57      0.73      0.64        11\n",
      "   elaboration       0.13      0.40      0.20        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.50      0.20      0.29        10\n",
      "interpretation       0.06      0.17      0.09        12\n",
      "         joint       0.30      0.24      0.27        29\n",
      "          list       0.44      0.46      0.45        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.80      1.00      0.89         4\n",
      "       purpose       0.67      0.67      0.67         3\n",
      "        reason       0.33      0.26      0.30        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.35       260\n",
      "     macro avg       0.29      0.34      0.30       260\n",
      "  weighted avg       0.34      0.35      0.33       260\n",
      "\n",
      "Best Test Loss: 2.271 |  Best Test Acc: 35.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best lastest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_latest', test_acc, 1)\n",
    "print(f'Best Test Loss: {test_loss:.3f} |  Best Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 1.9836 test_acc: 0.4139\n",
      "00:00:00.74\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.12      0.09      0.11        11\n",
      "    background       0.32      0.47      0.38        17\n",
      "         cause       0.00      0.00      0.00         7\n",
      "  circumstance       0.43      0.46      0.44        13\n",
      "    concession       0.73      0.73      0.73        11\n",
      "     condition       0.64      0.88      0.74         8\n",
      "   conjunction       0.78      0.88      0.82         8\n",
      "      contrast       0.00      0.00      0.00         3\n",
      " e-elaboration       0.69      0.69      0.69        13\n",
      "   elaboration       0.28      0.29      0.28        28\n",
      "  evaluation-n       0.00      0.00      0.00         8\n",
      "  evaluation-s       0.00      0.00      0.00         5\n",
      "      evidence       0.17      0.25      0.20         8\n",
      "interpretation       0.16      0.23      0.19        13\n",
      "         joint       0.20      0.17      0.18        18\n",
      "          list       0.52      0.61      0.56        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.86      0.55      0.67        11\n",
      "       purpose       0.75      0.60      0.67         5\n",
      "        reason       0.41      0.57      0.48        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         3\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.41       241\n",
      "     macro avg       0.29      0.31      0.30       241\n",
      "  weighted avg       0.37      0.41      0.38       241\n",
      "\n",
      "Val Loss: 1.984 |  Val Acc: 41.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best val acc\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
