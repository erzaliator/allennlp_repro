{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI6aVBQRy6LC"
   },
   "source": [
    "# 4️⃣ Zero-Shot Cross-Lingual Transfer using Adapters\n",
    "\n",
    "Beyond AdapterFusion, which we trained in [the previous notebook](https://github.com/Adapter-Hub/adapter-transformers/blob/master/notebooks/04_Cross_Lingual_Transfer.ipynb), we can compose adapters for zero-shot cross-lingual transfer between tasks. We will use the stacked adapter setup presented in **MAD-X** ([Pfeiffer et al., 2020](https://arxiv.org/pdf/2005.00052.pdf)) for this purpose.\n",
    "\n",
    "In this example, the base model is a pre-trained multilingual **XLM-R** (`xlm-roberta-base`) ([Conneau et al., 2019](https://arxiv.org/pdf/1911.02116.pdf)) model. Additionally, two types of adapters, language adapters and task adapters, are used. Here's how the MAD-X process works in detail:\n",
    "\n",
    "1. Train language adapters for the source and target language on a language modeling task. In this notebook, we won't train them ourselves but use [pre-trained language adapters from the Hub](https://adapterhub.ml/explore/text_lang/).\n",
    "2. Train a task adapter on the target task dataset. This task adapter is **stacked** upon the previously trained language adapter. During this step, only the weights of the task adapter are updated.\n",
    "3. Perform zero-shot cross-lingual transfer. In this last step, we simply replace the source language adapter with the target language adapter while keeping the stacked task adapter.\n",
    "\n",
    "Now to our concrete example: we select **XCOPA** ([Ponti et al., 2020](https://ducdauge.github.io/files/xcopa.pdf)), a multilingual extension of the **COPA** commonsence reasoning dataset ([Roemmele et al., 2011](https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF)) as our target task. The setup is trained on the original **English** dataset and then transferred to **Chinese**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L9gYpCV28OA"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Besides `adapter-transformers`, we use HuggingFace's `datasets` library for loading the data. So let's install both first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qL3Sq1HQynCq",
    "outputId": "1a53add7-208d-4767-a6f7-c51fad93787e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "MODEL_DIR = './training_output/deu_disrpt_vanilla_bert'\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP9OMSUT-FtL"
   },
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "We need the English COPA dataset for training our task adapter. It is part of the SuperGLUE benchmark and can be loaded via `datasets` using one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16002, 2155, 1621)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "en_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_train_enriched.rels'))\n",
    "en_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_test_enriched.rels'))\n",
    "en_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/eng.rst.rstdt_dev_enriched.rels'))\n",
    "\n",
    "de_train_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels'))\n",
    "de_test_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels'))\n",
    "de_valid_dataset_df = Dataset.from_pandas(read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels'))\n",
    "\n",
    "len(en_train_dataset_df), len(en_test_dataset_df), len(en_valid_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit1_txt': Value(dtype='string', id=None),\n",
       " 'unit1_sent': Value(dtype='string', id=None),\n",
       " 'unit2_txt': Value(dtype='string', id=None),\n",
       " 'unit2_sent': Value(dtype='string', id=None),\n",
       " 'dir': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='string', id=None),\n",
       " 'distance': Value(dtype='string', id=None),\n",
       " 'u1_depdir': Value(dtype='string', id=None),\n",
       " 'u2_depdir': Value(dtype='string', id=None),\n",
       " 'u2_func': Value(dtype='string', id=None),\n",
       " 'u1_position': Value(dtype='string', id=None),\n",
       " 'u2_position': Value(dtype='string', id=None),\n",
       " 'sat_children': Value(dtype='string', id=None),\n",
       " 'nuc_children': Value(dtype='string', id=None),\n",
       " 'genre': Value(dtype='string', id=None),\n",
       " 'unit1_case': Value(dtype='string', id=None),\n",
       " 'unit2_case': Value(dtype='string', id=None),\n",
       " 'u1_discontinuous': Value(dtype='string', id=None),\n",
       " 'u2_discontinuous': Value(dtype='string', id=None),\n",
       " 'same_speaker': Value(dtype='string', id=None),\n",
       " 'lex_overlap_length': Value(dtype='string', id=None),\n",
       " 'u1_func': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train_dataset_df.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INW7UEhC-I6b",
    "outputId": "b3e53380-c243-4b0c-88c5-629c272313e8"
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "from transformers.adapters.composition import Stack\n",
    "\n",
    "# dataset_en = load_dataset(\"super_glue\", \"copa\")\n",
    "# dataset_en.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epiKaEz5dDVe"
   },
   "source": [
    "Every dataset sample has a premise, a question and two possible answer choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifu4q5IJ-hYI",
    "outputId": "6ae68d07-3033-431b-ac31-5fcb24a2f24e"
   },
   "outputs": [],
   "source": [
    "# dataset_en['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVa3Vk0QdNYI"
   },
   "source": [
    "In this example, we model COPA as a multiple-choice task with two choices. Thus, we encode the premise and question as well as both choices as one input to our `xlm-roberta-base` model. Using `dataset.map()`, we can pass the full dataset through the tokenizer in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206,
     "referenced_widgets": [
      "acb9523d3e594c3d84036ad2348a7a64",
      "8d88b67069074ee6bc937b46cc10418a",
      "e71f76432d5e469d8cf742bbed6e0f1c",
      "a3da9679c78640c3be6e7cbbd5bcccae",
      "10e45676711b477e9a1ce2cf4ac8f3a9",
      "8cb6e0c49bd040b7bd5f266c4608dd31",
      "7a718fb0db5640fd8eb04ef18fe1e339",
      "0f3bac44e13246ab9f9c8564a44e1fa3",
      "c21fa18f6c4b4bdd9621ef29180646db",
      "fa8da5adaacd4534b60e51ba4dce6c4a",
      "249abcb1904c4d1ca4116b677011b017",
      "4a23a9bdd091425cbda38222f2e4c3a9",
      "df292d721c1748c485f281aa2162b9a9",
      "12ec755bb33c4ff894644e291ce33040",
      "77583bbefaf849eea83d3ae327e4070e",
      "58b17e932dd74756b62fb7f6ed0d37ba",
      "9380ff7e78f846babb16740cfc9cf7f8",
      "7a31bf9dedde47188efdfaf6a262b730",
      "f45f9a16f75e4d07abe5dcaf2fb300f4",
      "21bd77c2c70040548a696c5a40d81a00",
      "9c8548e2e4c54bf88e678c571c537867",
      "5321f4576a6c4fe69de0c97b43269d3b",
      "932d3ee3c9d74761bfc4bcf5c003d205",
      "ac8b24c5d6214716a409ca95580306f5"
     ]
    },
    "id": "hEnRCQfE_Oi3",
    "outputId": "27270898-730b-42a7-f028-875e2acf6a05"
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# def encode_batch(examples):\n",
    "#   \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "#   all_encoded = {\"input_ids\": [], \"attention_mask\": []}\n",
    "#   # Iterate through all examples in this batch\n",
    "#   for premise, question, choice1, choice2 in zip(examples[\"premise\"], examples[\"question\"], examples[\"choice1\"], examples[\"choice2\"]):\n",
    "#     sentences_a = [premise + \" \" + question for _ in range(2)]\n",
    "#     # Both answer choices are passed in an array according to the format needed for the multiple-choice prediction head\n",
    "#     sentences_b = [choice1, choice2]\n",
    "#     encoded = tokenizer(\n",
    "#         sentences_a,\n",
    "#         sentences_b,\n",
    "#         max_length=60,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "#     all_encoded[\"input_ids\"].append(encoded[\"input_ids\"])\n",
    "#     all_encoded[\"attention_mask\"].append(encoded[\"attention_mask\"])\n",
    "#   return all_encoded\n",
    "\n",
    "# def preprocess_dataset(dataset):\n",
    "#   # Encode the input data\n",
    "#   dataset = dataset.map(encode_batch, batched=True)\n",
    "#   # The transformers model expects the target class column to be named \"labels\"\n",
    "#   # dataset.rename_column(\"label\", \"labels\")\n",
    "#   # Transform to pytorch tensors and only output the required columns\n",
    "#   dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "#   return dataset\n",
    "\n",
    "# dataset_en = preprocess_dataset(dataset_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 16002 examples\n",
      "read 1621 examples\n",
      "read 2155 examples\n",
      "read 2164 examples\n",
      "read 241 examples\n",
      "read 260 examples\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from datasets import ClassLabel\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the SNLI dataset.\"\"\"\n",
    "    def __init__(self, dataset, labels, raw_text=False):\n",
    "        self.text = []\n",
    "        self.raw_text = []\n",
    "        self.raw_label = []\n",
    "        self.raw_text_flag = raw_text\n",
    "        self.num_rows = len(dataset)\n",
    "        for premise, hypothesis in zip(dataset['unit1_txt'], dataset['unit2_txt']):\n",
    "            self.text.append(tokenizer.encode_plus(premise, hypothesis, padding=\"max_length\", truncation=True, max_length=512, return_token_type_ids=True))\n",
    "            if raw_text: self.raw_text.append([premise, hypothesis])\n",
    "        # self.labels = torch.tensor(labels.str2int(dataset['label'])).to(device)\n",
    "        self.labels = labels.str2int(dataset['label'])\n",
    "        if raw_text: self.raw_label = dataset['label']\n",
    "        print('read ' + str(len(self.text)) + ' examples')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.raw_text_flag:  \n",
    "            return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'raw_text': self.raw_text[idx],\n",
    "                'label':self.labels[idx],\n",
    "                'raw_label': self.raw_label[idx]}\n",
    "\n",
    "        return {'input_ids':self.text[idx]['input_ids'], \n",
    "                'token_type_ids':self.text[idx]['token_type_ids'], \n",
    "                'attention_mask':self.text[idx]['attention_mask'], \n",
    "                'label':self.labels[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def combine_with_another_dataset(self, dataset2):\n",
    "        print('Adding datasets of sizes ', self.num_rows, ', ', dataset2.num_rows)\n",
    "        self.text = self.text + dataset2.text\n",
    "        self.raw_text = self.raw_text + dataset2.raw_text\n",
    "        self.raw_label = self.raw_label + dataset2.raw_label\n",
    "        self.num_rows = len(self.text) #update texts is now longer\n",
    "        assert self.raw_text_flag == dataset2.raw_text_flag\n",
    "        print('To new dataset size: ', self.num_rows)\n",
    "\n",
    "\n",
    "def load_data_snli(batch_size, train_dataset_df, valid_dataset_df, test_dataset_df, labels):\n",
    "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
    "    train_data = train_dataset_df\n",
    "    valid_data = valid_dataset_df\n",
    "    test_data = test_dataset_df\n",
    "    train_set = SNLIDataset(train_data, labels, raw_text=False)\n",
    "    valid_set = SNLIDataset(valid_data, labels, raw_text=False)\n",
    "    test_set = SNLIDataset(test_data, labels, raw_text=False)\n",
    "    return train_set, valid_set, test_set #TODO: MAKE INTO DICT\n",
    "\n",
    "en_labels = ClassLabel(names=list(set(en_train_dataset_df['label'])|set(en_test_dataset_df['label'])|set(en_valid_dataset_df['label'])))\n",
    "en_train_dataset, en_valid_dataset, en_test_dataset = load_data_snli(BATCH_SIZE, en_train_dataset_df, en_valid_dataset_df, en_test_dataset_df, en_labels)\n",
    "de_labels = ClassLabel(names=list(set(de_train_dataset_df['label'])|set(de_test_dataset_df['label'])|set(de_valid_dataset_df['label'])))\n",
    "de_train_dataset, de_valid_dataset, de_test_dataset = load_data_snli(BATCH_SIZE, de_train_dataset_df, de_valid_dataset_df, de_test_dataset_df, de_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs21MzEQ_0v4"
   },
   "source": [
    "## Task Adapter Training\n",
    "\n",
    "In this section, we will train the task adapter on the English COPA dataset. We use a pre-trained XLM-R model from HuggingFace and instantiate our model using `AutoAdapterModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnq8n_KP_3aX",
    "outputId": "590b1cae-a454-4110-c9fb-f76f4dff423a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaAdapterModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaAdapterModel were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoAdapterModel\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    ")\n",
    "model = AutoAdapterModel.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base AutoModel. If you print model before adding the adapters, you can see that the embeddings+12 transformer layers will be shared by En and Zh adapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDCNJzTXezcn"
   },
   "source": [
    "Now we only need to set up the adapters. As described, we need two language adapters (which are assumed to be pre-trained in this example) and a task adapter (which will be trained in a few moments).\n",
    "\n",
    "First, we load both the language adapters for our source language English (`\"en\"`) and our target language Chinese (`\"zh\"`) from the Hub. Then we add a new task adapter (`\"copa\"`) for our target task.\n",
    "\n",
    "Finally, we add a multiple-choice head with the same name as our task adapter on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jRqbBgS0BoHJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load adapter from source 'ah'...\n",
      "Found matching adapter at: adapters/ukp/xlm-roberta-base-en-wiki_pfeiffer.json\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/xlm-roberta-base/pfeiffer/en_relu_2.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/3e9c8c800af886cd1c684a3acf4929990b35f3ac75e050e942de2ff2ecf895fe-caabba7772816577124631d5b84810c4d32f49afcea4fca637162ec7f432174f-extracted/adapter_config.json\n",
      "Adding adapter 'en'.\n",
      "Loading module weights from ~/.cache/torch/adapters/3e9c8c800af886cd1c684a3acf4929990b35f3ac75e050e942de2ff2ecf895fe-caabba7772816577124631d5b84810c4d32f49afcea4fca637162ec7f432174f-extracted/pytorch_adapter.bin\n",
      "No matching prediction head found in '~/.cache/torch/adapters/3e9c8c800af886cd1c684a3acf4929990b35f3ac75e050e942de2ff2ecf895fe-caabba7772816577124631d5b84810c4d32f49afcea4fca637162ec7f432174f-extracted'\n",
      "Attempting to load adapter from source 'ah'...\n",
      "Found matching adapter at: adapters/ukp/xlm-roberta-base-de-wiki_pfeiffer.json\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/de/xlm-roberta-base/pfeiffer/de_relu_2.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/c0ef737b56498e44b5af1514ef430254e94dbe2b536513268a3e7ec4b87ea573-534c86150c5d2134893d9139d93a65ec2b60d9123fb53e0a26da2d1f785f0ffd-extracted/adapter_config.json\n",
      "Adding adapter 'de'.\n",
      "Loading module weights from ~/.cache/torch/adapters/c0ef737b56498e44b5af1514ef430254e94dbe2b536513268a3e7ec4b87ea573-534c86150c5d2134893d9139d93a65ec2b60d9123fb53e0a26da2d1f785f0ffd-extracted/pytorch_adapter.bin\n",
      "No matching prediction head found in '~/.cache/torch/adapters/c0ef737b56498e44b5af1514ef430254e94dbe2b536513268a3e7ec4b87ea573-534c86150c5d2134893d9139d93a65ec2b60d9123fb53e0a26da2d1f785f0ffd-extracted'\n",
      "Adding adapter 'disrpt'.\n",
      "Adding head 'disrpt' with config {'head_type': 'classification', 'num_labels': 26, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3, 'LABEL_4': 4, 'LABEL_5': 5, 'LABEL_6': 6, 'LABEL_7': 7, 'LABEL_8': 8, 'LABEL_9': 9, 'LABEL_10': 10, 'LABEL_11': 11, 'LABEL_12': 12, 'LABEL_13': 13, 'LABEL_14': 14, 'LABEL_15': 15, 'LABEL_16': 16, 'LABEL_17': 17, 'LABEL_18': 18, 'LABEL_19': 19, 'LABEL_20': 20, 'LABEL_21': 21, 'LABEL_22': 22, 'LABEL_23': 23, 'LABEL_24': 24, 'LABEL_25': 25}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdapterConfig\n",
    "\n",
    "# Load the language adapters\n",
    "lang_adapter_config = AdapterConfig.load(\"pfeiffer\", reduction_factor=2)\n",
    "model.load_adapter(\"en/wiki@ukp\", config=lang_adapter_config)\n",
    "model.load_adapter(\"de/wiki@ukp\", config=lang_adapter_config)\n",
    "\n",
    "# Add a new task adapter\n",
    "model.add_adapter(\"disrpt\")\n",
    "\n",
    "# Add a classification head for our target task\n",
    "num_labels=de_labels.num_classes\n",
    "print([num_labels])\n",
    "# model.add_multiple_choice_head(\"disrpt\", num_choices=num_labels)\n",
    "model.add_classification_head(\"disrpt\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `train_adapter()`, we tell our model to only train the task adapter in the following. This call will freeze the weights of the pre-trained model and the weights of the language adapters to prevent them from further finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7wBpjGWZ4v7O"
   },
   "outputs": [],
   "source": [
    "model.train_adapter([\"disrpt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60qIas8-il92"
   },
   "source": [
    "We want the task adapter to be stacked on top of the language adapter, so we have to tell our model to use this setup via the `active_adapters` property.\n",
    "\n",
    "A stack of adapters is represented by the `Stack` class, which takes the names of the adapters to be stacked as arguments.\n",
    "Of course, there are various other possibilities to compose adapters beyonde stacking. Learn more about those [in our documentation](https://docs.adapterhub.ml/adapter_composition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zgGqHJQbijgg"
   },
   "outputs": [],
   "source": [
    "# Unfreeze and activate stack setup\n",
    "model.active_adapters = Stack(\"en\", \"disrpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBDvwmUf_-mc"
   },
   "source": [
    "Great! Now, the input will be passed through the English language adapter first and the COPA task adapter second in every forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb8BY5RAmzkd"
   },
   "source": [
    "For training, we make use of the `Trainer` class built-in into `transformers`. We configure the training process using a `TrainingArguments` object.\n",
    "\n",
    "As the dataset splits of English COPA in the SuperGLUE are slightly different, we train on both the train and validation split of the dataset. Later, we will evaluate on the test split of XCOPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SHUFFLE print smples: https://discuss.huggingface.co/t/how-to-print-a-few-examples-at-the-beginning-of-training-when-using-trainer/7597/2\n",
    "# https://github.com/huggingface/datasets/blob/cd3169f3f35afcf73a36a8276113e1881d92e5e0/src/datasets/iterable_dataset.py#L223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "j0gFxQRdDkQ6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer\n",
    "# from datasets import concatenate_datasets\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def concatenate_datasets(dataset1, dataset2, shuffle=True):\n",
    "    y_iter = chain(dataset1, dataset2)\n",
    "    return y_iter\n",
    "    # tmp = list(yielding(y_iter))\n",
    "    # random.shuffle(tmp)\n",
    "    # for i in tmp:\n",
    "    #     print i\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=100,\n",
    "    output_dir=MODEL_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# train_dataset.combine_with_another_dataset(valid_dataset)\n",
    "# train_dataset = concatenate_datasets([dataset_en[\"train\"], dataset_en[\"validation\"]])\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=en_train_dataset,\n",
    "    eval_dataset=en_valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKlYjA9rm2Kp"
   },
   "source": [
    "Start the training 🚀 (this will take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMRobertaAdapterModel(\n",
      "  (shared_parameters): ModuleDict()\n",
      "  (roberta): RobertaModel(\n",
      "    (shared_parameters): ModuleDict()\n",
      "    (invertible_adapters): ModuleDict(\n",
      "      (en): NICECouplingBlock(\n",
      "        (F): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "        (G): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (de): NICECouplingBlock(\n",
      "        (F): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "        (G): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=192, bias=True)\n",
      "          (1): Activation_Function_Class(\n",
      "            (f): ReLU()\n",
      "          )\n",
      "          (2): Linear(in_features=192, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (key): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (value): Linear(\n",
      "                in_features=768, out_features=768, bias=True\n",
      "                (loras): ModuleDict()\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (prefix_tuning): PrefixTuningShim(\n",
      "                (prefix_gates): ModuleDict()\n",
      "                (pool): PrefixTuningPool(\n",
      "                  (prefix_tunings): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (adapters): ModuleDict()\n",
      "              (adapter_fusion_layer): ModuleDict()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(\n",
      "              in_features=768, out_features=3072, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(\n",
      "              in_features=3072, out_features=768, bias=True\n",
      "              (loras): ModuleDict()\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (adapters): ModuleDict(\n",
      "              (en): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (de): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=384, out_features=768, bias=True)\n",
      "              )\n",
      "              (disrpt): Adapter(\n",
      "                (non_linearity): Activation_Function_Class(\n",
      "                  (f): ReLU()\n",
      "                )\n",
      "                (adapter_down): Sequential(\n",
      "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
      "                  (1): Activation_Function_Class(\n",
      "                    (f): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (adapter_fusion_layer): ModuleDict()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "    (prefix_tuning): PrefixTuningPool(\n",
      "      (prefix_tunings): ModuleDict()\n",
      "    )\n",
      "  )\n",
      "  (heads): ModuleDict(\n",
      "    (disrpt): ClassificationHead(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (2): Activation_Function_Class(\n",
      "        (f): Tanh()\n",
      "      )\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=768, out_features=26, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "vSUs2FjXDmsx",
    "outputId": "2b8bb989-f6ca-4702-c222-15eea9823bbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 16002\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4008\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4008' max='4008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4008/4008 53:43, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.818600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.609600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.492300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.432600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.235700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.272500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.182800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.157300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.165300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.162100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.073800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.092700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.082800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.063100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.067300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.066800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1000/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-1500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2000/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-2500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3000/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-3500/disrpt/pytorch_model_head.bin\n",
      "Saving model checkpoint to ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/en/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/en/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/de/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/de/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/adapter_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/head_config.json\n",
      "Module weights saved in ./training_output/deu_disrpt_vanilla_bert/checkpoint-4000/disrpt/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4008, training_loss=1.29226510776969, metrics={'train_runtime': 3224.538, 'train_samples_per_second': 39.701, 'train_steps_per_second': 1.243, 'total_flos': 4.008443861031322e+16, 'train_loss': 1.29226510776969, 'epoch': 8.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2155\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2091971635818481,\n",
       " 'eval_acc': 0.6477958236658933,\n",
       " 'eval_runtime': 27.9135,\n",
       " 'eval_samples_per_second': 77.203,\n",
       " 'eval_steps_per_second': 9.673}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "eval_trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output_en\", remove_unused_columns=False,),\n",
    "    eval_dataset=en_test_dataset,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "eval_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axvDsmnJnGUG"
   },
   "source": [
    "## Cross-lingual transfer\n",
    "\n",
    "With the model and all adapters trained and ready, we can come to the cross-lingual transfer step here. We will evaluate our setup on the Chinese split of the XCOPA dataset.\n",
    "Therefore, we'll first download the data and preprocess it using the same method as the English dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344,
     "referenced_widgets": [
      "630597c0e70d4792b58c8942296692a4",
      "64e51ced10004147b21e51db1343cac8",
      "ff7c6d1bfc654c2db63e40bad4e3eb33",
      "f964d3d5333948e0b14117555b82275b",
      "949971635f1f498e86e04b9d4e28d353",
      "aebd284cd0ba4dfbafce1f0b99cd5213",
      "5df3d17d64e24faeab6cc644d333536a",
      "525a5c1a8ba04c8e89fc514064539d73",
      "c515e4e9f5b7470e8a17e4a4247878f5",
      "89f8555b95ec48b7b3282cb365b1cfdd",
      "c4b64289fc4445f59a94d6c51a288834",
      "568fedab4a4e44d9baa8213d54d60d38",
      "6025f45ce1af4c8caab09042992f2094",
      "1ccbb12bb5a548488c9b646159f893d3",
      "87c546c1a23c402f8a6de964828dc035",
      "f512c5cdfaa64005bb987f032957e530",
      "ea780b89e28a4348abfac40ef8fd140a",
      "4eac0e183d8047e498d3a576f3c3a1f4",
      "315cd377eae94488b258460f06e5cc10",
      "5b2e4c980b6a4e15bef86d1907b20f40",
      "9a8c7ea6d7ec4ec691525f6e3ca88d48",
      "02cb7dbc5b67469b8643c0ea3e6b3921",
      "3ccf15d7bea44e9bb91b9b3d32b3c691",
      "2d964df49d71456093b427af2a3ac6cc",
      "2a76413cb9cd4a6f901a8bef7dc70220",
      "13829992bf994ec5bbec71684cc824e6",
      "c154bfdf049147638c67d2844d25f9e6",
      "4fe615dff7104a018c48491fd711ed45",
      "3bc11633e20c460eb9058cc4b480b224",
      "5f708ccdb4f941918696d583ad9bd9c9",
      "527ea785de0a47f0ba5b0d0aea72cc97",
      "c2423ca88827446aa5b5c78ccc36a263",
      "71b51022c34247929dcb8f11c74a2de4",
      "8119426c8705459fb9df8b2c711d3c36",
      "1e70f23ca6f94a2099c2cca1eaf875d8",
      "11b4409af40748e0b760e91c3d91ede7",
      "c82fa83594a349c991626ee55b8edfa4",
      "8348929b740242d3bdc73ea2c8bcd9c8",
      "2393e906e07e4e8ba661b0eafd2268e8",
      "b28b184f13a948d5995ee04720748871",
      "342e98cd2d99438d861d5c1cf54b573d",
      "e3e3c18ef96e48999e14be0c60ad9f04",
      "d85845466e5a4ffd8370ef4c8b965684",
      "5b84c1bb95354f939bc1918b5478cf08",
      "b2b6f74edcdb465e94d9f07287fa506d",
      "c6ae198ebaf2467bba3f0a49f3aab196",
      "5d95a7e842dc43d995b3ad5f0b61ae8f",
      "fec9b3f47668416f8709fd7ab80a9730",
      "4a0b61f58dfd4b2c88e7fe818c4de4b8",
      "bc7b5cd3163b4b60877d80be43598436",
      "bfc579b1c3354bcd9a0be2fde370954c",
      "ed22b18a21c943f291c6326030cb2753",
      "67bde4b1393e48a1a5c1b00969317131",
      "efbd298ec8f0461ba89793855901330b",
      "e6bdcb09b73d4aa3844076829cf43f8a",
      "ecac341937124f21b04479a50a05c688"
     ]
    },
    "id": "cMgM1supdxpw",
    "outputId": "6cd4f3a5-6a95-41ea-dd98-f45e528d9f5f"
   },
   "outputs": [],
   "source": [
    "# dataset_zh = load_dataset(\"xcopa\", \"zh\", ignore_verifications=True)\n",
    "# dataset_zh = preprocess_dataset(dataset_zh)\n",
    "# print(dataset_zh[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0w3ofGZC4Oi"
   },
   "source": [
    "Next, let's adapt our setup to the new language. We simply replace the English language adapter with the Chinese language adapter we already loaded previously. The task adapter we just trained is kept. Again, we set this architecture using `active_adapters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "V04UntKfeK_z"
   },
   "outputs": [],
   "source": [
    "model.active_adapters = Stack(\"de\", \"disrpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9RAmZLzDk-j"
   },
   "source": [
    "Finally, let's see how well our adapter setup performs on the new language. We measure the zero-shot accuracy on the test split of the target language dataset. Evaluation is also performed using the built-in `Trainer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "CrW1cJyaeMox",
    "outputId": "f3f504c1-9518-4c21-e10f-b5202ae1c39f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 260\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.6125311851501465,\n",
       " 'eval_acc': 0.038461538461538464,\n",
       " 'eval_runtime': 3.432,\n",
       " 'eval_samples_per_second': 75.757,\n",
       " 'eval_steps_per_second': 9.615}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "eval_trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output\", remove_unused_columns=False,),\n",
    "    eval_dataset=de_test_dataset,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "eval_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "CrW1cJyaeMox",
    "outputId": "f3f504c1-9518-4c21-e10f-b5202ae1c39f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2155\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2605915069580078,\n",
       " 'eval_acc': 0.6264501160092807,\n",
       " 'eval_runtime': 27.9991,\n",
       " 'eval_samples_per_second': 76.967,\n",
       " 'eval_steps_per_second': 9.643}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  return {\"acc\": (preds == p.label_ids).mean()}\n",
    "eval_trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"./eval_output_en\", remove_unused_columns=False,),\n",
    "    eval_dataset=en_test_dataset,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "eval_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op8M7AfYnWhs"
   },
   "source": [
    "You should get an overall accuracy of about 56 which is on-par with full finetuning on COPA only but below the state-of-the-art which is sequentially finetuned on an additional dataset before finetuning on COPA.\n",
    "\n",
    "For results on different languages and a sequential finetuning setup which yields better results, make sure to check out [the MAD-X paper](https://arxiv.org/pdf/2005.00052.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you mean to say that even the SOTAs struggle to match randomized baseline for Zh."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_Cross_Lingual_Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02cb7dbc5b67469b8643c0ea3e6b3921": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f3bac44e13246ab9f9c8564a44e1fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e45676711b477e9a1ce2cf4ac8f3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "11b4409af40748e0b760e91c3d91ede7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28b184f13a948d5995ee04720748871",
      "placeholder": "​",
      "style": "IPY_MODEL_2393e906e07e4e8ba661b0eafd2268e8",
      "value": " 100/0 [00:00&lt;00:00, 1191.08 examples/s]"
     }
    },
    "12ec755bb33c4ff894644e291ce33040": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13829992bf994ec5bbec71684cc824e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ccbb12bb5a548488c9b646159f893d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e70f23ca6f94a2099c2cca1eaf875d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8348929b740242d3bdc73ea2c8bcd9c8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c82fa83594a349c991626ee55b8edfa4",
      "value": 1
     }
    },
    "21bd77c2c70040548a696c5a40d81a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac8b24c5d6214716a409ca95580306f5",
      "placeholder": "​",
      "style": "IPY_MODEL_932d3ee3c9d74761bfc4bcf5c003d205",
      "value": " 1/1 [00:10&lt;00:00, 10.75s/ba]"
     }
    },
    "2393e906e07e4e8ba661b0eafd2268e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "249abcb1904c4d1ca4116b677011b017": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12ec755bb33c4ff894644e291ce33040",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df292d721c1748c485f281aa2162b9a9",
      "value": 1
     }
    },
    "2a76413cb9cd4a6f901a8bef7dc70220": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c154bfdf049147638c67d2844d25f9e6",
       "IPY_MODEL_4fe615dff7104a018c48491fd711ed45"
      ],
      "layout": "IPY_MODEL_13829992bf994ec5bbec71684cc824e6"
     }
    },
    "2d964df49d71456093b427af2a3ac6cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "315cd377eae94488b258460f06e5cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02cb7dbc5b67469b8643c0ea3e6b3921",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a8c7ea6d7ec4ec691525f6e3ca88d48",
      "value": 1
     }
    },
    "342e98cd2d99438d861d5c1cf54b573d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d85845466e5a4ffd8370ef4c8b965684",
       "IPY_MODEL_5b84c1bb95354f939bc1918b5478cf08"
      ],
      "layout": "IPY_MODEL_e3e3c18ef96e48999e14be0c60ad9f04"
     }
    },
    "3bc11633e20c460eb9058cc4b480b224": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3ccf15d7bea44e9bb91b9b3d32b3c691": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a0b61f58dfd4b2c88e7fe818c4de4b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfc579b1c3354bcd9a0be2fde370954c",
       "IPY_MODEL_ed22b18a21c943f291c6326030cb2753"
      ],
      "layout": "IPY_MODEL_bc7b5cd3163b4b60877d80be43598436"
     }
    },
    "4a23a9bdd091425cbda38222f2e4c3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58b17e932dd74756b62fb7f6ed0d37ba",
      "placeholder": "​",
      "style": "IPY_MODEL_77583bbefaf849eea83d3ae327e4070e",
      "value": " 1/1 [00:00&lt;00:00,  2.51ba/s]"
     }
    },
    "4eac0e183d8047e498d3a576f3c3a1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fe615dff7104a018c48491fd711ed45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2423ca88827446aa5b5c78ccc36a263",
      "placeholder": "​",
      "style": "IPY_MODEL_527ea785de0a47f0ba5b0d0aea72cc97",
      "value": " 500/0 [00:00&lt;00:00, 2888.43 examples/s]"
     }
    },
    "525a5c1a8ba04c8e89fc514064539d73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527ea785de0a47f0ba5b0d0aea72cc97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5321f4576a6c4fe69de0c97b43269d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "568fedab4a4e44d9baa8213d54d60d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f512c5cdfaa64005bb987f032957e530",
      "placeholder": "​",
      "style": "IPY_MODEL_87c546c1a23c402f8a6de964828dc035",
      "value": " 28.2k/? [00:00&lt;00:00, 297kB/s]"
     }
    },
    "58b17e932dd74756b62fb7f6ed0d37ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b2e4c980b6a4e15bef86d1907b20f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d964df49d71456093b427af2a3ac6cc",
      "placeholder": "​",
      "style": "IPY_MODEL_3ccf15d7bea44e9bb91b9b3d32b3c691",
      "value": " 642k/? [00:00&lt;00:00, 3.06MB/s]"
     }
    },
    "5b84c1bb95354f939bc1918b5478cf08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fec9b3f47668416f8709fd7ab80a9730",
      "placeholder": "​",
      "style": "IPY_MODEL_5d95a7e842dc43d995b3ad5f0b61ae8f",
      "value": " 1/1 [00:00&lt;00:00,  2.28ba/s]"
     }
    },
    "5d95a7e842dc43d995b3ad5f0b61ae8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5df3d17d64e24faeab6cc644d333536a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f708ccdb4f941918696d583ad9bd9c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6025f45ce1af4c8caab09042992f2094": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "630597c0e70d4792b58c8942296692a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff7c6d1bfc654c2db63e40bad4e3eb33",
       "IPY_MODEL_f964d3d5333948e0b14117555b82275b"
      ],
      "layout": "IPY_MODEL_64e51ced10004147b21e51db1343cac8"
     }
    },
    "64e51ced10004147b21e51db1343cac8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67bde4b1393e48a1a5c1b00969317131": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71b51022c34247929dcb8f11c74a2de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e70f23ca6f94a2099c2cca1eaf875d8",
       "IPY_MODEL_11b4409af40748e0b760e91c3d91ede7"
      ],
      "layout": "IPY_MODEL_8119426c8705459fb9df8b2c711d3c36"
     }
    },
    "77583bbefaf849eea83d3ae327e4070e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a31bf9dedde47188efdfaf6a262b730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a718fb0db5640fd8eb04ef18fe1e339": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8119426c8705459fb9df8b2c711d3c36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8348929b740242d3bdc73ea2c8bcd9c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c546c1a23c402f8a6de964828dc035": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89f8555b95ec48b7b3282cb365b1cfdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb6e0c49bd040b7bd5f266c4608dd31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d88b67069074ee6bc937b46cc10418a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "932d3ee3c9d74761bfc4bcf5c003d205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9380ff7e78f846babb16740cfc9cf7f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f45f9a16f75e4d07abe5dcaf2fb300f4",
       "IPY_MODEL_21bd77c2c70040548a696c5a40d81a00"
      ],
      "layout": "IPY_MODEL_7a31bf9dedde47188efdfaf6a262b730"
     }
    },
    "949971635f1f498e86e04b9d4e28d353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9a8c7ea6d7ec4ec691525f6e3ca88d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9c8548e2e4c54bf88e678c571c537867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a3da9679c78640c3be6e7cbbd5bcccae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f3bac44e13246ab9f9c8564a44e1fa3",
      "placeholder": "​",
      "style": "IPY_MODEL_7a718fb0db5640fd8eb04ef18fe1e339",
      "value": " 1/1 [00:13&lt;00:00, 13.12s/ba]"
     }
    },
    "ac8b24c5d6214716a409ca95580306f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb9523d3e594c3d84036ad2348a7a64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e71f76432d5e469d8cf742bbed6e0f1c",
       "IPY_MODEL_a3da9679c78640c3be6e7cbbd5bcccae"
      ],
      "layout": "IPY_MODEL_8d88b67069074ee6bc937b46cc10418a"
     }
    },
    "aebd284cd0ba4dfbafce1f0b99cd5213": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28b184f13a948d5995ee04720748871": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2b6f74edcdb465e94d9f07287fa506d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bc7b5cd3163b4b60877d80be43598436": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfc579b1c3354bcd9a0be2fde370954c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efbd298ec8f0461ba89793855901330b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67bde4b1393e48a1a5c1b00969317131",
      "value": 1
     }
    },
    "c154bfdf049147638c67d2844d25f9e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f708ccdb4f941918696d583ad9bd9c9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bc11633e20c460eb9058cc4b480b224",
      "value": 1
     }
    },
    "c21fa18f6c4b4bdd9621ef29180646db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_249abcb1904c4d1ca4116b677011b017",
       "IPY_MODEL_4a23a9bdd091425cbda38222f2e4c3a9"
      ],
      "layout": "IPY_MODEL_fa8da5adaacd4534b60e51ba4dce6c4a"
     }
    },
    "c2423ca88827446aa5b5c78ccc36a263": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b64289fc4445f59a94d6c51a288834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ccbb12bb5a548488c9b646159f893d3",
      "max": 1750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6025f45ce1af4c8caab09042992f2094",
      "value": 1750
     }
    },
    "c515e4e9f5b7470e8a17e4a4247878f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4b64289fc4445f59a94d6c51a288834",
       "IPY_MODEL_568fedab4a4e44d9baa8213d54d60d38"
      ],
      "layout": "IPY_MODEL_89f8555b95ec48b7b3282cb365b1cfdd"
     }
    },
    "c6ae198ebaf2467bba3f0a49f3aab196": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82fa83594a349c991626ee55b8edfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d85845466e5a4ffd8370ef4c8b965684": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6ae198ebaf2467bba3f0a49f3aab196",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2b6f74edcdb465e94d9f07287fa506d",
      "value": 1
     }
    },
    "df292d721c1748c485f281aa2162b9a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e3e3c18ef96e48999e14be0c60ad9f04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6bdcb09b73d4aa3844076829cf43f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e71f76432d5e469d8cf742bbed6e0f1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cb6e0c49bd040b7bd5f266c4608dd31",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10e45676711b477e9a1ce2cf4ac8f3a9",
      "value": 1
     }
    },
    "ea780b89e28a4348abfac40ef8fd140a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_315cd377eae94488b258460f06e5cc10",
       "IPY_MODEL_5b2e4c980b6a4e15bef86d1907b20f40"
      ],
      "layout": "IPY_MODEL_4eac0e183d8047e498d3a576f3c3a1f4"
     }
    },
    "ecac341937124f21b04479a50a05c688": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed22b18a21c943f291c6326030cb2753": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecac341937124f21b04479a50a05c688",
      "placeholder": "​",
      "style": "IPY_MODEL_e6bdcb09b73d4aa3844076829cf43f8a",
      "value": " 1/1 [04:39&lt;00:00, 279.14s/ba]"
     }
    },
    "efbd298ec8f0461ba89793855901330b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f45f9a16f75e4d07abe5dcaf2fb300f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5321f4576a6c4fe69de0c97b43269d3b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c8548e2e4c54bf88e678c571c537867",
      "value": 1
     }
    },
    "f512c5cdfaa64005bb987f032957e530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f964d3d5333948e0b14117555b82275b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_525a5c1a8ba04c8e89fc514064539d73",
      "placeholder": "​",
      "style": "IPY_MODEL_5df3d17d64e24faeab6cc644d333536a",
      "value": " 4.89k/? [00:01&lt;00:00, 3.05kB/s]"
     }
    },
    "fa8da5adaacd4534b60e51ba4dce6c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fec9b3f47668416f8709fd7ab80a9730": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7c6d1bfc654c2db63e40bad4e3eb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aebd284cd0ba4dfbafce1f0b99cd5213",
      "max": 1935,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_949971635f1f498e86e04b9d4e28d353",
      "value": 1935
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
