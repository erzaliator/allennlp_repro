{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding for comparing experiment in part 2\n",
    "import torch\n",
    "import json\n",
    "SEED = 2011\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI Bert\n",
    "## Second Tutorial\n",
    "https://towardsdatascience.com/fine-tuning-pre-trained-transformer-models-for-sentence-entailment-d87caf9ec9db\n",
    "Check his Github code for complete notebook. I never referred to it. Medium was enough.\n",
    "BERT in keras-tf: https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define macros\n",
    "BERT_MODEL = 'bert-base-german-cased'\n",
    "batch_size = 4\n",
    "batches_per_epoch = 110\n",
    "\n",
    "save_path_suffix = '20visualizeBertPooler_rand_deu2013_debug_all+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# custom reader needed to handle quotechars\n",
    "def read_df_custom(file):\n",
    "    header = 'doc     unit1_toks      unit2_toks      unit1_txt       unit2_txt       s1_toks s2_toks unit1_sent      unit2_sent      dir     nuc_children    sat_children    genre   u1_discontinuous        u2_discontinuous       u1_issent        u2_issent       u1_length       u2_length       length_ratio    u1_speaker      u2_speaker      same_speaker    u1_func u1_pos  u1_depdir       u2_func u2_pos  u2_depdir       doclen  u1_position      u2_position     percent_distance        distance        lex_overlap_words       lex_overlap_length      unit1_case      unit2_case      label'\n",
    "    extracted_columns = ['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label', 'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case', 'unit2_case',\n",
    "                            'u1_discontinuous', 'u2_discontinuous', 'same_speaker', 'lex_overlap_length', 'u1_func']\n",
    "    header = header.split()\n",
    "    df = pd.DataFrame(columns=extracted_columns)\n",
    "    file = open(file, 'r')\n",
    "\n",
    "    rows = []\n",
    "    count = 0 \n",
    "    for line in file:\n",
    "        line = line[:-1].split('\\t')\n",
    "        count+=1\n",
    "        if count ==1: continue\n",
    "        row = {}\n",
    "        for column in extracted_columns:\n",
    "            index = header.index(column)\n",
    "            row[column] = line[index]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(rows)])\n",
    "    return df\n",
    "\n",
    "train_df = read_df_custom('../../processed/deu.rst.pcc_train_enriched.rels')\n",
    "test_df = read_df_custom('../../processed/deu.rst.pcc_test_enriched.rels')\n",
    "val_df = read_df_custom('../../processed/deu.rst.pcc_dev_enriched.rels')\n",
    "lang = 'deu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any empty values\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a dataset handler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'15': 1,\n",
       "         '1': 142,\n",
       "         '2': 41,\n",
       "         '3': 23,\n",
       "         '5': 9,\n",
       "         '6': 4,\n",
       "         '4': 10,\n",
       "         '7': 3,\n",
       "         '9': 3,\n",
       "         '12': 1,\n",
       "         '14': 1,\n",
       "         '8': 1,\n",
       "         '16': 1,\n",
       "         '10': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "Counter(val_df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit1_txt</th>\n",
       "      <th>unit1_sent</th>\n",
       "      <th>unit2_txt</th>\n",
       "      <th>unit2_sent</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>distance</th>\n",
       "      <th>u1_depdir</th>\n",
       "      <th>u2_depdir</th>\n",
       "      <th>u2_func</th>\n",
       "      <th>...</th>\n",
       "      <th>sat_children</th>\n",
       "      <th>nuc_children</th>\n",
       "      <th>genre</th>\n",
       "      <th>unit1_case</th>\n",
       "      <th>unit2_case</th>\n",
       "      <th>u1_discontinuous</th>\n",
       "      <th>u2_discontinuous</th>\n",
       "      <th>same_speaker</th>\n",
       "      <th>lex_overlap_length</th>\n",
       "      <th>u1_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>Dagmar Ziegler sitzt in der Schuldenfalle .</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>RIGHT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>Der Rückzieher der Finanzministerin ist aber v...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>evaluation-n</td>\n",
       "      <td>4</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>cap_initial</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>und vorgeschlagen , erst 2003 darüber zu entsc...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>conj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hat sie jetzt eine seit mehr als einem Jahr er...</td>\n",
       "      <td>Auf Grund der dramatischen Kassenlage in Brand...</td>\n",
       "      <td>Überraschend ,</td>\n",
       "      <td>Überraschend , weil das Finanz- und das Bildun...</td>\n",
       "      <td>1&lt;2</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>other</td>\n",
       "      <td>title</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unit1_txt  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "3  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "4  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "\n",
       "                                          unit1_sent  \\\n",
       "0        Dagmar Ziegler sitzt in der Schuldenfalle .   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "2  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "4  Auf Grund der dramatischen Kassenlage in Brand...   \n",
       "\n",
       "                                           unit2_txt  \\\n",
       "0  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "1  hat sie jetzt eine seit mehr als einem Jahr er...   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...   \n",
       "3  und vorgeschlagen , erst 2003 darüber zu entsc...   \n",
       "4                                     Überraschend ,   \n",
       "\n",
       "                                          unit2_sent  dir           label  \\\n",
       "0  Auf Grund der dramatischen Kassenlage in Brand...  1>2  interpretation   \n",
       "1  Auf Grund der dramatischen Kassenlage in Brand...  1>2           cause   \n",
       "2  Der Rückzieher der Finanzministerin ist aber v...  1>2    evaluation-n   \n",
       "3  Auf Grund der dramatischen Kassenlage in Brand...  1<2     conjunction   \n",
       "4  Überraschend , weil das Finanz- und das Bildun...  1<2  interpretation   \n",
       "\n",
       "  distance u1_depdir u2_depdir u2_func  ... sat_children nuc_children genre  \\\n",
       "0        2      ROOT      ROOT    root  ...            0            4  news   \n",
       "1        1     RIGHT      ROOT    root  ...            0            4  news   \n",
       "2        4      ROOT      ROOT    root  ...            4            3  news   \n",
       "3        1      ROOT      LEFT    conj  ...            0            4  news   \n",
       "4        2      ROOT      ROOT    root  ...            1            4  news   \n",
       "\n",
       "    unit1_case   unit2_case u1_discontinuous u2_discontinuous same_speaker  \\\n",
       "0  cap_initial        other            False            False         True   \n",
       "1  cap_initial        other            False            False         True   \n",
       "2        other  cap_initial            False            False         True   \n",
       "3        other        other            False            False         True   \n",
       "4        other        title            False            False         True   \n",
       "\n",
       "  lex_overlap_length u1_func  \n",
       "0                  0    root  \n",
       "1                  0     obl  \n",
       "2                  0    root  \n",
       "3                  0    root  \n",
       "4                  0    root  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit1_txt', 'unit1_sent', 'unit2_txt', 'unit2_sent', 'dir', 'label',\n",
       "       'distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position',\n",
       "       'u2_position', 'sat_children', 'nuc_children', 'genre', 'unit1_case',\n",
       "       'unit2_case', 'u1_discontinuous', 'u2_discontinuous', 'same_speaker',\n",
       "       'lex_overlap_length', 'u1_func'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 05:03:09.301155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 05:03:09.701219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-16 05:03:09.701248: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-16 05:03:09.770534: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-16 05:03:11.001826: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-16 05:03:11.001935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.2/targets/x86_64-linux/lib/:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/home/VD/kaveri/anaconda3/envs/py310/lib/\n",
      "2022-12-16 05:03:11.001943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.sharedctypes import Value\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, ConcatDataset\n",
    "from sys import path\n",
    "path.append('/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/allennlp/data/data_loaders/')\n",
    "from allennlp.data import allennlp_collate, Vocabulary\n",
    "from features_custom2 import get_vocab_feature_name\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df):\n",
    "    self.lang = lang\n",
    "    self.num_labels = set()\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True) # Using a pre-trained BERT tokenizer to encode sentences\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.train_idx = None\n",
    "    self.val_idx = None\n",
    "    self.test_idx = None\n",
    "    self.vocab = Vocabulary(counter=None, max_vocab_size=100000)\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.get_label_mapping()\n",
    "    self.init_feature_list()\n",
    "    self.init_feature_mappings_and_bins()\n",
    "    self.apply_bins()\n",
    "    self.calculate_unique_values()\n",
    "    self.train_data, self.train_idx = self.load_data(self.train_df)\n",
    "    self.val_data, self.val_idx = self.load_data(self.val_df)\n",
    "    self.test_data, self.test_idx = self.load_data(self.test_df)\n",
    "    \n",
    "\n",
    "  def combine_unique_column_values_to_dict(self, column_name):\n",
    "    ini_set = set([*self.train_df[column_name].unique(), *self.val_df[column_name].unique()])\n",
    "    res = dict.fromkeys(ini_set, 0)\n",
    "    return res\n",
    "\n",
    "  def get_label_mapping(self):\n",
    "    labels = {}\n",
    "    labels_list = list(set(list(self.train_df['label'].unique()) + list(self.test_df['label'].unique()) + list(self.val_df['label'].unique())))\n",
    "    for i in range(len(labels_list)):\n",
    "        labels[labels_list[i]] = i\n",
    "    self.label_dict = labels\n",
    "    # needed later for classification report object to generate precision and recall on test dataset\n",
    "    self.rev_label_dict = {self.label_dict[k]:k for k in self.label_dict.keys()} \n",
    "\n",
    "  def init_feature_mappings_and_bins(self):\n",
    "    self.feature_maps = { 'genre': self.combine_unique_column_values_to_dict('genre'),\n",
    "                          'unit1_case': self.combine_unique_column_values_to_dict('unit1_case'),\n",
    "                          'unit2_case': self.combine_unique_column_values_to_dict('unit2_case'),\n",
    "                          'u1_func': self.combine_unique_column_values_to_dict('u1_func'),\n",
    "                          'u2_func': self.combine_unique_column_values_to_dict('u2_func') }\n",
    "\n",
    "    self.bins = {\n",
    "      'distance': [[-1e9, -8], [-8, -2], [-2, 0], [0, 2], [2, 8], [8, 1e9]],\n",
    "      'u1_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'u2_position': [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0], [1.0, 1e9]],\n",
    "      'lex_overlap_length': [[0, 2], [2, 7], [7, 1e9]]\n",
    "    }   \n",
    "\n",
    "  def add_directionality(self, premise, hypothesis, dir):\n",
    "    if dir == \"1<2\":\n",
    "        hypothesis = '< ' + hypothesis + ' {'\n",
    "    else:\n",
    "        premise = '} ' + premise + ' >'\n",
    "    return premise, hypothesis\n",
    "\n",
    "  def init_feature_list(self):\n",
    "    if self.lang=='nld':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'sat_children', 'genre', 'u1_position']\n",
    "    elif self.lang=='deu':\n",
    "      self.feature_list = ['distance', 'u1_depdir', 'u2_depdir', 'u2_func', 'u1_position', 'u2_position', 'sat_children', 'nuc_children']\n",
    "    elif self.lang=='eng.rst.gum':\n",
    "      self.feature_list = ['distance', 'same_speaker', 'u2_func', 'u2_depdir', 'unit1_case', 'unit2_case', 'nuc_children',\n",
    "                      'sat_children', 'genre', 'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'u1_position', 'u2_position']\n",
    "    elif self.lang=='fas':\n",
    "      self.feature_list = ['distance', 'nuc_children', 'sat_children', 'u2_discontinuous', 'genre']\n",
    "    elif self.lang=='spa.rst.sctb':\n",
    "      self.feature_list = ['distance', 'u1_position', 'sat_children']\n",
    "    elif self.lang=='zho.rst.sctb':\n",
    "      self.feature_list = ['sat_children', 'nuc_children', 'genre', 'u2_discontinuous', 'u1_discontinuous', 'u1_depdir', 'u1_func']\n",
    "    else: \n",
    "      raise ValueError()\n",
    "\n",
    "  def get_mapping_from_dictionary(self, column_name, dict_val):\n",
    "    return self.feature_maps[column_name][dict_val]\n",
    "\n",
    "  def get_allen_features_list(self, features, feature_name):\n",
    "    if feature_name in ['distance', 'u1_depdir', 'u2_depdir', 'u1_func', 'u2_func', \n",
    "    'u1_position', 'u2_position', 'genre', 'same_speaker', 'unit1_case', 'unit2_case',\n",
    "    'lex_overlap_length', 'u2_discontinuous', 'u1_discontinuous', 'dir']: feature_value = self.apply_vocab(features[feature_name], feature_name) #for categorical values\n",
    "    elif feature_name in ['sat_children', 'nuc_children']: feature_value = float(features[feature_name]) #for identiy values\n",
    "    else: \n",
    "      print(feature_name)\n",
    "      raise ValueError()\n",
    "    return feature_value\n",
    "\n",
    "  def transform_feature(self, features):\n",
    "    assert len(features)==17\n",
    "    #after applying the vocab. we need to pass them as int\n",
    "    return {feature_name: torch.tensor(int(self.get_allen_features_list(features, feature_name))).to(device) for feature_name in self.feature_list+['dir']}\n",
    "\n",
    "  def calculate_unique_values(self):\n",
    "    for feature_name in self.feature_list+['dir']:\n",
    "      vocab_feature_name = get_vocab_feature_name(feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(train_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "      self.vocab.add_tokens_to_namespace(val_df[feature_name].apply(lambda x: str(x)), namespace=vocab_feature_name)\n",
    "\n",
    "  def apply_bins(self):\n",
    "    for df in [self.train_df, self.test_df, self.val_df]:\n",
    "      for feature_name in self.bins.keys():\n",
    "        df[feature_name] = df[feature_name].apply(lambda x: self.get_mapping_from_bin(feature_name, float(x)))\n",
    "\n",
    "  def get_mapping_from_bin(self, column_name, dict_val):\n",
    "    bins = self.bins[column_name]\n",
    "    for b,i in zip(bins, range(len(bins))):\n",
    "      left = b[0]\n",
    "      right = b[1]\n",
    "      if left<=dict_val and right>=dict_val: return i\n",
    "\n",
    "  def apply_vocab(self, feature_value, feature_name):\n",
    "    return self.vocab.get_token_index(str(feature_value), namespace=get_vocab_feature_name(feature_name))\n",
    "\n",
    "  def set_labels(self):\n",
    "    self.num_labels = len(self.num_labels)\n",
    "    \n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512 \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "    feats = []\n",
    "    idx = []\n",
    "    idx_map = {}\n",
    "\n",
    "    self.num_labels.update(df['label'].unique())\n",
    "\n",
    "    count=0\n",
    "    for row in df.iterrows():\n",
    "      row = row[1]\n",
    "      premise = row['unit1_txt']\n",
    "      hypothesis = row['unit2_txt']\n",
    "      label = row['label']\n",
    "      dir = row['dir']\n",
    "\n",
    "      features = {'distance': row['distance'],\n",
    "                'u1_depdir': row['u1_depdir'],\n",
    "                'u2_depdir': row['u2_depdir'],\n",
    "                'u1_func': row['u1_func'],\n",
    "                'u2_func': row['u2_func'],\n",
    "                'u1_position': row['u1_position'],\n",
    "                'u2_position': row['u2_position'],\n",
    "                'sat_children': row['sat_children'],\n",
    "                'nuc_children': row['nuc_children'],\n",
    "                'genre': row['genre'],\n",
    "                'unit1_case': row['unit1_case'],\n",
    "                'unit2_case': row['unit2_case'],\n",
    "                'u1_discontinuous': row['u1_discontinuous'],\n",
    "                'u2_discontinuous': row['u2_discontinuous'],\n",
    "                'same_speaker': row['same_speaker'],\n",
    "                'lex_overlap_length': row['lex_overlap_length'],\n",
    "                'dir': row['dir']}\n",
    "\n",
    "      premise, hypothesis = self.add_directionality(premise, hypothesis, dir)\n",
    "      encoded = self.tokenizer.encode_plus(premise, hypothesis, add_special_tokens = True, max_length=MAX_LEN, truncation=True, padding=False) #padding='max_length'\n",
    "      pair_token_ids = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "      segment_ids = torch.tensor(encoded['token_type_ids'])\n",
    "      attention_mask_ids = torch.tensor(encoded['attention_mask'])\n",
    "      assert len(pair_token_ids)==len(attention_mask_ids)\n",
    "\n",
    "      features = self.transform_feature(features)\n",
    "\n",
    "      token_ids.append(pair_token_ids)\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "      feats.append(features)\n",
    "      \n",
    "      idx_map[count] = [premise, hypothesis]\n",
    "      idx.append(count)\n",
    "      count+=1\n",
    "      \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    idx = torch.tensor(idx)\n",
    "\n",
    "    class featureDataset(Dataset):\n",
    "      def __init__(self, token_ids, mask_ids, seg_ids, feats, y, idx):\n",
    "          self.token_ids = token_ids\n",
    "          self.mask_ids = mask_ids\n",
    "          self.seg_ids = seg_ids\n",
    "          self.feats = feats\n",
    "          self.y = y\n",
    "          self.idx = idx\n",
    "\n",
    "      def __len__(self):\n",
    "          return len(self.feats)\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "          return self.token_ids[idx], self.mask_ids[idx], self.seg_ids[idx], self.feats[idx], self.y[idx], self.idx[idx]\n",
    "\n",
    "    dataset = featureDataset(token_ids, mask_ids, seg_ids, feats, y, idx)\n",
    "    return dataset, idx_map\n",
    "\n",
    "  def get_data_loaders(self, batch_size=4, batches_per_epoch=402, shuffle=True): #1609 samples / 64:25=1600 / 402:4=1608\n",
    "    self.set_labels()\n",
    "    train_loader_torch = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_loader_torch = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_loader_torch = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=False,\n",
    "      batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    train_loader = LoaderWrapper(train_loader_torch, n_step=batches_per_epoch)\n",
    "    val_loader = LoaderWrapper(val_loader_torch, n_step=batches_per_epoch)\n",
    "    test_loader = LoaderWrapper(test_loader_torch, n_step=batches_per_epoch)\n",
    "\n",
    "    return train_loader, val_loader_torch, test_loader_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderWrapper:\n",
    "    def __init__(self, loader, n_step):\n",
    "        self.step = n_step\n",
    "        self.idx = 0\n",
    "        self.iter_loader = iter(loader)\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.step\n",
    "\n",
    "    def __next__(self):\n",
    "        # if reached number of steps desired, stop\n",
    "        if self.idx == self.step:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.idx += 1\n",
    "        # while True\n",
    "        try:\n",
    "            return next(self.iter_loader)\n",
    "        except StopIteration:\n",
    "            # reinstate iter_loader, then continue\n",
    "            self.iter_loader = iter(self.loader)\n",
    "            return next(self.iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df)\n",
    "\n",
    "train_loader, val_loader, test_loader = mnli_dataset.get_data_loaders(batch_size=batch_size, batches_per_epoch=batches_per_epoch) #64X250\n",
    "label_dict = mnli_dataset.label_dict # required by custom func to calculate accuracy, bert model\n",
    "rev_label_dict = mnli_dataset.rev_label_dict # required by custom func to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '3': 2, '4': 3, '5': 4}\n",
      "u1_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_depdir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'ROOT': 2, 'RIGHT': 3, 'LEFT': 4}\n",
      "u2_func :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, 'root': 2, 'conj': 3, 'advcl': 4, 'acl': 5, 'xcomp': 6, 'obl': 7, 'ccomp': 8, 'parataxis': 9, 'advmod': 10, 'dep': 11, 'csubj': 12, 'nmod': 13, 'punct': 14, 'cc': 15, 'appos': 16, 'aux': 17, 'obj': 18, 'iobj': 19, 'nsubj': 20, 'nsubj:pass': 21, 'csubj:pass': 22}\n",
      "u1_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '1': 11}\n",
      "u2_position :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '2': 3, '1': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
      "sat_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '0': 2, '4': 3, '1': 4, '2': 5, '3': 6, '5': 7, '6': 8}\n",
      "nuc_children :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '4': 2, '3': 3, '1': 4, '2': 5, '5': 6, '6': 7, '7': 8, '8': 9}\n",
      "dir :  {'@@PADDING@@': 0, '@@UNKNOWN@@': 1, '1>2': 2, '1<2': 3}\n"
     ]
    }
   ],
   "source": [
    "for feature in mnli_dataset.feature_list:\n",
    "    vocab_feature_name = get_vocab_feature_name(feature)\n",
    "    print(feature, ': ', mnli_dataset.vocab.get_token_to_index_vocabulary(vocab_feature_name))\n",
    "print('dir', ': ', mnli_dataset.vocab.get_token_to_index_vocabulary('dir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "    # assert pair_token_ids.shape[-1]==512 #torch.Size([4, 512])\n",
    "    # assert mask_ids.shape[-1]==512\n",
    "    # assert seg_ids.shape[-1]==512\n",
    "    assert len(feat)==len(mnli_dataset.feature_list)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch import optim\n",
    "import os\n",
    "path.append(os.path.join(os.getcwd(), '../utils/'))\n",
    "from CategoricalAccuracy import CategoricalAccuracy as CA\n",
    "import numpy as np\n",
    "\n",
    "ca = CA()\n",
    "\n",
    "x = torch.tensor(np.array([[[1,0,0], [1,0,0], [1,0,0]]]))\n",
    "y1 = torch.tensor(np.array([[0], [1], [1]]))\n",
    "y2 = torch.tensor(np.array([[0], [0], [0]]))\n",
    "\n",
    "ca(x,y1)\n",
    "print(ca.get_metric(reset=True))\n",
    "ca(x,y2)\n",
    "print(ca.get_metric(reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '@@PADDING@@', 1: '@@UNKNOWN@@'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_dataset.vocab.get_index_to_token_vocabulary('u1_depdir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define evaulation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate model for train and test. And also use classification report for testing\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# helper function to calculate the batch accuracy\n",
    "def multi_acc(y_pred, y_test, allennlp=False):\n",
    "  if allennlp==False:\n",
    "    acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "    return acc\n",
    "\n",
    "# freeze model weights and measure validation / test \n",
    "def evaluate_accuracy(model, optimizer, data_loader, rev_label_dict, label_dict, is_training=True):\n",
    "  model.eval()\n",
    "  total_val_acc  = 0\n",
    "  total_val_loss = 0\n",
    "  \n",
    "  #for classification report\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  idx_list = []\n",
    "  premise_list = []\n",
    "  hypo_list = []\n",
    "  idx_map = mnli_dataset.val_idx if is_training else mnli_dataset.test_idx\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(data_loader):      \n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      \n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      acc = multi_acc(outputs, labels)\n",
    "\n",
    "      total_val_loss += loss.item()\n",
    "      total_val_acc  += acc.item()\n",
    "\n",
    "      # log predictions for classification report\n",
    "      argmax_predictions = torch.argmax(outputs,dim=1).tolist()\n",
    "      labels_list = labels.tolist()\n",
    "      assert(len(labels_list)==len(argmax_predictions))\n",
    "      for p in argmax_predictions: y_pred.append(rev_label_dict[int(p)])\n",
    "      for l in labels_list: y_true.append(rev_label_dict[l])\n",
    "      for i in idx.tolist():\n",
    "        idx_list.append(i)\n",
    "        if i not in idx_map.keys():\n",
    "          print(idx_map)\n",
    "        premise_list.append(idx_map[i][0])\n",
    "        hypo_list.append(idx_map[i][1])\n",
    "\n",
    "  val_acc  = total_val_acc/len(data_loader)\n",
    "  val_loss = total_val_loss/len(data_loader)\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "\n",
    "  idx_json = {'idx': idx_list, 'gold_label': y_true, 'pred_label': y_pred, 'premise': premise_list, 'hypothesis': hypo_list}\n",
    "  \n",
    "  return val_acc, val_loss, cr, model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGN: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing FeaturefulBert: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing FeaturefulBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FeaturefulBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, Optional\n",
    "from transformers import BertModel, AutoTokenizer, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from featurefulbertembedder_custom2 import FeaturefulBertEmbedder\n",
    "from featureful_bert_custom2 import get_combined_feature_tensor_2 as get_combined_feature_tensor_forward\n",
    "from featureful_bert_custom2 import get_feature_modules\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class CustomPooler2(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                        requires_grad: bool = True,\n",
    "                        dropout: float = 0.0,\n",
    "                        randomize_weights: bool = False,\n",
    "                        transformer_kwargs: Optional[Dict[str, Any]] = None, ) -> None:\n",
    "        super().__init__()\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL) #only used to pass config. BertAttentionClass used in FeatureFulBert\n",
    "        self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.pooler = copy.deepcopy(bert.pooler)\n",
    "        if randomize_weights:\n",
    "            print(self.pooler.dense.weight.shape)\n",
    "            self.pooler.dense.weight = nn.Parameter(torch.rand(self.pooler.dense.weight.shape))\n",
    "            self.pooler.dense.bias = nn.Parameter(torch.rand(self.pooler.dense.bias.shape))\n",
    "            print(self.pooler.dense.weight.shape)\n",
    "        for param in self.pooler.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        self._embedding_dim = bert.config.hidden_size\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._embedding_dim\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor = None, num_wrapping_dims: int = 0):\n",
    "        pooler = self.pooler\n",
    "        \n",
    "        for _ in range(num_wrapping_dims):\n",
    "            pooler = TimeDistributed(pooler)\n",
    "        pooled = pooler(tokens)\n",
    "        pooled = self._dropout(pooled)\n",
    "        return pooled\n",
    "\n",
    "class MyModule(nn.Module):    \n",
    "    def __init__(self, feature_list, vocab):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.feature_list = feature_list\n",
    "        self.feature_modules, self._feature_module_size = get_feature_modules(feature_list, vocab)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return get_combined_feature_tensor_forward(features, self.feature_list, self.feature_modules)\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels, vocab):\n",
    "          super(CustomBERTModel, self).__init__()\n",
    "          self.num_classes = num_labels\n",
    "          self.feature_list = mnli_dataset.feature_list\n",
    "          print('ASSIGN:', self.num_classes)\n",
    "\n",
    "          self.embedder = self.create_featureful_bert()\n",
    "          self.encoder = CustomPooler2()\n",
    "          self.module1 = MyModule(self.feature_list, vocab)\n",
    "          self.dropout1 = nn.Dropout(p=0.0)\n",
    "        #   self.dropout_decoder = nn.Dropout(p=0.5)\n",
    "          self._decoder_input_size = self.encoder._embedding_dim + self.module1._feature_module_size\n",
    "          self.relation_decoder = nn.Linear(self._decoder_input_size, self.num_classes)\n",
    "\n",
    "          self.history_outerpooler = {\n",
    "            'cos': [],\n",
    "            'l2': []\n",
    "          }\n",
    "          self.history_innerpooler = {\n",
    "            'cos': [],\n",
    "            'l2': []\n",
    "          }\n",
    "          self.history_transformerlayer = {\n",
    "            'cos': [],\n",
    "            'l2': []\n",
    "          }\n",
    "          self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "          self.innerpooler_weight = copy.deepcopy(self.embedder.transformer_model.pooler.dense.weight)\n",
    "          self.transformerlayer_weight = copy.deepcopy(self.embedder.transformer_model.encoder.layer[11].output.dense.weight)\n",
    "          print(self.pooler_weight)\n",
    "\n",
    "    def forward(self, pair_token_ids, token_type_ids, attention_mask, feat):\n",
    "        direction_tensor = feat['dir'].to(device)\n",
    "        embedded_sentence = self.embedder(token_ids=pair_token_ids, #featurefulmebedder\n",
    "                        mask=attention_mask, \n",
    "                        type_ids=token_type_ids,\n",
    "                        segment_concat_mask = None,\n",
    "                        direction_tensor = direction_tensor,\n",
    "                        feature_list = self.feature_list,\n",
    "                        features = feat)\n",
    "        mask = token_type_ids\n",
    "        bertpooler_output = self.encoder(tokens=embedded_sentence, mask=mask)\n",
    "        feat = self.convert_to_feature_list(feat)\n",
    "        feat = self.dropout1(feat)\n",
    "        feat = self.module1(feat)\n",
    "        # print(bertpooler_output.shape, self.module1._feature_module_size, feat.shape)\n",
    "        try:\n",
    "            feat_concat = torch.concat((bertpooler_output, feat),-1)\n",
    "        except:\n",
    "            print(bertpooler_output.shape, feat.shape)\n",
    "            raise ValueError()\n",
    "        assert feat_concat.shape[-1] == self._decoder_input_size\n",
    "        feat_concat = self.dropout1(feat_concat)\n",
    "        # feat_concat = self.dropout_decoder(feat_concat)\n",
    "        linear1_output = self.relation_decoder(feat_concat)\n",
    "        return linear1_output\n",
    "\n",
    "    def compute_pooler_similarity(self):\n",
    "        cur = self.encoder.pooler.dense.weight\n",
    "        pre = self.pooler_weight\n",
    "        print('self.pooler_weight')\n",
    "        print(cur)\n",
    "        assert not torch.all(cur.eq(pre))\n",
    "        for metric in self.history_outerpooler.keys():\n",
    "            self.history_outerpooler[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.pooler_weight = copy.deepcopy(self.encoder.pooler.dense.weight)\n",
    "\n",
    "        cur = self.embedder.transformer_model.pooler.dense.weight\n",
    "        pre = self.innerpooler_weight\n",
    "        print('self.innerpooler_weight')\n",
    "        print(cur)\n",
    "        for metric in self.history_innerpooler.keys():\n",
    "            self.history_innerpooler[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.innerpooler_weight = copy.deepcopy(self.embedder.transformer_model.pooler.dense.weight)\n",
    "\n",
    "        cur = self.embedder.transformer_model.encoder.layer[11].output.dense.weight\n",
    "        pre = self.transformerlayer_weight\n",
    "        print('self.transformerlayer_weight')\n",
    "        print(cur)\n",
    "        assert not torch.all(cur.eq(pre))\n",
    "        for metric in self.history_transformerlayer.keys():\n",
    "            self.history_transformerlayer[metric].append(self.similarity(cur, pre, metric))\n",
    "        self.transformerlayer_weight = copy.deepcopy(self.embedder.transformer_model.encoder.layer[11].output.dense.weight)\n",
    "\n",
    "    def similarity(self, cur, pre, metric_name):\n",
    "        metric = 0\n",
    "        n = 0\n",
    "        A = copy.deepcopy(cur)\n",
    "        B = copy.deepcopy(pre)\n",
    "        A = cur.cpu().detach().numpy().ravel()\n",
    "        B = B.cpu().detach().numpy().ravel()\n",
    "        for A, B in zip(A, B):\n",
    "            cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "            euclid = np.linalg.norm(A - B) #Frobenius norm\n",
    "            if metric_name=='cos': metric+= cosine\n",
    "            elif metric_name=='l2': metric+= euclid\n",
    "            n+=1\n",
    "        del A, B\n",
    "        return float(metric)/float(n), metric\n",
    "\n",
    "    def create_bert_without_activations(self):\n",
    "        config = BertConfig.from_pretrained(BERT_MODEL, hidden_act='gelu')\n",
    "        bert = BertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "        return bert\n",
    "\n",
    "    def create_featureful_bert(self):\n",
    "        featureful_bert = FeaturefulBertEmbedder(model_name = BERT_MODEL,\n",
    "                                hidden_activation_allen = 'gelu',\n",
    "                                feature_list = self.feature_list, \n",
    "                                vocab=mnli_dataset.vocab)\n",
    "        return featureful_bert\n",
    "\n",
    "    def convert_to_feature_list(self, feat):\n",
    "        feature_linear = [feat[feature_name] for feature_name in self.feature_list]\n",
    "        feature_linear = torch.stack(feature_linear, dim=-1)\n",
    "        return feature_linear\n",
    "        \n",
    "\n",
    "model = CustomBERTModel(mnli_dataset.num_labels, mnli_dataset.vocab)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6, correct_bias=False) # original 2e-5\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, mode='max', patience=35, min_lr=5e-7, verbose=True) #original factor=0.6, min_lr=5e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prinintg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomBERTModel(\n",
      "  (embedder): FeaturefulBertEmbedder(\n",
      "    (transformer_model): FeaturefulBert(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "      (feature_modules): ModuleDict(\n",
      "        (distance): Embedding(5, 3, padding_idx=0)\n",
      "        (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "        (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "        (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "        (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "        (sat_children): Identity()\n",
      "        (nuc_children): Identity()\n",
      "      )\n",
      "      (feature_projector): Linear(in_features=25, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): CustomPooler2(\n",
      "    (_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (module1): MyModule(\n",
      "    (feature_modules): ModuleDict(\n",
      "      (distance): Embedding(5, 3, padding_idx=0)\n",
      "      (u1_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_depdir): Embedding(5, 3, padding_idx=0)\n",
      "      (u2_func): Embedding(23, 5, padding_idx=0)\n",
      "      (u1_position): Embedding(12, 4, padding_idx=0)\n",
      "      (u2_position): Embedding(12, 4, padding_idx=0)\n",
      "      (sat_children): Identity()\n",
      "      (nuc_children): Identity()\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.0, inplace=False)\n",
      "  (relation_decoder): Linear(in_features=792, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['events.out.tfevents.1671162956.57e5cab0c4d9.13864.0']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def writer_init(save_path_suffix):\n",
    "    writer_path = 'run1/'+save_path_suffix[:-1]+'/'\n",
    "    if os.path.isdir(writer_path):\n",
    "        filelist = [ f for f in os.listdir(writer_path) if 'events.out' in f ]\n",
    "        print(filelist)\n",
    "        for f in filelist:\n",
    "            os.remove(os.path.join(writer_path, f))\n",
    "    else:\n",
    "        os.mkdir(writer_path)\n",
    "    writer = SummaryWriter(log_dir=writer_path)\n",
    "    return writer\n",
    "\n",
    "writer = writer_init(save_path_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFIED\n",
    "import time\n",
    "import traceback\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, Iterable, Dict, Any\n",
    "from EarlyStopperUtil import MetricTracker\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict):  \n",
    "  EarlyStopper = MetricTracker(patience=12, metric_name='+accuracy')\n",
    "  best_val_acc = 0\n",
    "\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    \n",
    "    # logging for scheduler\n",
    "    losses = []\n",
    "    accuracies= []\n",
    "\n",
    "    train_size = 0\n",
    "\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, feat, y, idx) in enumerate(train_loader):\n",
    "      train_size+=1\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # feat = feat.to(device)\n",
    "      outputs = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids,\n",
    "                            feat=feat)\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      acc = multi_acc(outputs, labels)\n",
    "      optimizer.step()\n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "      losses.append(loss)\n",
    "      accuracies.append(acc)\n",
    "      \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "\n",
    "    val_acc, val_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, val_loader, rev_label_dict, label_dict, None)\n",
    "    if val_acc>best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    if val_acc>=best_val_acc:\n",
    "      torch.save(model.state_dict(), save_path_suffix+'_best_latest.pt')\n",
    "      best_val_acc = val_acc\n",
    "      print(f'Epoch {epoch+1}: Best val_acc: {best_val_acc:.4f}')\n",
    "    EarlyStopper.add_metric(val_acc)\n",
    "    if EarlyStopper.should_stop_early(): break\n",
    "\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    print(f'train_size: {train_size}')\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val_loss', val_loss, epoch)\n",
    "    writer.add_scalar('val_acc', val_acc, epoch)\n",
    "\n",
    "    model.compute_pooler_similarity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Best val_acc: 0.1352\n",
      "Epoch 1: Best val_acc: 0.1352\n",
      "Epoch 1: train_loss: 3.0063 train_acc: 0.1273 | val_loss: 2.7424 val_acc: 0.1352\n",
      "00:00:16.48\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0419,  0.0082,  0.0120,  ...,  0.0006, -0.0078, -0.0989],\n",
      "        [ 0.0131,  0.0051,  0.0155,  ..., -0.0031,  0.0097, -0.0132],\n",
      "        [-0.0177,  0.0173, -0.0045,  ...,  0.0210, -0.0204, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0162,  0.0061,  ...,  0.0093, -0.0018,  0.0119],\n",
      "        [ 0.0875, -0.0188,  0.0053,  ...,  0.0104, -0.0170,  0.0195],\n",
      "        [ 0.0239,  0.0014, -0.0048,  ...,  0.0059,  0.0230,  0.0118]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0245, -0.1000,  0.0363,  ...,  0.0118, -0.0203,  0.0078],\n",
      "        [ 0.0212,  0.0125, -0.0101,  ..., -0.0124,  0.0436,  0.0559],\n",
      "        [ 0.0212,  0.0402, -0.0246,  ...,  0.0171,  0.0337,  0.0045],\n",
      "        ...,\n",
      "        [-0.0154, -0.0277, -0.0472,  ..., -0.0366,  0.0163, -0.0937],\n",
      "        [-0.0301, -0.0362,  0.0797,  ..., -0.0322, -0.0595,  0.0294],\n",
      "        [ 0.0021, -0.0483,  0.0048,  ...,  0.0474,  0.0396,  0.0101]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 2: Best val_acc: 0.2049\n",
      "Epoch 2: Best val_acc: 0.2049\n",
      "Epoch 2: train_loss: 2.6504 train_acc: 0.1841 | val_loss: 2.5074 val_acc: 0.2049\n",
      "00:00:09.31\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0419,  0.0082,  0.0124,  ...,  0.0005, -0.0076, -0.0986],\n",
      "        [ 0.0128,  0.0050,  0.0155,  ..., -0.0032,  0.0096, -0.0132],\n",
      "        [-0.0180,  0.0175, -0.0044,  ...,  0.0213, -0.0202, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0162,  0.0061,  ...,  0.0094, -0.0019,  0.0120],\n",
      "        [ 0.0870, -0.0189,  0.0053,  ...,  0.0105, -0.0169,  0.0196],\n",
      "        [ 0.0242,  0.0013, -0.0046,  ...,  0.0056,  0.0231,  0.0119]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.0998,  0.0366,  ...,  0.0117, -0.0202,  0.0079],\n",
      "        [ 0.0212,  0.0126, -0.0102,  ..., -0.0126,  0.0438,  0.0559],\n",
      "        [ 0.0214,  0.0399, -0.0248,  ...,  0.0169,  0.0337,  0.0045],\n",
      "        ...,\n",
      "        [-0.0154, -0.0280, -0.0477,  ..., -0.0367,  0.0162, -0.0939],\n",
      "        [-0.0300, -0.0363,  0.0793,  ..., -0.0324, -0.0592,  0.0295],\n",
      "        [ 0.0022, -0.0486,  0.0049,  ...,  0.0476,  0.0395,  0.0101]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 3: Best val_acc: 0.2295\n",
      "Epoch 3: Best val_acc: 0.2295\n",
      "Epoch 3: train_loss: 2.4853 train_acc: 0.2341 | val_loss: 2.4250 val_acc: 0.2295\n",
      "00:00:12.35\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0421,  0.0082,  0.0122,  ...,  0.0007, -0.0074, -0.0984],\n",
      "        [ 0.0128,  0.0050,  0.0155,  ..., -0.0032,  0.0095, -0.0133],\n",
      "        [-0.0181,  0.0176, -0.0042,  ...,  0.0215, -0.0202, -0.0039],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0162,  0.0062,  ...,  0.0094, -0.0020,  0.0118],\n",
      "        [ 0.0868, -0.0189,  0.0051,  ...,  0.0105, -0.0169,  0.0197],\n",
      "        [ 0.0244,  0.0013, -0.0046,  ...,  0.0055,  0.0232,  0.0119]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0245, -0.0999,  0.0365,  ...,  0.0116, -0.0204,  0.0079],\n",
      "        [ 0.0212,  0.0127, -0.0101,  ..., -0.0125,  0.0439,  0.0560],\n",
      "        [ 0.0213,  0.0400, -0.0248,  ...,  0.0169,  0.0336,  0.0044],\n",
      "        ...,\n",
      "        [-0.0155, -0.0280, -0.0477,  ..., -0.0367,  0.0162, -0.0940],\n",
      "        [-0.0300, -0.0362,  0.0794,  ..., -0.0325, -0.0592,  0.0295],\n",
      "        [ 0.0022, -0.0487,  0.0049,  ...,  0.0476,  0.0395,  0.0101]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 4: Best val_acc: 0.2869\n",
      "Epoch 4: Best val_acc: 0.2869\n",
      "Epoch 4: train_loss: 2.4026 train_acc: 0.2568 | val_loss: 2.3202 val_acc: 0.2869\n",
      "00:00:10.58\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0420,  0.0081,  0.0123,  ...,  0.0007, -0.0075, -0.0984],\n",
      "        [ 0.0128,  0.0049,  0.0155,  ..., -0.0032,  0.0094, -0.0133],\n",
      "        [-0.0181,  0.0177, -0.0042,  ...,  0.0217, -0.0202, -0.0039],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0161,  0.0061,  ...,  0.0094, -0.0020,  0.0118],\n",
      "        [ 0.0869, -0.0187,  0.0053,  ...,  0.0107, -0.0170,  0.0195],\n",
      "        [ 0.0244,  0.0012, -0.0045,  ...,  0.0054,  0.0233,  0.0120]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0246, -0.0999,  0.0363,  ...,  0.0116, -0.0203,  0.0078],\n",
      "        [ 0.0212,  0.0128, -0.0101,  ..., -0.0125,  0.0439,  0.0561],\n",
      "        [ 0.0213,  0.0400, -0.0248,  ...,  0.0169,  0.0335,  0.0044],\n",
      "        ...,\n",
      "        [-0.0155, -0.0279, -0.0477,  ..., -0.0366,  0.0161, -0.0940],\n",
      "        [-0.0302, -0.0362,  0.0794,  ..., -0.0325, -0.0593,  0.0294],\n",
      "        [ 0.0021, -0.0488,  0.0048,  ...,  0.0475,  0.0393,  0.0100]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 5: train_loss: 2.1928 train_acc: 0.3295 | val_loss: 2.3017 val_acc: 0.2828\n",
      "00:00:08.82\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0420,  0.0079,  0.0123,  ...,  0.0007, -0.0074, -0.0982],\n",
      "        [ 0.0128,  0.0049,  0.0155,  ..., -0.0032,  0.0093, -0.0134],\n",
      "        [-0.0183,  0.0178, -0.0042,  ...,  0.0217, -0.0201, -0.0041],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0161,  0.0061,  ...,  0.0094, -0.0021,  0.0115],\n",
      "        [ 0.0868, -0.0186,  0.0052,  ...,  0.0107, -0.0171,  0.0194],\n",
      "        [ 0.0246,  0.0013, -0.0045,  ...,  0.0055,  0.0235,  0.0122]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0247, -0.0999,  0.0362,  ...,  0.0116, -0.0203,  0.0076],\n",
      "        [ 0.0211,  0.0128, -0.0102,  ..., -0.0125,  0.0439,  0.0560],\n",
      "        [ 0.0213,  0.0401, -0.0249,  ...,  0.0169,  0.0337,  0.0044],\n",
      "        ...,\n",
      "        [-0.0155, -0.0279, -0.0478,  ..., -0.0366,  0.0161, -0.0940],\n",
      "        [-0.0303, -0.0360,  0.0793,  ..., -0.0326, -0.0593,  0.0293],\n",
      "        [ 0.0021, -0.0489,  0.0048,  ...,  0.0474,  0.0391,  0.0101]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 6: Best val_acc: 0.3115\n",
      "Epoch 6: Best val_acc: 0.3115\n",
      "Epoch 6: train_loss: 2.1660 train_acc: 0.4136 | val_loss: 2.2365 val_acc: 0.3115\n",
      "00:00:15.88\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0422,  0.0079,  0.0122,  ...,  0.0006, -0.0074, -0.0982],\n",
      "        [ 0.0126,  0.0049,  0.0154,  ..., -0.0032,  0.0093, -0.0134],\n",
      "        [-0.0184,  0.0178, -0.0042,  ...,  0.0218, -0.0200, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0149,  0.0161,  0.0061,  ...,  0.0094, -0.0022,  0.0116],\n",
      "        [ 0.0868, -0.0186,  0.0051,  ...,  0.0107, -0.0171,  0.0193],\n",
      "        [ 0.0247,  0.0012, -0.0045,  ...,  0.0054,  0.0235,  0.0122]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0247, -0.0998,  0.0361,  ...,  0.0116, -0.0202,  0.0076],\n",
      "        [ 0.0212,  0.0128, -0.0100,  ..., -0.0125,  0.0441,  0.0560],\n",
      "        [ 0.0212,  0.0401, -0.0248,  ...,  0.0168,  0.0337,  0.0044],\n",
      "        ...,\n",
      "        [-0.0155, -0.0277, -0.0480,  ..., -0.0366,  0.0161, -0.0938],\n",
      "        [-0.0303, -0.0360,  0.0792,  ..., -0.0326, -0.0593,  0.0293],\n",
      "        [ 0.0021, -0.0490,  0.0049,  ...,  0.0474,  0.0389,  0.0101]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 7: Best val_acc: 0.3361\n",
      "Epoch 7: Best val_acc: 0.3361\n",
      "Epoch 7: train_loss: 2.2060 train_acc: 0.3614 | val_loss: 2.1722 val_acc: 0.3361\n",
      "00:00:27.76\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0423,  0.0079,  0.0122,  ...,  0.0005, -0.0074, -0.0981],\n",
      "        [ 0.0124,  0.0048,  0.0154,  ..., -0.0031,  0.0092, -0.0134],\n",
      "        [-0.0184,  0.0178, -0.0041,  ...,  0.0219, -0.0201, -0.0041],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0161,  0.0061,  ...,  0.0095, -0.0022,  0.0115],\n",
      "        [ 0.0868, -0.0185,  0.0051,  ...,  0.0107, -0.0171,  0.0192],\n",
      "        [ 0.0248,  0.0012, -0.0045,  ...,  0.0053,  0.0237,  0.0123]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0246, -0.0999,  0.0358,  ...,  0.0116, -0.0201,  0.0076],\n",
      "        [ 0.0213,  0.0129, -0.0102,  ..., -0.0125,  0.0441,  0.0561],\n",
      "        [ 0.0212,  0.0402, -0.0249,  ...,  0.0169,  0.0337,  0.0044],\n",
      "        ...,\n",
      "        [-0.0155, -0.0276, -0.0479,  ..., -0.0365,  0.0161, -0.0938],\n",
      "        [-0.0303, -0.0360,  0.0792,  ..., -0.0325, -0.0593,  0.0293],\n",
      "        [ 0.0021, -0.0490,  0.0050,  ...,  0.0474,  0.0388,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 8: Best val_acc: 0.3689\n",
      "Epoch 8: Best val_acc: 0.3689\n",
      "Epoch 8: train_loss: 2.1175 train_acc: 0.3682 | val_loss: 2.1012 val_acc: 0.3689\n",
      "00:00:29.06\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0424,  0.0079,  0.0121,  ...,  0.0003, -0.0074, -0.0981],\n",
      "        [ 0.0123,  0.0048,  0.0153,  ..., -0.0031,  0.0091, -0.0133],\n",
      "        [-0.0185,  0.0179, -0.0040,  ...,  0.0219, -0.0202, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0160,  0.0062,  ...,  0.0095, -0.0022,  0.0114],\n",
      "        [ 0.0869, -0.0185,  0.0051,  ...,  0.0107, -0.0172,  0.0192],\n",
      "        [ 0.0248,  0.0012, -0.0045,  ...,  0.0054,  0.0237,  0.0123]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0246, -0.0998,  0.0359,  ...,  0.0118, -0.0200,  0.0076],\n",
      "        [ 0.0213,  0.0129, -0.0101,  ..., -0.0125,  0.0440,  0.0561],\n",
      "        [ 0.0211,  0.0402, -0.0247,  ...,  0.0168,  0.0337,  0.0044],\n",
      "        ...,\n",
      "        [-0.0155, -0.0275, -0.0479,  ..., -0.0365,  0.0162, -0.0938],\n",
      "        [-0.0303, -0.0359,  0.0792,  ..., -0.0325, -0.0593,  0.0293],\n",
      "        [ 0.0021, -0.0492,  0.0050,  ...,  0.0473,  0.0387,  0.0101]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 9: train_loss: 2.0281 train_acc: 0.3818 | val_loss: 2.1036 val_acc: 0.3566\n",
      "00:00:08.29\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0424,  0.0079,  0.0120,  ...,  0.0002, -0.0074, -0.0981],\n",
      "        [ 0.0122,  0.0048,  0.0153,  ..., -0.0032,  0.0090, -0.0134],\n",
      "        [-0.0185,  0.0180, -0.0039,  ...,  0.0219, -0.0203, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0161,  0.0062,  ...,  0.0095, -0.0022,  0.0113],\n",
      "        [ 0.0870, -0.0185,  0.0052,  ...,  0.0108, -0.0173,  0.0192],\n",
      "        [ 0.0248,  0.0013, -0.0045,  ...,  0.0053,  0.0239,  0.0124]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0246, -0.0999,  0.0358,  ...,  0.0116, -0.0200,  0.0076],\n",
      "        [ 0.0212,  0.0129, -0.0100,  ..., -0.0125,  0.0440,  0.0560],\n",
      "        [ 0.0212,  0.0404, -0.0246,  ...,  0.0169,  0.0339,  0.0045],\n",
      "        ...,\n",
      "        [-0.0156, -0.0273, -0.0479,  ..., -0.0365,  0.0161, -0.0938],\n",
      "        [-0.0304, -0.0358,  0.0793,  ..., -0.0326, -0.0593,  0.0292],\n",
      "        [ 0.0022, -0.0493,  0.0049,  ...,  0.0472,  0.0386,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 10: train_loss: 1.8753 train_acc: 0.4932 | val_loss: 2.0622 val_acc: 0.3566\n",
      "00:00:08.24\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0425,  0.0079,  0.0119,  ...,  0.0002, -0.0075, -0.0980],\n",
      "        [ 0.0121,  0.0048,  0.0154,  ..., -0.0032,  0.0089, -0.0133],\n",
      "        [-0.0185,  0.0180, -0.0039,  ...,  0.0220, -0.0203, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0160,  0.0062,  ...,  0.0095, -0.0022,  0.0113],\n",
      "        [ 0.0872, -0.0184,  0.0052,  ...,  0.0108, -0.0172,  0.0190],\n",
      "        [ 0.0248,  0.0013, -0.0044,  ...,  0.0053,  0.0239,  0.0125]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0245, -0.0999,  0.0357,  ...,  0.0117, -0.0199,  0.0077],\n",
      "        [ 0.0213,  0.0128, -0.0101,  ..., -0.0125,  0.0441,  0.0560],\n",
      "        [ 0.0212,  0.0404, -0.0245,  ...,  0.0168,  0.0339,  0.0045],\n",
      "        ...,\n",
      "        [-0.0156, -0.0273, -0.0479,  ..., -0.0365,  0.0162, -0.0939],\n",
      "        [-0.0305, -0.0358,  0.0793,  ..., -0.0326, -0.0594,  0.0291],\n",
      "        [ 0.0021, -0.0494,  0.0049,  ...,  0.0472,  0.0385,  0.0101]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 11: Best val_acc: 0.3730\n",
      "Epoch 11: Best val_acc: 0.3730\n",
      "Epoch 11: train_loss: 1.8444 train_acc: 0.4932 | val_loss: 2.0854 val_acc: 0.3730\n",
      "00:00:11.24\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0426,  0.0079,  0.0119,  ...,  0.0001, -0.0075, -0.0979],\n",
      "        [ 0.0120,  0.0048,  0.0152,  ..., -0.0032,  0.0088, -0.0134],\n",
      "        [-0.0184,  0.0180, -0.0040,  ...,  0.0220, -0.0203, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0161,  0.0063,  ...,  0.0096, -0.0022,  0.0113],\n",
      "        [ 0.0872, -0.0183,  0.0051,  ...,  0.0108, -0.0173,  0.0190],\n",
      "        [ 0.0248,  0.0013, -0.0044,  ...,  0.0053,  0.0239,  0.0126]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0245, -0.1000,  0.0356,  ...,  0.0117, -0.0199,  0.0077],\n",
      "        [ 0.0214,  0.0128, -0.0101,  ..., -0.0124,  0.0441,  0.0561],\n",
      "        [ 0.0211,  0.0405, -0.0244,  ...,  0.0170,  0.0339,  0.0045],\n",
      "        ...,\n",
      "        [-0.0155, -0.0272, -0.0480,  ..., -0.0364,  0.0163, -0.0937],\n",
      "        [-0.0305, -0.0358,  0.0795,  ..., -0.0325, -0.0594,  0.0292],\n",
      "        [ 0.0021, -0.0493,  0.0049,  ...,  0.0472,  0.0385,  0.0103]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 12: train_loss: 1.7965 train_acc: 0.4795 | val_loss: 2.0427 val_acc: 0.3648\n",
      "00:00:08.82\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0427,  0.0078,  0.0118,  ..., -0.0001, -0.0076, -0.0980],\n",
      "        [ 0.0119,  0.0048,  0.0152,  ..., -0.0032,  0.0088, -0.0134],\n",
      "        [-0.0184,  0.0182, -0.0039,  ...,  0.0221, -0.0203, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0162,  0.0064,  ...,  0.0096, -0.0022,  0.0112],\n",
      "        [ 0.0872, -0.0183,  0.0051,  ...,  0.0108, -0.0173,  0.0190],\n",
      "        [ 0.0248,  0.0013, -0.0045,  ...,  0.0052,  0.0240,  0.0126]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1000,  0.0355,  ...,  0.0116, -0.0198,  0.0077],\n",
      "        [ 0.0213,  0.0130, -0.0100,  ..., -0.0123,  0.0441,  0.0560],\n",
      "        [ 0.0211,  0.0404, -0.0244,  ...,  0.0170,  0.0338,  0.0044],\n",
      "        ...,\n",
      "        [-0.0155, -0.0273, -0.0480,  ..., -0.0364,  0.0162, -0.0938],\n",
      "        [-0.0305, -0.0356,  0.0796,  ..., -0.0325, -0.0595,  0.0291],\n",
      "        [ 0.0021, -0.0495,  0.0049,  ...,  0.0471,  0.0383,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 13: Best val_acc: 0.3730\n",
      "Epoch 13: train_loss: 1.7340 train_acc: 0.5159 | val_loss: 1.9706 val_acc: 0.3730\n",
      "00:00:08.70\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0427,  0.0077,  0.0118,  ..., -0.0001, -0.0075, -0.0980],\n",
      "        [ 0.0119,  0.0048,  0.0152,  ..., -0.0031,  0.0088, -0.0133],\n",
      "        [-0.0184,  0.0182, -0.0038,  ...,  0.0222, -0.0203, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0162,  0.0064,  ...,  0.0096, -0.0022,  0.0110],\n",
      "        [ 0.0872, -0.0183,  0.0052,  ...,  0.0108, -0.0173,  0.0191],\n",
      "        [ 0.0248,  0.0012, -0.0046,  ...,  0.0052,  0.0240,  0.0126]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0244, -0.1000,  0.0354,  ...,  0.0117, -0.0197,  0.0078],\n",
      "        [ 0.0213,  0.0130, -0.0100,  ..., -0.0124,  0.0440,  0.0560],\n",
      "        [ 0.0211,  0.0404, -0.0244,  ...,  0.0169,  0.0340,  0.0045],\n",
      "        ...,\n",
      "        [-0.0154, -0.0271, -0.0481,  ..., -0.0365,  0.0162, -0.0938],\n",
      "        [-0.0305, -0.0355,  0.0795,  ..., -0.0325, -0.0594,  0.0292],\n",
      "        [ 0.0021, -0.0496,  0.0049,  ...,  0.0470,  0.0382,  0.0101]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 14: train_loss: 1.6697 train_acc: 0.5136 | val_loss: 1.9833 val_acc: 0.3648\n",
      "00:00:07.61\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0427,  0.0077,  0.0117,  ..., -0.0003, -0.0077, -0.0980],\n",
      "        [ 0.0117,  0.0047,  0.0151,  ..., -0.0031,  0.0088, -0.0133],\n",
      "        [-0.0185,  0.0183, -0.0037,  ...,  0.0222, -0.0203, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0162,  0.0065,  ...,  0.0096, -0.0022,  0.0110],\n",
      "        [ 0.0872, -0.0183,  0.0051,  ...,  0.0109, -0.0174,  0.0190],\n",
      "        [ 0.0249,  0.0012, -0.0046,  ...,  0.0051,  0.0240,  0.0127]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0243, -0.0999,  0.0354,  ...,  0.0118, -0.0196,  0.0080],\n",
      "        [ 0.0214,  0.0131, -0.0100,  ..., -0.0124,  0.0441,  0.0560],\n",
      "        [ 0.0211,  0.0404, -0.0244,  ...,  0.0169,  0.0340,  0.0045],\n",
      "        ...,\n",
      "        [-0.0154, -0.0270, -0.0481,  ..., -0.0364,  0.0163, -0.0938],\n",
      "        [-0.0305, -0.0354,  0.0794,  ..., -0.0326, -0.0594,  0.0293],\n",
      "        [ 0.0021, -0.0496,  0.0049,  ...,  0.0470,  0.0382,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 15: Best val_acc: 0.3730\n",
      "Epoch 15: train_loss: 1.5549 train_acc: 0.5773 | val_loss: 1.9868 val_acc: 0.3730\n",
      "00:00:08.82\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0428,  0.0077,  0.0117,  ..., -0.0003, -0.0077, -0.0980],\n",
      "        [ 0.0116,  0.0047,  0.0151,  ..., -0.0031,  0.0089, -0.0131],\n",
      "        [-0.0186,  0.0183, -0.0036,  ...,  0.0222, -0.0203, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0162,  0.0066,  ...,  0.0096, -0.0022,  0.0111],\n",
      "        [ 0.0872, -0.0183,  0.0051,  ...,  0.0109, -0.0173,  0.0191],\n",
      "        [ 0.0250,  0.0012, -0.0045,  ...,  0.0051,  0.0241,  0.0127]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.0999,  0.0353,  ...,  0.0118, -0.0195,  0.0081],\n",
      "        [ 0.0213,  0.0130, -0.0099,  ..., -0.0125,  0.0440,  0.0558],\n",
      "        [ 0.0211,  0.0403, -0.0243,  ...,  0.0169,  0.0340,  0.0044],\n",
      "        ...,\n",
      "        [-0.0154, -0.0271, -0.0480,  ..., -0.0364,  0.0162, -0.0938],\n",
      "        [-0.0306, -0.0353,  0.0795,  ..., -0.0325, -0.0594,  0.0293],\n",
      "        [ 0.0022, -0.0497,  0.0047,  ...,  0.0469,  0.0383,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 16: Best val_acc: 0.4180\n",
      "Epoch 16: Best val_acc: 0.4180\n",
      "Epoch 16: train_loss: 1.4469 train_acc: 0.6295 | val_loss: 1.9404 val_acc: 0.4180\n",
      "00:00:10.99\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0077,  0.0116,  ..., -0.0004, -0.0077, -0.0979],\n",
      "        [ 0.0115,  0.0047,  0.0150,  ..., -0.0031,  0.0088, -0.0131],\n",
      "        [-0.0187,  0.0184, -0.0036,  ...,  0.0223, -0.0203, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0152,  0.0162,  0.0067,  ...,  0.0096, -0.0023,  0.0110],\n",
      "        [ 0.0872, -0.0183,  0.0050,  ...,  0.0109, -0.0174,  0.0191],\n",
      "        [ 0.0249,  0.0013, -0.0046,  ...,  0.0051,  0.0241,  0.0127]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0242, -0.0999,  0.0352,  ...,  0.0119, -0.0195,  0.0082],\n",
      "        [ 0.0213,  0.0130, -0.0100,  ..., -0.0124,  0.0441,  0.0558],\n",
      "        [ 0.0211,  0.0404, -0.0242,  ...,  0.0169,  0.0341,  0.0045],\n",
      "        ...,\n",
      "        [-0.0154, -0.0270, -0.0481,  ..., -0.0363,  0.0163, -0.0937],\n",
      "        [-0.0306, -0.0352,  0.0795,  ..., -0.0325, -0.0594,  0.0294],\n",
      "        [ 0.0021, -0.0497,  0.0048,  ...,  0.0469,  0.0381,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 17: Best val_acc: 0.4221\n",
      "Epoch 17: Best val_acc: 0.4221\n",
      "Epoch 17: train_loss: 1.4874 train_acc: 0.6045 | val_loss: 1.9011 val_acc: 0.4221\n",
      "00:00:10.52\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0076,  0.0115,  ..., -0.0004, -0.0078, -0.0979],\n",
      "        [ 0.0113,  0.0047,  0.0150,  ..., -0.0032,  0.0088, -0.0132],\n",
      "        [-0.0188,  0.0185, -0.0035,  ...,  0.0223, -0.0203, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0162,  0.0068,  ...,  0.0096, -0.0023,  0.0109],\n",
      "        [ 0.0872, -0.0182,  0.0051,  ...,  0.0108, -0.0173,  0.0191],\n",
      "        [ 0.0250,  0.0012, -0.0047,  ...,  0.0051,  0.0241,  0.0129]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0241, -0.0999,  0.0352,  ...,  0.0120, -0.0194,  0.0082],\n",
      "        [ 0.0213,  0.0131, -0.0100,  ..., -0.0126,  0.0440,  0.0559],\n",
      "        [ 0.0211,  0.0403, -0.0242,  ...,  0.0168,  0.0340,  0.0045],\n",
      "        ...,\n",
      "        [-0.0153, -0.0270, -0.0482,  ..., -0.0363,  0.0163, -0.0937],\n",
      "        [-0.0306, -0.0351,  0.0795,  ..., -0.0325, -0.0595,  0.0294],\n",
      "        [ 0.0022, -0.0497,  0.0048,  ...,  0.0468,  0.0382,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 18: train_loss: 1.4239 train_acc: 0.6159 | val_loss: 1.9716 val_acc: 0.4139\n",
      "00:00:08.18\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0075,  0.0115,  ..., -0.0005, -0.0079, -0.0979],\n",
      "        [ 0.0112,  0.0047,  0.0149,  ..., -0.0031,  0.0087, -0.0132],\n",
      "        [-0.0188,  0.0185, -0.0035,  ...,  0.0223, -0.0203, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0152,  0.0162,  0.0068,  ...,  0.0096, -0.0022,  0.0109],\n",
      "        [ 0.0873, -0.0181,  0.0050,  ...,  0.0108, -0.0174,  0.0191],\n",
      "        [ 0.0250,  0.0012, -0.0047,  ...,  0.0050,  0.0241,  0.0129]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0240, -0.1000,  0.0352,  ...,  0.0120, -0.0194,  0.0082],\n",
      "        [ 0.0213,  0.0131, -0.0100,  ..., -0.0126,  0.0440,  0.0559],\n",
      "        [ 0.0211,  0.0404, -0.0241,  ...,  0.0168,  0.0340,  0.0044],\n",
      "        ...,\n",
      "        [-0.0153, -0.0270, -0.0482,  ..., -0.0364,  0.0163, -0.0937],\n",
      "        [-0.0306, -0.0351,  0.0795,  ..., -0.0325, -0.0595,  0.0294],\n",
      "        [ 0.0022, -0.0498,  0.0048,  ...,  0.0468,  0.0382,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 19: train_loss: 1.3855 train_acc: 0.6318 | val_loss: 1.9088 val_acc: 0.3893\n",
      "00:00:08.45\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0075,  0.0115,  ..., -0.0006, -0.0080, -0.0979],\n",
      "        [ 0.0111,  0.0047,  0.0148,  ..., -0.0031,  0.0087, -0.0131],\n",
      "        [-0.0189,  0.0186, -0.0035,  ...,  0.0223, -0.0202, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0162,  0.0069,  ...,  0.0096, -0.0022,  0.0108],\n",
      "        [ 0.0873, -0.0181,  0.0050,  ...,  0.0108, -0.0174,  0.0190],\n",
      "        [ 0.0250,  0.0012, -0.0047,  ...,  0.0050,  0.0241,  0.0130]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0239, -0.1000,  0.0351,  ...,  0.0120, -0.0193,  0.0083],\n",
      "        [ 0.0213,  0.0132, -0.0100,  ..., -0.0126,  0.0440,  0.0559],\n",
      "        [ 0.0212,  0.0404, -0.0240,  ...,  0.0168,  0.0342,  0.0045],\n",
      "        ...,\n",
      "        [-0.0153, -0.0269, -0.0482,  ..., -0.0363,  0.0164, -0.0937],\n",
      "        [-0.0306, -0.0350,  0.0795,  ..., -0.0325, -0.0595,  0.0294],\n",
      "        [ 0.0022, -0.0499,  0.0048,  ...,  0.0468,  0.0381,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 20: train_loss: 1.2214 train_acc: 0.6932 | val_loss: 1.9305 val_acc: 0.4098\n",
      "00:00:08.77\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0074,  0.0115,  ..., -0.0006, -0.0081, -0.0980],\n",
      "        [ 0.0109,  0.0046,  0.0148,  ..., -0.0031,  0.0086, -0.0130],\n",
      "        [-0.0189,  0.0186, -0.0035,  ...,  0.0224, -0.0203, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0152,  0.0162,  0.0069,  ...,  0.0096, -0.0021,  0.0107],\n",
      "        [ 0.0873, -0.0181,  0.0050,  ...,  0.0108, -0.0175,  0.0191],\n",
      "        [ 0.0251,  0.0011, -0.0047,  ...,  0.0050,  0.0241,  0.0131]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0239, -0.1000,  0.0351,  ...,  0.0119, -0.0192,  0.0083],\n",
      "        [ 0.0213,  0.0132, -0.0100,  ..., -0.0127,  0.0439,  0.0559],\n",
      "        [ 0.0212,  0.0404, -0.0239,  ...,  0.0168,  0.0341,  0.0045],\n",
      "        ...,\n",
      "        [-0.0152, -0.0268, -0.0481,  ..., -0.0362,  0.0163, -0.0937],\n",
      "        [-0.0307, -0.0349,  0.0795,  ..., -0.0324, -0.0596,  0.0294],\n",
      "        [ 0.0022, -0.0498,  0.0048,  ...,  0.0468,  0.0382,  0.0103]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 21: train_loss: 1.1828 train_acc: 0.6977 | val_loss: 1.9007 val_acc: 0.4139\n",
      "00:00:08.34\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0429,  0.0073,  0.0114,  ..., -0.0006, -0.0081, -0.0979],\n",
      "        [ 0.0108,  0.0046,  0.0148,  ..., -0.0030,  0.0086, -0.0130],\n",
      "        [-0.0189,  0.0187, -0.0035,  ...,  0.0224, -0.0203, -0.0041],\n",
      "        ...,\n",
      "        [ 0.0153,  0.0163,  0.0070,  ...,  0.0096, -0.0021,  0.0106],\n",
      "        [ 0.0873, -0.0181,  0.0050,  ...,  0.0108, -0.0175,  0.0191],\n",
      "        [ 0.0251,  0.0011, -0.0048,  ...,  0.0049,  0.0241,  0.0131]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0239, -0.1001,  0.0351,  ...,  0.0120, -0.0193,  0.0084],\n",
      "        [ 0.0213,  0.0133, -0.0100,  ..., -0.0127,  0.0439,  0.0558],\n",
      "        [ 0.0211,  0.0404, -0.0239,  ...,  0.0168,  0.0341,  0.0045],\n",
      "        ...,\n",
      "        [-0.0152, -0.0268, -0.0481,  ..., -0.0362,  0.0164, -0.0937],\n",
      "        [-0.0307, -0.0348,  0.0795,  ..., -0.0324, -0.0595,  0.0295],\n",
      "        [ 0.0022, -0.0498,  0.0047,  ...,  0.0467,  0.0381,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 22: train_loss: 1.1848 train_acc: 0.6750 | val_loss: 1.9575 val_acc: 0.3893\n",
      "00:00:08.43\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0431,  0.0073,  0.0114,  ..., -0.0007, -0.0082, -0.0978],\n",
      "        [ 0.0107,  0.0046,  0.0147,  ..., -0.0030,  0.0085, -0.0129],\n",
      "        [-0.0189,  0.0188, -0.0034,  ...,  0.0224, -0.0203, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0153,  0.0164,  0.0070,  ...,  0.0096, -0.0022,  0.0107],\n",
      "        [ 0.0873, -0.0181,  0.0050,  ...,  0.0108, -0.0176,  0.0191],\n",
      "        [ 0.0251,  0.0011, -0.0048,  ...,  0.0049,  0.0242,  0.0131]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0238, -0.1002,  0.0350,  ...,  0.0120, -0.0192,  0.0085],\n",
      "        [ 0.0212,  0.0133, -0.0100,  ..., -0.0127,  0.0438,  0.0558],\n",
      "        [ 0.0211,  0.0404, -0.0238,  ...,  0.0167,  0.0341,  0.0045],\n",
      "        ...,\n",
      "        [-0.0153, -0.0267, -0.0480,  ..., -0.0361,  0.0163, -0.0937],\n",
      "        [-0.0308, -0.0348,  0.0794,  ..., -0.0325, -0.0595,  0.0295],\n",
      "        [ 0.0022, -0.0498,  0.0048,  ...,  0.0467,  0.0380,  0.0103]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 23: train_loss: 1.1666 train_acc: 0.7114 | val_loss: 1.9464 val_acc: 0.3566\n",
      "00:00:08.48\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0431,  0.0072,  0.0113,  ..., -0.0007, -0.0084, -0.0978],\n",
      "        [ 0.0107,  0.0045,  0.0146,  ..., -0.0030,  0.0085, -0.0129],\n",
      "        [-0.0190,  0.0188, -0.0034,  ...,  0.0224, -0.0202, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0153,  0.0164,  0.0071,  ...,  0.0096, -0.0021,  0.0106],\n",
      "        [ 0.0873, -0.0181,  0.0050,  ...,  0.0108, -0.0176,  0.0191],\n",
      "        [ 0.0252,  0.0010, -0.0049,  ...,  0.0049,  0.0241,  0.0131]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0238, -0.1002,  0.0350,  ...,  0.0120, -0.0192,  0.0086],\n",
      "        [ 0.0212,  0.0134, -0.0100,  ..., -0.0127,  0.0439,  0.0558],\n",
      "        [ 0.0211,  0.0404, -0.0237,  ...,  0.0168,  0.0341,  0.0045],\n",
      "        ...,\n",
      "        [-0.0152, -0.0267, -0.0481,  ..., -0.0361,  0.0163, -0.0936],\n",
      "        [-0.0308, -0.0348,  0.0795,  ..., -0.0324, -0.0595,  0.0295],\n",
      "        [ 0.0022, -0.0498,  0.0048,  ...,  0.0468,  0.0380,  0.0102]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 24: train_loss: 1.0803 train_acc: 0.7205 | val_loss: 1.9336 val_acc: 0.4098\n",
      "00:00:07.87\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0072,  0.0113,  ..., -0.0007, -0.0085, -0.0977],\n",
      "        [ 0.0105,  0.0046,  0.0146,  ..., -0.0030,  0.0085, -0.0128],\n",
      "        [-0.0191,  0.0189, -0.0033,  ...,  0.0224, -0.0201, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0153,  0.0164,  0.0073,  ...,  0.0096, -0.0022,  0.0106],\n",
      "        [ 0.0872, -0.0181,  0.0049,  ...,  0.0108, -0.0175,  0.0191],\n",
      "        [ 0.0253,  0.0010, -0.0049,  ...,  0.0049,  0.0241,  0.0132]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0238, -0.1002,  0.0350,  ...,  0.0120, -0.0191,  0.0085],\n",
      "        [ 0.0212,  0.0134, -0.0101,  ..., -0.0128,  0.0440,  0.0558],\n",
      "        [ 0.0210,  0.0404, -0.0237,  ...,  0.0169,  0.0342,  0.0044],\n",
      "        ...,\n",
      "        [-0.0152, -0.0268, -0.0482,  ..., -0.0360,  0.0163, -0.0936],\n",
      "        [-0.0308, -0.0348,  0.0795,  ..., -0.0323, -0.0595,  0.0295],\n",
      "        [ 0.0023, -0.0498,  0.0047,  ...,  0.0468,  0.0380,  0.0103]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 25: train_loss: 0.8728 train_acc: 0.8136 | val_loss: 1.9038 val_acc: 0.4016\n",
      "00:00:08.20\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0431,  0.0071,  0.0112,  ..., -0.0007, -0.0085, -0.0977],\n",
      "        [ 0.0104,  0.0045,  0.0145,  ..., -0.0029,  0.0086, -0.0129],\n",
      "        [-0.0192,  0.0189, -0.0033,  ...,  0.0224, -0.0201, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0152,  0.0164,  0.0073,  ...,  0.0096, -0.0022,  0.0105],\n",
      "        [ 0.0873, -0.0181,  0.0049,  ...,  0.0107, -0.0175,  0.0192],\n",
      "        [ 0.0253,  0.0010, -0.0049,  ...,  0.0049,  0.0242,  0.0132]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0237, -0.1002,  0.0350,  ...,  0.0120, -0.0190,  0.0086],\n",
      "        [ 0.0213,  0.0133, -0.0101,  ..., -0.0127,  0.0440,  0.0558],\n",
      "        [ 0.0210,  0.0404, -0.0237,  ...,  0.0168,  0.0343,  0.0044],\n",
      "        ...,\n",
      "        [-0.0152, -0.0267, -0.0482,  ..., -0.0360,  0.0163, -0.0935],\n",
      "        [-0.0308, -0.0348,  0.0796,  ..., -0.0322, -0.0595,  0.0296],\n",
      "        [ 0.0023, -0.0498,  0.0047,  ...,  0.0467,  0.0380,  0.0103]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 26: train_loss: 0.8366 train_acc: 0.8318 | val_loss: 1.9216 val_acc: 0.4180\n",
      "00:00:08.14\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0431,  0.0071,  0.0113,  ..., -0.0008, -0.0086, -0.0977],\n",
      "        [ 0.0102,  0.0044,  0.0144,  ..., -0.0028,  0.0086, -0.0128],\n",
      "        [-0.0192,  0.0189, -0.0032,  ...,  0.0225, -0.0201, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0153,  0.0164,  0.0074,  ...,  0.0096, -0.0022,  0.0106],\n",
      "        [ 0.0873, -0.0180,  0.0049,  ...,  0.0108, -0.0175,  0.0191],\n",
      "        [ 0.0253,  0.0010, -0.0050,  ...,  0.0049,  0.0243,  0.0133]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0237, -0.1002,  0.0350,  ...,  0.0120, -0.0189,  0.0087],\n",
      "        [ 0.0213,  0.0133, -0.0101,  ..., -0.0128,  0.0440,  0.0557],\n",
      "        [ 0.0210,  0.0404, -0.0237,  ...,  0.0168,  0.0344,  0.0044],\n",
      "        ...,\n",
      "        [-0.0152, -0.0268, -0.0482,  ..., -0.0359,  0.0163, -0.0935],\n",
      "        [-0.0308, -0.0347,  0.0796,  ..., -0.0322, -0.0596,  0.0296],\n",
      "        [ 0.0023, -0.0499,  0.0046,  ...,  0.0466,  0.0379,  0.0104]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 27: train_loss: 0.9933 train_acc: 0.7432 | val_loss: 1.9569 val_acc: 0.3975\n",
      "00:00:08.46\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0431,  0.0071,  0.0113,  ..., -0.0008, -0.0087, -0.0976],\n",
      "        [ 0.0101,  0.0044,  0.0144,  ..., -0.0027,  0.0085, -0.0128],\n",
      "        [-0.0193,  0.0189, -0.0032,  ...,  0.0225, -0.0201, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0154,  0.0164,  0.0074,  ...,  0.0095, -0.0022,  0.0105],\n",
      "        [ 0.0872, -0.0180,  0.0049,  ...,  0.0107, -0.0175,  0.0191],\n",
      "        [ 0.0254,  0.0009, -0.0051,  ...,  0.0048,  0.0242,  0.0132]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0238, -0.1002,  0.0350,  ...,  0.0120, -0.0189,  0.0088],\n",
      "        [ 0.0213,  0.0133, -0.0101,  ..., -0.0128,  0.0439,  0.0557],\n",
      "        [ 0.0211,  0.0405, -0.0236,  ...,  0.0168,  0.0344,  0.0044],\n",
      "        ...,\n",
      "        [-0.0152, -0.0266, -0.0483,  ..., -0.0360,  0.0163, -0.0935],\n",
      "        [-0.0308, -0.0346,  0.0795,  ..., -0.0322, -0.0596,  0.0295],\n",
      "        [ 0.0022, -0.0498,  0.0045,  ...,  0.0465,  0.0379,  0.0105]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Epoch 28: train_loss: 0.9646 train_acc: 0.7341 | val_loss: 1.9416 val_acc: 0.3811\n",
      "00:00:09.01\n",
      "train_size: 110\n",
      "self.pooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0432,  0.0071,  0.0112,  ..., -0.0009, -0.0087, -0.0976],\n",
      "        [ 0.0100,  0.0043,  0.0144,  ..., -0.0027,  0.0084, -0.0128],\n",
      "        [-0.0194,  0.0190, -0.0031,  ...,  0.0225, -0.0201, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0153,  0.0165,  0.0075,  ...,  0.0096, -0.0022,  0.0105],\n",
      "        [ 0.0871, -0.0181,  0.0049,  ...,  0.0107, -0.0175,  0.0190],\n",
      "        [ 0.0255,  0.0008, -0.0052,  ...,  0.0048,  0.0242,  0.0132]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.innerpooler_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0415,  0.0087,  0.0124,  ...,  0.0006, -0.0079, -0.0992],\n",
      "        [ 0.0130,  0.0058,  0.0161,  ..., -0.0027,  0.0095, -0.0131],\n",
      "        [-0.0177,  0.0175, -0.0046,  ...,  0.0208, -0.0203, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0150,  0.0158,  0.0057,  ...,  0.0090, -0.0014,  0.0119],\n",
      "        [ 0.0873, -0.0189,  0.0052,  ...,  0.0098, -0.0168,  0.0202],\n",
      "        [ 0.0238,  0.0019, -0.0044,  ...,  0.0067,  0.0224,  0.0113]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "self.transformerlayer_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0237, -0.1001,  0.0349,  ...,  0.0120, -0.0188,  0.0087],\n",
      "        [ 0.0213,  0.0132, -0.0100,  ..., -0.0128,  0.0439,  0.0556],\n",
      "        [ 0.0211,  0.0405, -0.0237,  ...,  0.0169,  0.0344,  0.0044],\n",
      "        ...,\n",
      "        [-0.0151, -0.0266, -0.0483,  ..., -0.0359,  0.0162, -0.0936],\n",
      "        [-0.0309, -0.0346,  0.0795,  ..., -0.0322, -0.0595,  0.0295],\n",
      "        [ 0.0023, -0.0498,  0.0046,  ...,  0.0466,  0.0380,  0.0105]],\n",
      "       device='cuda:2', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    train(model, train_loader, val_loader, optimizer, scheduler, rev_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9892544216579862, 0.9935709635416666, 0.9956868489583334, 0.9967380099826388, 0.9968227810329862, 0.9970635308159722, 0.997589111328125, 0.9977043999565972, 0.9976874457465278, 0.9975789388020834, 0.9975958930121528, 0.9976467556423612, 0.99786376953125, 0.9980299207899306, 0.9980095757378472, 0.9979214138454862, 0.9980943467881944, 0.9980434841579862, 0.9982740614149306, 0.9980367024739584, 0.9981892903645834, 0.9979960123697916, 0.9980604383680556, 0.9981587727864584, 0.9981486002604166, 0.998046875, 0.9980638292100694, 0.9982672797309028]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_outerpooler['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: Cos: BertPooler')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0002504727252055469, 0.0001564964110376127, 0.00010089926749678454, 7.492726921307206e-05, 7.307966621747056e-05, 7.175531545572474e-05, 6.170098543850374e-05, 6.01042819430417e-05, 5.9019354611744915e-05, 5.827902249132652e-05, 5.936186466960642e-05, 5.551473053136278e-05, 5.422796444122312e-05, 4.743216300485309e-05, 5.02671340166492e-05, 5.1335151325441146e-05, 4.804413639387958e-05, 4.67591540256306e-05, 4.5078258814554374e-05, 4.8371463008272525e-05, 4.592062072479923e-05, 4.823324717150371e-05, 4.6173824950156844e-05, 4.538948060333904e-05, 4.581699341516652e-05, 4.504740226194947e-05, 4.541925751277322e-05, 4.437328075744174e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_outerpooler['l2']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: L2: BertPooler')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9942169189453125, 0.99713134765625, 0.9980061848958334, 0.9983579847547743, 0.9982418484157987, 0.9982672797309028, 0.9984520806206597, 0.9986284044053819, 0.9986436631944444, 0.9986809624565972, 0.9986775716145834, 0.9987377590603299, 0.9987835354275174, 0.9989089965820312, 0.9987674289279513, 0.9988081190321181, 0.998854743109809, 0.998854743109809, 0.9988844129774306, 0.9988691541883681, 0.9988937377929688, 0.9989132351345487, 0.9989005194769965, 0.9989242553710938, 0.9989971584743924, 0.9990064832899306, 0.9989513821072049, 0.9988649156358507]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_transformerlayer['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: Cos: Last Dense Layer')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00024292826769641037, 0.00012019963335818453, 8.279188868723253e-05, 6.835182179173137e-05, 7.115576896449319e-05, 7.375848689997102e-05, 6.379763031186015e-05, 5.746367525010129e-05, 5.609773580276029e-05, 5.702778180177634e-05, 5.873645531233256e-05, 5.3332004570830426e-05, 5.2710479815719066e-05, 4.657096108368546e-05, 5.1028235269950155e-05, 4.945857990769744e-05, 4.719176163916402e-05, 4.582974020255208e-05, 4.522830591187017e-05, 4.695262020166868e-05, 4.436274349165154e-05, 4.570365236119281e-05, 4.598829559141476e-05, 4.49352042885991e-05, 4.171211080986628e-05, 4.0904110516946736e-05, 4.538128297220425e-05, 4.55398951534375e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_transformerlayer['l2']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: L2: Last Dense Layer')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAADoCAYAAADIZG9fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAg1ElEQVR4nO3de3QU5f3H8c/mtrmQREIgIYGEaBXEBKjh0kAVIjUYBRUEsSoGixcQtDFSq+VXQWqJxcqhpwYsWkWqtqmK8VJKjHK1YAUqrYXWgqKhQgwEJSRIEPL9/eHJls2FBFjczPJ+nbPnMDPPzn73yUP2k5l5Zl1mZgIAAHCAIH8XAAAA0FYEFwAA4BgEFwAA4BgEFwAA4BgEFwAA4BgEFwAA4BgEFwAA4BgEFwAA4BgEFwAA4BgEF5xxFi9eLJfL1exj+vTpnnY9evTQxIkTT+o15syZo5KSkibrt27dqlmzZunjjz8+ueK/YcOGDdOwYcNOaR+fffaZ7rvvPmVkZKhDhw4KDw/Xueeeqx/+8Ifatm2bbwo9BRMnTlSHDh38XUabTJw40Wu8ut1u9ezZUzNnztShQ4dO2+ueyv8FwNdC/F0A4C9PP/20evXq5bUuKSnJJ/ueM2eOxo4dq6uvvtpr/datW/Xggw9q2LBh6tGjh09eqz179913NXLkSJmZpk2bpqysLIWFhemDDz7Qs88+q4EDB+rzzz/3d5mOEhERoRUrVkiSPv/8c/3+97/X7Nmz9e9//1vFxcV+rg44/QguOGOlp6erf//+/i4jYFVXV+uqq65SeHi41q1bp27dunm2DRs2TLfffrtefPFFP1boHAcPHlRkZKQkKSgoSN/5znc823Jzc/Xxxx/rj3/8o+bNm6fk5GR/ldkmZqZDhw4pIiLC36XAoThVBLTRoUOHdM8996hfv36KjY1VXFycsrKy9Morr3i1c7lcqq2t1TPPPOM5pD9s2DAtXrxY48aNkyRlZ2d7ti1evNjz3DfffFPDhw9XTEyMIiMjNWTIEL311lte+581a5ZcLpe2bNmi73//+4qNjVVCQoJ+8IMfaP/+/V5tzUwLFixQv379FBERoY4dO2rs2LH66KOPmrSbO3euUlNTFR4ergsvvFB//vOfT6m/nnjiCVVUVGju3LleoeVYY8eO9Vp+9dVXlZWVpcjISEVHR+vSSy/V+vXrvdrs2bNHt912m7p37y63263OnTtryJAhevPNN0+p3mP16NFDI0eO1PLly3XhhRcqIiJCvXr10lNPPeXVruG048qVKzVlyhTFx8erU6dOGjNmjHbt2tVkv8XFxcrKylJUVJQ6dOigESNG6L333vNq03Dq6v3331dOTo6io6M1fPjw49bbEGQ++eQTSVJ5ebluvPFGdenSRW63W+eff74effRR1dfXez1v3759uuOOO5ScnKywsDCdffbZmjFjhurq6lrto+rqak2fPl1paWkKCwtTcnKy8vPzVVtb69XO5XJp2rRpevzxx3X++efL7XbrmWeeaXX/QIsMOMM8/fTTJsneeecd++qrr7wex0pNTbW8vDzP8hdffGETJ0603/3ud7ZixQpbvny5TZ8+3YKCguyZZ57xtFu/fr1FRETY5ZdfbuvXr7f169fbli1brLKy0ubMmWOSrKioyLOtsrLSzMx+97vfmcvlsquvvtqWLl1qr732mo0cOdKCg4PtzTff9Ox/5syZJsl69uxpDzzwgJWVldm8efPM7XbbzTff7PUebr31VgsNDbV77rnHli9fbs8//7z16tXLEhISrKKiosk+J02aZH/+859t0aJFlpycbImJiTZ06FCvfQ4dOtTa8qsjJyfHgoODraamptW2ZmbPPfecSbKcnBwrKSmx4uJiy8zMtLCwMFu7dq2n3YgRI6xz5862aNEiW7VqlZWUlNgDDzxgf/jDHzxtVq5caZJs5syZrb5uXl6eRUVFea1LTU21bt26We/evW3JkiVWWlpq48aNM0m2evVqT7uGsXT22WfbnXfeaaWlpfbkk09ax44dLTs722ufP//5z83lctkPfvADe/31123p0qWWlZVlUVFRtmXLFq96QkNDrUePHlZYWGhvvfWWlZaWtlirmdno0aNNkv3nP/+xyspKS05Ots6dO9vjjz9uy5cvt2nTppkkmzJliuc5X375pfXp08eioqLsl7/8pb3xxhv205/+1EJCQuzyyy9v0h/H/l+ora21fv36WXx8vM2bN8/efPNN+9WvfmWxsbF2ySWXWH19vaetJEtOTrY+ffrY888/bytWrLB//vOfrf5cgJYQXHDGafiwae5xbHhp/Mu6sSNHjthXX31lkyZNsm9/+9te26Kiopp97gsvvGCSbOXKlV7ra2trLS4uzkaNGuW1/ujRo9a3b18bOHCgZ11DyJg7d65X2zvuuMPCw8M9Hxrr1683Sfboo496tdu5c6dFRETYvffea2Zmn3/+uYWHh9vo0aO92v3lL38xSU2CyyWXXGLBwcHNd8oxevXqZYmJia22a3ifSUlJlpGRYUePHvWsP3DggHXp0sUGDx7sWdehQwfLz88/7v5WrVplwcHB9uCDD7b62i0Fl/DwcPvkk08867788kuLi4uz22+/3bOuYSzdcccdXs+fO3euSbLdu3ebmVl5ebmFhITYnXfe6dXuwIEDlpiYaNdee61XPZLsqaeearHWhqC9Z88e+9WvfmUul8sGDBhgZmb33XefSbK//vWvXs+dMmWKuVwu++CDD8zM7PHHHzdJ9sc//tGr3S9+8QuTZG+88YZXfxw7ngsLCy0oKMg2bNjg9dwXX3zRJNmyZcs86yRZbGys7du3r8n7AU4Gp4pwxlqyZIk2bNjg9QgJOf5lXy+88IKGDBmiDh06KCQkRKGhofrtb3+rf/3rX6dUy7p167Rv3z7l5eXpyJEjnkd9fb0uu+wybdiwockh+CuvvNJruU+fPjp06JAqKyslSa+//rpcLpduvPFGr30mJiaqb9++WrVqlSRp/fr1OnTokG644Qav/Q0ePFipqalNan3rrbd05MiRU3q/jX3wwQfatWuXJkyYoKCg//1a6tChg6655hq98847OnjwoCRp4MCBWrx4sR566CG98847+uqrr5rsb+jQoTpy5IgeeOCBk66pX79+SklJ8SyHh4frvPPO85yOOVZzPwvpf6duSktLdeTIEd10001eP4vw8HANHTrU87M41jXXXNNsXbW1tQoNDVVoaKg6d+6s/Px85ebm6uWXX5YkrVixQr1799bAgQO9njdx4kSZmefC3hUrVigqKqrJ6bqG2UONT1Ee6/XXX1d6err69evn9X5GjBghl8vV5P1ccskl6tixY4v7A04EF+fijHX++eef0MW5S5cu1bXXXqtx48bpRz/6kRITExUSEqKFCxc2ufbhRH322WeSml7zcax9+/YpKirKs9ypUyev7W63W5L05ZdfevZpZkpISGh2f2effbYkqaqqSpKUmJjYpE1z69oqJSVF27ZtU21trVfdzWmooWvXrk22JSUlqb6+Xp9//rkiIyNVXFyshx56SE8++aR++tOfqkOHDho9erTmzp17SvU21rh/pa/7uKF/j9e2uZ+FJA0YMKDZ1zo2rElSZGSkYmJimm0bERGhNWvWeF4nNTXVq21VVVWzM9YaZsw19HVVVZUSExPlcrm82nXp0kUhISGeds357LPPtH37doWGhja7fe/evV7Lzf1cgZNFcAHa6Nlnn1VaWpqKi4u9ftm35ULG1sTHx0uSfv3rX3vNGDlWSwHkePt0uVxau3at54P0WA3rGj50KyoqmrSpqKg46WnbI0aM0BtvvKHXXntN11133XHbNtSwe/fuJtt27dqloKAgz1/s8fHxmj9/vubPn6/y8nK9+uqruu+++1RZWanly5efVK2nW8PP98UXX2z2KFZjjcPEsYKCgo4buDt16tRiPx5bS6dOnfTXv/5VZub1epWVlTpy5IinXXPi4+MVERHRYmBv/NzjvR/gRHGqCGgjl8ulsLAwr1/CFRUVTWYVSS3/Zd74L/EGQ4YM0VlnnaWtW7eqf//+zT7CwsJOqN6G+6d8+umnze4vIyND0tczUsLDw/Xcc895PX/dunXNnhZpq0mTJikxMVH33nuvPv3002bbLF26VJLUs2dPJScn6/nnn5eZebbX1tbqpZde8sw0aiwlJUXTpk3TpZdeqr/97W8nXevpNmLECIWEhOjDDz9s8efrK8OHD9fWrVub9MeSJUvkcrmUnZ3taVdTU9PkRolLlizxbG/JyJEj9eGHH6pTp07Nvpcz4R5F8B+OuABtNHLkSC1dulR33HGHxo4dq507d+pnP/uZunbt2uQOsBkZGVq1apVee+01de3aVdHR0erZs6fS09MlSYsWLVJ0dLTCw8OVlpamTp066de//rXy8vK0b98+jR07Vl26dNGePXv097//XXv27NHChQtPqN4hQ4botttu080336yNGzfq4osvVlRUlHbv3q23335bGRkZmjJlijp27Kjp06froYce0i233KJx48Zp586dmjVrVrOnXoYPH67Vq1e3ep1LbGysXnnlFY0cOVLf/va3vW5At23bNj377LP6+9//rjFjxigoKEhz587VDTfcoJEjR+r2229XXV2dHnnkEX3xxRd6+OGHJUn79+9Xdna2rr/+evXq1UvR0dHasGGDli9frjFjxnhee/Xq1Ro+fLgeeOCBU7rOxVd69Oih2bNna8aMGfroo4902WWXqWPHjvrss8/07rvvKioqSg8++KBPXuvuu+/WkiVLdMUVV2j27NlKTU3Vn/70Jy1YsEBTpkzReeedJ0m66aabVFRUpLy8PH388cfKyMjQ22+/rTlz5ujyyy/X9773vRZfIz8/Xy+99JIuvvhi3X333erTp4/q6+tVXl6uN954Q/fcc48GDRrkk/cDNOHXS4MBP2iYCdJ4RkRjzc0qevjhh61Hjx7mdrvt/PPPtyeeeMIzy+dYmzdvtiFDhlhkZGSTmTnz58+3tLQ0Cw4ONkn29NNPe7atXr3arrjiCouLi7PQ0FBLTk62K664wl544QVPm4bX27NnT7Pva8eOHV7rn3rqKRs0aJBFRUVZRESEnXPOOXbTTTfZxo0bPW3q6+utsLDQunfvbmFhYdanTx977bXXbOjQoSc9HbpBRUWF/fjHP7YLLrjAIiMjze1227e+9S27/fbb7f333/dqW1JSYoMGDbLw8HCLioqy4cOH21/+8hfP9kOHDtnkyZOtT58+FhMTYxEREdazZ0+bOXOm1dbWetr5Yjr0FVdc0aRt4/5oaSw1vH7j2WMlJSWWnZ1tMTEx5na7LTU11caOHes13b2lKc+tbTvWJ598Ytdff7116tTJQkNDrWfPnvbII494zdgyM6uqqrLJkydb165dLSQkxFJTU+3++++3Q4cONemPxv8Xampq7P/+7/+sZ8+eFhYWZrGxsZaRkWF3332311R7STZ16tRWawbaymV2zHFZAACAdoxrXAAAgGMQXAAAgGMQXAAAgGMQXAAAgGMQXAAAgGMQXAAAgGME3A3o6uvrtWvXLkVHR3ObaQAAHMLMdODAASUlJTX5/q5jBVxw2bVrl7p37+7vMgAAwEnYuXOnunXr1uL2gAsu0dHRkr5+4y19uyoAAGhfqqur1b17d8/neEvaZXAZPXq0Vq1apeHDh+vFF188oec2nB6KiYkhuAAA4DCtXebRLi/OveuuuzzfUAoAANCgXQaX7OzsVg8VAQCAM4/Pg8uaNWs0atQoJSUlyeVyqaSkpEmbBQsWKC0tTeHh4crMzNTatWt9XQYAAAhAPg8utbW16tu3rx577LFmtxcXFys/P18zZszQe++9p4suuki5ubkqLy/3dSkAACDA+Pzi3NzcXOXm5ra4fd68eZo0aZJuueUWSdL8+fNVWlqqhQsXqrCw8IRfr66uTnV1dZ7l6urqEy8aAAA4wjd6jcvhw4e1adMm5eTkeK3PycnRunXrTmqfhYWFio2N9Ty4hwsAAIHrGw0ue/fu1dGjR5WQkOC1PiEhQRUVFZ7lESNGaNy4cVq2bJm6deumDRs2tLjP+++/X/v37/c8du7cedrqBwAA/uWX+7g0nqNtZl7rSktL27wvt9stt9vts9oAAED79Y0ecYmPj1dwcLDX0RVJqqysbHIU5kQVFRWpd+/eGjBgwCntBwAAtF/faHAJCwtTZmamysrKvNaXlZVp8ODBp7TvqVOnauvWrcc9rQQAAJzN56eKampqtH37ds/yjh07tHnzZsXFxSklJUUFBQWaMGGC+vfvr6ysLC1atEjl5eWaPHmyr0sBAAABxufBZePGjcrOzvYsFxQUSJLy8vK0ePFijR8/XlVVVZo9e7Z2796t9PR0LVu2TKmpqb4uBQAABBiXmZm/i/CFoqIiFRUV6ejRo/rPf/6j/fv38yWLAAA4RHV1tWJjY1v9/A6Y4NKgrW8cAAC0H239/G6XX7IIAADQHIILAABwDIILAABwjIAJLtyADgCAwMfFuQAAwO+4OBcAAAQcggsAAHAMggsAAHCMgAkuXJwLAEDg4+JcAADgd1ycCwAAAg7BBQAAOAbBBQAAOAbBBQAAOEbABBdmFQEAEPiYVQQAAPyOWUUAACDgEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjBExwYTo0AACBj+nQAADA75gODQAAAg7BBQAAOAbBBQAAOAbBBQAAOAbBBQAAOAbBBQAAOAbBBQAAOAbBBQAAOEbABBfunAsAQODjzrkAAMDvuHMuAAAIOAQXAADgGAQXAADgGAQXAADgGAQXAADgGAQXAADgGAQXAADgGAQXAADgGAQXAADgGAQXAADgGAQXAADgGAETXPiSRQAAAh9fsggAAPyOL1kEAAABh+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAcg+ACAAAco10Gl9dff109e/bUueeeqyeffNLf5QAAgHYixN8FNHbkyBEVFBRo5cqViomJ0YUXXqgxY8YoLi7O36UBAAA/a3dHXN59911dcMEFSk5OVnR0tC6//HKVlpb6uywAANAO+Dy4rFmzRqNGjVJSUpJcLpdKSkqatFmwYIHS0tIUHh6uzMxMrV271rNt165dSk5O9ix369ZNn376qa/LBAAADuTzU0W1tbXq27evbr75Zl1zzTVNthcXFys/P18LFizQkCFD9Jvf/Ea5ubnaunWrUlJSZGZNnuNyuXxd5gkxkw4e9GsJAAC0G5GRkr8+mn0eXHJzc5Wbm9vi9nnz5mnSpEm65ZZbJEnz589XaWmpFi5cqMLCQiUnJ3sdYfnvf/+rQYMGtbi/uro61dXVeZarq6t98C68HTwodejg890CAOBINTVSVJR/Xvsbvcbl8OHD2rRpk3JycrzW5+TkaN26dZKkgQMH6p///Kc+/fRTHThwQMuWLdOIESNa3GdhYaFiY2M9j+7du5/W9wAAAPznG51VtHfvXh09elQJCQle6xMSElRRUfF1QSEhevTRR5Wdna36+nrde++96tSpU4v7vP/++1VQUOBZrq6u9nl4iYz8Ol0CAICvPxf9xS/ToRtfs2JmXuuuvPJKXXnllW3al9vtltvt9ml9jblc/jskBgAA/ucbPVUUHx+v4OBgz9GVBpWVlU2OwgAAADT2jQaXsLAwZWZmqqyszGt9WVmZBg8efEr7LioqUu/evTVgwIBT2g8AAGi/fH6qqKamRtu3b/cs79ixQ5s3b1ZcXJxSUlJUUFCgCRMmqH///srKytKiRYtUXl6uyZMnn9LrTp06VVOnTlV1dbViY2NP9W0AAIB2yOfBZePGjcrOzvYsN1w4m5eXp8WLF2v8+PGqqqrS7NmztXv3bqWnp2vZsmVKTU31dSkAACDAuKy5O745WMMRl/379ysmJsbf5QAAgDZo6+d3u/uuopPFNS4AAAQ+jrgAAAC/O+OOuAAAgMBHcAEAAI4RMMGFa1wAAAh8XOMCAAD8jmtcAABAwCG4AAAAxyC4AAAAxwiY4MLFuQAABD4uzgUAAH7HxbkAACDgEFwAAIBjEFwAAIBjEFwAAIBjBExwYVYRAACBj1lFAADA75hVBAAAAg7BBQAAOAbBBQAAOAbBBQAAOAbBBQAAOAbBBQAAOEbABBfu4wIAQODjPi4AAMDvuI8LAAAIOAQXAADgGAQXAADgGAQXAADgGAQXAADgGAQXAADgGAQXAADgGAETXLgBHQAAgY8b0AEAAL/jBnQAACDgEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjEFwAAIBjBExw4duhAQAIfHw7NAAA8Du+HRoAAAQcggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHAMggsAAHCMdhlcRo8erY4dO2rs2LH+LgUAALQj7TK43HXXXVqyZIm/ywAAAO1Muwwu2dnZio6O9ncZAACgnTnh4LJmzRqNGjVKSUlJcrlcKikpadJmwYIFSktLU3h4uDIzM7V27Vpf1AoAAM5wJxxcamtr1bdvXz322GPNbi8uLlZ+fr5mzJih9957TxdddJFyc3NVXl7uaZOZman09PQmj127dp38OwEAAAEv5ESfkJubq9zc3Ba3z5s3T5MmTdItt9wiSZo/f75KS0u1cOFCFRYWSpI2bdp0kuUCAIAzmU+vcTl8+LA2bdqknJwcr/U5OTlat26dL1/Ko66uTtXV1V4PAAAQmHwaXPbu3aujR48qISHBa31CQoIqKiravJ8RI0Zo3LhxWrZsmbp166YNGza02LawsFCxsbGeR/fu3U+6fgAA0L6d8KmitnC5XF7LZtZk3fGUlpa2ue3999+vgoICz3J1dTXhBQCAAOXT4BIfH6/g4OAmR1cqKyubHIXxFbfbLbfbfVr2DQAA2hefnioKCwtTZmamysrKvNaXlZVp8ODBvnypJoqKitS7d28NGDDgtL4OAADwnxM+4lJTU6Pt27d7lnfs2KHNmzcrLi5OKSkpKigo0IQJE9S/f39lZWVp0aJFKi8v1+TJk31aeGNTp07V1KlTVV1drdjY2NP6WgAAwD9OOLhs3LhR2dnZnuWG60vy8vK0ePFijR8/XlVVVZo9e7Z2796t9PR0LVu2TKmpqb6rGgAAnJFcZmb+LsKX9u/fr7POOks7d+5UTEyMv8sBAABt0DC55osvvjjumZPTMqvIH4qKilRUVKTDhw9LEjOLAABwoAMHDhw3uATcEZf6+nrt2rVL0dHRJzQFuzUNSZAjOb5Bf/oOfelb9Kfv0Je+Fej9aWY6cOCAkpKSFBTU8tyhgDni0iAoKEjdunU7bfuPiYkJyAHjL/Sn79CXvkV/+g596VuB3J9tmVzj0+nQAAAApxPBBQAAOAbBpY3cbrdmzpzJXXp9hP70HfrSt+hP36EvfYv+/FrAXZwLAAACF0dcAACAYxBcAACAYxBcAACAYxBcAACAYxBc2mjBggVKS0tTeHi4MjMztXbtWn+X5EizZs2Sy+XyeiQmJvq7LEdYs2aNRo0apaSkJLlcLpWUlHhtNzPNmjVLSUlJioiI0LBhw7Rlyxb/FOsArfXnxIkTm4zV73znO/4ptp0rLCzUgAEDFB0drS5duujqq6/WBx984NWG8dk2benLM31sElzaoLi4WPn5+ZoxY4bee+89XXTRRcrNzVV5ebm/S3OkCy64QLt37/Y83n//fX+X5Ai1tbXq27evHnvssWa3z507V/PmzdNjjz2mDRs2KDExUZdeeqkOHDjwDVfqDK31pyRddtllXmN12bJl32CFzrF69WpNnTpV77zzjsrKynTkyBHl5OSotrbW04bx2TZt6UvpDB+bhlYNHDjQJk+e7LWuV69edt999/mpIueaOXOm9e3b199lOJ4ke/nllz3L9fX1lpiYaA8//LBn3aFDhyw2NtYef/xxP1ToLI3708wsLy/PrrrqKr/U43SVlZUmyVavXm1mjM9T0bgvzRibHHFpxeHDh7Vp0ybl5OR4rc/JydG6dev8VJWzbdu2TUlJSUpLS9N1112njz76yN8lOd6OHTtUUVHhNU7dbreGDh3KOD0Fq1atUpcuXXTeeefp1ltvVWVlpb9LcoT9+/dLkuLi4iQxPk9F475scCaPTYJLK/bu3aujR48qISHBa31CQoIqKir8VJVzDRo0SEuWLFFpaameeOIJVVRUaPDgwaqqqvJ3aY7WMBYZp76Tm5ur5557TitWrNCjjz6qDRs26JJLLlFdXZ2/S2vXzEwFBQX67ne/q/T0dEmMz5PVXF9KjM2A+3bo08Xlcnktm1mTdWhdbm6u598ZGRnKysrSOeeco2eeeUYFBQV+rCwwME59Z/z48Z5/p6enq3///kpNTdWf/vQnjRkzxo+VtW/Tpk3TP/7xD7399ttNtjE+T0xLfXmmj02OuLQiPj5ewcHBTf4qqKysbPLXA05cVFSUMjIytG3bNn+X4mgNM7MYp6dP165dlZqaylg9jjvvvFOvvvqqVq5cqW7dunnWMz5PXEt92ZwzbWwSXFoRFhamzMxMlZWVea0vKyvT4MGD/VRV4Kirq9O//vUvde3a1d+lOFpaWpoSExO9xunhw4e1evVqxqmPVFVVaefOnYzVZpiZpk2bpqVLl2rFihVKS0vz2s74bLvW+rI5Z9rY5FRRGxQUFGjChAnq37+/srKytGjRIpWXl2vy5Mn+Ls1xpk+frlGjRiklJUWVlZV66KGHVF1drby8PH+X1u7V1NRo+/btnuUdO3Zo8+bNiouLU0pKivLz8zVnzhyde+65OvfcczVnzhxFRkbq+uuv92PV7dfx+jMuLk6zZs3SNddco65du+rjjz/WT37yE8XHx2v06NF+rLp9mjp1qp5//nm98sorio6O9hxZiY2NVUREhFwuF+OzjVrry5qaGsamH2c0OUpRUZGlpqZaWFiYXXjhhV5T09B248ePt65du1poaKglJSXZmDFjbMuWLf4uyxFWrlxpkpo88vLyzOzrKaczZ860xMREc7vddvHFF9v777/v36LbseP158GDBy0nJ8c6d+5soaGhlpKSYnl5eVZeXu7vstul5vpRkj399NOeNozPtmmtLxmbZi4zs28yKAEAAJwsrnEBAACOQXABAACOQXABAACOQXABAACOQXABAACOQXABAACOQXABAACOQXABAACOQXABAACOQXABAACOQXABAACOQXABAACO8f9ElOQksDEnZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_innerpooler['cos']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: Cos: InnerPooler')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20403/337760207.py:10: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model.history_innerpooler['l2']\n",
    "y = [x[0] for x in y]\n",
    "print(y)\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "line, = ax.plot(y, color='blue')\n",
    "ax.set_yscale('log')\n",
    "plt.title('Flattened: L2: InnerPooler')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.2146 test_acc: 0.3808\n",
      "00:00:00.91\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       1.00      0.39      0.56        18\n",
      "    background       0.30      0.41      0.35        17\n",
      "         cause       0.20      1.00      0.33         2\n",
      "  circumstance       0.31      0.27      0.29        15\n",
      "    concession       0.41      0.54      0.47        13\n",
      "     condition       0.58      0.78      0.67         9\n",
      "   conjunction       0.44      0.57      0.50         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.89      0.73      0.80        11\n",
      "   elaboration       0.15      0.30      0.20        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.29      0.20      0.24        10\n",
      "interpretation       0.04      0.08      0.05        12\n",
      "         joint       0.32      0.48      0.38        29\n",
      "          list       0.62      0.58      0.60        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.60      0.75      0.67         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.43      0.38      0.41        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.38       260\n",
      "     macro avg       0.32      0.34      0.30       260\n",
      "  weighted avg       0.39      0.38      0.37       260\n",
      "\n",
      "Test Loss: 2.215 |  Test Acc: 38.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#latest\n",
    "def validate(model, test_loader, optimizer, rev_label_dict, label_dict):\n",
    "  start = time.time()\n",
    "  test_acc, test_loss, cr, model, optimizer = evaluate_accuracy(model, optimizer, test_loader, rev_label_dict, label_dict, is_training=False)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'Test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  print(cr)\n",
    "\n",
    "  return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_latest', test_acc, 1)\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.1226 test_acc: 0.3808\n",
      "00:00:01.39\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.67      0.22      0.33        18\n",
      "    background       0.28      0.53      0.37        17\n",
      "         cause       0.33      1.00      0.50         2\n",
      "  circumstance       0.50      0.40      0.44        15\n",
      "    concession       0.44      0.54      0.48        13\n",
      "     condition       0.53      1.00      0.69         9\n",
      "   conjunction       0.36      0.57      0.44         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.80      0.73      0.76        11\n",
      "   elaboration       0.07      0.10      0.08        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.00      0.00      0.00        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.30      0.48      0.37        29\n",
      "          list       0.50      0.69      0.58        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.44      1.00      0.62         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.38      0.32      0.35        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.38       260\n",
      "     macro avg       0.28      0.34      0.28       260\n",
      "  weighted avg       0.33      0.38      0.34       260\n",
      "\n",
      "Latest Test Loss: 2.123 |  Latest Test Acc: 38.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best earliest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_earliest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_earliest', test_acc, 1)\n",
    "print(f'Latest Test Loss: {test_loss:.3f} |  Latest Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 2.1226 test_acc: 0.3808\n",
      "00:00:00.82\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.67      0.22      0.33        18\n",
      "    background       0.28      0.53      0.37        17\n",
      "         cause       0.33      1.00      0.50         2\n",
      "  circumstance       0.50      0.40      0.44        15\n",
      "    concession       0.44      0.54      0.48        13\n",
      "     condition       0.53      1.00      0.69         9\n",
      "   conjunction       0.36      0.57      0.44         7\n",
      "      contrast       0.00      0.00      0.00         8\n",
      " e-elaboration       0.80      0.73      0.76        11\n",
      "   elaboration       0.07      0.10      0.08        10\n",
      "  evaluation-n       0.00      0.00      0.00         3\n",
      "  evaluation-s       0.00      0.00      0.00        17\n",
      "      evidence       0.00      0.00      0.00        10\n",
      "interpretation       0.00      0.00      0.00        12\n",
      "         joint       0.30      0.48      0.37        29\n",
      "          list       0.50      0.69      0.58        26\n",
      "         means       0.00      0.00      0.00         2\n",
      "   preparation       0.44      1.00      0.62         4\n",
      "       purpose       1.00      0.67      0.80         3\n",
      "        reason       0.38      0.32      0.35        34\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "      sequence       0.00      0.00      0.00         7\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         1\n",
      "\n",
      "      accuracy                           0.38       260\n",
      "     macro avg       0.28      0.34      0.28       260\n",
      "  weighted avg       0.33      0.38      0.34       260\n",
      "\n",
      "Best Test Loss: 2.123 |  Best Test Acc: 38.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best lastest\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, test_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('test_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('test_acc_best_latest', test_acc, 1)\n",
    "print(f'Best Test Loss: {test_loss:.3f} |  Best Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:763: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 1.9496 test_acc: 0.4098\n",
      "00:00:00.97\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    antithesis       0.33      0.09      0.14        11\n",
      "    background       0.31      0.82      0.45        17\n",
      "         cause       0.20      0.14      0.17         7\n",
      "  circumstance       0.57      0.31      0.40        13\n",
      "    concession       0.57      0.73      0.64        11\n",
      "     condition       0.64      0.88      0.74         8\n",
      "   conjunction       0.70      0.88      0.78         8\n",
      "      contrast       0.00      0.00      0.00         3\n",
      " e-elaboration       0.78      0.54      0.64        13\n",
      "   elaboration       0.20      0.11      0.14        28\n",
      "  evaluation-n       0.00      0.00      0.00         8\n",
      "  evaluation-s       0.00      0.00      0.00         5\n",
      "      evidence       0.50      0.12      0.20         8\n",
      "interpretation       0.33      0.15      0.21        13\n",
      "         joint       0.29      0.56      0.38        18\n",
      "          list       0.31      0.61      0.42        18\n",
      "         means       0.00      0.00      0.00         1\n",
      "   preparation       0.67      0.73      0.70        11\n",
      "       purpose       1.00      0.40      0.57         5\n",
      "        reason       0.47      0.50      0.48        28\n",
      "   restatement       0.00      0.00      0.00         1\n",
      "        result       0.00      0.00      0.00         3\n",
      "  solutionhood       0.00      0.00      0.00         1\n",
      "       summary       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.41       241\n",
      "     macro avg       0.33      0.32      0.29       241\n",
      "  weighted avg       0.39      0.41      0.37       241\n",
      "\n",
      "Val Loss: 1.950 |  Val Acc: 40.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/VD/kaveri/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#best val acc\n",
    "model.load_state_dict(torch.load(save_path_suffix+'_best_latest.pt'))\n",
    "test_loss, test_acc = validate(model, val_loader, optimizer, rev_label_dict, label_dict)\n",
    "writer.add_scalar('val_loss_best_latest', test_loss, 1)\n",
    "writer.add_scalar('val_acc_best_latest', test_acc, 1)\n",
    "print(f'Val Loss: {test_loss:.3f} |  Val Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3409ea685db85227fbd9509d1b1ace14d085473eb2d57f3ba9dd0302d25f838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
